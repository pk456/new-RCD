nohup: ignoring input
/home/liujiaqi/miniconda3/envs/dpl/lib/python3.9/site-packages/dgl/heterograph.py:92: DGLWarning: Recommend creating graphs by `dgl.graph(data)` instead of `dgl.DGLGraph(data)`.
  dgl_warning(
Net(
  (knowledge_emb): Embedding(835, 64)
  (exercise_emb): Embedding(835, 64)
  (student_emb): Embedding(10000, 64)
  (FusionLayer1): Fusion(
    (directed_gat): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (undirected_gat): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (e_to_k): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (k_to_e): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (e_to_u): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (u_to_e): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (k_attn_fc1): Linear(in_features=128, out_features=1, bias=True)
    (k_attn_fc2): Linear(in_features=128, out_features=1, bias=True)
    (k_attn_fc3): Linear(in_features=128, out_features=1, bias=True)
    (e_attn_fc1): Linear(in_features=128, out_features=1, bias=True)
    (e_attn_fc2): Linear(in_features=128, out_features=1, bias=True)
  )
  (FusionLayer2): Fusion(
    (directed_gat): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (undirected_gat): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (e_to_k): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (k_to_e): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (e_to_u): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (u_to_e): GraphLayer(
      (fc): Linear(in_features=64, out_features=64, bias=False)
      (attn_fc): Linear(in_features=128, out_features=1, bias=False)
    )
    (k_attn_fc1): Linear(in_features=128, out_features=1, bias=True)
    (k_attn_fc2): Linear(in_features=128, out_features=1, bias=True)
    (k_attn_fc3): Linear(in_features=128, out_features=1, bias=True)
    (e_attn_fc1): Linear(in_features=128, out_features=1, bias=True)
    (e_attn_fc2): Linear(in_features=128, out_features=1, bias=True)
  )
  (prednet_full1): Linear(in_features=128, out_features=64, bias=False)
  (prednet_full2): Linear(in_features=128, out_features=64, bias=False)
  (prednet_full3): Linear(in_features=64, out_features=1, bias=True)
)
training model...
train--1/100 [9/1090] loss: 0.6182842791080475
train--1/100 [19/1090] loss: 0.6843031764030456
train--1/100 [29/1090] loss: 0.6823046207427979
train--1/100 [39/1090] loss: 0.6795076668262482
train--1/100 [49/1090] loss: 0.6755275249481201
train--1/100 [59/1090] loss: 0.6705345511436462
train--1/100 [69/1090] loss: 0.6679786443710327
train--1/100 [79/1090] loss: 0.6656227827072143
train--1/100 [89/1090] loss: 0.6603412747383117
train--1/100 [99/1090] loss: 0.6551439702510834
train--1/100 [109/1090] loss: 0.6466968715190887
train--1/100 [119/1090] loss: 0.6404577732086182
train--1/100 [129/1090] loss: 0.6243589341640472
train--1/100 [139/1090] loss: 0.6226822555065155
train--1/100 [149/1090] loss: 0.6126918017864227
train--1/100 [159/1090] loss: 0.6036902904510498
train--1/100 [169/1090] loss: 0.5928782522678375
train--1/100 [179/1090] loss: 0.5825886905193329
train--1/100 [189/1090] loss: 0.5810734689235687
train--1/100 [199/1090] loss: 0.5737398266792297
train--1/100 [209/1090] loss: 0.5773676872253418
train--1/100 [219/1090] loss: 0.5607195496559143
train--1/100 [229/1090] loss: 0.5520705223083496
train--1/100 [239/1090] loss: 0.5506227970123291
train--1/100 [249/1090] loss: 0.5566746711730957
train--1/100 [259/1090] loss: 0.5498561263084412
train--1/100 [269/1090] loss: 0.5313410699367523
train--1/100 [279/1090] loss: 0.5599930346012115
train--1/100 [289/1090] loss: 0.5445794582366943
train--1/100 [299/1090] loss: 0.5388352066278458
train--1/100 [309/1090] loss: 0.5542752802371979
train--1/100 [319/1090] loss: 0.5344265878200531
train--1/100 [329/1090] loss: 0.5326706111431122
train--1/100 [339/1090] loss: 0.5283567070960998
train--1/100 [349/1090] loss: 0.5234939187765122
train--1/100 [359/1090] loss: 0.5252318024635315
train--1/100 [369/1090] loss: 0.5441270619630814
train--1/100 [379/1090] loss: 0.5283516138792038
train--1/100 [389/1090] loss: 0.5297301292419434
train--1/100 [399/1090] loss: 0.5184550404548645
train--1/100 [409/1090] loss: 0.5148914158344269
train--1/100 [419/1090] loss: 0.5033519834280014
train--1/100 [429/1090] loss: 0.5257453918457031
train--1/100 [439/1090] loss: 0.5132462590932846
train--1/100 [449/1090] loss: 0.516520556807518
train--1/100 [459/1090] loss: 0.5283178895711899
train--1/100 [469/1090] loss: 0.5269367903470993
train--1/100 [479/1090] loss: 0.5256775230169296
train--1/100 [489/1090] loss: 0.5105001091957092
train--1/100 [499/1090] loss: 0.5229438275098801
train--1/100 [509/1090] loss: 0.5071625411510468
train--1/100 [519/1090] loss: 0.5368504524230957
train--1/100 [529/1090] loss: 0.5133450448513031
train--1/100 [539/1090] loss: 0.5178559362888336
train--1/100 [549/1090] loss: 0.5135631620883941
train--1/100 [559/1090] loss: 0.5240207821130752
train--1/100 [569/1090] loss: 0.5120210886001587
train--1/100 [579/1090] loss: 0.5306640714406967
train--1/100 [589/1090] loss: 0.5117412000894547
train--1/100 [599/1090] loss: 0.505696314573288
train--1/100 [609/1090] loss: 0.4997016489505768
train--1/100 [619/1090] loss: 0.5336210697889328
train--1/100 [629/1090] loss: 0.5055993646383286
train--1/100 [639/1090] loss: 0.5035589963197709
train--1/100 [649/1090] loss: 0.5088625311851501
train--1/100 [659/1090] loss: 0.5016034096479416
train--1/100 [669/1090] loss: 0.5076273262500763
train--1/100 [679/1090] loss: 0.4964312642812729
train--1/100 [689/1090] loss: 0.5251304775476455
train--1/100 [699/1090] loss: 0.4994558185338974
train--1/100 [709/1090] loss: 0.5213210761547089
train--1/100 [719/1090] loss: 0.4886320888996124
train--1/100 [729/1090] loss: 0.5063346654176712
train--1/100 [739/1090] loss: 0.5096564531326294
train--1/100 [749/1090] loss: 0.5081919133663177
train--1/100 [759/1090] loss: 0.49506349861621857
train--1/100 [769/1090] loss: 0.4969067215919495
train--1/100 [779/1090] loss: 0.5225463300943375
train--1/100 [789/1090] loss: 0.5124102652072906
train--1/100 [799/1090] loss: 0.49671543538570406
train--1/100 [809/1090] loss: 0.5013843804597855
train--1/100 [819/1090] loss: 0.49074695706367494
train--1/100 [829/1090] loss: 0.5098723918199539
train--1/100 [839/1090] loss: 0.5081736952066421
train--1/100 [849/1090] loss: 0.4999814689159393
train--1/100 [859/1090] loss: 0.5062809973955155
train--1/100 [869/1090] loss: 0.4919627159833908
train--1/100 [879/1090] loss: 0.5057523965835571
train--1/100 [889/1090] loss: 0.5005223035812378
train--1/100 [899/1090] loss: 0.484930956363678
train--1/100 [909/1090] loss: 0.5079908043146133
train--1/100 [919/1090] loss: 0.5095158696174622
train--1/100 [929/1090] loss: 0.5054324984550476
train--1/100 [939/1090] loss: 0.500181844830513
train--1/100 [949/1090] loss: 0.4981440335512161
train--1/100 [959/1090] loss: 0.5007858842611312
train--1/100 [969/1090] loss: 0.5025912344455719
train--1/100 [979/1090] loss: 0.515402439236641
train--1/100 [989/1090] loss: 0.5019371420145035
train--1/100 [999/1090] loss: 0.5149338006973266
train--1/100 [1009/1090] loss: 0.5084508955478668
train--1/100 [1019/1090] loss: 0.48415084183216095
train--1/100 [1029/1090] loss: 0.4993502289056778
train--1/100 [1039/1090] loss: 0.513992092013359
train--1/100 [1049/1090] loss: 0.512109312415123
train--1/100 [1059/1090] loss: 0.5173997700214386
train--1/100 [1069/1090] loss: 0.47843853533267977
train--1/100 [1079/1090] loss: 0.4926262736320496
train--1/100 [1089/1090] loss: 0.5049105167388916
predicting model...
val--1/100 [10/1090] acc: 0.765234375
val--1/100 [20/1090] acc: 0.762109375
val--1/100 [30/1090] acc: 0.7615885416666667
val--1/100 [40/1090] acc: 0.76318359375
val--1/100 [50/1090] acc: 0.7609375
val--1/100 [60/1090] acc: 0.7596354166666667
val--1/100 [70/1090] acc: 0.7591517857142858
val--1/100 [80/1090] acc: 0.759326171875
val--1/100 [90/1090] acc: 0.7607638888888889
val--1/100 [100/1090] acc: 0.76125
val--1/100 [110/1090] acc: 0.7609375
val--1/100 [120/1090] acc: 0.75986328125
val--1/100 [130/1090] acc: 0.7612079326923077
val--1/100 [140/1090] acc: 0.7616908482142857
val--1/100 [150/1090] acc: 0.762109375
val--1/100 [160/1090] acc: 0.7624267578125
val--1/100 [170/1090] acc: 0.7620634191176471
val--1/100 [180/1090] acc: 0.7618489583333333
val--1/100 [190/1090] acc: 0.7624588815789474
val--1/100 [200/1090] acc: 0.7624609375
val--1/100 [210/1090] acc: 0.7629464285714286
val--1/100 [220/1090] acc: 0.7622691761363637
val--1/100 [230/1090] acc: 0.7625339673913043
val--1/100 [240/1090] acc: 0.762255859375
val--1/100 [250/1090] acc: 0.762203125
val--1/100 [260/1090] acc: 0.7624098557692308
val--1/100 [270/1090] acc: 0.7628472222222222
val--1/100 [280/1090] acc: 0.7630022321428571
val--1/100 [290/1090] acc: 0.7629714439655172
val--1/100 [300/1090] acc: 0.7629817708333333
val--1/100 [310/1090] acc: 0.7628528225806451
val--1/100 [320/1090] acc: 0.76307373046875
val--1/100 [330/1090] acc: 0.7628787878787879
val--1/100 [340/1090] acc: 0.7629365808823529
val--1/100 [350/1090] acc: 0.7629910714285715
val--1/100 [360/1090] acc: 0.7628580729166666
val--1/100 [370/1090] acc: 0.7629117398648648
val--1/100 [380/1090] acc: 0.7629214638157895
val--1/100 [390/1090] acc: 0.7626602564102564
val--1/100 [400/1090] acc: 0.762734375
val--1/100 [410/1090] acc: 0.762938262195122
val--1/100 [420/1090] acc: 0.7630859375
val--1/100 [430/1090] acc: 0.7630178052325581
val--1/100 [440/1090] acc: 0.7630149147727273
val--1/100 [450/1090] acc: 0.762890625
val--1/100 [460/1090] acc: 0.7629840353260869
val--1/100 [470/1090] acc: 0.7628823138297872
val--1/100 [480/1090] acc: 0.7630452473958333
val--1/100 [490/1090] acc: 0.7631935586734694
val--1/100 [500/1090] acc: 0.763453125
val--1/100 [510/1090] acc: 0.763235294117647
val--1/100 [520/1090] acc: 0.7633413461538462
val--1/100 [530/1090] acc: 0.76328125
val--1/100 [540/1090] acc: 0.7634331597222223
val--1/100 [550/1090] acc: 0.7632883522727273
val--1/100 [560/1090] acc: 0.7633579799107143
val--1/100 [570/1090] acc: 0.763233278508772
val--1/100 [580/1090] acc: 0.763153286637931
val--1/100 [590/1090] acc: 0.763082627118644
val--1/100 [600/1090] acc: 0.7627734375
val--1/100 [610/1090] acc: 0.7627945696721311
val--1/100 [620/1090] acc: 0.7627709173387097
val--1/100 [630/1090] acc: 0.7629278273809523
val--1/100 [640/1090] acc: 0.7632080078125
val--1/100 [650/1090] acc: 0.7632331730769231
val--1/100 [660/1090] acc: 0.7631687973484849
val--1/100 [670/1090] acc: 0.7628556436567164
val--1/100 [680/1090] acc: 0.7628044577205882
val--1/100 [690/1090] acc: 0.7628962862318841
val--1/100 [700/1090] acc: 0.7628515625
val--1/100 [710/1090] acc: 0.7628521126760563
val--1/100 [720/1090] acc: 0.7627549913194445
val--1/100 [730/1090] acc: 0.7626926369863014
val--1/100 [740/1090] acc: 0.7627164273648649
val--1/100 [750/1090] acc: 0.7628385416666666
val--1/100 [760/1090] acc: 0.7628238075657895
val--1/100 [770/1090] acc: 0.7627739448051948
val--1/100 [780/1090] acc: 0.7627804487179487
val--1/100 [790/1090] acc: 0.7628362341772152
val--1/100 [800/1090] acc: 0.76306640625
val--1/100 [810/1090] acc: 0.7630449459876543
val--1/100 [820/1090] acc: 0.7631621570121951
val--1/100 [830/1090] acc: 0.763257718373494
val--1/100 [840/1090] acc: 0.7631463913690476
val--1/100 [850/1090] acc: 0.7632398897058823
val--1/100 [860/1090] acc: 0.7633948037790698
val--1/100 [870/1090] acc: 0.7634473778735632
val--1/100 [880/1090] acc: 0.7634410511363636
val--1/100 [890/1090] acc: 0.7636982092696629
val--1/100 [900/1090] acc: 0.76375
val--1/100 [910/1090] acc: 0.7638650412087912
val--1/100 [920/1090] acc: 0.7637610394021739
val--1/100 [930/1090] acc: 0.7638482862903225
val--1/100 [940/1090] acc: 0.763954454787234
val--1/100 [950/1090] acc: 0.7639514802631578
val--1/100 [960/1090] acc: 0.7638590494791667
val--1/100 [970/1090] acc: 0.7638812822164949
val--1/100 [980/1090] acc: 0.7638791454081633
val--1/100 [990/1090] acc: 0.7637784090909091
val--1/100 [1000/1090] acc: 0.7636640625
val--1/100 [1010/1090] acc: 0.763490099009901
val--1/100 [1020/1090] acc: 0.7635723039215686
val--1/100 [1030/1090] acc: 0.7636832524271845
val--1/100 [1040/1090] acc: 0.7636981670673076
val--1/100 [1050/1090] acc: 0.7637239583333333
val--1/100 [1060/1090] acc: 0.7635760613207547
val--1/100 [1070/1090] acc: 0.7635915595794392
val--1/100 [1080/1090] acc: 0.7634982638888889
val--1/100 [1090/1090] acc: 0.7635285263761468
epoch= 1, accuracy= 0.763529, rmse= 0.402952, auc= 0.815648
train--2/100 [9/1090] loss: 0.4571641445159912
train--2/100 [19/1090] loss: 0.4953888028860092
train--2/100 [29/1090] loss: 0.49778467416763306
train--2/100 [39/1090] loss: 0.49683363139629366
train--2/100 [49/1090] loss: 0.5019541084766388
train--2/100 [59/1090] loss: 0.4854115754365921
train--2/100 [69/1090] loss: 0.4822491019964218
train--2/100 [79/1090] loss: 0.4840298980474472
train--2/100 [89/1090] loss: 0.4873953253030777
train--2/100 [99/1090] loss: 0.502859604358673
train--2/100 [109/1090] loss: 0.49191695749759673
train--2/100 [119/1090] loss: 0.506021249294281
train--2/100 [129/1090] loss: 0.5006782859563828
train--2/100 [139/1090] loss: 0.4898744076490402
train--2/100 [149/1090] loss: 0.5058366268873214
train--2/100 [159/1090] loss: 0.47904094457626345
train--2/100 [169/1090] loss: 0.4943890988826752
train--2/100 [179/1090] loss: 0.49668406546115873
train--2/100 [189/1090] loss: 0.48053630292415617
train--2/100 [199/1090] loss: 0.4926278442144394
train--2/100 [209/1090] loss: 0.47529656291007993
train--2/100 [219/1090] loss: 0.5024830400943756
train--2/100 [229/1090] loss: 0.47588835954666137
train--2/100 [239/1090] loss: 0.4920855015516281
train--2/100 [249/1090] loss: 0.48450841307640075
train--2/100 [259/1090] loss: 0.48164077997207644
train--2/100 [269/1090] loss: 0.48340953290462496
train--2/100 [279/1090] loss: 0.49446341693401336
train--2/100 [289/1090] loss: 0.4736384689807892
train--2/100 [299/1090] loss: 0.490701961517334
train--2/100 [309/1090] loss: 0.49132253527641295
train--2/100 [319/1090] loss: 0.47627955973148345
train--2/100 [329/1090] loss: 0.4883459508419037
train--2/100 [339/1090] loss: 0.46690196096897124
train--2/100 [349/1090] loss: 0.4821824938058853
train--2/100 [359/1090] loss: 0.4671515226364136
train--2/100 [369/1090] loss: 0.48248411118984225
train--2/100 [379/1090] loss: 0.49151437282562255
train--2/100 [389/1090] loss: 0.46809556782245637
train--2/100 [399/1090] loss: 0.502473670244217
train--2/100 [409/1090] loss: 0.4754859030246735
train--2/100 [419/1090] loss: 0.4784813016653061
train--2/100 [429/1090] loss: 0.4922299563884735
train--2/100 [439/1090] loss: 0.48478493094444275
train--2/100 [449/1090] loss: 0.4870685636997223
train--2/100 [459/1090] loss: 0.4791694849729538
train--2/100 [469/1090] loss: 0.47929181456565856
train--2/100 [479/1090] loss: 0.49048389196395875
train--2/100 [489/1090] loss: 0.47391427755355836
train--2/100 [499/1090] loss: 0.47903152704238894
train--2/100 [509/1090] loss: 0.49336826205253603
train--2/100 [519/1090] loss: 0.46963181495666506
train--2/100 [529/1090] loss: 0.48359174430370333
train--2/100 [539/1090] loss: 0.47500178813934324
train--2/100 [549/1090] loss: 0.4842436581850052
train--2/100 [559/1090] loss: 0.47662060260772704
train--2/100 [569/1090] loss: 0.47331300377845764
train--2/100 [579/1090] loss: 0.48084369897842405
train--2/100 [589/1090] loss: 0.47749275267124175
train--2/100 [599/1090] loss: 0.48317026495933535
train--2/100 [609/1090] loss: 0.4858755826950073
train--2/100 [619/1090] loss: 0.46769853234291076
train--2/100 [629/1090] loss: 0.49407838881015775
train--2/100 [639/1090] loss: 0.48432691395282745
train--2/100 [649/1090] loss: 0.4817009150981903
train--2/100 [659/1090] loss: 0.4819201916456223
train--2/100 [669/1090] loss: 0.46725334525108336
train--2/100 [679/1090] loss: 0.46582681834697726
train--2/100 [689/1090] loss: 0.4819591879844666
train--2/100 [699/1090] loss: 0.4884459346532822
train--2/100 [709/1090] loss: 0.47351734042167665
train--2/100 [719/1090] loss: 0.48445762097835543
train--2/100 [729/1090] loss: 0.47882001399993895
train--2/100 [739/1090] loss: 0.4802312195301056
train--2/100 [749/1090] loss: 0.4817045718431473
train--2/100 [759/1090] loss: 0.4882752984762192
train--2/100 [769/1090] loss: 0.46402324736118317
train--2/100 [779/1090] loss: 0.49687897562980654
train--2/100 [789/1090] loss: 0.4698176860809326
train--2/100 [799/1090] loss: 0.45273889899253844
train--2/100 [809/1090] loss: 0.4897691965103149
train--2/100 [819/1090] loss: 0.46207325756549833
train--2/100 [829/1090] loss: 0.4861604243516922
train--2/100 [839/1090] loss: 0.4876994967460632
train--2/100 [849/1090] loss: 0.4847610354423523
train--2/100 [859/1090] loss: 0.483378267288208
train--2/100 [869/1090] loss: 0.47252404391765596
train--2/100 [879/1090] loss: 0.47439266443252565
train--2/100 [889/1090] loss: 0.48224744498729705
train--2/100 [899/1090] loss: 0.4871052116155624
train--2/100 [909/1090] loss: 0.45639007687568667
train--2/100 [919/1090] loss: 0.4876375198364258
train--2/100 [929/1090] loss: 0.46855467557907104
train--2/100 [939/1090] loss: 0.4746542364358902
train--2/100 [949/1090] loss: 0.4666204899549484
train--2/100 [959/1090] loss: 0.45759216845035555
train--2/100 [969/1090] loss: 0.4596460223197937
train--2/100 [979/1090] loss: 0.47694397866725924
train--2/100 [989/1090] loss: 0.4692863017320633
train--2/100 [999/1090] loss: 0.4621470898389816
train--2/100 [1009/1090] loss: 0.4684757173061371
train--2/100 [1019/1090] loss: 0.470258492231369
train--2/100 [1029/1090] loss: 0.4724310725927353
train--2/100 [1039/1090] loss: 0.48130702078342436
train--2/100 [1049/1090] loss: 0.47267009019851686
train--2/100 [1059/1090] loss: 0.4778082281351089
train--2/100 [1069/1090] loss: 0.48256940245628355
train--2/100 [1079/1090] loss: 0.4704515039920807
train--2/100 [1089/1090] loss: 0.47802452445030214
predicting model...
val--2/100 [10/1090] acc: 0.7796875
val--2/100 [20/1090] acc: 0.7798828125
val--2/100 [30/1090] acc: 0.7802083333333333
val--2/100 [40/1090] acc: 0.78046875
val--2/100 [50/1090] acc: 0.77875
val--2/100 [60/1090] acc: 0.7780598958333333
val--2/100 [70/1090] acc: 0.7781808035714286
val--2/100 [80/1090] acc: 0.77783203125
val--2/100 [90/1090] acc: 0.7794270833333333
val--2/100 [100/1090] acc: 0.78078125
val--2/100 [110/1090] acc: 0.7802556818181818
val--2/100 [120/1090] acc: 0.77958984375
val--2/100 [130/1090] acc: 0.7810997596153846
val--2/100 [140/1090] acc: 0.7812220982142857
val--2/100 [150/1090] acc: 0.78171875
val--2/100 [160/1090] acc: 0.7816650390625
val--2/100 [170/1090] acc: 0.7813878676470588
val--2/100 [180/1090] acc: 0.7810112847222223
val--2/100 [190/1090] acc: 0.7817434210526316
val--2/100 [200/1090] acc: 0.7819921875
val--2/100 [210/1090] acc: 0.7823474702380953
val--2/100 [220/1090] acc: 0.781640625
val--2/100 [230/1090] acc: 0.7822180706521739
val--2/100 [240/1090] acc: 0.781787109375
val--2/100 [250/1090] acc: 0.78175
val--2/100 [260/1090] acc: 0.7818810096153846
val--2/100 [270/1090] acc: 0.7821325231481482
val--2/100 [280/1090] acc: 0.7824358258928571
val--2/100 [290/1090] acc: 0.7824353448275863
val--2/100 [300/1090] acc: 0.7825130208333333
val--2/100 [310/1090] acc: 0.7820564516129033
val--2/100 [320/1090] acc: 0.782275390625
val--2/100 [330/1090] acc: 0.7821496212121212
val--2/100 [340/1090] acc: 0.7822954963235295
val--2/100 [350/1090] acc: 0.7824888392857143
val--2/100 [360/1090] acc: 0.7824435763888888
val--2/100 [370/1090] acc: 0.7825274493243243
val--2/100 [380/1090] acc: 0.7823293585526315
val--2/100 [390/1090] acc: 0.7821514423076923
val--2/100 [400/1090] acc: 0.78216796875
val--2/100 [410/1090] acc: 0.7823266006097561
val--2/100 [420/1090] acc: 0.7823381696428572
val--2/100 [430/1090] acc: 0.7822856104651162
val--2/100 [440/1090] acc: 0.7822709517045454
val--2/100 [450/1090] acc: 0.7822482638888889
val--2/100 [460/1090] acc: 0.7822180706521739
val--2/100 [470/1090] acc: 0.7820063164893617
val--2/100 [480/1090] acc: 0.7822428385416667
val--2/100 [490/1090] acc: 0.7823262117346939
val--2/100 [500/1090] acc: 0.7826171875
val--2/100 [510/1090] acc: 0.7825061274509804
val--2/100 [520/1090] acc: 0.7827073317307692
val--2/100 [530/1090] acc: 0.782701945754717
val--2/100 [540/1090] acc: 0.7827690972222222
val--2/100 [550/1090] acc: 0.7826633522727273
val--2/100 [560/1090] acc: 0.7826729910714286
val--2/100 [570/1090] acc: 0.7825246710526316
val--2/100 [580/1090] acc: 0.7826441271551724
val--2/100 [590/1090] acc: 0.7826072563559322
val--2/100 [600/1090] acc: 0.7823567708333333
val--2/100 [610/1090] acc: 0.7822169569672132
val--2/100 [620/1090] acc: 0.7822013608870968
val--2/100 [630/1090] acc: 0.782483878968254
val--2/100 [640/1090] acc: 0.7828369140625
val--2/100 [650/1090] acc: 0.7827944711538461
val--2/100 [660/1090] acc: 0.782711884469697
val--2/100 [670/1090] acc: 0.7823868936567164
val--2/100 [680/1090] acc: 0.7822954963235295
val--2/100 [690/1090] acc: 0.7825011322463769
val--2/100 [700/1090] acc: 0.7825446428571429
val--2/100 [710/1090] acc: 0.7824823943661972
val--2/100 [720/1090] acc: 0.7823350694444444
val--2/100 [730/1090] acc: 0.782277397260274
val--2/100 [740/1090] acc: 0.7821737753378378
val--2/100 [750/1090] acc: 0.7822239583333334
val--2/100 [760/1090] acc: 0.7822419819078947
val--2/100 [770/1090] acc: 0.782224025974026
val--2/100 [780/1090] acc: 0.7822866586538462
val--2/100 [790/1090] acc: 0.7823328718354431
val--2/100 [800/1090] acc: 0.7825830078125
val--2/100 [810/1090] acc: 0.7826292438271605
val--2/100 [820/1090] acc: 0.7827362804878049
val--2/100 [830/1090] acc: 0.7828219126506024
val--2/100 [840/1090] acc: 0.7826729910714286
val--2/100 [850/1090] acc: 0.7826746323529412
val--2/100 [860/1090] acc: 0.782835210755814
val--2/100 [870/1090] acc: 0.7827990301724138
val--2/100 [880/1090] acc: 0.7827769886363637
val--2/100 [890/1090] acc: 0.7830012289325843
val--2/100 [900/1090] acc: 0.7829991319444445
val--2/100 [910/1090] acc: 0.7830400068681319
val--2/100 [920/1090] acc: 0.7829568614130434
val--2/100 [930/1090] acc: 0.7830813172043011
val--2/100 [940/1090] acc: 0.7831117021276596
val--2/100 [950/1090] acc: 0.7830263157894737
val--2/100 [960/1090] acc: 0.78289794921875
val--2/100 [970/1090] acc: 0.782848743556701
val--2/100 [980/1090] acc: 0.7829320790816326
val--2/100 [990/1090] acc: 0.7828559027777777
val--2/100 [1000/1090] acc: 0.782734375
val--2/100 [1010/1090] acc: 0.7825881806930693
val--2/100 [1020/1090] acc: 0.7827205882352941
val--2/100 [1030/1090] acc: 0.7828011225728155
val--2/100 [1040/1090] acc: 0.7828237680288461
val--2/100 [1050/1090] acc: 0.7828162202380953
val--2/100 [1060/1090] acc: 0.7826908903301887
val--2/100 [1070/1090] acc: 0.7826956775700935
val--2/100 [1080/1090] acc: 0.7826280381944445
val--2/100 [1090/1090] acc: 0.7825508887614679
epoch= 2, accuracy= 0.782551, rmse= 0.388371, auc= 0.840296
train--3/100 [9/1090] loss: 0.41615402400493623
train--3/100 [19/1090] loss: 0.4576639741659164
train--3/100 [29/1090] loss: 0.453241628408432
train--3/100 [39/1090] loss: 0.4672106772661209
train--3/100 [49/1090] loss: 0.4475648641586304
train--3/100 [59/1090] loss: 0.48172172009944914
train--3/100 [69/1090] loss: 0.47305492758750917
train--3/100 [79/1090] loss: 0.4816888391971588
train--3/100 [89/1090] loss: 0.4681143254041672
train--3/100 [99/1090] loss: 0.46630625426769257
train--3/100 [109/1090] loss: 0.463901948928833
train--3/100 [119/1090] loss: 0.46130264103412627
train--3/100 [129/1090] loss: 0.4803646206855774
train--3/100 [139/1090] loss: 0.44457984566688535
train--3/100 [149/1090] loss: 0.4645959347486496
train--3/100 [159/1090] loss: 0.46647003293037415
train--3/100 [169/1090] loss: 0.47550717294216155
train--3/100 [179/1090] loss: 0.46771685481071473
train--3/100 [189/1090] loss: 0.47575352489948275
train--3/100 [199/1090] loss: 0.46321589350700376
train--3/100 [209/1090] loss: 0.45400002896785735
train--3/100 [219/1090] loss: 0.4541979908943176
train--3/100 [229/1090] loss: 0.4681566447019577
train--3/100 [239/1090] loss: 0.4680208146572113
train--3/100 [249/1090] loss: 0.478764083981514
train--3/100 [259/1090] loss: 0.447124770283699
train--3/100 [269/1090] loss: 0.4634444683790207
train--3/100 [279/1090] loss: 0.4611886143684387
train--3/100 [289/1090] loss: 0.4312182664871216
train--3/100 [299/1090] loss: 0.45487449765205384
train--3/100 [309/1090] loss: 0.4536579430103302
train--3/100 [319/1090] loss: 0.45923362374305726
train--3/100 [329/1090] loss: 0.4664030522108078
train--3/100 [339/1090] loss: 0.47713435292243955
train--3/100 [349/1090] loss: 0.44125416278839114
train--3/100 [359/1090] loss: 0.4573483645915985
train--3/100 [369/1090] loss: 0.4763408213853836
train--3/100 [379/1090] loss: 0.4569602608680725
train--3/100 [389/1090] loss: 0.4584111601114273
train--3/100 [399/1090] loss: 0.46503244042396547
train--3/100 [409/1090] loss: 0.45475265085697175
train--3/100 [419/1090] loss: 0.4621055841445923
train--3/100 [429/1090] loss: 0.456966233253479
train--3/100 [439/1090] loss: 0.4494728684425354
train--3/100 [449/1090] loss: 0.46855915784835817
train--3/100 [459/1090] loss: 0.46710601150989534
train--3/100 [469/1090] loss: 0.4613739401102066
train--3/100 [479/1090] loss: 0.4516811430454254
train--3/100 [489/1090] loss: 0.4599557399749756
train--3/100 [499/1090] loss: 0.4408353239297867
train--3/100 [509/1090] loss: 0.4584011763334274
train--3/100 [519/1090] loss: 0.46268590688705447
train--3/100 [529/1090] loss: 0.48413918614387513
train--3/100 [539/1090] loss: 0.45045133531093595
train--3/100 [549/1090] loss: 0.45581763982772827
train--3/100 [559/1090] loss: 0.4675864100456238
train--3/100 [569/1090] loss: 0.46556533575057985
train--3/100 [579/1090] loss: 0.45907842218875883
train--3/100 [589/1090] loss: 0.4454325944185257
train--3/100 [599/1090] loss: 0.44740156531333924
train--3/100 [609/1090] loss: 0.4517514258623123
train--3/100 [619/1090] loss: 0.47134358882904054
train--3/100 [629/1090] loss: 0.4700189918279648
train--3/100 [639/1090] loss: 0.4805793255567551
train--3/100 [649/1090] loss: 0.4677414059638977
train--3/100 [659/1090] loss: 0.46975008547306063
train--3/100 [669/1090] loss: 0.4610001027584076
train--3/100 [679/1090] loss: 0.4540803462266922
train--3/100 [689/1090] loss: 0.4806423455476761
train--3/100 [699/1090] loss: 0.45408503115177157
train--3/100 [709/1090] loss: 0.46943257451057435
train--3/100 [719/1090] loss: 0.46638848781585696
train--3/100 [729/1090] loss: 0.44702705442905427
train--3/100 [739/1090] loss: 0.46082755029201505
train--3/100 [749/1090] loss: 0.46518643796443937
train--3/100 [759/1090] loss: 0.46939782202243807
train--3/100 [769/1090] loss: 0.44950962662696836
train--3/100 [779/1090] loss: 0.4558579295873642
train--3/100 [789/1090] loss: 0.45741039514541626
train--3/100 [799/1090] loss: 0.45683261156082156
train--3/100 [809/1090] loss: 0.4832442104816437
train--3/100 [819/1090] loss: 0.44376502335071566
train--3/100 [829/1090] loss: 0.45276834070682526
train--3/100 [839/1090] loss: 0.47346738576889036
train--3/100 [849/1090] loss: 0.4545013964176178
train--3/100 [859/1090] loss: 0.46063651144504547
train--3/100 [869/1090] loss: 0.46274347603321075
train--3/100 [879/1090] loss: 0.4573091953992844
train--3/100 [889/1090] loss: 0.44405036270618437
train--3/100 [899/1090] loss: 0.46613497734069825
train--3/100 [909/1090] loss: 0.44897930026054383
train--3/100 [919/1090] loss: 0.46202618479728697
train--3/100 [929/1090] loss: 0.460158371925354
train--3/100 [939/1090] loss: 0.44161441922187805
train--3/100 [949/1090] loss: 0.46642095148563384
train--3/100 [959/1090] loss: 0.458185601234436
train--3/100 [969/1090] loss: 0.4730828195810318
train--3/100 [979/1090] loss: 0.4787869542837143
train--3/100 [989/1090] loss: 0.4636730760335922
train--3/100 [999/1090] loss: 0.44545055329799654
train--3/100 [1009/1090] loss: 0.44751518666744233
train--3/100 [1019/1090] loss: 0.4763169318437576
train--3/100 [1029/1090] loss: 0.45073490142822265
train--3/100 [1039/1090] loss: 0.46066508293151853
train--3/100 [1049/1090] loss: 0.4786970019340515
train--3/100 [1059/1090] loss: 0.4568613827228546
train--3/100 [1069/1090] loss: 0.46625547111034393
train--3/100 [1079/1090] loss: 0.46310751140117645
train--3/100 [1089/1090] loss: 0.47975383400917054
predicting model...
val--3/100 [10/1090] acc: 0.789453125
val--3/100 [20/1090] acc: 0.7900390625
val--3/100 [30/1090] acc: 0.7869791666666667
val--3/100 [40/1090] acc: 0.7865234375
val--3/100 [50/1090] acc: 0.78515625
val--3/100 [60/1090] acc: 0.7844401041666667
val--3/100 [70/1090] acc: 0.7850446428571428
val--3/100 [80/1090] acc: 0.78408203125
val--3/100 [90/1090] acc: 0.7849826388888889
val--3/100 [100/1090] acc: 0.78625
val--3/100 [110/1090] acc: 0.7866122159090909
val--3/100 [120/1090] acc: 0.7864583333333334
val--3/100 [130/1090] acc: 0.7875600961538461
val--3/100 [140/1090] acc: 0.7877790178571429
val--3/100 [150/1090] acc: 0.7880989583333333
val--3/100 [160/1090] acc: 0.78828125
val--3/100 [170/1090] acc: 0.7881893382352941
val--3/100 [180/1090] acc: 0.78828125
val--3/100 [190/1090] acc: 0.7890830592105263
val--3/100 [200/1090] acc: 0.78919921875
val--3/100 [210/1090] acc: 0.7894159226190476
val--3/100 [220/1090] acc: 0.7885653409090909
val--3/100 [230/1090] acc: 0.7890625
val--3/100 [240/1090] acc: 0.7888020833333333
val--3/100 [250/1090] acc: 0.788953125
val--3/100 [260/1090] acc: 0.7890024038461538
val--3/100 [270/1090] acc: 0.7894241898148148
val--3/100 [280/1090] acc: 0.7896623883928572
val--3/100 [290/1090] acc: 0.7896551724137931
val--3/100 [300/1090] acc: 0.7896223958333334
val--3/100 [310/1090] acc: 0.7893775201612904
val--3/100 [320/1090] acc: 0.78966064453125
val--3/100 [330/1090] acc: 0.7896661931818182
val--3/100 [340/1090] acc: 0.7898667279411765
val--3/100 [350/1090] acc: 0.7900892857142857
val--3/100 [360/1090] acc: 0.7899739583333333
val--3/100 [370/1090] acc: 0.7900232263513514
val--3/100 [380/1090] acc: 0.7898745888157894
val--3/100 [390/1090] acc: 0.7895532852564102
val--3/100 [400/1090] acc: 0.789462890625
val--3/100 [410/1090] acc: 0.7895960365853658
val--3/100 [420/1090] acc: 0.7896856398809524
val--3/100 [430/1090] acc: 0.7896257267441861
val--3/100 [440/1090] acc: 0.7896484375
val--3/100 [450/1090] acc: 0.7895920138888889
val--3/100 [460/1090] acc: 0.789546535326087
val--3/100 [470/1090] acc: 0.7892619680851064
val--3/100 [480/1090] acc: 0.7894205729166667
val--3/100 [490/1090] acc: 0.7895408163265306
val--3/100 [500/1090] acc: 0.7897578125
val--3/100 [510/1090] acc: 0.7896829044117647
val--3/100 [520/1090] acc: 0.7899038461538461
val--3/100 [530/1090] acc: 0.7899469339622641
val--3/100 [540/1090] acc: 0.7900028935185185
val--3/100 [550/1090] acc: 0.7898579545454546
val--3/100 [560/1090] acc: 0.7898158482142857
val--3/100 [570/1090] acc: 0.7896587171052631
val--3/100 [580/1090] acc: 0.7896888469827587
val--3/100 [590/1090] acc: 0.7896385063559322
val--3/100 [600/1090] acc: 0.78951171875
val--3/100 [610/1090] acc: 0.7894082991803278
val--3/100 [620/1090] acc: 0.7893838205645162
val--3/100 [630/1090] acc: 0.7896329365079365
val--3/100 [640/1090] acc: 0.789886474609375
val--3/100 [650/1090] acc: 0.7899459134615384
val--3/100 [660/1090] acc: 0.7899206912878788
val--3/100 [670/1090] acc: 0.7895580690298507
val--3/100 [680/1090] acc: 0.7894473805147059
val--3/100 [690/1090] acc: 0.7895776721014492
val--3/100 [700/1090] acc: 0.7896316964285715
val--3/100 [710/1090] acc: 0.7895356514084507
val--3/100 [720/1090] acc: 0.789404296875
val--3/100 [730/1090] acc: 0.7892658390410959
val--3/100 [740/1090] acc: 0.7891786317567567
val--3/100 [750/1090] acc: 0.7893072916666667
val--3/100 [760/1090] acc: 0.7893503289473685
val--3/100 [770/1090] acc: 0.7893922483766234
val--3/100 [780/1090] acc: 0.7893529647435897
val--3/100 [790/1090] acc: 0.7893740110759494
val--3/100 [800/1090] acc: 0.7895703125
val--3/100 [810/1090] acc: 0.7896267361111111
val--3/100 [820/1090] acc: 0.7896960746951219
val--3/100 [830/1090] acc: 0.7897919804216867
val--3/100 [840/1090] acc: 0.7897228422619048
val--3/100 [850/1090] acc: 0.7897748161764706
val--3/100 [860/1090] acc: 0.7899709302325582
val--3/100 [870/1090] acc: 0.7898751795977011
val--3/100 [880/1090] acc: 0.7898481889204545
val--3/100 [890/1090] acc: 0.7900193117977528
val--3/100 [900/1090] acc: 0.7899782986111111
val--3/100 [910/1090] acc: 0.7899811126373626
val--3/100 [920/1090] acc: 0.7899796195652173
val--3/100 [930/1090] acc: 0.7901167674731183
val--3/100 [940/1090] acc: 0.7901969747340426
val--3/100 [950/1090] acc: 0.7900863486842106
val--3/100 [960/1090] acc: 0.78997802734375
val--3/100 [970/1090] acc: 0.7899887242268041
val--3/100 [980/1090] acc: 0.7900271045918368
val--3/100 [990/1090] acc: 0.7899226641414141
val--3/100 [1000/1090] acc: 0.78978515625
val--3/100 [1010/1090] acc: 0.7896310334158416
val--3/100 [1020/1090] acc: 0.7897556678921569
val--3/100 [1030/1090] acc: 0.7898399575242718
val--3/100 [1040/1090] acc: 0.7898174579326923
val--3/100 [1050/1090] acc: 0.789873511904762
val--3/100 [1060/1090] acc: 0.789817954009434
val--3/100 [1070/1090] acc: 0.7897962908878504
val--3/100 [1080/1090] acc: 0.7897171585648148
val--3/100 [1090/1090] acc: 0.7895928899082569
epoch= 3, accuracy= 0.789593, rmse= 0.382005, auc= 0.849907
train--4/100 [9/1090] loss: 0.39605790078639985
train--4/100 [19/1090] loss: 0.43315406143665314
train--4/100 [29/1090] loss: 0.45139487087726593
train--4/100 [39/1090] loss: 0.44849965572357176
train--4/100 [49/1090] loss: 0.45118547677993776
train--4/100 [59/1090] loss: 0.4484668344259262
train--4/100 [69/1090] loss: 0.45857930183410645
train--4/100 [79/1090] loss: 0.44956710040569303
train--4/100 [89/1090] loss: 0.45177105963230135
train--4/100 [99/1090] loss: 0.46581880152225497
train--4/100 [109/1090] loss: 0.4561142325401306
train--4/100 [119/1090] loss: 0.46650512516498566
train--4/100 [129/1090] loss: 0.45718362629413606
train--4/100 [139/1090] loss: 0.46080788373947146
train--4/100 [149/1090] loss: 0.44598257541656494
train--4/100 [159/1090] loss: 0.45364693403244016
train--4/100 [169/1090] loss: 0.463056692481041
train--4/100 [179/1090] loss: 0.45777955651283264
train--4/100 [189/1090] loss: 0.46843644678592683
train--4/100 [199/1090] loss: 0.4519736111164093
train--4/100 [209/1090] loss: 0.45036610066890714
train--4/100 [219/1090] loss: 0.4322052001953125
train--4/100 [229/1090] loss: 0.4566991746425629
train--4/100 [239/1090] loss: 0.4650268733501434
train--4/100 [249/1090] loss: 0.43192502558231355
train--4/100 [259/1090] loss: 0.4649781048297882
train--4/100 [269/1090] loss: 0.45486012399196624
train--4/100 [279/1090] loss: 0.44376869797706603
train--4/100 [289/1090] loss: 0.4659713089466095
train--4/100 [299/1090] loss: 0.4526293486356735
train--4/100 [309/1090] loss: 0.4519760966300964
train--4/100 [319/1090] loss: 0.46150068044662473
train--4/100 [329/1090] loss: 0.43873720765113833
train--4/100 [339/1090] loss: 0.44945513308048246
train--4/100 [349/1090] loss: 0.45685731470584867
train--4/100 [359/1090] loss: 0.44446620941162107
train--4/100 [369/1090] loss: 0.46651815474033353
train--4/100 [379/1090] loss: 0.44912825226783754
train--4/100 [389/1090] loss: 0.44854128658771514
train--4/100 [399/1090] loss: 0.4647143930196762
train--4/100 [409/1090] loss: 0.4516926944255829
train--4/100 [419/1090] loss: 0.4593721032142639
train--4/100 [429/1090] loss: 0.4401572227478027
train--4/100 [439/1090] loss: 0.4342188537120819
train--4/100 [449/1090] loss: 0.4394402414560318
train--4/100 [459/1090] loss: 0.4602195292711258
train--4/100 [469/1090] loss: 0.4477625638246536
train--4/100 [479/1090] loss: 0.4672181189060211
train--4/100 [489/1090] loss: 0.45871494710445404
train--4/100 [499/1090] loss: 0.4542624861001968
train--4/100 [509/1090] loss: 0.461722531914711
train--4/100 [519/1090] loss: 0.4431333839893341
train--4/100 [529/1090] loss: 0.43893419206142426
train--4/100 [539/1090] loss: 0.47318107485771177
train--4/100 [549/1090] loss: 0.45965331196784975
train--4/100 [559/1090] loss: 0.442119237780571
train--4/100 [569/1090] loss: 0.43847286999225615
train--4/100 [579/1090] loss: 0.4406334549188614
train--4/100 [589/1090] loss: 0.46849122643470764
train--4/100 [599/1090] loss: 0.4719217598438263
train--4/100 [609/1090] loss: 0.45463176667690275
train--4/100 [619/1090] loss: 0.4427999138832092
train--4/100 [629/1090] loss: 0.45731054842472074
train--4/100 [639/1090] loss: 0.47015188038349154
train--4/100 [649/1090] loss: 0.44917598068714143
train--4/100 [659/1090] loss: 0.44767999947071074
train--4/100 [669/1090] loss: 0.45857492089271545
train--4/100 [679/1090] loss: 0.4691762089729309
train--4/100 [689/1090] loss: 0.45513506829738615
train--4/100 [699/1090] loss: 0.4620952785015106
train--4/100 [709/1090] loss: 0.473417666554451
train--4/100 [719/1090] loss: 0.4453279793262482
train--4/100 [729/1090] loss: 0.44254847168922423
train--4/100 [739/1090] loss: 0.4457551509141922
train--4/100 [749/1090] loss: 0.46857281029224396
train--4/100 [759/1090] loss: 0.4235397219657898
train--4/100 [769/1090] loss: 0.4451429218053818
train--4/100 [779/1090] loss: 0.46048418879508973
train--4/100 [789/1090] loss: 0.4725698560476303
train--4/100 [799/1090] loss: 0.46307537257671355
train--4/100 [809/1090] loss: 0.4587537169456482
train--4/100 [819/1090] loss: 0.44291476011276243
train--4/100 [829/1090] loss: 0.4577822983264923
train--4/100 [839/1090] loss: 0.4415630638599396
train--4/100 [849/1090] loss: 0.45074560344219206
train--4/100 [859/1090] loss: 0.47147504687309266
train--4/100 [869/1090] loss: 0.4582032710313797
train--4/100 [879/1090] loss: 0.47788129448890687
train--4/100 [889/1090] loss: 0.4521662265062332
train--4/100 [899/1090] loss: 0.4739135533571243
train--4/100 [909/1090] loss: 0.45425655245780944
train--4/100 [919/1090] loss: 0.44831213653087615
train--4/100 [929/1090] loss: 0.4522269606590271
train--4/100 [939/1090] loss: 0.4617652714252472
train--4/100 [949/1090] loss: 0.4714632272720337
train--4/100 [959/1090] loss: 0.4600794553756714
train--4/100 [969/1090] loss: 0.4657956600189209
train--4/100 [979/1090] loss: 0.4621712565422058
train--4/100 [989/1090] loss: 0.4398315906524658
train--4/100 [999/1090] loss: 0.4500341683626175
train--4/100 [1009/1090] loss: 0.45630142986774447
train--4/100 [1019/1090] loss: 0.46216434240341187
train--4/100 [1029/1090] loss: 0.45472936034202577
train--4/100 [1039/1090] loss: 0.4574629247188568
train--4/100 [1049/1090] loss: 0.45854324102401733
train--4/100 [1059/1090] loss: 0.45533626675605776
train--4/100 [1069/1090] loss: 0.462630906701088
train--4/100 [1079/1090] loss: 0.4641770511865616
train--4/100 [1089/1090] loss: 0.4498978048563004
predicting model...
val--4/100 [10/1090] acc: 0.7890625
val--4/100 [20/1090] acc: 0.790234375
val--4/100 [30/1090] acc: 0.7891927083333333
val--4/100 [40/1090] acc: 0.78935546875
val--4/100 [50/1090] acc: 0.788515625
val--4/100 [60/1090] acc: 0.7881510416666667
val--4/100 [70/1090] acc: 0.7892857142857143
val--4/100 [80/1090] acc: 0.787841796875
val--4/100 [90/1090] acc: 0.7888020833333333
val--4/100 [100/1090] acc: 0.789921875
val--4/100 [110/1090] acc: 0.7899502840909091
val--4/100 [120/1090] acc: 0.7896158854166667
val--4/100 [130/1090] acc: 0.7908353365384615
val--4/100 [140/1090] acc: 0.7908203125
val--4/100 [150/1090] acc: 0.7909375
val--4/100 [160/1090] acc: 0.791064453125
val--4/100 [170/1090] acc: 0.7911305147058824
val--4/100 [180/1090] acc: 0.7909288194444445
val--4/100 [190/1090] acc: 0.7917557565789474
val--4/100 [200/1090] acc: 0.792109375
val--4/100 [210/1090] acc: 0.7923549107142858
val--4/100 [220/1090] acc: 0.7916015625
val--4/100 [230/1090] acc: 0.7922214673913044
val--4/100 [240/1090] acc: 0.7920247395833333
val--4/100 [250/1090] acc: 0.7920625
val--4/100 [260/1090] acc: 0.7922175480769231
val--4/100 [270/1090] acc: 0.7924913194444444
val--4/100 [280/1090] acc: 0.7925502232142857
val--4/100 [290/1090] acc: 0.7924703663793103
val--4/100 [300/1090] acc: 0.7924348958333334
val--4/100 [310/1090] acc: 0.7921622983870967
val--4/100 [320/1090] acc: 0.7923828125
val--4/100 [330/1090] acc: 0.7925307765151515
val--4/100 [340/1090] acc: 0.7926815257352942
val--4/100 [350/1090] acc: 0.7928236607142857
val--4/100 [360/1090] acc: 0.7926323784722222
val--4/100 [370/1090] acc: 0.7926625844594595
val--4/100 [380/1090] acc: 0.7925986842105263
val--4/100 [390/1090] acc: 0.7921875
val--4/100 [400/1090] acc: 0.792099609375
val--4/100 [410/1090] acc: 0.7922256097560976
val--4/100 [420/1090] acc: 0.7922712053571429
val--4/100 [430/1090] acc: 0.7921329941860465
val--4/100 [440/1090] acc: 0.7921253551136364
val--4/100 [450/1090] acc: 0.7919878472222223
val--4/100 [460/1090] acc: 0.7918733016304348
val--4/100 [470/1090] acc: 0.7917802526595744
val--4/100 [480/1090] acc: 0.7918538411458333
val--4/100 [490/1090] acc: 0.7919164540816327
val--4/100 [500/1090] acc: 0.792125
val--4/100 [510/1090] acc: 0.7919653799019608
val--4/100 [520/1090] acc: 0.7921799879807693
val--4/100 [530/1090] acc: 0.7921727594339623
val--4/100 [540/1090] acc: 0.7922815393518519
val--4/100 [550/1090] acc: 0.7920738636363637
val--4/100 [560/1090] acc: 0.7919294084821429
val--4/100 [570/1090] acc: 0.7917420504385965
val--4/100 [580/1090] acc: 0.7917025862068966
val--4/100 [590/1090] acc: 0.7917571504237289
val--4/100 [600/1090] acc: 0.7916927083333334
val--4/100 [610/1090] acc: 0.7916239754098361
val--4/100 [620/1090] acc: 0.7915448588709677
val--4/100 [630/1090] acc: 0.7916790674603175
val--4/100 [640/1090] acc: 0.791943359375
val--4/100 [650/1090] acc: 0.7919771634615385
val--4/100 [660/1090] acc: 0.7919330018939394
val--4/100 [670/1090] acc: 0.7915869869402985
val--4/100 [680/1090] acc: 0.7914407169117647
val--4/100 [690/1090] acc: 0.7915647644927536
val--4/100 [700/1090] acc: 0.7915736607142857
val--4/100 [710/1090] acc: 0.7913842429577465
val--4/100 [720/1090] acc: 0.7912868923611112
val--4/100 [730/1090] acc: 0.7911708047945205
val--4/100 [740/1090] acc: 0.7911000844594595
val--4/100 [750/1090] acc: 0.7911770833333334
val--4/100 [760/1090] acc: 0.791246916118421
val--4/100 [770/1090] acc: 0.791208400974026
val--4/100 [780/1090] acc: 0.7911658653846154
val--4/100 [790/1090] acc: 0.791198575949367
val--4/100 [800/1090] acc: 0.79138671875
val--4/100 [810/1090] acc: 0.7914592978395062
val--4/100 [820/1090] acc: 0.7915396341463414
val--4/100 [830/1090] acc: 0.7916274472891566
val--4/100 [840/1090] acc: 0.791592261904762
val--4/100 [850/1090] acc: 0.791672794117647
val--4/100 [860/1090] acc: 0.791905886627907
val--4/100 [870/1090] acc: 0.7918238146551724
val--4/100 [880/1090] acc: 0.7918146306818182
val--4/100 [890/1090] acc: 0.7920031601123596
val--4/100 [900/1090] acc: 0.7919227430555555
val--4/100 [910/1090] acc: 0.7919342376373626
val--4/100 [920/1090] acc: 0.7919921875
val--4/100 [930/1090] acc: 0.7920950940860215
val--4/100 [940/1090] acc: 0.7920960771276596
val--4/100 [950/1090] acc: 0.7919901315789474
val--4/100 [960/1090] acc: 0.7918782552083333
val--4/100 [970/1090] acc: 0.7918290914948454
val--4/100 [980/1090] acc: 0.7918686224489796
val--4/100 [990/1090] acc: 0.7917732007575757
val--4/100 [1000/1090] acc: 0.79169921875
val--4/100 [1010/1090] acc: 0.7915454826732673
val--4/100 [1020/1090] acc: 0.7916053921568628
val--4/100 [1030/1090] acc: 0.7916831007281553
val--4/100 [1040/1090] acc: 0.7916466346153846
val--4/100 [1050/1090] acc: 0.7916517857142857
val--4/100 [1060/1090] acc: 0.7915978773584905
val--4/100 [1070/1090] acc: 0.7915413259345795
val--4/100 [1080/1090] acc: 0.7914677372685185
val--4/100 [1090/1090] acc: 0.7913274082568807
epoch= 4, accuracy= 0.791327, rmse= 0.380445, auc= 0.852210
train--5/100 [9/1090] loss: 0.4104174941778183
train--5/100 [19/1090] loss: 0.4417937070131302
train--5/100 [29/1090] loss: 0.431349378824234
train--5/100 [39/1090] loss: 0.4410602986812592
train--5/100 [49/1090] loss: 0.43869020640850065
train--5/100 [59/1090] loss: 0.4360391139984131
train--5/100 [69/1090] loss: 0.4454738050699234
train--5/100 [79/1090] loss: 0.45234653651714324
train--5/100 [89/1090] loss: 0.43729090988636016
train--5/100 [99/1090] loss: 0.42694864273071287
train--5/100 [109/1090] loss: 0.44531036615371705
train--5/100 [119/1090] loss: 0.44935583770275117
train--5/100 [129/1090] loss: 0.4425831586122513
train--5/100 [139/1090] loss: 0.4407258480787277
train--5/100 [149/1090] loss: 0.4532769024372101
train--5/100 [159/1090] loss: 0.4556768089532852
train--5/100 [169/1090] loss: 0.44983568489551545
train--5/100 [179/1090] loss: 0.46325342655181884
train--5/100 [189/1090] loss: 0.4448283135890961
train--5/100 [199/1090] loss: 0.44247121214866636
train--5/100 [209/1090] loss: 0.44762089252471926
train--5/100 [219/1090] loss: 0.44590806066989896
train--5/100 [229/1090] loss: 0.44562859535217286
train--5/100 [239/1090] loss: 0.43645249903202055
train--5/100 [249/1090] loss: 0.460237929224968
train--5/100 [259/1090] loss: 0.4642865777015686
train--5/100 [269/1090] loss: 0.450528284907341
train--5/100 [279/1090] loss: 0.44945046603679656
train--5/100 [289/1090] loss: 0.466290482878685
train--5/100 [299/1090] loss: 0.46236024498939515
train--5/100 [309/1090] loss: 0.45767309069633483
train--5/100 [319/1090] loss: 0.4556771457195282
train--5/100 [329/1090] loss: 0.4519283026456833
train--5/100 [339/1090] loss: 0.45062818229198454
train--5/100 [349/1090] loss: 0.4205673336982727
train--5/100 [359/1090] loss: 0.4649346977472305
train--5/100 [369/1090] loss: 0.46546621024608614
train--5/100 [379/1090] loss: 0.4299910306930542
train--5/100 [389/1090] loss: 0.4625556796789169
train--5/100 [399/1090] loss: 0.4627568632364273
train--5/100 [409/1090] loss: 0.4409141570329666
train--5/100 [419/1090] loss: 0.444408991932869
train--5/100 [429/1090] loss: 0.44845340251922605
train--5/100 [439/1090] loss: 0.4477285295724869
train--5/100 [449/1090] loss: 0.4513607084751129
train--5/100 [459/1090] loss: 0.4803112089633942
train--5/100 [469/1090] loss: 0.45934455692768095
train--5/100 [479/1090] loss: 0.46181730926036835
train--5/100 [489/1090] loss: 0.4405372440814972
train--5/100 [499/1090] loss: 0.4554352730512619
train--5/100 [509/1090] loss: 0.4530961334705353
train--5/100 [519/1090] loss: 0.4545925110578537
train--5/100 [529/1090] loss: 0.4522862434387207
train--5/100 [539/1090] loss: 0.4435188561677933
train--5/100 [549/1090] loss: 0.44800724685192106
train--5/100 [559/1090] loss: 0.45661923587322234
train--5/100 [569/1090] loss: 0.4308853507041931
train--5/100 [579/1090] loss: 0.47283231317996977
train--5/100 [589/1090] loss: 0.44924753308296206
train--5/100 [599/1090] loss: 0.44404964745044706
train--5/100 [609/1090] loss: 0.45212934613227845
train--5/100 [619/1090] loss: 0.45013139843940736
train--5/100 [629/1090] loss: 0.4491698980331421
train--5/100 [639/1090] loss: 0.4718983590602875
train--5/100 [649/1090] loss: 0.43989534080028536
train--5/100 [659/1090] loss: 0.4450073540210724
train--5/100 [669/1090] loss: 0.42473653256893157
train--5/100 [679/1090] loss: 0.4760085940361023
train--5/100 [689/1090] loss: 0.4755593568086624
train--5/100 [699/1090] loss: 0.44346754550933837
train--5/100 [709/1090] loss: 0.45742073059082033
train--5/100 [719/1090] loss: 0.4618486016988754
train--5/100 [729/1090] loss: 0.4668566852807999
train--5/100 [739/1090] loss: 0.4562656879425049
train--5/100 [749/1090] loss: 0.45051799416542054
train--5/100 [759/1090] loss: 0.4481158494949341
train--5/100 [769/1090] loss: 0.44840741753578184
train--5/100 [779/1090] loss: 0.4577843815088272
train--5/100 [789/1090] loss: 0.4294334679841995
train--5/100 [799/1090] loss: 0.4629515618085861
train--5/100 [809/1090] loss: 0.4676267832517624
train--5/100 [819/1090] loss: 0.45876245200634
train--5/100 [829/1090] loss: 0.4606240689754486
train--5/100 [839/1090] loss: 0.4644437462091446
train--5/100 [849/1090] loss: 0.4753771036863327
train--5/100 [859/1090] loss: 0.46890018582344056
train--5/100 [869/1090] loss: 0.475182244181633
train--5/100 [879/1090] loss: 0.4517266571521759
train--5/100 [889/1090] loss: 0.4463171511888504
train--5/100 [899/1090] loss: 0.45596604943275454
train--5/100 [909/1090] loss: 0.4509557008743286
train--5/100 [919/1090] loss: 0.46976081728935243
train--5/100 [929/1090] loss: 0.4612337350845337
train--5/100 [939/1090] loss: 0.464431694149971
train--5/100 [949/1090] loss: 0.45500941574573517
train--5/100 [959/1090] loss: 0.45983462035655975
train--5/100 [969/1090] loss: 0.4573520958423615
train--5/100 [979/1090] loss: 0.4635850995779037
train--5/100 [989/1090] loss: 0.4351231396198273
train--5/100 [999/1090] loss: 0.445344015955925
train--5/100 [1009/1090] loss: 0.4478881239891052
train--5/100 [1019/1090] loss: 0.449349045753479
train--5/100 [1029/1090] loss: 0.45876251459121703
train--5/100 [1039/1090] loss: 0.459953311085701
train--5/100 [1049/1090] loss: 0.4458616375923157
train--5/100 [1059/1090] loss: 0.4680690050125122
train--5/100 [1069/1090] loss: 0.446971720457077
train--5/100 [1079/1090] loss: 0.4661982297897339
train--5/100 [1089/1090] loss: 0.45763756334781647
predicting model...
val--5/100 [10/1090] acc: 0.791796875
val--5/100 [20/1090] acc: 0.792578125
val--5/100 [30/1090] acc: 0.7911458333333333
val--5/100 [40/1090] acc: 0.7916015625
val--5/100 [50/1090] acc: 0.7903125
val--5/100 [60/1090] acc: 0.7901041666666667
val--5/100 [70/1090] acc: 0.7905133928571428
val--5/100 [80/1090] acc: 0.78935546875
val--5/100 [90/1090] acc: 0.7900607638888889
val--5/100 [100/1090] acc: 0.7909375
val--5/100 [110/1090] acc: 0.7910866477272728
val--5/100 [120/1090] acc: 0.7908528645833334
val--5/100 [130/1090] acc: 0.7918870192307692
val--5/100 [140/1090] acc: 0.7919363839285715
val--5/100 [150/1090] acc: 0.7918229166666667
val--5/100 [160/1090] acc: 0.79208984375
val--5/100 [170/1090] acc: 0.7922334558823529
val--5/100 [180/1090] acc: 0.7920355902777778
val--5/100 [190/1090] acc: 0.7927220394736842
val--5/100 [200/1090] acc: 0.79294921875
val--5/100 [210/1090] acc: 0.7932291666666667
val--5/100 [220/1090] acc: 0.7924715909090909
val--5/100 [230/1090] acc: 0.7931555706521739
val--5/100 [240/1090] acc: 0.7927734375
val--5/100 [250/1090] acc: 0.7928125
val--5/100 [260/1090] acc: 0.7928335336538461
val--5/100 [270/1090] acc: 0.7929832175925926
val--5/100 [280/1090] acc: 0.7930245535714285
val--5/100 [290/1090] acc: 0.7929822198275862
val--5/100 [300/1090] acc: 0.7929036458333333
val--5/100 [310/1090] acc: 0.7926663306451613
val--5/100 [320/1090] acc: 0.7928955078125
val--5/100 [330/1090] acc: 0.7930871212121212
val--5/100 [340/1090] acc: 0.7932100183823529
val--5/100 [350/1090] acc: 0.7934040178571429
val--5/100 [360/1090] acc: 0.7932725694444445
val--5/100 [370/1090] acc: 0.7933382601351351
val--5/100 [380/1090] acc: 0.793297697368421
val--5/100 [390/1090] acc: 0.7929387019230769
val--5/100 [400/1090] acc: 0.792841796875
val--5/100 [410/1090] acc: 0.7930068597560975
val--5/100 [420/1090] acc: 0.7930245535714285
val--5/100 [430/1090] acc: 0.7928869912790698
val--5/100 [440/1090] acc: 0.7928622159090909
val--5/100 [450/1090] acc: 0.7927777777777778
val--5/100 [460/1090] acc: 0.7926630434782609
val--5/100 [470/1090] acc: 0.7925864361702127
val--5/100 [480/1090] acc: 0.7926595052083333
val--5/100 [490/1090] acc: 0.7927694515306123
val--5/100 [500/1090] acc: 0.7929765625
val--5/100 [510/1090] acc: 0.7928538602941176
val--5/100 [520/1090] acc: 0.7930138221153846
val--5/100 [530/1090] acc: 0.7930424528301887
val--5/100 [540/1090] acc: 0.7932002314814814
val--5/100 [550/1090] acc: 0.7930539772727273
val--5/100 [560/1090] acc: 0.7928641183035714
val--5/100 [570/1090] acc: 0.7926260964912281
val--5/100 [580/1090] acc: 0.7926454741379311
val--5/100 [590/1090] acc: 0.7926906779661017
val--5/100 [600/1090] acc: 0.7927278645833333
val--5/100 [610/1090] acc: 0.7926293545081967
val--5/100 [620/1090] acc: 0.7925214213709677
val--5/100 [630/1090] acc: 0.7927021329365079
val--5/100 [640/1090] acc: 0.792901611328125
val--5/100 [650/1090] acc: 0.79296875
val--5/100 [660/1090] acc: 0.7929154829545455
val--5/100 [670/1090] acc: 0.792636427238806
val--5/100 [680/1090] acc: 0.7924862132352941
val--5/100 [690/1090] acc: 0.7926234148550725
val--5/100 [700/1090] acc: 0.7925558035714285
val--5/100 [710/1090] acc: 0.7923470510563381
val--5/100 [720/1090] acc: 0.7922146267361111
val--5/100 [730/1090] acc: 0.7921179366438356
val--5/100 [740/1090] acc: 0.7920449746621622
val--5/100 [750/1090] acc: 0.7920885416666666
val--5/100 [760/1090] acc: 0.7921566611842106
val--5/100 [770/1090] acc: 0.7921519886363636
val--5/100 [780/1090] acc: 0.7921173878205128
val--5/100 [790/1090] acc: 0.7921776107594937
val--5/100 [800/1090] acc: 0.79236328125
val--5/100 [810/1090] acc: 0.7924141589506173
val--5/100 [820/1090] acc: 0.7925161966463414
val--5/100 [830/1090] acc: 0.7926110692771084
val--5/100 [840/1090] acc: 0.7925734747023809
val--5/100 [850/1090] acc: 0.7925919117647059
val--5/100 [860/1090] acc: 0.7928143168604651
val--5/100 [870/1090] acc: 0.7926769037356322
val--5/100 [880/1090] acc: 0.7926535866477272
val--5/100 [890/1090] acc: 0.7928019662921348
val--5/100 [900/1090] acc: 0.7928298611111111
val--5/100 [910/1090] acc: 0.7928313873626374
val--5/100 [920/1090] acc: 0.792875339673913
val--5/100 [930/1090] acc: 0.7929351478494624
val--5/100 [940/1090] acc: 0.7929562832446808
val--5/100 [950/1090] acc: 0.7928536184210526
val--5/100 [960/1090] acc: 0.7927815755208333
val--5/100 [970/1090] acc: 0.7927351804123711
val--5/100 [980/1090] acc: 0.7927216198979592
val--5/100 [990/1090] acc: 0.7926530934343434
val--5/100 [1000/1090] acc: 0.79258203125
val--5/100 [1010/1090] acc: 0.7924582301980198
val--5/100 [1020/1090] acc: 0.7925091911764706
val--5/100 [1030/1090] acc: 0.7925591626213592
val--5/100 [1040/1090] acc: 0.7925330528846154
val--5/100 [1050/1090] acc: 0.7925892857142857
val--5/100 [1060/1090] acc: 0.7925633844339622
val--5/100 [1070/1090] acc: 0.7925671728971962
val--5/100 [1080/1090] acc: 0.7925130208333333
val--5/100 [1090/1090] acc: 0.7923810206422018
epoch= 5, accuracy= 0.792381, rmse= 0.379794, auc= 0.853140
train--6/100 [9/1090] loss: 0.3727590322494507
train--6/100 [19/1090] loss: 0.4506638437509537
train--6/100 [29/1090] loss: 0.4244998037815094
train--6/100 [39/1090] loss: 0.44261318147182466
train--6/100 [49/1090] loss: 0.445463964343071
train--6/100 [59/1090] loss: 0.4530467987060547
train--6/100 [69/1090] loss: 0.46567183136940005
train--6/100 [79/1090] loss: 0.4349169135093689
train--6/100 [89/1090] loss: 0.45368193089962006
train--6/100 [99/1090] loss: 0.4639213889837265
train--6/100 [109/1090] loss: 0.43518148064613343
train--6/100 [119/1090] loss: 0.45020343363285065
train--6/100 [129/1090] loss: 0.4506510227918625
train--6/100 [139/1090] loss: 0.45280866622924804
train--6/100 [149/1090] loss: 0.4478260099887848
train--6/100 [159/1090] loss: 0.4503995031118393
train--6/100 [169/1090] loss: 0.4358814537525177
train--6/100 [179/1090] loss: 0.44959532618522646
train--6/100 [189/1090] loss: 0.4560068279504776
train--6/100 [199/1090] loss: 0.4389401376247406
train--6/100 [209/1090] loss: 0.4464788317680359
train--6/100 [219/1090] loss: 0.44540599584579466
train--6/100 [229/1090] loss: 0.46975736021995546
train--6/100 [239/1090] loss: 0.4479929506778717
train--6/100 [249/1090] loss: 0.4577544242143631
train--6/100 [259/1090] loss: 0.44587222337722776
train--6/100 [269/1090] loss: 0.4535120725631714
train--6/100 [279/1090] loss: 0.4411257833242416
train--6/100 [289/1090] loss: 0.4577286094427109
train--6/100 [299/1090] loss: 0.4582413464784622
train--6/100 [309/1090] loss: 0.43179919123649596
train--6/100 [319/1090] loss: 0.4529618114233017
train--6/100 [329/1090] loss: 0.43939281702041627
train--6/100 [339/1090] loss: 0.43912750482559204
train--6/100 [349/1090] loss: 0.4390861064195633
train--6/100 [359/1090] loss: 0.4452379673719406
train--6/100 [369/1090] loss: 0.4490294516086578
train--6/100 [379/1090] loss: 0.45116610527038575
train--6/100 [389/1090] loss: 0.4537804424762726
train--6/100 [399/1090] loss: 0.44587376415729524
train--6/100 [409/1090] loss: 0.44023088812828065
train--6/100 [419/1090] loss: 0.46034412682056425
train--6/100 [429/1090] loss: 0.44303245544433595
train--6/100 [439/1090] loss: 0.4459241986274719
train--6/100 [449/1090] loss: 0.4438342720270157
train--6/100 [459/1090] loss: 0.45898631513118743
train--6/100 [469/1090] loss: 0.46091224253177643
train--6/100 [479/1090] loss: 0.43355114161968233
train--6/100 [489/1090] loss: 0.4499089390039444
train--6/100 [499/1090] loss: 0.4409372121095657
train--6/100 [509/1090] loss: 0.46898182332515714
train--6/100 [519/1090] loss: 0.4387634575366974
train--6/100 [529/1090] loss: 0.45512349903583527
train--6/100 [539/1090] loss: 0.473868253827095
train--6/100 [549/1090] loss: 0.45069907009601595
train--6/100 [559/1090] loss: 0.4252250164747238
train--6/100 [569/1090] loss: 0.4368555128574371
train--6/100 [579/1090] loss: 0.4647694081068039
train--6/100 [589/1090] loss: 0.4427702993154526
train--6/100 [599/1090] loss: 0.4623295426368713
train--6/100 [609/1090] loss: 0.4724209487438202
train--6/100 [619/1090] loss: 0.4474904328584671
train--6/100 [629/1090] loss: 0.4561196804046631
train--6/100 [639/1090] loss: 0.4664748400449753
train--6/100 [649/1090] loss: 0.4468389183282852
train--6/100 [659/1090] loss: 0.45546368062496184
train--6/100 [669/1090] loss: 0.44781104028224944
train--6/100 [679/1090] loss: 0.4729173332452774
train--6/100 [689/1090] loss: 0.4686026781797409
train--6/100 [699/1090] loss: 0.46432230770587923
train--6/100 [709/1090] loss: 0.45947718918323516
train--6/100 [719/1090] loss: 0.4404143214225769
train--6/100 [729/1090] loss: 0.46727354824543
train--6/100 [739/1090] loss: 0.4500877022743225
train--6/100 [749/1090] loss: 0.43830705881118776
train--6/100 [759/1090] loss: 0.453245148062706
train--6/100 [769/1090] loss: 0.4762780427932739
train--6/100 [779/1090] loss: 0.443358901143074
train--6/100 [789/1090] loss: 0.4760048180818558
train--6/100 [799/1090] loss: 0.44474923610687256
train--6/100 [809/1090] loss: 0.4649284273386002
train--6/100 [819/1090] loss: 0.4517796039581299
train--6/100 [829/1090] loss: 0.4779150873422623
train--6/100 [839/1090] loss: 0.4413834661245346
train--6/100 [849/1090] loss: 0.4576803117990494
train--6/100 [859/1090] loss: 0.4453953832387924
train--6/100 [869/1090] loss: 0.4740935891866684
train--6/100 [879/1090] loss: 0.4482214093208313
train--6/100 [889/1090] loss: 0.453403040766716
train--6/100 [899/1090] loss: 0.4678540527820587
train--6/100 [909/1090] loss: 0.46139250695705414
train--6/100 [919/1090] loss: 0.4621596157550812
train--6/100 [929/1090] loss: 0.4610765099525452
train--6/100 [939/1090] loss: 0.44029046297073365
train--6/100 [949/1090] loss: 0.4477779150009155
train--6/100 [959/1090] loss: 0.43826557099819186
train--6/100 [969/1090] loss: 0.44197180569171907
train--6/100 [979/1090] loss: 0.44516284465789796
train--6/100 [989/1090] loss: 0.45673094391822816
train--6/100 [999/1090] loss: 0.4438973605632782
train--6/100 [1009/1090] loss: 0.454868757724762
train--6/100 [1019/1090] loss: 0.4616351991891861
train--6/100 [1029/1090] loss: 0.4439470201730728
train--6/100 [1039/1090] loss: 0.4569206595420837
train--6/100 [1049/1090] loss: 0.46704557836055755
train--6/100 [1059/1090] loss: 0.45350731909275055
train--6/100 [1069/1090] loss: 0.44065937101840974
train--6/100 [1079/1090] loss: 0.45379669666290284
train--6/100 [1089/1090] loss: 0.46505962014198304
predicting model...
val--6/100 [10/1090] acc: 0.794921875
val--6/100 [20/1090] acc: 0.7939453125
val--6/100 [30/1090] acc: 0.7927083333333333
val--6/100 [40/1090] acc: 0.7921875
val--6/100 [50/1090] acc: 0.7909375
val--6/100 [60/1090] acc: 0.7904947916666667
val--6/100 [70/1090] acc: 0.7909040178571428
val--6/100 [80/1090] acc: 0.789501953125
val--6/100 [90/1090] acc: 0.7898871527777778
val--6/100 [100/1090] acc: 0.790859375
val--6/100 [110/1090] acc: 0.7909090909090909
val--6/100 [120/1090] acc: 0.7904296875
val--6/100 [130/1090] acc: 0.79140625
val--6/100 [140/1090] acc: 0.7913783482142858
val--6/100 [150/1090] acc: 0.7914322916666666
val--6/100 [160/1090] acc: 0.79150390625
val--6/100 [170/1090] acc: 0.7915900735294118
val--6/100 [180/1090] acc: 0.7916232638888889
val--6/100 [190/1090] acc: 0.7922902960526316
val--6/100 [200/1090] acc: 0.79271484375
val--6/100 [210/1090] acc: 0.7928385416666667
val--6/100 [220/1090] acc: 0.7920276988636363
val--6/100 [230/1090] acc: 0.7927649456521739
val--6/100 [240/1090] acc: 0.7924479166666667
val--6/100 [250/1090] acc: 0.79265625
val--6/100 [260/1090] acc: 0.792578125
val--6/100 [270/1090] acc: 0.7928096064814815
val--6/100 [280/1090] acc: 0.7928292410714286
val--6/100 [290/1090] acc: 0.7927801724137931
val--6/100 [300/1090] acc: 0.7928255208333334
val--6/100 [310/1090] acc: 0.7925151209677419
val--6/100 [320/1090] acc: 0.79288330078125
val--6/100 [330/1090] acc: 0.793063446969697
val--6/100 [340/1090] acc: 0.7931410845588235
val--6/100 [350/1090] acc: 0.7932700892857143
val--6/100 [360/1090] acc: 0.7932400173611112
val--6/100 [370/1090] acc: 0.7933065878378378
val--6/100 [380/1090] acc: 0.7933490953947369
val--6/100 [390/1090] acc: 0.792958733974359
val--6/100 [400/1090] acc: 0.79291015625
val--6/100 [410/1090] acc: 0.7930926067073171
val--6/100 [420/1090] acc: 0.7931640625
val--6/100 [430/1090] acc: 0.7930414244186047
val--6/100 [440/1090] acc: 0.7930575284090909
val--6/100 [450/1090] acc: 0.7929861111111111
val--6/100 [460/1090] acc: 0.7929347826086957
val--6/100 [470/1090] acc: 0.7928274601063829
val--6/100 [480/1090] acc: 0.7929361979166667
val--6/100 [490/1090] acc: 0.7930325255102041
val--6/100 [500/1090] acc: 0.793171875
val--6/100 [510/1090] acc: 0.7931066176470588
val--6/100 [520/1090] acc: 0.7932692307692307
val--6/100 [530/1090] acc: 0.7932930424528302
val--6/100 [540/1090] acc: 0.7934172453703704
val--6/100 [550/1090] acc: 0.7932315340909091
val--6/100 [560/1090] acc: 0.7930803571428572
val--6/100 [570/1090] acc: 0.7928385416666667
val--6/100 [580/1090] acc: 0.7928475215517241
val--6/100 [590/1090] acc: 0.792869438559322
val--6/100 [600/1090] acc: 0.7928385416666667
val--6/100 [610/1090] acc: 0.7927574282786886
val--6/100 [620/1090] acc: 0.7926663306451613
val--6/100 [630/1090] acc: 0.7929315476190476
val--6/100 [640/1090] acc: 0.793133544921875
val--6/100 [650/1090] acc: 0.7931850961538461
val--6/100 [660/1090] acc: 0.7931226325757575
val--6/100 [670/1090] acc: 0.7928346548507462
val--6/100 [680/1090] acc: 0.7926528033088235
val--6/100 [690/1090] acc: 0.7928045742753623
val--6/100 [700/1090] acc: 0.7927566964285714
val--6/100 [710/1090] acc: 0.7925891285211267
val--6/100 [720/1090] acc: 0.7924099392361111
val--6/100 [730/1090] acc: 0.7923212756849315
val--6/100 [740/1090] acc: 0.7922244510135135
val--6/100 [750/1090] acc: 0.7923020833333333
val--6/100 [760/1090] acc: 0.7924033717105263
val--6/100 [770/1090] acc: 0.7924310064935065
val--6/100 [780/1090] acc: 0.7923828125
val--6/100 [790/1090] acc: 0.7924198971518988
val--6/100 [800/1090] acc: 0.7926318359375
val--6/100 [810/1090] acc: 0.7926697530864197
val--6/100 [820/1090] acc: 0.7927591463414634
val--6/100 [830/1090] acc: 0.7928416792168674
val--6/100 [840/1090] acc: 0.7928199404761904
val--6/100 [850/1090] acc: 0.7928308823529412
val--6/100 [860/1090] acc: 0.7930505087209302
val--6/100 [870/1090] acc: 0.7928924209770115
val--6/100 [880/1090] acc: 0.7928666548295454
val--6/100 [890/1090] acc: 0.7930082514044944
val--6/100 [900/1090] acc: 0.7929730902777777
val--6/100 [910/1090] acc: 0.7929472870879121
val--6/100 [920/1090] acc: 0.79296875
val--6/100 [930/1090] acc: 0.7930611559139785
val--6/100 [940/1090] acc: 0.7930934175531915
val--6/100 [950/1090] acc: 0.79296875
val--6/100 [960/1090] acc: 0.7928792317708333
val--6/100 [970/1090] acc: 0.7928318298969073
val--6/100 [980/1090] acc: 0.7928451849489796
val--6/100 [990/1090] acc: 0.7927438446969697
val--6/100 [1000/1090] acc: 0.79267578125
val--6/100 [1010/1090] acc: 0.7925201113861386
val--6/100 [1020/1090] acc: 0.792593443627451
val--6/100 [1030/1090] acc: 0.7926388046116505
val--6/100 [1040/1090] acc: 0.7925931490384616
val--6/100 [1050/1090] acc: 0.7926599702380952
val--6/100 [1060/1090] acc: 0.7926149764150944
val--6/100 [1070/1090] acc: 0.7925854264018691
val--6/100 [1080/1090] acc: 0.7925311053240741
val--6/100 [1090/1090] acc: 0.7923595183486238
epoch= 6, accuracy= 0.792360, rmse= 0.379551, auc= 0.853467
train--7/100 [9/1090] loss: 0.39651611149311067
train--7/100 [19/1090] loss: 0.4451999098062515
train--7/100 [29/1090] loss: 0.44613468945026397
train--7/100 [39/1090] loss: 0.43620823621749877
train--7/100 [49/1090] loss: 0.4475089222192764
train--7/100 [59/1090] loss: 0.44230020344257354
train--7/100 [69/1090] loss: 0.43932553827762605
train--7/100 [79/1090] loss: 0.4524324208498001
train--7/100 [89/1090] loss: 0.44711088836193086
train--7/100 [99/1090] loss: 0.45529826283454894
train--7/100 [109/1090] loss: 0.43250368535518646
train--7/100 [119/1090] loss: 0.4392964571714401
train--7/100 [129/1090] loss: 0.44250366985797884
train--7/100 [139/1090] loss: 0.4793261826038361
train--7/100 [149/1090] loss: 0.4750644892454147
train--7/100 [159/1090] loss: 0.4413504511117935
train--7/100 [169/1090] loss: 0.45669218301773074
train--7/100 [179/1090] loss: 0.4769221872091293
train--7/100 [189/1090] loss: 0.4501658916473389
train--7/100 [199/1090] loss: 0.46054871678352355
train--7/100 [209/1090] loss: 0.4495514452457428
train--7/100 [219/1090] loss: 0.4640193432569504
train--7/100 [229/1090] loss: 0.44570707678794863
train--7/100 [239/1090] loss: 0.4610968679189682
train--7/100 [249/1090] loss: 0.43355013728141784
train--7/100 [259/1090] loss: 0.443675696849823
train--7/100 [269/1090] loss: 0.4366637110710144
train--7/100 [279/1090] loss: 0.46368632912635804
train--7/100 [289/1090] loss: 0.45205520689487455
train--7/100 [299/1090] loss: 0.44414413869380953
train--7/100 [309/1090] loss: 0.43360114097595215
train--7/100 [319/1090] loss: 0.4426174610853195
train--7/100 [329/1090] loss: 0.43989510238170626
train--7/100 [339/1090] loss: 0.45574648678302765
train--7/100 [349/1090] loss: 0.4670014053583145
train--7/100 [359/1090] loss: 0.44485420882701876
train--7/100 [369/1090] loss: 0.4390217989683151
train--7/100 [379/1090] loss: 0.4494543969631195
train--7/100 [389/1090] loss: 0.4516762673854828
train--7/100 [399/1090] loss: 0.433666867017746
train--7/100 [409/1090] loss: 0.44009206891059877
train--7/100 [419/1090] loss: 0.44295933544635774
train--7/100 [429/1090] loss: 0.43927641212940216
train--7/100 [439/1090] loss: 0.45870509147644045
train--7/100 [449/1090] loss: 0.4450033336877823
train--7/100 [459/1090] loss: 0.4544460505247116
train--7/100 [469/1090] loss: 0.4442261248826981
train--7/100 [479/1090] loss: 0.45150389075279235
train--7/100 [489/1090] loss: 0.434164497256279
train--7/100 [499/1090] loss: 0.4377516329288483
train--7/100 [509/1090] loss: 0.4549568176269531
train--7/100 [519/1090] loss: 0.45032745897769927
train--7/100 [529/1090] loss: 0.4521412819623947
train--7/100 [539/1090] loss: 0.4683050662279129
train--7/100 [549/1090] loss: 0.45225395560264586
train--7/100 [559/1090] loss: 0.4720079243183136
train--7/100 [569/1090] loss: 0.46795581877231596
train--7/100 [579/1090] loss: 0.43890212178230287
train--7/100 [589/1090] loss: 0.4460202485322952
train--7/100 [599/1090] loss: 0.45304758548736573
train--7/100 [609/1090] loss: 0.4537556320428848
train--7/100 [619/1090] loss: 0.4448424994945526
train--7/100 [629/1090] loss: 0.45458013415336607
train--7/100 [639/1090] loss: 0.4657368272542953
train--7/100 [649/1090] loss: 0.45788541436195374
train--7/100 [659/1090] loss: 0.44656811058521273
train--7/100 [669/1090] loss: 0.4585250377655029
train--7/100 [679/1090] loss: 0.43991935849189756
train--7/100 [689/1090] loss: 0.4241949260234833
train--7/100 [699/1090] loss: 0.4550574779510498
train--7/100 [709/1090] loss: 0.4676675945520401
train--7/100 [719/1090] loss: 0.46754359304904936
train--7/100 [729/1090] loss: 0.45330575108528137
train--7/100 [739/1090] loss: 0.44636736810207367
train--7/100 [749/1090] loss: 0.4540007054805756
train--7/100 [759/1090] loss: 0.4459512859582901
train--7/100 [769/1090] loss: 0.4560856193304062
train--7/100 [779/1090] loss: 0.46127681732177733
train--7/100 [789/1090] loss: 0.4303474187850952
train--7/100 [799/1090] loss: 0.46594840884208677
train--7/100 [809/1090] loss: 0.4477238029241562
train--7/100 [819/1090] loss: 0.43273109197616577
train--7/100 [829/1090] loss: 0.4685645639896393
train--7/100 [839/1090] loss: 0.4561318516731262
train--7/100 [849/1090] loss: 0.45310614705085756
train--7/100 [859/1090] loss: 0.4651802361011505
train--7/100 [869/1090] loss: 0.4710700660943985
train--7/100 [879/1090] loss: 0.43803282976150515
train--7/100 [889/1090] loss: 0.45739454329013823
train--7/100 [899/1090] loss: 0.44377581775188446
train--7/100 [909/1090] loss: 0.45495094954967497
train--7/100 [919/1090] loss: 0.4562706798315048
train--7/100 [929/1090] loss: 0.4407991230487823
train--7/100 [939/1090] loss: 0.4469084769487381
train--7/100 [949/1090] loss: 0.46767022013664244
train--7/100 [959/1090] loss: 0.45891281962394714
train--7/100 [969/1090] loss: 0.4444271892309189
train--7/100 [979/1090] loss: 0.4373138189315796
train--7/100 [989/1090] loss: 0.4715552359819412
train--7/100 [999/1090] loss: 0.44767260551452637
train--7/100 [1009/1090] loss: 0.4471574813127518
train--7/100 [1019/1090] loss: 0.4454555720090866
train--7/100 [1029/1090] loss: 0.4636752724647522
train--7/100 [1039/1090] loss: 0.48394168317317965
train--7/100 [1049/1090] loss: 0.4356492668390274
train--7/100 [1059/1090] loss: 0.46461987793445586
train--7/100 [1069/1090] loss: 0.4395037829875946
train--7/100 [1079/1090] loss: 0.4457886129617691
train--7/100 [1089/1090] loss: 0.4549789637327194
predicting model...
val--7/100 [10/1090] acc: 0.7890625
val--7/100 [20/1090] acc: 0.7900390625
val--7/100 [30/1090] acc: 0.7904947916666667
val--7/100 [40/1090] acc: 0.79052734375
val--7/100 [50/1090] acc: 0.790234375
val--7/100 [60/1090] acc: 0.7890625
val--7/100 [70/1090] acc: 0.7899553571428571
val--7/100 [80/1090] acc: 0.788623046875
val--7/100 [90/1090] acc: 0.7894965277777778
val--7/100 [100/1090] acc: 0.79046875
val--7/100 [110/1090] acc: 0.7905894886363637
val--7/100 [120/1090] acc: 0.7900390625
val--7/100 [130/1090] acc: 0.7911658653846154
val--7/100 [140/1090] acc: 0.7911272321428572
val--7/100 [150/1090] acc: 0.7912239583333334
val--7/100 [160/1090] acc: 0.7913818359375
val--7/100 [170/1090] acc: 0.7915670955882353
val--7/100 [180/1090] acc: 0.7912760416666667
val--7/100 [190/1090] acc: 0.7919202302631579
val--7/100 [200/1090] acc: 0.7922265625
val--7/100 [210/1090] acc: 0.7926339285714286
val--7/100 [220/1090] acc: 0.791690340909091
val--7/100 [230/1090] acc: 0.7923403532608696
val--7/100 [240/1090] acc: 0.7921875
val--7/100 [250/1090] acc: 0.792296875
val--7/100 [260/1090] acc: 0.7924278846153846
val--7/100 [270/1090] acc: 0.7926938657407407
val--7/100 [280/1090] acc: 0.7927594866071429
val--7/100 [290/1090] acc: 0.7927532327586206
val--7/100 [300/1090] acc: 0.7927083333333333
val--7/100 [310/1090] acc: 0.7924395161290323
val--7/100 [320/1090] acc: 0.792724609375
val--7/100 [330/1090] acc: 0.7929805871212121
val--7/100 [340/1090] acc: 0.7932215073529412
val--7/100 [350/1090] acc: 0.7934263392857143
val--7/100 [360/1090] acc: 0.7932834201388889
val--7/100 [370/1090] acc: 0.793359375
val--7/100 [380/1090] acc: 0.7933799342105263
val--7/100 [390/1090] acc: 0.7930588942307693
val--7/100 [400/1090] acc: 0.792919921875
val--7/100 [410/1090] acc: 0.7931497713414634
val--7/100 [420/1090] acc: 0.7931454613095238
val--7/100 [430/1090] acc: 0.7929505813953488
val--7/100 [440/1090] acc: 0.79296875
val--7/100 [450/1090] acc: 0.7927777777777778
val--7/100 [460/1090] acc: 0.7927055027173913
val--7/100 [470/1090] acc: 0.7926778590425532
val--7/100 [480/1090] acc: 0.7927327473958333
val--7/100 [490/1090] acc: 0.7928093112244898
val--7/100 [500/1090] acc: 0.793015625
val--7/100 [510/1090] acc: 0.792953431372549
val--7/100 [520/1090] acc: 0.7931565504807693
val--7/100 [530/1090] acc: 0.793138266509434
val--7/100 [540/1090] acc: 0.7932942708333334
val--7/100 [550/1090] acc: 0.7930752840909091
val--7/100 [560/1090] acc: 0.7929129464285715
val--7/100 [570/1090] acc: 0.7927288925438597
val--7/100 [580/1090] acc: 0.7927599676724137
val--7/100 [590/1090] acc: 0.7927502648305085
val--7/100 [600/1090] acc: 0.79279296875
val--7/100 [610/1090] acc: 0.792719006147541
val--7/100 [620/1090] acc: 0.792609627016129
val--7/100 [630/1090] acc: 0.7928447420634921
val--7/100 [640/1090] acc: 0.7930419921875
val--7/100 [650/1090] acc: 0.7930348557692307
val--7/100 [660/1090] acc: 0.7929214015151516
val--7/100 [670/1090] acc: 0.7926422574626866
val--7/100 [680/1090] acc: 0.7925379136029411
val--7/100 [690/1090] acc: 0.7927196557971015
val--7/100 [700/1090] acc: 0.7926729910714285
val--7/100 [710/1090] acc: 0.7924900968309859
val--7/100 [720/1090] acc: 0.7922905815972222
val--7/100 [730/1090] acc: 0.7921928510273972
val--7/100 [740/1090] acc: 0.7921030405405406
val--7/100 [750/1090] acc: 0.792140625
val--7/100 [760/1090] acc: 0.7922080592105263
val--7/100 [770/1090] acc: 0.7922128652597402
val--7/100 [780/1090] acc: 0.7921724759615385
val--7/100 [790/1090] acc: 0.792217167721519
val--7/100 [800/1090] acc: 0.7924560546875
val--7/100 [810/1090] acc: 0.7925395447530864
val--7/100 [820/1090] acc: 0.7926352896341463
val--7/100 [830/1090] acc: 0.7927616716867469
val--7/100 [840/1090] acc: 0.7926618303571429
val--7/100 [850/1090] acc: 0.7926608455882352
val--7/100 [860/1090] acc: 0.792882449127907
val--7/100 [870/1090] acc: 0.7927756824712644
val--7/100 [880/1090] acc: 0.7928133877840909
val--7/100 [890/1090] acc: 0.7929336376404494
val--7/100 [900/1090] acc: 0.7929427083333334
val--7/100 [910/1090] acc: 0.7929644574175824
val--7/100 [920/1090] acc: 0.7929984714673913
val--7/100 [930/1090] acc: 0.7930653561827957
val--7/100 [940/1090] acc: 0.7930975731382979
val--7/100 [950/1090] acc: 0.7930057565789473
val--7/100 [960/1090] acc: 0.7929158528645833
val--7/100 [970/1090] acc: 0.7928721005154639
val--7/100 [980/1090] acc: 0.7928730867346939
val--7/100 [990/1090] acc: 0.7927635732323233
val--7/100 [1000/1090] acc: 0.7926796875
val--7/100 [1010/1090] acc: 0.792551051980198
val--7/100 [1020/1090] acc: 0.7926279105392157
val--7/100 [1030/1090] acc: 0.7926843143203883
val--7/100 [1040/1090] acc: 0.79267578125
val--7/100 [1050/1090] acc: 0.7927269345238095
val--7/100 [1060/1090] acc: 0.7926665683962264
val--7/100 [1070/1090] acc: 0.7927058995327103
val--7/100 [1080/1090] acc: 0.7926396122685185
val--7/100 [1090/1090] acc: 0.7924491112385321
epoch= 7, accuracy= 0.792449, rmse= 0.379430, auc= 0.853692
train--8/100 [9/1090] loss: 0.4026000052690506
train--8/100 [19/1090] loss: 0.460945850610733
train--8/100 [29/1090] loss: 0.4457434356212616
train--8/100 [39/1090] loss: 0.44719441533088683
train--8/100 [49/1090] loss: 0.46936950981616976
train--8/100 [59/1090] loss: 0.44555510580539703
train--8/100 [69/1090] loss: 0.43616212010383604
train--8/100 [79/1090] loss: 0.44307510554790497
train--8/100 [89/1090] loss: 0.46030986607074736
train--8/100 [99/1090] loss: 0.43770093023777007
train--8/100 [109/1090] loss: 0.42736888825893404
train--8/100 [119/1090] loss: 0.4591635078191757
train--8/100 [129/1090] loss: 0.4460453808307648
train--8/100 [139/1090] loss: 0.4403981566429138
train--8/100 [149/1090] loss: 0.44187505841255187
train--8/100 [159/1090] loss: 0.4493197023868561
train--8/100 [169/1090] loss: 0.4749858617782593
train--8/100 [179/1090] loss: 0.4478079617023468
train--8/100 [189/1090] loss: 0.4497129738330841
train--8/100 [199/1090] loss: 0.4456171840429306
train--8/100 [209/1090] loss: 0.44899713099002836
train--8/100 [219/1090] loss: 0.45806410908699036
train--8/100 [229/1090] loss: 0.4395431488752365
train--8/100 [239/1090] loss: 0.4533031344413757
train--8/100 [249/1090] loss: 0.4518822282552719
train--8/100 [259/1090] loss: 0.45511744916439056
train--8/100 [269/1090] loss: 0.44905358254909516
train--8/100 [279/1090] loss: 0.46296949982643126
train--8/100 [289/1090] loss: 0.43953912854194643
train--8/100 [299/1090] loss: 0.45132629573345184
train--8/100 [309/1090] loss: 0.4304744750261307
train--8/100 [319/1090] loss: 0.4341269999742508
train--8/100 [329/1090] loss: 0.4539904922246933
train--8/100 [339/1090] loss: 0.45812016129493716
train--8/100 [349/1090] loss: 0.4388925492763519
train--8/100 [359/1090] loss: 0.4505758285522461
train--8/100 [369/1090] loss: 0.4625507265329361
train--8/100 [379/1090] loss: 0.4645336985588074
train--8/100 [389/1090] loss: 0.44730721414089203
train--8/100 [399/1090] loss: 0.45395220816135406
train--8/100 [409/1090] loss: 0.43495548963546754
train--8/100 [419/1090] loss: 0.43425689041614535
train--8/100 [429/1090] loss: 0.4490751653909683
train--8/100 [439/1090] loss: 0.43097260892391204
train--8/100 [449/1090] loss: 0.4294393718242645
train--8/100 [459/1090] loss: 0.4586379170417786
train--8/100 [469/1090] loss: 0.4375793993473053
train--8/100 [479/1090] loss: 0.4593697637319565
train--8/100 [489/1090] loss: 0.4587110608816147
train--8/100 [499/1090] loss: 0.43111298978328705
train--8/100 [509/1090] loss: 0.440951281785965
train--8/100 [519/1090] loss: 0.428654208779335
train--8/100 [529/1090] loss: 0.4470644533634186
train--8/100 [539/1090] loss: 0.4516265392303467
train--8/100 [549/1090] loss: 0.4504642218351364
train--8/100 [559/1090] loss: 0.46350337266922
train--8/100 [569/1090] loss: 0.4384555220603943
train--8/100 [579/1090] loss: 0.4370725005865097
train--8/100 [589/1090] loss: 0.46124284863471987
train--8/100 [599/1090] loss: 0.4534573137760162
train--8/100 [609/1090] loss: 0.4364640414714813
train--8/100 [619/1090] loss: 0.45737994015216826
train--8/100 [629/1090] loss: 0.4625610917806625
train--8/100 [639/1090] loss: 0.46349151730537413
train--8/100 [649/1090] loss: 0.43457818031311035
train--8/100 [659/1090] loss: 0.4277411729097366
train--8/100 [669/1090] loss: 0.4413216203451157
train--8/100 [679/1090] loss: 0.43094787895679476
train--8/100 [689/1090] loss: 0.4430482655763626
train--8/100 [699/1090] loss: 0.45621790885925295
train--8/100 [709/1090] loss: 0.448588165640831
train--8/100 [719/1090] loss: 0.4452122151851654
train--8/100 [729/1090] loss: 0.4346062570810318
train--8/100 [739/1090] loss: 0.45413649678230283
train--8/100 [749/1090] loss: 0.47225778102874755
train--8/100 [759/1090] loss: 0.443740701675415
train--8/100 [769/1090] loss: 0.4581628680229187
train--8/100 [779/1090] loss: 0.4396091908216476
train--8/100 [789/1090] loss: 0.45509136021137236
train--8/100 [799/1090] loss: 0.4439469397068024
train--8/100 [809/1090] loss: 0.46581495702266695
train--8/100 [819/1090] loss: 0.45639191567897797
train--8/100 [829/1090] loss: 0.44801773726940153
train--8/100 [839/1090] loss: 0.44318526089191435
train--8/100 [849/1090] loss: 0.46041932702064514
train--8/100 [859/1090] loss: 0.45663692355155944
train--8/100 [869/1090] loss: 0.4672314375638962
train--8/100 [879/1090] loss: 0.45425513088703157
train--8/100 [889/1090] loss: 0.4563175618648529
train--8/100 [899/1090] loss: 0.4635472893714905
train--8/100 [909/1090] loss: 0.45912398099899293
train--8/100 [919/1090] loss: 0.45685065984725953
train--8/100 [929/1090] loss: 0.4491405785083771
train--8/100 [939/1090] loss: 0.4652534335851669
train--8/100 [949/1090] loss: 0.4588976114988327
train--8/100 [959/1090] loss: 0.44829108119010924
train--8/100 [969/1090] loss: 0.4809087127447128
train--8/100 [979/1090] loss: 0.465806782245636
train--8/100 [989/1090] loss: 0.4579173058271408
train--8/100 [999/1090] loss: 0.4464059740304947
train--8/100 [1009/1090] loss: 0.46381527185440063
train--8/100 [1019/1090] loss: 0.4683545470237732
train--8/100 [1029/1090] loss: 0.4661160379648209
train--8/100 [1039/1090] loss: 0.44974367022514344
train--8/100 [1049/1090] loss: 0.44113418459892273
train--8/100 [1059/1090] loss: 0.45212257504463194
train--8/100 [1069/1090] loss: 0.45753646790981295
train--8/100 [1079/1090] loss: 0.4648802250623703
train--8/100 [1089/1090] loss: 0.4600380927324295
predicting model...
val--8/100 [10/1090] acc: 0.794140625
val--8/100 [20/1090] acc: 0.7927734375
val--8/100 [30/1090] acc: 0.7912760416666667
val--8/100 [40/1090] acc: 0.79091796875
val--8/100 [50/1090] acc: 0.79
val--8/100 [60/1090] acc: 0.7896484375
val--8/100 [70/1090] acc: 0.7903459821428571
val--8/100 [80/1090] acc: 0.789208984375
val--8/100 [90/1090] acc: 0.78984375
val--8/100 [100/1090] acc: 0.7910546875
val--8/100 [110/1090] acc: 0.791015625
val--8/100 [120/1090] acc: 0.7908528645833334
val--8/100 [130/1090] acc: 0.7919471153846154
val--8/100 [140/1090] acc: 0.7919921875
val--8/100 [150/1090] acc: 0.7919791666666667
val--8/100 [160/1090] acc: 0.79228515625
val--8/100 [170/1090] acc: 0.7925551470588236
val--8/100 [180/1090] acc: 0.7923611111111111
val--8/100 [190/1090] acc: 0.7931332236842106
val--8/100 [200/1090] acc: 0.793359375
val--8/100 [210/1090] acc: 0.793843005952381
val--8/100 [220/1090] acc: 0.7928622159090909
val--8/100 [230/1090] acc: 0.7935461956521739
val--8/100 [240/1090] acc: 0.7933268229166667
val--8/100 [250/1090] acc: 0.7934375
val--8/100 [260/1090] acc: 0.7934344951923077
val--8/100 [270/1090] acc: 0.7935763888888889
val--8/100 [280/1090] acc: 0.7935965401785714
val--8/100 [290/1090] acc: 0.7934401939655172
val--8/100 [300/1090] acc: 0.7933854166666666
val--8/100 [310/1090] acc: 0.7931325604838709
val--8/100 [320/1090] acc: 0.7933837890625
val--8/100 [330/1090] acc: 0.7935724431818182
val--8/100 [340/1090] acc: 0.7937270220588235
val--8/100 [350/1090] acc: 0.7939174107142857
val--8/100 [360/1090] acc: 0.7938259548611111
val--8/100 [370/1090] acc: 0.7939294763513514
val--8/100 [380/1090] acc: 0.7938425164473685
val--8/100 [390/1090] acc: 0.7935897435897435
val--8/100 [400/1090] acc: 0.793388671875
val--8/100 [410/1090] acc: 0.7935880335365854
val--8/100 [420/1090] acc: 0.7935267857142857
val--8/100 [430/1090] acc: 0.7934047965116279
val--8/100 [440/1090] acc: 0.7933682528409091
val--8/100 [450/1090] acc: 0.7932378472222222
val--8/100 [460/1090] acc: 0.7931555706521739
val--8/100 [470/1090] acc: 0.7930684840425531
val--8/100 [480/1090] acc: 0.7931315104166666
val--8/100 [490/1090] acc: 0.7932716836734693
val--8/100 [500/1090] acc: 0.793390625
val--8/100 [510/1090] acc: 0.7932827818627451
val--8/100 [520/1090] acc: 0.7934870793269231
val--8/100 [530/1090] acc: 0.7934404481132076
val--8/100 [540/1090] acc: 0.7936125578703703
val--8/100 [550/1090] acc: 0.7934588068181818
val--8/100 [560/1090] acc: 0.793310546875
val--8/100 [570/1090] acc: 0.7930715460526315
val--8/100 [580/1090] acc: 0.7931505926724138
val--8/100 [590/1090] acc: 0.7931607521186441
val--8/100 [600/1090] acc: 0.7932161458333333
val--8/100 [610/1090] acc: 0.7931288422131147
val--8/100 [620/1090] acc: 0.7930443548387097
val--8/100 [630/1090] acc: 0.7932353670634921
val--8/100 [640/1090] acc: 0.793438720703125
val--8/100 [650/1090] acc: 0.7935276442307693
val--8/100 [660/1090] acc: 0.7934067234848485
val--8/100 [670/1090] acc: 0.7931261660447761
val--8/100 [680/1090] acc: 0.7929744944852941
val--8/100 [690/1090] acc: 0.7931555706521739
val--8/100 [700/1090] acc: 0.7930970982142858
val--8/100 [710/1090] acc: 0.7928972271126761
val--8/100 [720/1090] acc: 0.7927517361111112
val--8/100 [730/1090] acc: 0.7926690924657535
val--8/100 [740/1090] acc: 0.7925517314189189
val--8/100 [750/1090] acc: 0.792640625
val--8/100 [760/1090] acc: 0.7927785773026316
val--8/100 [770/1090] acc: 0.7927607548701299
val--8/100 [780/1090] acc: 0.7926883012820513
val--8/100 [790/1090] acc: 0.7927412974683544
val--8/100 [800/1090] acc: 0.7929248046875
val--8/100 [810/1090] acc: 0.7930073302469136
val--8/100 [820/1090] acc: 0.7930973704268293
val--8/100 [830/1090] acc: 0.7931758283132531
val--8/100 [840/1090] acc: 0.7931129092261905
val--8/100 [850/1090] acc: 0.7931341911764705
val--8/100 [860/1090] acc: 0.7933820857558139
val--8/100 [870/1090] acc: 0.7932156968390804
val--8/100 [880/1090] acc: 0.7931906960227273
val--8/100 [890/1090] acc: 0.7933549859550562
val--8/100 [900/1090] acc: 0.7933940972222222
val--8/100 [910/1090] acc: 0.7934581043956044
val--8/100 [920/1090] acc: 0.7935122282608695
val--8/100 [930/1090] acc: 0.7935819892473118
val--8/100 [940/1090] acc: 0.7936003989361702
val--8/100 [950/1090] acc: 0.7935115131578947
val--8/100 [960/1090] acc: 0.7934326171875
val--8/100 [970/1090] acc: 0.7933634020618556
val--8/100 [980/1090] acc: 0.7933832908163265
val--8/100 [990/1090] acc: 0.793292297979798
val--8/100 [1000/1090] acc: 0.79323828125
val--8/100 [1010/1090] acc: 0.7930886448019802
val--8/100 [1020/1090] acc: 0.7931602328431373
val--8/100 [1030/1090] acc: 0.7931811286407767
val--8/100 [1040/1090] acc: 0.7931715745192308
val--8/100 [1050/1090] acc: 0.7932403273809524
val--8/100 [1060/1090] acc: 0.7931935436320755
val--8/100 [1070/1090] acc: 0.7932060455607477
val--8/100 [1080/1090] acc: 0.7931387442129629
val--8/100 [1090/1090] acc: 0.792947247706422
epoch= 8, accuracy= 0.792947, rmse= 0.379379, auc= 0.853892
train--9/100 [9/1090] loss: 0.4128131538629532
train--9/100 [19/1090] loss: 0.4542481780052185
train--9/100 [29/1090] loss: 0.4496557652950287
train--9/100 [39/1090] loss: 0.44431238770484927
train--9/100 [49/1090] loss: 0.45110062658786776
train--9/100 [59/1090] loss: 0.4511840969324112
train--9/100 [69/1090] loss: 0.45300841629505156
train--9/100 [79/1090] loss: 0.43932871520519257
train--9/100 [89/1090] loss: 0.4436098515987396
train--9/100 [99/1090] loss: 0.4564121633768082
train--9/100 [109/1090] loss: 0.46579973995685575
train--9/100 [119/1090] loss: 0.4556592106819153
train--9/100 [129/1090] loss: 0.4362366050481796
train--9/100 [139/1090] loss: 0.4327577203512192
train--9/100 [149/1090] loss: 0.44662615954875945
train--9/100 [159/1090] loss: 0.4358315795660019
train--9/100 [169/1090] loss: 0.46350288987159727
train--9/100 [179/1090] loss: 0.4431503891944885
train--9/100 [189/1090] loss: 0.4579867273569107
train--9/100 [199/1090] loss: 0.4390646815299988
train--9/100 [209/1090] loss: 0.45564760863780973
train--9/100 [219/1090] loss: 0.4587910324335098
train--9/100 [229/1090] loss: 0.4446781903505325
train--9/100 [239/1090] loss: 0.4334860771894455
train--9/100 [249/1090] loss: 0.4496669709682465
train--9/100 [259/1090] loss: 0.44057321548461914
train--9/100 [269/1090] loss: 0.4465050369501114
train--9/100 [279/1090] loss: 0.4636957675218582
train--9/100 [289/1090] loss: 0.45379880368709563
train--9/100 [299/1090] loss: 0.44827566742897035
train--9/100 [309/1090] loss: 0.43383454978466035
train--9/100 [319/1090] loss: 0.44533986151218413
train--9/100 [329/1090] loss: 0.4468311876058578
train--9/100 [339/1090] loss: 0.446844556927681
train--9/100 [349/1090] loss: 0.4330251097679138
train--9/100 [359/1090] loss: 0.45577857196331023
train--9/100 [369/1090] loss: 0.45296542942523954
train--9/100 [379/1090] loss: 0.4374714821577072
train--9/100 [389/1090] loss: 0.45144274830818176
train--9/100 [399/1090] loss: 0.45298005640506744
train--9/100 [409/1090] loss: 0.4436051994562149
train--9/100 [419/1090] loss: 0.43788758516311643
train--9/100 [429/1090] loss: 0.45133560001850126
train--9/100 [439/1090] loss: 0.44032601416110995
train--9/100 [449/1090] loss: 0.4681231021881104
train--9/100 [459/1090] loss: 0.46655875742435454
train--9/100 [469/1090] loss: 0.4530697137117386
train--9/100 [479/1090] loss: 0.4690482705831528
train--9/100 [489/1090] loss: 0.4229599475860596
train--9/100 [499/1090] loss: 0.4422873467206955
train--9/100 [509/1090] loss: 0.45309996902942656
train--9/100 [519/1090] loss: 0.46820786595344543
train--9/100 [529/1090] loss: 0.4594284474849701
train--9/100 [539/1090] loss: 0.4601179718971252
train--9/100 [549/1090] loss: 0.47036105394363403
train--9/100 [559/1090] loss: 0.44786950945854187
train--9/100 [569/1090] loss: 0.44590744972229
train--9/100 [579/1090] loss: 0.44598578214645385
train--9/100 [589/1090] loss: 0.44234925508499146
train--9/100 [599/1090] loss: 0.45279923677444456
train--9/100 [609/1090] loss: 0.4397044897079468
train--9/100 [619/1090] loss: 0.4446389198303223
train--9/100 [629/1090] loss: 0.4367036521434784
train--9/100 [639/1090] loss: 0.4464831411838531
train--9/100 [649/1090] loss: 0.45342825949192045
train--9/100 [659/1090] loss: 0.438419833779335
train--9/100 [669/1090] loss: 0.4648360341787338
train--9/100 [679/1090] loss: 0.45154556930065154
train--9/100 [689/1090] loss: 0.43468883633613586
train--9/100 [699/1090] loss: 0.43101985156536105
train--9/100 [709/1090] loss: 0.4522482991218567
train--9/100 [719/1090] loss: 0.44300835132598876
train--9/100 [729/1090] loss: 0.4718047797679901
train--9/100 [739/1090] loss: 0.45952084064483645
train--9/100 [749/1090] loss: 0.4270242303609848
train--9/100 [759/1090] loss: 0.44004523754119873
train--9/100 [769/1090] loss: 0.44483989775180816
train--9/100 [779/1090] loss: 0.4391347885131836
train--9/100 [789/1090] loss: 0.43659332394599915
train--9/100 [799/1090] loss: 0.4485484600067139
train--9/100 [809/1090] loss: 0.451615697145462
train--9/100 [819/1090] loss: 0.45077568888664243
train--9/100 [829/1090] loss: 0.46391784250736234
train--9/100 [839/1090] loss: 0.4609664559364319
train--9/100 [849/1090] loss: 0.45012523233890533
train--9/100 [859/1090] loss: 0.4536157488822937
train--9/100 [869/1090] loss: 0.43408909142017366
train--9/100 [879/1090] loss: 0.466293066740036
train--9/100 [889/1090] loss: 0.4509278893470764
train--9/100 [899/1090] loss: 0.4632641404867172
train--9/100 [909/1090] loss: 0.46668665409088134
train--9/100 [919/1090] loss: 0.45117386281490324
train--9/100 [929/1090] loss: 0.4613364517688751
train--9/100 [939/1090] loss: 0.4403443455696106
train--9/100 [949/1090] loss: 0.4534934341907501
train--9/100 [959/1090] loss: 0.4545098453760147
train--9/100 [969/1090] loss: 0.4447780132293701
train--9/100 [979/1090] loss: 0.46949676871299745
train--9/100 [989/1090] loss: 0.45495725572109225
train--9/100 [999/1090] loss: 0.4490469306707382
train--9/100 [1009/1090] loss: 0.4632545530796051
train--9/100 [1019/1090] loss: 0.452061665058136
train--9/100 [1029/1090] loss: 0.4467286467552185
train--9/100 [1039/1090] loss: 0.44339899122715
train--9/100 [1049/1090] loss: 0.45107499659061434
train--9/100 [1059/1090] loss: 0.4502891391515732
train--9/100 [1069/1090] loss: 0.4678086876869202
train--9/100 [1079/1090] loss: 0.4664178878068924
train--9/100 [1089/1090] loss: 0.47727555930614474
predicting model...
val--9/100 [10/1090] acc: 0.7921875
val--9/100 [20/1090] acc: 0.7927734375
val--9/100 [30/1090] acc: 0.7919270833333333
val--9/100 [40/1090] acc: 0.79150390625
val--9/100 [50/1090] acc: 0.790625
val--9/100 [60/1090] acc: 0.7902994791666667
val--9/100 [70/1090] acc: 0.7910714285714285
val--9/100 [80/1090] acc: 0.7896484375
val--9/100 [90/1090] acc: 0.7899739583333333
val--9/100 [100/1090] acc: 0.7908203125
val--9/100 [110/1090] acc: 0.7909446022727272
val--9/100 [120/1090] acc: 0.7908203125
val--9/100 [130/1090] acc: 0.7919170673076923
val--9/100 [140/1090] acc: 0.7921316964285714
val--9/100 [150/1090] acc: 0.792265625
val--9/100 [160/1090] acc: 0.7926025390625
val--9/100 [170/1090] acc: 0.7926240808823529
val--9/100 [180/1090] acc: 0.7922526041666667
val--9/100 [190/1090] acc: 0.7930921052631579
val--9/100 [200/1090] acc: 0.79337890625
val--9/100 [210/1090] acc: 0.7935825892857142
val--9/100 [220/1090] acc: 0.7927379261363636
val--9/100 [230/1090] acc: 0.7934442934782608
val--9/100 [240/1090] acc: 0.7931315104166666
val--9/100 [250/1090] acc: 0.7934375
val--9/100 [260/1090] acc: 0.7934344951923077
val--9/100 [270/1090] acc: 0.793677662037037
val--9/100 [280/1090] acc: 0.7936104910714286
val--9/100 [290/1090] acc: 0.7935883620689655
val--9/100 [300/1090] acc: 0.7935546875
val--9/100 [310/1090] acc: 0.7932333669354839
val--9/100 [320/1090] acc: 0.793408203125
val--9/100 [330/1090] acc: 0.7936553030303031
val--9/100 [340/1090] acc: 0.793795955882353
val--9/100 [350/1090] acc: 0.7939397321428572
val--9/100 [360/1090] acc: 0.7938802083333333
val--9/100 [370/1090] acc: 0.7940139358108108
val--9/100 [380/1090] acc: 0.7938939144736842
val--9/100 [390/1090] acc: 0.7936698717948718
val--9/100 [400/1090] acc: 0.79353515625
val--9/100 [410/1090] acc: 0.7937404725609756
val--9/100 [420/1090] acc: 0.7936755952380953
val--9/100 [430/1090] acc: 0.7934593023255814
val--9/100 [440/1090] acc: 0.7933771306818181
val--9/100 [450/1090] acc: 0.7932118055555556
val--9/100 [460/1090] acc: 0.793070652173913
val--9/100 [470/1090] acc: 0.7930269281914893
val--9/100 [480/1090] acc: 0.7931233723958333
val--9/100 [490/1090] acc: 0.7931999362244898
val--9/100 [500/1090] acc: 0.793328125
val--9/100 [510/1090] acc: 0.7932674632352941
val--9/100 [520/1090] acc: 0.7934044471153846
val--9/100 [530/1090] acc: 0.7934257075471698
val--9/100 [540/1090] acc: 0.7935908564814815
val--9/100 [550/1090] acc: 0.7934375
val--9/100 [560/1090] acc: 0.7932896205357143
val--9/100 [570/1090] acc: 0.7930441337719298
val--9/100 [580/1090] acc: 0.7930765086206897
val--9/100 [590/1090] acc: 0.7930813029661017
val--9/100 [600/1090] acc: 0.7931184895833333
val--9/100 [610/1090] acc: 0.7930519979508197
val--9/100 [620/1090] acc: 0.7929813508064516
val--9/100 [630/1090] acc: 0.7931299603174603
val--9/100 [640/1090] acc: 0.793304443359375
val--9/100 [650/1090] acc: 0.7933413461538461
val--9/100 [660/1090] acc: 0.7932410037878788
val--9/100 [670/1090] acc: 0.7929862406716418
val--9/100 [680/1090] acc: 0.7928825827205882
val--9/100 [690/1090] acc: 0.7930253623188406
val--9/100 [700/1090] acc: 0.7929854910714286
val--9/100 [710/1090] acc: 0.7927816901408451
val--9/100 [720/1090] acc: 0.7926378038194445
val--9/100 [730/1090] acc: 0.7925834760273973
val--9/100 [740/1090] acc: 0.7924144847972973
val--9/100 [750/1090] acc: 0.7925
val--9/100 [760/1090] acc: 0.7925935444078948
val--9/100 [770/1090] acc: 0.7925629058441559
val--9/100 [780/1090] acc: 0.7924879807692308
val--9/100 [790/1090] acc: 0.7925237341772152
val--9/100 [800/1090] acc: 0.7927587890625
val--9/100 [810/1090] acc: 0.7928433641975309
val--9/100 [820/1090] acc: 0.7929735137195122
val--9/100 [830/1090] acc: 0.7930487575301205
val--9/100 [840/1090] acc: 0.7929594494047619
val--9/100 [850/1090] acc: 0.7929871323529412
val--9/100 [860/1090] acc: 0.7932140261627907
val--9/100 [870/1090] acc: 0.7930675287356321
val--9/100 [880/1090] acc: 0.7930220170454545
val--9/100 [890/1090] acc: 0.7931750351123595
val--9/100 [900/1090] acc: 0.7931987847222223
val--9/100 [910/1090] acc: 0.7931833791208791
val--9/100 [920/1090] acc: 0.7932362432065218
val--9/100 [930/1090] acc: 0.793296370967742
val--9/100 [940/1090] acc: 0.7933136635638298
val--9/100 [950/1090] acc: 0.7932154605263158
val--9/100 [960/1090] acc: 0.7931396484375
val--9/100 [970/1090] acc: 0.7930734536082474
val--9/100 [980/1090] acc: 0.7930524553571429
val--9/100 [990/1090] acc: 0.7929884785353535
val--9/100 [1000/1090] acc: 0.7929140625
val--9/100 [1010/1090] acc: 0.7927792388613861
val--9/100 [1020/1090] acc: 0.7928691789215686
val--9/100 [1030/1090] acc: 0.7929042779126214
val--9/100 [1040/1090] acc: 0.7928936298076923
val--9/100 [1050/1090] acc: 0.7929092261904762
val--9/100 [1060/1090] acc: 0.7928729363207547
val--9/100 [1070/1090] acc: 0.7928920852803738
val--9/100 [1080/1090] acc: 0.7927915219907408
val--9/100 [1090/1090] acc: 0.7926211295871559
epoch= 9, accuracy= 0.792621, rmse= 0.379286, auc= 0.854019
train--10/100 [9/1090] loss: 0.4056197822093964
train--10/100 [19/1090] loss: 0.44895599484443666
train--10/100 [29/1090] loss: 0.44864691197872164
train--10/100 [39/1090] loss: 0.4509155422449112
train--10/100 [49/1090] loss: 0.45297324657440186
train--10/100 [59/1090] loss: 0.4419092059135437
train--10/100 [69/1090] loss: 0.41386653780937194
train--10/100 [79/1090] loss: 0.44140705466270447
train--10/100 [89/1090] loss: 0.4558847457170486
train--10/100 [99/1090] loss: 0.4565508455038071
train--10/100 [109/1090] loss: 0.44502879977226256
train--10/100 [119/1090] loss: 0.4446765035390854
train--10/100 [129/1090] loss: 0.4561108618974686
train--10/100 [139/1090] loss: 0.45225676596164704
train--10/100 [149/1090] loss: 0.45608808398246764
train--10/100 [159/1090] loss: 0.43943560421466826
train--10/100 [169/1090] loss: 0.45054305493831637
train--10/100 [179/1090] loss: 0.4384044945240021
train--10/100 [189/1090] loss: 0.4482463836669922
train--10/100 [199/1090] loss: 0.45720490217208865
train--10/100 [209/1090] loss: 0.43687001168727874
train--10/100 [219/1090] loss: 0.4305513113737106
train--10/100 [229/1090] loss: 0.45176714062690737
train--10/100 [239/1090] loss: 0.44552046358585357
train--10/100 [249/1090] loss: 0.45216272473335267
train--10/100 [259/1090] loss: 0.44835828244686127
train--10/100 [269/1090] loss: 0.44867420196533203
train--10/100 [279/1090] loss: 0.4540500998497009
train--10/100 [289/1090] loss: 0.44429426789283755
train--10/100 [299/1090] loss: 0.4347093731164932
train--10/100 [309/1090] loss: 0.43984802067279816
train--10/100 [319/1090] loss: 0.42476980984210966
train--10/100 [329/1090] loss: 0.4551376312971115
train--10/100 [339/1090] loss: 0.45625077486038207
train--10/100 [349/1090] loss: 0.4562269955873489
train--10/100 [359/1090] loss: 0.44937342703342437
train--10/100 [369/1090] loss: 0.45365357100963594
train--10/100 [379/1090] loss: 0.45550324618816374
train--10/100 [389/1090] loss: 0.4434975951910019
train--10/100 [399/1090] loss: 0.4462039083242416
train--10/100 [409/1090] loss: 0.4349309951066971
train--10/100 [419/1090] loss: 0.45888096988201144
train--10/100 [429/1090] loss: 0.4394310027360916
train--10/100 [439/1090] loss: 0.4394645899534225
train--10/100 [449/1090] loss: 0.4358904004096985
train--10/100 [459/1090] loss: 0.45891931653022766
train--10/100 [469/1090] loss: 0.45884408354759215
train--10/100 [479/1090] loss: 0.43892103135585786
train--10/100 [489/1090] loss: 0.44367570281028745
train--10/100 [499/1090] loss: 0.4550804555416107
train--10/100 [509/1090] loss: 0.4577113062143326
train--10/100 [519/1090] loss: 0.4484280675649643
train--10/100 [529/1090] loss: 0.45561741590499877
train--10/100 [539/1090] loss: 0.455090206861496
train--10/100 [549/1090] loss: 0.4458201378583908
train--10/100 [559/1090] loss: 0.4507465809583664
train--10/100 [569/1090] loss: 0.4274678289890289
train--10/100 [579/1090] loss: 0.4574654161930084
train--10/100 [589/1090] loss: 0.46662522852420807
train--10/100 [599/1090] loss: 0.45492579936981203
train--10/100 [609/1090] loss: 0.45302089154720304
train--10/100 [619/1090] loss: 0.4519847989082336
train--10/100 [629/1090] loss: 0.4345973521471024
train--10/100 [639/1090] loss: 0.45938592553138735
train--10/100 [649/1090] loss: 0.45842958986759186
train--10/100 [659/1090] loss: 0.45833668410778045
train--10/100 [669/1090] loss: 0.43494805693626404
train--10/100 [679/1090] loss: 0.44391224086284636
train--10/100 [689/1090] loss: 0.4612805932760239
train--10/100 [699/1090] loss: 0.4625213474035263
train--10/100 [709/1090] loss: 0.45002148747444154
train--10/100 [719/1090] loss: 0.44959643185138704
train--10/100 [729/1090] loss: 0.44929116070270536
train--10/100 [739/1090] loss: 0.4541869252920151
train--10/100 [749/1090] loss: 0.4552527666091919
train--10/100 [759/1090] loss: 0.4510419487953186
train--10/100 [769/1090] loss: 0.45124177932739257
train--10/100 [779/1090] loss: 0.42993037700653075
train--10/100 [789/1090] loss: 0.44694341719150543
train--10/100 [799/1090] loss: 0.44190182983875276
train--10/100 [809/1090] loss: 0.437576562166214
train--10/100 [819/1090] loss: 0.45949884355068205
train--10/100 [829/1090] loss: 0.47048010528087614
train--10/100 [839/1090] loss: 0.43870237171649934
train--10/100 [849/1090] loss: 0.45501543283462526
train--10/100 [859/1090] loss: 0.45337845385074615
train--10/100 [869/1090] loss: 0.47220798432826994
train--10/100 [879/1090] loss: 0.4468165248632431
train--10/100 [889/1090] loss: 0.4504748284816742
train--10/100 [899/1090] loss: 0.4475649356842041
train--10/100 [909/1090] loss: 0.46033055484294894
train--10/100 [919/1090] loss: 0.45409256815910337
train--10/100 [929/1090] loss: 0.4431202203035355
train--10/100 [939/1090] loss: 0.4450878471136093
train--10/100 [949/1090] loss: 0.4646557182073593
train--10/100 [959/1090] loss: 0.45687215626239774
train--10/100 [969/1090] loss: 0.45212812125682833
train--10/100 [979/1090] loss: 0.4559682339429855
train--10/100 [989/1090] loss: 0.4428712338209152
train--10/100 [999/1090] loss: 0.4708279013633728
train--10/100 [1009/1090] loss: 0.4521568775177002
train--10/100 [1019/1090] loss: 0.45089080929756165
train--10/100 [1029/1090] loss: 0.46425547301769254
train--10/100 [1039/1090] loss: 0.4411008387804031
train--10/100 [1049/1090] loss: 0.46728805303573606
train--10/100 [1059/1090] loss: 0.45886950492858886
train--10/100 [1069/1090] loss: 0.4619226515293121
train--10/100 [1079/1090] loss: 0.4758444607257843
train--10/100 [1089/1090] loss: 0.45312284529209135
predicting model...
val--10/100 [10/1090] acc: 0.790234375
val--10/100 [20/1090] acc: 0.7904296875
val--10/100 [30/1090] acc: 0.7904947916666667
val--10/100 [40/1090] acc: 0.78984375
val--10/100 [50/1090] acc: 0.789296875
val--10/100 [60/1090] acc: 0.7888671875
val--10/100 [70/1090] acc: 0.7891741071428572
val--10/100 [80/1090] acc: 0.78798828125
val--10/100 [90/1090] acc: 0.7884982638888889
val--10/100 [100/1090] acc: 0.789609375
val--10/100 [110/1090] acc: 0.789453125
val--10/100 [120/1090] acc: 0.7890950520833333
val--10/100 [130/1090] acc: 0.7901141826923077
val--10/100 [140/1090] acc: 0.7902064732142857
val--10/100 [150/1090] acc: 0.7905729166666666
val--10/100 [160/1090] acc: 0.7910400390625
val--10/100 [170/1090] acc: 0.7911534926470588
val--10/100 [180/1090] acc: 0.7908637152777778
val--10/100 [190/1090] acc: 0.7917763157894737
val--10/100 [200/1090] acc: 0.79212890625
val--10/100 [210/1090] acc: 0.7925409226190476
val--10/100 [220/1090] acc: 0.7917613636363636
val--10/100 [230/1090] acc: 0.7925271739130435
val--10/100 [240/1090] acc: 0.7924479166666667
val--10/100 [250/1090] acc: 0.79275
val--10/100 [260/1090] acc: 0.7928485576923077
val--10/100 [270/1090] acc: 0.7930700231481481
val--10/100 [280/1090] acc: 0.7931082589285714
val--10/100 [290/1090] acc: 0.7929956896551724
val--10/100 [300/1090] acc: 0.7928645833333333
val--10/100 [310/1090] acc: 0.7925655241935484
val--10/100 [320/1090] acc: 0.79278564453125
val--10/100 [330/1090] acc: 0.7930516098484849
val--10/100 [340/1090] acc: 0.7931985294117647
val--10/100 [350/1090] acc: 0.7933705357142857
val--10/100 [360/1090] acc: 0.7932725694444445
val--10/100 [370/1090] acc: 0.793359375
val--10/100 [380/1090] acc: 0.7932668585526316
val--10/100 [390/1090] acc: 0.7930088141025641
val--10/100 [400/1090] acc: 0.792900390625
val--10/100 [410/1090] acc: 0.7931021341463415
val--10/100 [420/1090] acc: 0.7931082589285714
val--10/100 [430/1090] acc: 0.79296875
val--10/100 [440/1090] acc: 0.7929865056818182
val--10/100 [450/1090] acc: 0.7929079861111111
val--10/100 [460/1090] acc: 0.7928074048913043
val--10/100 [470/1090] acc: 0.7927775930851064
val--10/100 [480/1090] acc: 0.7928792317708333
val--10/100 [490/1090] acc: 0.7930325255102041
val--10/100 [500/1090] acc: 0.793140625
val--10/100 [510/1090] acc: 0.7930759803921569
val--10/100 [520/1090] acc: 0.7933143028846154
val--10/100 [530/1090] acc: 0.7933667452830189
val--10/100 [540/1090] acc: 0.7934678819444444
val--10/100 [550/1090] acc: 0.7932954545454546
val--10/100 [560/1090] acc: 0.793212890625
val--10/100 [570/1090] acc: 0.7930030153508771
val--10/100 [580/1090] acc: 0.7930495689655173
val--10/100 [590/1090] acc: 0.793068061440678
val--10/100 [600/1090] acc: 0.7930794270833333
val--10/100 [610/1090] acc: 0.7929367315573771
val--10/100 [620/1090] acc: 0.7927734375
val--10/100 [630/1090] acc: 0.7930059523809524
val--10/100 [640/1090] acc: 0.793157958984375
val--10/100 [650/1090] acc: 0.7931790865384616
val--10/100 [660/1090] acc: 0.7930752840909091
val--10/100 [670/1090] acc: 0.7927588619402985
val--10/100 [680/1090] acc: 0.7926355698529411
val--10/100 [690/1090] acc: 0.7928045742753623
val--10/100 [700/1090] acc: 0.7928069196428571
val--10/100 [710/1090] acc: 0.7926221390845071
val--10/100 [720/1090] acc: 0.7925021701388889
val--10/100 [730/1090] acc: 0.7924175941780822
val--10/100 [740/1090] acc: 0.7923300253378378
val--10/100 [750/1090] acc: 0.7923854166666666
val--10/100 [760/1090] acc: 0.79248046875
val--10/100 [770/1090] acc: 0.7924969561688312
val--10/100 [780/1090] acc: 0.7924479166666667
val--10/100 [790/1090] acc: 0.7925089003164557
val--10/100 [800/1090] acc: 0.7926611328125
val--10/100 [810/1090] acc: 0.7926890432098765
val--10/100 [820/1090] acc: 0.7927686737804878
val--10/100 [830/1090] acc: 0.7928699171686747
val--10/100 [840/1090] acc: 0.7928245907738095
val--10/100 [850/1090] acc: 0.7928125
val--10/100 [860/1090] acc: 0.7930732194767441
val--10/100 [870/1090] acc: 0.7929552801724138
val--10/100 [880/1090] acc: 0.792911044034091
val--10/100 [890/1090] acc: 0.7930258075842697
val--10/100 [900/1090] acc: 0.7930512152777778
val--10/100 [910/1090] acc: 0.793041723901099
val--10/100 [920/1090] acc: 0.7930961277173914
val--10/100 [930/1090] acc: 0.7931997647849462
val--10/100 [940/1090] acc: 0.7932471742021276
val--10/100 [950/1090] acc: 0.793125
val--10/100 [960/1090] acc: 0.79307861328125
val--10/100 [970/1090] acc: 0.7930291559278351
val--10/100 [980/1090] acc: 0.7930404974489796
val--10/100 [990/1090] acc: 0.7929450757575758
val--10/100 [1000/1090] acc: 0.79291015625
val--10/100 [1010/1090] acc: 0.7927831064356435
val--10/100 [1020/1090] acc: 0.7928576899509804
val--10/100 [1030/1090] acc: 0.7929004854368932
val--10/100 [1040/1090] acc: 0.7928973858173077
val--10/100 [1050/1090] acc: 0.7929799107142858
val--10/100 [1060/1090] acc: 0.7929318985849056
val--10/100 [1070/1090] acc: 0.7929614485981309
val--10/100 [1080/1090] acc: 0.7929036458333333
val--10/100 [1090/1090] acc: 0.7927465596330275
epoch= 10, accuracy= 0.792747, rmse= 0.379339, auc= 0.853903
train--11/100 [9/1090] loss: 0.3945758819580078
train--11/100 [19/1090] loss: 0.44389925301074984
train--11/100 [29/1090] loss: 0.4451084226369858
train--11/100 [39/1090] loss: 0.45488002002239225
train--11/100 [49/1090] loss: 0.4552305579185486
train--11/100 [59/1090] loss: 0.4442280411720276
train--11/100 [69/1090] loss: 0.4636033266782761
train--11/100 [79/1090] loss: 0.45679461061954496
train--11/100 [89/1090] loss: 0.44775902628898623
train--11/100 [99/1090] loss: 0.43733606934547425
train--11/100 [109/1090] loss: 0.44306878447532655
train--11/100 [119/1090] loss: 0.45093482434749604
train--11/100 [129/1090] loss: 0.4632472962141037
train--11/100 [139/1090] loss: 0.4372185796499252
train--11/100 [149/1090] loss: 0.4524225205183029
train--11/100 [159/1090] loss: 0.4541248708963394
train--11/100 [169/1090] loss: 0.43585286736488343
train--11/100 [179/1090] loss: 0.44264154732227323
train--11/100 [189/1090] loss: 0.4342934817075729
train--11/100 [199/1090] loss: 0.4507502049207687
train--11/100 [209/1090] loss: 0.4528414875268936
train--11/100 [219/1090] loss: 0.43268164396286013
train--11/100 [229/1090] loss: 0.4487107485532761
train--11/100 [239/1090] loss: 0.45957723557949065
train--11/100 [249/1090] loss: 0.4553305596113205
train--11/100 [259/1090] loss: 0.4351175367832184
train--11/100 [269/1090] loss: 0.44693297147750854
train--11/100 [279/1090] loss: 0.4483988732099533
train--11/100 [289/1090] loss: 0.45318691432476044
train--11/100 [299/1090] loss: 0.4497318834066391
train--11/100 [309/1090] loss: 0.4466075152158737
train--11/100 [319/1090] loss: 0.43714450001716615
train--11/100 [329/1090] loss: 0.44712035059928895
train--11/100 [339/1090] loss: 0.4364337831735611
train--11/100 [349/1090] loss: 0.42951480746269227
train--11/100 [359/1090] loss: 0.44945210218429565
train--11/100 [369/1090] loss: 0.47463188171386717
train--11/100 [379/1090] loss: 0.4395498514175415
train--11/100 [389/1090] loss: 0.4445200443267822
train--11/100 [399/1090] loss: 0.42676165997982024
train--11/100 [409/1090] loss: 0.453973251581192
train--11/100 [419/1090] loss: 0.44413272738456727
train--11/100 [429/1090] loss: 0.4483058452606201
train--11/100 [439/1090] loss: 0.44344825446605685
train--11/100 [449/1090] loss: 0.4455864876508713
train--11/100 [459/1090] loss: 0.44183850586414336
train--11/100 [469/1090] loss: 0.4385249435901642
train--11/100 [479/1090] loss: 0.4425320953130722
train--11/100 [489/1090] loss: 0.4495188772678375
train--11/100 [499/1090] loss: 0.4558432251214981
train--11/100 [509/1090] loss: 0.4610324829816818
train--11/100 [519/1090] loss: 0.4557413637638092
train--11/100 [529/1090] loss: 0.459365451335907
train--11/100 [539/1090] loss: 0.4240081340074539
train--11/100 [549/1090] loss: 0.4368469148874283
train--11/100 [559/1090] loss: 0.4579542398452759
train--11/100 [569/1090] loss: 0.4611365169286728
train--11/100 [579/1090] loss: 0.43389495015144347
train--11/100 [589/1090] loss: 0.4471477657556534
train--11/100 [599/1090] loss: 0.4770697444677353
train--11/100 [609/1090] loss: 0.4516161948442459
train--11/100 [619/1090] loss: 0.4447456121444702
train--11/100 [629/1090] loss: 0.4383338361978531
train--11/100 [639/1090] loss: 0.4755386531352997
train--11/100 [649/1090] loss: 0.4486635386943817
train--11/100 [659/1090] loss: 0.4294892132282257
train--11/100 [669/1090] loss: 0.45900851786136626
train--11/100 [679/1090] loss: 0.46704687774181364
train--11/100 [689/1090] loss: 0.4672462075948715
train--11/100 [699/1090] loss: 0.448064860701561
train--11/100 [709/1090] loss: 0.45417900681495665
train--11/100 [719/1090] loss: 0.4471417784690857
train--11/100 [729/1090] loss: 0.4334826171398163
train--11/100 [739/1090] loss: 0.4456695348024368
train--11/100 [749/1090] loss: 0.4610936552286148
train--11/100 [759/1090] loss: 0.4419751226902008
train--11/100 [769/1090] loss: 0.4630886882543564
train--11/100 [779/1090] loss: 0.45757746398448945
train--11/100 [789/1090] loss: 0.4606936901807785
train--11/100 [799/1090] loss: 0.458310604095459
train--11/100 [809/1090] loss: 0.47675045728683474
train--11/100 [819/1090] loss: 0.4586242586374283
train--11/100 [829/1090] loss: 0.4587049901485443
train--11/100 [839/1090] loss: 0.43980401158332827
train--11/100 [849/1090] loss: 0.4527195870876312
train--11/100 [859/1090] loss: 0.4440786600112915
train--11/100 [869/1090] loss: 0.45682930052280424
train--11/100 [879/1090] loss: 0.4629820972681046
train--11/100 [889/1090] loss: 0.4518634170293808
train--11/100 [899/1090] loss: 0.44912256598472594
train--11/100 [909/1090] loss: 0.4514788031578064
train--11/100 [919/1090] loss: 0.43390185534954073
train--11/100 [929/1090] loss: 0.4545144081115723
train--11/100 [939/1090] loss: 0.4611737698316574
train--11/100 [949/1090] loss: 0.4511573910713196
train--11/100 [959/1090] loss: 0.4823770135641098
train--11/100 [969/1090] loss: 0.45937506556510926
train--11/100 [979/1090] loss: 0.4389737218618393
train--11/100 [989/1090] loss: 0.4419155716896057
train--11/100 [999/1090] loss: 0.453224316239357
train--11/100 [1009/1090] loss: 0.42942322194576266
train--11/100 [1019/1090] loss: 0.45647085309028623
train--11/100 [1029/1090] loss: 0.4674908846616745
train--11/100 [1039/1090] loss: 0.45308551788330076
train--11/100 [1049/1090] loss: 0.4297319740056992
train--11/100 [1059/1090] loss: 0.4536062926054001
train--11/100 [1069/1090] loss: 0.4547443360090256
train--11/100 [1079/1090] loss: 0.4527235597372055
train--11/100 [1089/1090] loss: 0.46506834030151367
predicting model...
val--11/100 [10/1090] acc: 0.790234375
val--11/100 [20/1090] acc: 0.79140625
val--11/100 [30/1090] acc: 0.7912760416666667
val--11/100 [40/1090] acc: 0.79189453125
val--11/100 [50/1090] acc: 0.79078125
val--11/100 [60/1090] acc: 0.78984375
val--11/100 [70/1090] acc: 0.7907366071428571
val--11/100 [80/1090] acc: 0.789306640625
val--11/100 [90/1090] acc: 0.7899305555555556
val--11/100 [100/1090] acc: 0.7909765625
val--11/100 [110/1090] acc: 0.7909446022727272
val--11/100 [120/1090] acc: 0.7904622395833333
val--11/100 [130/1090] acc: 0.7915564903846154
val--11/100 [140/1090] acc: 0.7918526785714286
val--11/100 [150/1090] acc: 0.7918489583333334
val--11/100 [160/1090] acc: 0.7921142578125
val--11/100 [170/1090] acc: 0.7923253676470589
val--11/100 [180/1090] acc: 0.7919270833333333
val--11/100 [190/1090] acc: 0.7926603618421053
val--11/100 [200/1090] acc: 0.7930078125
val--11/100 [210/1090] acc: 0.7933965773809524
val--11/100 [220/1090] acc: 0.7926491477272727
val--11/100 [230/1090] acc: 0.7933084239130435
val--11/100 [240/1090] acc: 0.7930501302083334
val--11/100 [250/1090] acc: 0.793421875
val--11/100 [260/1090] acc: 0.7934194711538461
val--11/100 [270/1090] acc: 0.7934461805555556
val--11/100 [280/1090] acc: 0.7935965401785714
val--11/100 [290/1090] acc: 0.7935479525862069
val--11/100 [300/1090] acc: 0.7935286458333334
val--11/100 [310/1090] acc: 0.7932081653225806
val--11/100 [320/1090] acc: 0.79356689453125
val--11/100 [330/1090] acc: 0.7937144886363636
val--11/100 [340/1090] acc: 0.7938419117647059
val--11/100 [350/1090] acc: 0.7939955357142857
val--11/100 [360/1090] acc: 0.7938368055555556
val--11/100 [370/1090] acc: 0.7938872466216216
val--11/100 [380/1090] acc: 0.79375
val--11/100 [390/1090] acc: 0.7934795673076923
val--11/100 [400/1090] acc: 0.793310546875
val--11/100 [410/1090] acc: 0.7934546493902439
val--11/100 [420/1090] acc: 0.7934988839285714
val--11/100 [430/1090] acc: 0.7933230377906977
val--11/100 [440/1090] acc: 0.7933238636363636
val--11/100 [450/1090] acc: 0.7931597222222222
val--11/100 [460/1090] acc: 0.7930366847826087
val--11/100 [470/1090] acc: 0.7929105718085107
val--11/100 [480/1090] acc: 0.79296875
val--11/100 [490/1090] acc: 0.7931202168367347
val--11/100 [500/1090] acc: 0.7934140625
val--11/100 [510/1090] acc: 0.793344056372549
val--11/100 [520/1090] acc: 0.7935471754807693
val--11/100 [530/1090] acc: 0.7935731132075472
val--11/100 [540/1090] acc: 0.79375
val--11/100 [550/1090] acc: 0.7935795454545455
val--11/100 [560/1090] acc: 0.7934151785714286
val--11/100 [570/1090] acc: 0.7931949013157895
val--11/100 [580/1090] acc: 0.7931707974137931
val--11/100 [590/1090] acc: 0.7932004766949152
val--11/100 [600/1090] acc: 0.7932421875
val--11/100 [610/1090] acc: 0.7931160348360655
val--11/100 [620/1090] acc: 0.7930128528225806
val--11/100 [630/1090] acc: 0.7931733630952381
val--11/100 [640/1090] acc: 0.793389892578125
val--11/100 [650/1090] acc: 0.7934194711538461
val--11/100 [660/1090] acc: 0.7933120265151515
val--11/100 [670/1090] acc: 0.7930095615671642
val--11/100 [680/1090] acc: 0.7928940716911764
val--11/100 [690/1090] acc: 0.793070652173913
val--11/100 [700/1090] acc: 0.7930301339285715
val--11/100 [710/1090] acc: 0.7928367077464789
val--11/100 [720/1090] acc: 0.7926703559027778
val--11/100 [730/1090] acc: 0.7925460188356165
val--11/100 [740/1090] acc: 0.7924250422297298
val--11/100 [750/1090] acc: 0.7924739583333333
val--11/100 [760/1090] acc: 0.7925678453947368
val--11/100 [770/1090] acc: 0.7925629058441559
val--11/100 [780/1090] acc: 0.7924979967948718
val--11/100 [790/1090] acc: 0.7925583465189874
val--11/100 [800/1090] acc: 0.7927685546875
val--11/100 [810/1090] acc: 0.7928337191358025
val--11/100 [820/1090] acc: 0.7929163490853659
val--11/100 [830/1090] acc: 0.7930393448795181
val--11/100 [840/1090] acc: 0.7929780505952381
val--11/100 [850/1090] acc: 0.7929871323529412
val--11/100 [860/1090] acc: 0.793227652616279
val--11/100 [870/1090] acc: 0.7930675287356321
val--11/100 [880/1090] acc: 0.7930708451704546
val--11/100 [890/1090] acc: 0.793236481741573
val--11/100 [900/1090] acc: 0.7932508680555556
val--11/100 [910/1090] acc: 0.793277815934066
val--11/100 [920/1090] acc: 0.7933084239130435
val--11/100 [930/1090] acc: 0.7933425739247312
val--11/100 [940/1090] acc: 0.7933801529255319
val--11/100 [950/1090] acc: 0.7932401315789473
val--11/100 [960/1090] acc: 0.7931966145833333
val--11/100 [970/1090] acc: 0.7931378865979382
val--11/100 [980/1090] acc: 0.793180006377551
val--11/100 [990/1090] acc: 0.7930950126262626
val--11/100 [1000/1090] acc: 0.79299609375
val--11/100 [1010/1090] acc: 0.7928836633663366
val--11/100 [1020/1090] acc: 0.7929572610294118
val--11/100 [1030/1090] acc: 0.793018052184466
val--11/100 [1040/1090] acc: 0.7930025540865384
val--11/100 [1050/1090] acc: 0.7930840773809524
val--11/100 [1060/1090] acc: 0.7930019162735849
val--11/100 [1070/1090] acc: 0.7930308119158879
val--11/100 [1080/1090] acc: 0.7929361979166667
val--11/100 [1090/1090] acc: 0.7927823967889909
epoch= 11, accuracy= 0.792782, rmse= 0.379371, auc= 0.853979
train--12/100 [9/1090] loss: 0.403079017996788
train--12/100 [19/1090] loss: 0.43578473627567293
train--12/100 [29/1090] loss: 0.42799279987812044
train--12/100 [39/1090] loss: 0.45226877331733706
train--12/100 [49/1090] loss: 0.431783464550972
train--12/100 [59/1090] loss: 0.4540013372898102
train--12/100 [69/1090] loss: 0.45472487807273865
train--12/100 [79/1090] loss: 0.4523295223712921
train--12/100 [89/1090] loss: 0.4427377015352249
train--12/100 [99/1090] loss: 0.4314895659685135
train--12/100 [109/1090] loss: 0.44721253514289855
train--12/100 [119/1090] loss: 0.44587782919406893
train--12/100 [129/1090] loss: 0.4733213633298874
train--12/100 [139/1090] loss: 0.43903779685497285
train--12/100 [149/1090] loss: 0.4508894383907318
train--12/100 [159/1090] loss: 0.47024606466293334
train--12/100 [169/1090] loss: 0.43409968316555025
train--12/100 [179/1090] loss: 0.44027045667171477
train--12/100 [189/1090] loss: 0.4310304015874863
train--12/100 [199/1090] loss: 0.4520699232816696
train--12/100 [209/1090] loss: 0.4335024803876877
train--12/100 [219/1090] loss: 0.4438395857810974
train--12/100 [229/1090] loss: 0.4483807921409607
train--12/100 [239/1090] loss: 0.44766064286231994
train--12/100 [249/1090] loss: 0.4489876598119736
train--12/100 [259/1090] loss: 0.43132597506046294
train--12/100 [269/1090] loss: 0.4363873779773712
train--12/100 [279/1090] loss: 0.44984031319618223
train--12/100 [289/1090] loss: 0.44147099554538727
train--12/100 [299/1090] loss: 0.454400908946991
train--12/100 [309/1090] loss: 0.4472770422697067
train--12/100 [319/1090] loss: 0.4590510994195938
train--12/100 [329/1090] loss: 0.45208523273468015
train--12/100 [339/1090] loss: 0.4400548726320267
train--12/100 [349/1090] loss: 0.46561203598976136
train--12/100 [359/1090] loss: 0.44932381212711336
train--12/100 [369/1090] loss: 0.43911377489566805
train--12/100 [379/1090] loss: 0.4460591167211533
train--12/100 [389/1090] loss: 0.4597362488508224
train--12/100 [399/1090] loss: 0.4250397115945816
train--12/100 [409/1090] loss: 0.4411826580762863
train--12/100 [419/1090] loss: 0.4530003905296326
train--12/100 [429/1090] loss: 0.4488825261592865
train--12/100 [439/1090] loss: 0.4525381803512573
train--12/100 [449/1090] loss: 0.4527126342058182
train--12/100 [459/1090] loss: 0.43464417159557345
train--12/100 [469/1090] loss: 0.44880477488040926
train--12/100 [479/1090] loss: 0.4370226711034775
train--12/100 [489/1090] loss: 0.4558157712221146
train--12/100 [499/1090] loss: 0.42739946842193605
train--12/100 [509/1090] loss: 0.4501142859458923
train--12/100 [519/1090] loss: 0.4555804759263992
train--12/100 [529/1090] loss: 0.45336365699768066
train--12/100 [539/1090] loss: 0.4504579156637192
train--12/100 [549/1090] loss: 0.46975277364254
train--12/100 [559/1090] loss: 0.4357593387365341
train--12/100 [569/1090] loss: 0.43500063717365267
train--12/100 [579/1090] loss: 0.4454493522644043
train--12/100 [589/1090] loss: 0.4696424424648285
train--12/100 [599/1090] loss: 0.4556440621614456
train--12/100 [609/1090] loss: 0.47364217042922974
train--12/100 [619/1090] loss: 0.45268199145793914
train--12/100 [629/1090] loss: 0.4484508067369461
train--12/100 [639/1090] loss: 0.4568017512559891
train--12/100 [649/1090] loss: 0.47690860033035276
train--12/100 [659/1090] loss: 0.44996402859687806
train--12/100 [669/1090] loss: 0.42321681380271914
train--12/100 [679/1090] loss: 0.46079556941986083
train--12/100 [689/1090] loss: 0.4456645339727402
train--12/100 [699/1090] loss: 0.46187969148159025
train--12/100 [709/1090] loss: 0.44750105440616605
train--12/100 [719/1090] loss: 0.45369447469711305
train--12/100 [729/1090] loss: 0.45289078652858733
train--12/100 [739/1090] loss: 0.468785834312439
train--12/100 [749/1090] loss: 0.4494685232639313
train--12/100 [759/1090] loss: 0.44627898931503296
train--12/100 [769/1090] loss: 0.4547319829463959
train--12/100 [779/1090] loss: 0.45714370012283323
train--12/100 [789/1090] loss: 0.4338148385286331
train--12/100 [799/1090] loss: 0.4478096753358841
train--12/100 [809/1090] loss: 0.4581024140119553
train--12/100 [819/1090] loss: 0.4474072605371475
train--12/100 [829/1090] loss: 0.4433800369501114
train--12/100 [839/1090] loss: 0.45313612520694735
train--12/100 [849/1090] loss: 0.43854102194309236
train--12/100 [859/1090] loss: 0.4352298557758331
train--12/100 [869/1090] loss: 0.47018552422523496
train--12/100 [879/1090] loss: 0.4609850734472275
train--12/100 [889/1090] loss: 0.4363636583089828
train--12/100 [899/1090] loss: 0.4739332258701324
train--12/100 [909/1090] loss: 0.4575439214706421
train--12/100 [919/1090] loss: 0.4696365773677826
train--12/100 [929/1090] loss: 0.4319079011678696
train--12/100 [939/1090] loss: 0.45503805577754974
train--12/100 [949/1090] loss: 0.44782550632953644
train--12/100 [959/1090] loss: 0.4353821575641632
train--12/100 [969/1090] loss: 0.45944333970546725
train--12/100 [979/1090] loss: 0.4609257638454437
train--12/100 [989/1090] loss: 0.4387591630220413
train--12/100 [999/1090] loss: 0.4615672558546066
train--12/100 [1009/1090] loss: 0.456859290599823
train--12/100 [1019/1090] loss: 0.4535889118909836
train--12/100 [1029/1090] loss: 0.4718445062637329
train--12/100 [1039/1090] loss: 0.45077902674674986
train--12/100 [1049/1090] loss: 0.4428642362356186
train--12/100 [1059/1090] loss: 0.4558938890695572
train--12/100 [1069/1090] loss: 0.46206981837749483
train--12/100 [1079/1090] loss: 0.47582985162734986
train--12/100 [1089/1090] loss: 0.4492030739784241
predicting model...
val--12/100 [10/1090] acc: 0.79140625
val--12/100 [20/1090] acc: 0.7927734375
val--12/100 [30/1090] acc: 0.79140625
val--12/100 [40/1090] acc: 0.79169921875
val--12/100 [50/1090] acc: 0.790703125
val--12/100 [60/1090] acc: 0.7902994791666667
val--12/100 [70/1090] acc: 0.7910714285714285
val--12/100 [80/1090] acc: 0.789990234375
val--12/100 [90/1090] acc: 0.7905381944444444
val--12/100 [100/1090] acc: 0.7915625
val--12/100 [110/1090] acc: 0.791690340909091
val--12/100 [120/1090] acc: 0.7914713541666667
val--12/100 [130/1090] acc: 0.7925480769230769
val--12/100 [140/1090] acc: 0.7928013392857143
val--12/100 [150/1090] acc: 0.7929166666666667
val--12/100 [160/1090] acc: 0.793310546875
val--12/100 [170/1090] acc: 0.793405330882353
val--12/100 [180/1090] acc: 0.7931857638888888
val--12/100 [190/1090] acc: 0.7937705592105263
val--12/100 [200/1090] acc: 0.7940234375
val--12/100 [210/1090] acc: 0.794233630952381
val--12/100 [220/1090] acc: 0.793270596590909
val--12/100 [230/1090] acc: 0.7939198369565217
val--12/100 [240/1090] acc: 0.7937825520833334
val--12/100 [250/1090] acc: 0.793984375
val--12/100 [260/1090] acc: 0.7939753605769231
val--12/100 [270/1090] acc: 0.7941550925925925
val--12/100 [280/1090] acc: 0.7940708705357142
val--12/100 [290/1090] acc: 0.7939116379310345
val--12/100 [300/1090] acc: 0.7939453125
val--12/100 [310/1090] acc: 0.7935105846774193
val--12/100 [320/1090] acc: 0.79381103515625
val--12/100 [330/1090] acc: 0.794045928030303
val--12/100 [340/1090] acc: 0.7942440257352941
val--12/100 [350/1090] acc: 0.7943415178571429
val--12/100 [360/1090] acc: 0.7942708333333334
val--12/100 [370/1090] acc: 0.7943517736486486
val--12/100 [380/1090] acc: 0.7943462171052632
val--12/100 [390/1090] acc: 0.7941306089743589
val--12/100 [400/1090] acc: 0.794013671875
val--12/100 [410/1090] acc: 0.7942073170731707
val--12/100 [420/1090] acc: 0.794233630952381
val--12/100 [430/1090] acc: 0.7940679505813953
val--12/100 [440/1090] acc: 0.794140625
val--12/100 [450/1090] acc: 0.7940017361111111
val--12/100 [460/1090] acc: 0.7938858695652173
val--12/100 [470/1090] acc: 0.7938248005319148
val--12/100 [480/1090] acc: 0.7938720703125
val--12/100 [490/1090] acc: 0.7939732142857143
val--12/100 [500/1090] acc: 0.7941484375
val--12/100 [510/1090] acc: 0.7940716911764706
val--12/100 [520/1090] acc: 0.7942608173076923
val--12/100 [530/1090] acc: 0.7942438089622641
val--12/100 [540/1090] acc: 0.7943793402777778
val--12/100 [550/1090] acc: 0.7942826704545455
val--12/100 [560/1090] acc: 0.79404296875
val--12/100 [570/1090] acc: 0.7937979714912281
val--12/100 [580/1090] acc: 0.7937432650862069
val--12/100 [590/1090] acc: 0.7937831038135593
val--12/100 [600/1090] acc: 0.793828125
val--12/100 [610/1090] acc: 0.79375
val--12/100 [620/1090] acc: 0.7936239919354838
val--12/100 [630/1090] acc: 0.7938492063492063
val--12/100 [640/1090] acc: 0.79405517578125
val--12/100 [650/1090] acc: 0.7940805288461539
val--12/100 [660/1090] acc: 0.7939808238636363
val--12/100 [670/1090] acc: 0.7937033582089552
val--12/100 [680/1090] acc: 0.7936236213235294
val--12/100 [690/1090] acc: 0.7937839673913043
val--12/100 [700/1090] acc: 0.7937834821428571
val--12/100 [710/1090] acc: 0.7935354313380282
val--12/100 [720/1090] acc: 0.7933539496527777
val--12/100 [730/1090] acc: 0.793316566780822
val--12/100 [740/1090] acc: 0.7931957347972973
val--12/100 [750/1090] acc: 0.79328125
val--12/100 [760/1090] acc: 0.7933799342105263
val--12/100 [770/1090] acc: 0.7933543019480519
val--12/100 [780/1090] acc: 0.7933243189102565
val--12/100 [790/1090] acc: 0.7933643196202531
val--12/100 [800/1090] acc: 0.7935986328125
val--12/100 [810/1090] acc: 0.7936824845679012
val--12/100 [820/1090] acc: 0.793797637195122
val--12/100 [830/1090] acc: 0.7938864834337349
val--12/100 [840/1090] acc: 0.7937965029761904
val--12/100 [850/1090] acc: 0.7937821691176471
val--12/100 [860/1090] acc: 0.7939816497093023
val--12/100 [870/1090] acc: 0.7938218390804598
val--12/100 [880/1090] acc: 0.7938210227272727
val--12/100 [890/1090] acc: 0.7939694522471911
val--12/100 [900/1090] acc: 0.7939713541666666
val--12/100 [910/1090] acc: 0.793986092032967
val--12/100 [920/1090] acc: 0.7939835258152174
val--12/100 [930/1090] acc: 0.7940272177419355
val--12/100 [940/1090] acc: 0.7940575132978723
val--12/100 [950/1090] acc: 0.7939309210526316
val--12/100 [960/1090] acc: 0.7938557942708333
val--12/100 [970/1090] acc: 0.7938144329896907
val--12/100 [980/1090] acc: 0.7938257334183674
val--12/100 [990/1090] acc: 0.7937342171717172
val--12/100 [1000/1090] acc: 0.79365234375
val--12/100 [1010/1090] acc: 0.7935218131188119
val--12/100 [1020/1090] acc: 0.7935814950980392
val--12/100 [1030/1090] acc: 0.7936096783980583
val--12/100 [1040/1090] acc: 0.7935546875
val--12/100 [1050/1090] acc: 0.7936049107142857
val--12/100 [1060/1090] acc: 0.7935436320754717
val--12/100 [1070/1090] acc: 0.7935382593457944
val--12/100 [1080/1090] acc: 0.7934497974537037
val--12/100 [1090/1090] acc: 0.7932661983944954
epoch= 12, accuracy= 0.793266, rmse= 0.379247, auc= 0.854108
train--13/100 [9/1090] loss: 0.39635433852672575
train--13/100 [19/1090] loss: 0.4370824545621872
train--13/100 [29/1090] loss: 0.44277445673942567
train--13/100 [39/1090] loss: 0.43975635766983034
train--13/100 [49/1090] loss: 0.4407354980707169
train--13/100 [59/1090] loss: 0.4483975499868393
train--13/100 [69/1090] loss: 0.42599834203720094
train--13/100 [79/1090] loss: 0.4465169161558151
train--13/100 [89/1090] loss: 0.4590893805027008
train--13/100 [99/1090] loss: 0.4458692342042923
train--13/100 [109/1090] loss: 0.4576194703578949
train--13/100 [119/1090] loss: 0.4249995917081833
train--13/100 [129/1090] loss: 0.43790275454521177
train--13/100 [139/1090] loss: 0.4400805115699768
train--13/100 [149/1090] loss: 0.4240118056535721
train--13/100 [159/1090] loss: 0.4334201842546463
train--13/100 [169/1090] loss: 0.44070177972316743
train--13/100 [179/1090] loss: 0.4392446309328079
train--13/100 [189/1090] loss: 0.4470835506916046
train--13/100 [199/1090] loss: 0.44252529442310334
train--13/100 [209/1090] loss: 0.44594381749629974
train--13/100 [219/1090] loss: 0.43974292278289795
train--13/100 [229/1090] loss: 0.4414379358291626
train--13/100 [239/1090] loss: 0.43998666703701017
train--13/100 [249/1090] loss: 0.45940235555171965
train--13/100 [259/1090] loss: 0.449474036693573
train--13/100 [269/1090] loss: 0.4505364835262299
train--13/100 [279/1090] loss: 0.4388727813959122
train--13/100 [289/1090] loss: 0.4573128640651703
train--13/100 [299/1090] loss: 0.4291948229074478
train--13/100 [309/1090] loss: 0.4471900641918182
train--13/100 [319/1090] loss: 0.4493466138839722
train--13/100 [329/1090] loss: 0.4611514925956726
train--13/100 [339/1090] loss: 0.4472484439611435
train--13/100 [349/1090] loss: 0.45220525860786437
train--13/100 [359/1090] loss: 0.4543613135814667
train--13/100 [369/1090] loss: 0.467102512717247
train--13/100 [379/1090] loss: 0.43994310200214387
train--13/100 [389/1090] loss: 0.43631338477134707
train--13/100 [399/1090] loss: 0.42857580482959745
train--13/100 [409/1090] loss: 0.45389568209648135
train--13/100 [419/1090] loss: 0.44054403603076936
train--13/100 [429/1090] loss: 0.4368202298879623
train--13/100 [439/1090] loss: 0.46317440569400786
train--13/100 [449/1090] loss: 0.47207197546958923
train--13/100 [459/1090] loss: 0.45505430996418
train--13/100 [469/1090] loss: 0.45365172028541567
train--13/100 [479/1090] loss: 0.461185222864151
train--13/100 [489/1090] loss: 0.4294501692056656
train--13/100 [499/1090] loss: 0.46601179242134094
train--13/100 [509/1090] loss: 0.45780273973941804
train--13/100 [519/1090] loss: 0.4541570723056793
train--13/100 [529/1090] loss: 0.4395016938447952
train--13/100 [539/1090] loss: 0.4348250240087509
train--13/100 [549/1090] loss: 0.46303907930850985
train--13/100 [559/1090] loss: 0.4636294305324554
train--13/100 [569/1090] loss: 0.4366565078496933
train--13/100 [579/1090] loss: 0.45497213304042816
train--13/100 [589/1090] loss: 0.43844262063503264
train--13/100 [599/1090] loss: 0.4490940719842911
train--13/100 [609/1090] loss: 0.44359070658683775
train--13/100 [619/1090] loss: 0.45456208288669586
train--13/100 [629/1090] loss: 0.4493951141834259
train--13/100 [639/1090] loss: 0.44876353442668915
train--13/100 [649/1090] loss: 0.46797473430633546
train--13/100 [659/1090] loss: 0.44489592015743257
train--13/100 [669/1090] loss: 0.44369418919086456
train--13/100 [679/1090] loss: 0.4710466742515564
train--13/100 [689/1090] loss: 0.46192157864570615
train--13/100 [699/1090] loss: 0.4592494547367096
train--13/100 [709/1090] loss: 0.45187422931194304
train--13/100 [719/1090] loss: 0.4423787772655487
train--13/100 [729/1090] loss: 0.4505952954292297
train--13/100 [739/1090] loss: 0.4484244793653488
train--13/100 [749/1090] loss: 0.4642947971820831
train--13/100 [759/1090] loss: 0.4531440645456314
train--13/100 [769/1090] loss: 0.4540868490934372
train--13/100 [779/1090] loss: 0.46620288491249084
train--13/100 [789/1090] loss: 0.4488965541124344
train--13/100 [799/1090] loss: 0.45243691802024844
train--13/100 [809/1090] loss: 0.4365661710500717
train--13/100 [819/1090] loss: 0.47095140516757966
train--13/100 [829/1090] loss: 0.4482520312070847
train--13/100 [839/1090] loss: 0.4450865775346756
train--13/100 [849/1090] loss: 0.47071432769298555
train--13/100 [859/1090] loss: 0.4555103421211243
train--13/100 [869/1090] loss: 0.44511294066905976
train--13/100 [879/1090] loss: 0.4619275003671646
train--13/100 [889/1090] loss: 0.46269677877426146
train--13/100 [899/1090] loss: 0.4424478650093079
train--13/100 [909/1090] loss: 0.44449540674686433
train--13/100 [919/1090] loss: 0.45619508922100066
train--13/100 [929/1090] loss: 0.44304180443286895
train--13/100 [939/1090] loss: 0.45183066725730897
train--13/100 [949/1090] loss: 0.4545817464590073
train--13/100 [959/1090] loss: 0.4358988881111145
train--13/100 [969/1090] loss: 0.4457320123910904
train--13/100 [979/1090] loss: 0.4444712340831757
train--13/100 [989/1090] loss: 0.4463867872953415
train--13/100 [999/1090] loss: 0.46316211819648745
train--13/100 [1009/1090] loss: 0.47199382185935973
train--13/100 [1019/1090] loss: 0.45134781301021576
train--13/100 [1029/1090] loss: 0.4559616565704346
train--13/100 [1039/1090] loss: 0.45315090715885165
train--13/100 [1049/1090] loss: 0.45545892119407655
train--13/100 [1059/1090] loss: 0.44339185059070585
train--13/100 [1069/1090] loss: 0.46037741005420685
train--13/100 [1079/1090] loss: 0.48896615505218505
train--13/100 [1089/1090] loss: 0.44656733572483065
predicting model...
val--13/100 [10/1090] acc: 0.79453125
val--13/100 [20/1090] acc: 0.7939453125
val--13/100 [30/1090] acc: 0.793359375
val--13/100 [40/1090] acc: 0.79287109375
val--13/100 [50/1090] acc: 0.791640625
val--13/100 [60/1090] acc: 0.7906901041666666
val--13/100 [70/1090] acc: 0.7913504464285714
val--13/100 [80/1090] acc: 0.78974609375
val--13/100 [90/1090] acc: 0.7902777777777777
val--13/100 [100/1090] acc: 0.79140625
val--13/100 [110/1090] acc: 0.79140625
val--13/100 [120/1090] acc: 0.7910481770833333
val--13/100 [130/1090] acc: 0.7920372596153846
val--13/100 [140/1090] acc: 0.7921595982142857
val--13/100 [150/1090] acc: 0.7922135416666667
val--13/100 [160/1090] acc: 0.7925537109375
val--13/100 [170/1090] acc: 0.7926240808823529
val--13/100 [180/1090] acc: 0.7922526041666667
val--13/100 [190/1090] acc: 0.7928865131578947
val--13/100 [200/1090] acc: 0.7931640625
val--13/100 [210/1090] acc: 0.7934337797619048
val--13/100 [220/1090] acc: 0.7924005681818181
val--13/100 [230/1090] acc: 0.7931385869565217
val--13/100 [240/1090] acc: 0.792919921875
val--13/100 [250/1090] acc: 0.79309375
val--13/100 [260/1090] acc: 0.7931640625
val--13/100 [270/1090] acc: 0.7933449074074074
val--13/100 [280/1090] acc: 0.7932756696428571
val--13/100 [290/1090] acc: 0.7931842672413794
val--13/100 [300/1090] acc: 0.7931510416666666
val--13/100 [310/1090] acc: 0.7928049395161291
val--13/100 [320/1090] acc: 0.79305419921875
val--13/100 [330/1090] acc: 0.7932410037878788
val--13/100 [340/1090] acc: 0.7933938419117647
val--13/100 [350/1090] acc: 0.7936272321428571
val--13/100 [360/1090] acc: 0.79345703125
val--13/100 [370/1090] acc: 0.7935599662162162
val--13/100 [380/1090] acc: 0.7935341282894737
val--13/100 [390/1090] acc: 0.7933092948717949
val--13/100 [400/1090] acc: 0.7931640625
val--13/100 [410/1090] acc: 0.7933403201219512
val--13/100 [420/1090] acc: 0.7933500744047619
val--13/100 [430/1090] acc: 0.7932412790697675
val--13/100 [440/1090] acc: 0.7931906960227273
val--13/100 [450/1090] acc: 0.7930295138888889
val--13/100 [460/1090] acc: 0.7930112092391305
val--13/100 [470/1090] acc: 0.7929604388297873
val--13/100 [480/1090] acc: 0.79296875
val--13/100 [490/1090] acc: 0.7930803571428572
val--13/100 [500/1090] acc: 0.7931953125
val--13/100 [510/1090] acc: 0.7931142769607843
val--13/100 [520/1090] acc: 0.7933293269230769
val--13/100 [530/1090] acc: 0.7933888561320754
val--13/100 [540/1090] acc: 0.7935402199074074
val--13/100 [550/1090] acc: 0.7934446022727273
val--13/100 [560/1090] acc: 0.7933175223214286
val--13/100 [570/1090] acc: 0.7930646929824562
val--13/100 [580/1090] acc: 0.7930563038793104
val--13/100 [590/1090] acc: 0.7931011652542372
val--13/100 [600/1090] acc: 0.7931575520833334
val--13/100 [610/1090] acc: 0.7930776127049181
val--13/100 [620/1090] acc: 0.7929750504032258
val--13/100 [630/1090] acc: 0.7931423611111111
val--13/100 [640/1090] acc: 0.793359375
val--13/100 [650/1090] acc: 0.7934014423076923
val--13/100 [660/1090] acc: 0.7932765151515152
val--13/100 [670/1090] acc: 0.7930328824626866
val--13/100 [680/1090] acc: 0.7929457720588236
val--13/100 [690/1090] acc: 0.7931499094202898
val--13/100 [700/1090] acc: 0.7931026785714286
val--13/100 [710/1090] acc: 0.7929192341549296
val--13/100 [720/1090] acc: 0.7927354600694444
val--13/100 [730/1090] acc: 0.7926744434931506
val--13/100 [740/1090] acc: 0.7925675675675675
val--13/100 [750/1090] acc: 0.7926354166666667
val--13/100 [760/1090] acc: 0.7927425986842105
val--13/100 [770/1090] acc: 0.7926948051948052
val--13/100 [780/1090] acc: 0.7926933092948718
val--13/100 [790/1090] acc: 0.7927165743670886
val--13/100 [800/1090] acc: 0.79294921875
val--13/100 [810/1090] acc: 0.7930121527777778
val--13/100 [820/1090] acc: 0.793116425304878
val--13/100 [830/1090] acc: 0.7932370105421687
val--13/100 [840/1090] acc: 0.793159412202381
val--13/100 [850/1090] acc: 0.7931525735294118
val--13/100 [860/1090] acc: 0.793359375
val--13/100 [870/1090] acc: 0.7932156968390804
val--13/100 [880/1090] acc: 0.7932040127840909
val--13/100 [890/1090] acc: 0.7933418188202247
val--13/100 [900/1090] acc: 0.7933506944444444
val--13/100 [910/1090] acc: 0.7933464972527473
val--13/100 [920/1090] acc: 0.7933806046195652
val--13/100 [930/1090] acc: 0.7934601814516129
val--13/100 [940/1090] acc: 0.7934591090425532
val--13/100 [950/1090] acc: 0.7933717105263158
val--13/100 [960/1090] acc: 0.79329833984375
val--13/100 [970/1090] acc: 0.7932748067010309
val--13/100 [980/1090] acc: 0.7932796556122449
val--13/100 [990/1090] acc: 0.7931818181818182
val--13/100 [1000/1090] acc: 0.79309765625
val--13/100 [1010/1090] acc: 0.79296875
val--13/100 [1020/1090] acc: 0.7930453431372549
val--13/100 [1030/1090] acc: 0.7930863167475728
val--13/100 [1040/1090] acc: 0.7930739182692308
val--13/100 [1050/1090] acc: 0.7931361607142857
val--13/100 [1060/1090] acc: 0.7930682488207547
val--13/100 [1070/1090] acc: 0.7930855724299065
val--13/100 [1080/1090] acc: 0.7929904513888889
val--13/100 [1090/1090] acc: 0.7928254013761468
epoch= 13, accuracy= 0.792825, rmse= 0.379244, auc= 0.854119
train--14/100 [9/1090] loss: 0.3887436866760254
train--14/100 [19/1090] loss: 0.4435136437416077
train--14/100 [29/1090] loss: 0.45522902309894564
train--14/100 [39/1090] loss: 0.44392227530479433
train--14/100 [49/1090] loss: 0.4126287281513214
train--14/100 [59/1090] loss: 0.4430541455745697
train--14/100 [69/1090] loss: 0.4474764049053192
train--14/100 [79/1090] loss: 0.4541659325361252
train--14/100 [89/1090] loss: 0.4597107946872711
train--14/100 [99/1090] loss: 0.47719437777996065
train--14/100 [109/1090] loss: 0.43415028750896456
train--14/100 [119/1090] loss: 0.44754347801208494
train--14/100 [129/1090] loss: 0.4373041599988937
train--14/100 [139/1090] loss: 0.4446865677833557
train--14/100 [149/1090] loss: 0.43855284452438353
train--14/100 [159/1090] loss: 0.4418118119239807
train--14/100 [169/1090] loss: 0.43310741186141966
train--14/100 [179/1090] loss: 0.4410209059715271
train--14/100 [189/1090] loss: 0.4600820690393448
train--14/100 [199/1090] loss: 0.4167975813150406
train--14/100 [209/1090] loss: 0.4397989422082901
train--14/100 [219/1090] loss: 0.4549384504556656
train--14/100 [229/1090] loss: 0.44354659616947173
train--14/100 [239/1090] loss: 0.4469010144472122
train--14/100 [249/1090] loss: 0.4362493485212326
train--14/100 [259/1090] loss: 0.43400726318359373
train--14/100 [269/1090] loss: 0.472059839963913
train--14/100 [279/1090] loss: 0.4475791484117508
train--14/100 [289/1090] loss: 0.4184888333082199
train--14/100 [299/1090] loss: 0.4536655008792877
train--14/100 [309/1090] loss: 0.44812064468860624
train--14/100 [319/1090] loss: 0.45902869701385496
train--14/100 [329/1090] loss: 0.4577343225479126
train--14/100 [339/1090] loss: 0.4585886627435684
train--14/100 [349/1090] loss: 0.46410501897335055
train--14/100 [359/1090] loss: 0.4587861865758896
train--14/100 [369/1090] loss: 0.43784969449043276
train--14/100 [379/1090] loss: 0.46552582681179044
train--14/100 [389/1090] loss: 0.4487261354923248
train--14/100 [399/1090] loss: 0.4374758780002594
train--14/100 [409/1090] loss: 0.45087566673755647
train--14/100 [419/1090] loss: 0.4518236815929413
train--14/100 [429/1090] loss: 0.4493660479784012
train--14/100 [439/1090] loss: 0.46152343451976774
train--14/100 [449/1090] loss: 0.4503434866666794
train--14/100 [459/1090] loss: 0.4484587341547012
train--14/100 [469/1090] loss: 0.43628023862838744
train--14/100 [479/1090] loss: 0.46614880859851837
train--14/100 [489/1090] loss: 0.4466150313615799
train--14/100 [499/1090] loss: 0.42901304066181184
train--14/100 [509/1090] loss: 0.428165128827095
train--14/100 [519/1090] loss: 0.44240314066410064
train--14/100 [529/1090] loss: 0.4571837931871414
train--14/100 [539/1090] loss: 0.4339115649461746
train--14/100 [549/1090] loss: 0.44260474145412443
train--14/100 [559/1090] loss: 0.4498662382364273
train--14/100 [569/1090] loss: 0.45089962184429166
train--14/100 [579/1090] loss: 0.4271428495645523
train--14/100 [589/1090] loss: 0.4417504042387009
train--14/100 [599/1090] loss: 0.4438291549682617
train--14/100 [609/1090] loss: 0.4438157111406326
train--14/100 [619/1090] loss: 0.44777138233184816
train--14/100 [629/1090] loss: 0.44165646731853486
train--14/100 [639/1090] loss: 0.4559270113706589
train--14/100 [649/1090] loss: 0.44617690742015836
train--14/100 [659/1090] loss: 0.4392101228237152
train--14/100 [669/1090] loss: 0.46910606026649476
train--14/100 [679/1090] loss: 0.43500883877277374
train--14/100 [689/1090] loss: 0.4469026535749435
train--14/100 [699/1090] loss: 0.4656915605068207
train--14/100 [709/1090] loss: 0.4480928689241409
train--14/100 [719/1090] loss: 0.4601156562566757
train--14/100 [729/1090] loss: 0.4652892529964447
train--14/100 [739/1090] loss: 0.45158523619174956
train--14/100 [749/1090] loss: 0.4519112378358841
train--14/100 [759/1090] loss: 0.4553277999162674
train--14/100 [769/1090] loss: 0.43329122960567473
train--14/100 [779/1090] loss: 0.4620283395051956
train--14/100 [789/1090] loss: 0.45831744074821473
train--14/100 [799/1090] loss: 0.4501025974750519
train--14/100 [809/1090] loss: 0.4438585340976715
train--14/100 [819/1090] loss: 0.45186726152896883
train--14/100 [829/1090] loss: 0.45031910240650175
train--14/100 [839/1090] loss: 0.43983881175518036
train--14/100 [849/1090] loss: 0.4465043008327484
train--14/100 [859/1090] loss: 0.46154719293117524
train--14/100 [869/1090] loss: 0.46795080304145814
train--14/100 [879/1090] loss: 0.448864483833313
train--14/100 [889/1090] loss: 0.4434887647628784
train--14/100 [899/1090] loss: 0.46317841708660124
train--14/100 [909/1090] loss: 0.4749880939722061
train--14/100 [919/1090] loss: 0.4584195286035538
train--14/100 [929/1090] loss: 0.45647795796394347
train--14/100 [939/1090] loss: 0.4599683493375778
train--14/100 [949/1090] loss: 0.44485386908054353
train--14/100 [959/1090] loss: 0.4597919791936874
train--14/100 [969/1090] loss: 0.45947339236736295
train--14/100 [979/1090] loss: 0.4730750977993011
train--14/100 [989/1090] loss: 0.4645999640226364
train--14/100 [999/1090] loss: 0.4555920988321304
train--14/100 [1009/1090] loss: 0.4462576389312744
train--14/100 [1019/1090] loss: 0.4593193382024765
train--14/100 [1029/1090] loss: 0.4440415382385254
train--14/100 [1039/1090] loss: 0.4554563045501709
train--14/100 [1049/1090] loss: 0.44685969948768617
train--14/100 [1059/1090] loss: 0.45571030080318453
train--14/100 [1069/1090] loss: 0.4646917343139648
train--14/100 [1079/1090] loss: 0.44951954782009124
train--14/100 [1089/1090] loss: 0.4545990198850632
predicting model...
val--14/100 [10/1090] acc: 0.7921875
val--14/100 [20/1090] acc: 0.793359375
val--14/100 [30/1090] acc: 0.7927083333333333
val--14/100 [40/1090] acc: 0.79306640625
val--14/100 [50/1090] acc: 0.79125
val--14/100 [60/1090] acc: 0.7905598958333333
val--14/100 [70/1090] acc: 0.7909040178571428
val--14/100 [80/1090] acc: 0.78974609375
val--14/100 [90/1090] acc: 0.7902777777777777
val--14/100 [100/1090] acc: 0.791484375
val--14/100 [110/1090] acc: 0.7913352272727273
val--14/100 [120/1090] acc: 0.7911783854166666
val--14/100 [130/1090] acc: 0.7921875
val--14/100 [140/1090] acc: 0.7922154017857143
val--14/100 [150/1090] acc: 0.7921875
val--14/100 [160/1090] acc: 0.79248046875
val--14/100 [170/1090] acc: 0.7927159926470588
val--14/100 [180/1090] acc: 0.7922743055555556
val--14/100 [190/1090] acc: 0.7931537828947368
val--14/100 [200/1090] acc: 0.79333984375
val--14/100 [210/1090] acc: 0.7936383928571429
val--14/100 [220/1090] acc: 0.7927024147727273
val--14/100 [230/1090] acc: 0.7933254076086956
val--14/100 [240/1090] acc: 0.7931966145833333
val--14/100 [250/1090] acc: 0.79346875
val--14/100 [260/1090] acc: 0.7935096153846154
val--14/100 [270/1090] acc: 0.7936197916666666
val--14/100 [280/1090] acc: 0.7935965401785714
val--14/100 [290/1090] acc: 0.7935614224137931
val--14/100 [300/1090] acc: 0.7935546875
val--14/100 [310/1090] acc: 0.7931325604838709
val--14/100 [320/1090] acc: 0.7934326171875
val--14/100 [330/1090] acc: 0.7936079545454545
val--14/100 [340/1090] acc: 0.7936925551470588
val--14/100 [350/1090] acc: 0.7938616071428571
val--14/100 [360/1090] acc: 0.7937825520833334
val--14/100 [370/1090] acc: 0.7938661317567568
val--14/100 [380/1090] acc: 0.7938116776315789
val--14/100 [390/1090] acc: 0.7935296474358975
val--14/100 [400/1090] acc: 0.793486328125
val--14/100 [410/1090] acc: 0.7936451981707318
val--14/100 [420/1090] acc: 0.7937220982142857
val--14/100 [430/1090] acc: 0.7936228197674419
val--14/100 [440/1090] acc: 0.79365234375
val--14/100 [450/1090] acc: 0.7934895833333333
val--14/100 [460/1090] acc: 0.7934103260869565
val--14/100 [470/1090] acc: 0.7933178191489362
val--14/100 [480/1090] acc: 0.7933675130208333
val--14/100 [490/1090] acc: 0.7935427295918367
val--14/100 [500/1090] acc: 0.793734375
val--14/100 [510/1090] acc: 0.7936810661764706
val--14/100 [520/1090] acc: 0.7938777043269231
val--14/100 [530/1090] acc: 0.7938826650943396
val--14/100 [540/1090] acc: 0.794068287037037
val--14/100 [550/1090] acc: 0.793984375
val--14/100 [560/1090] acc: 0.7938127790178572
val--14/100 [570/1090] acc: 0.793530701754386
val--14/100 [580/1090] acc: 0.7935614224137931
val--14/100 [590/1090] acc: 0.7935315148305084
val--14/100 [600/1090] acc: 0.7934700520833333
val--14/100 [610/1090] acc: 0.7933785860655738
val--14/100 [620/1090] acc: 0.793227066532258
val--14/100 [630/1090] acc: 0.7934399801587302
val--14/100 [640/1090] acc: 0.79365234375
val--14/100 [650/1090] acc: 0.7937019230769231
val--14/100 [660/1090] acc: 0.7935606060606061
val--14/100 [670/1090] acc: 0.7932660914179105
val--14/100 [680/1090] acc: 0.7931525735294118
val--14/100 [690/1090] acc: 0.7933084239130435
val--14/100 [700/1090] acc: 0.7932924107142857
val--14/100 [710/1090] acc: 0.7930897887323943
val--14/100 [720/1090] acc: 0.7929524739583333
val--14/100 [730/1090] acc: 0.7928670804794521
val--14/100 [740/1090] acc: 0.7927628800675676
val--14/100 [750/1090] acc: 0.7928072916666666
val--14/100 [760/1090] acc: 0.7929173519736842
val--14/100 [770/1090] acc: 0.7928520698051948
val--14/100 [780/1090] acc: 0.7928435496794872
val--14/100 [790/1090] acc: 0.7929242484177215
val--14/100 [800/1090] acc: 0.7931396484375
val--14/100 [810/1090] acc: 0.7931712962962963
val--14/100 [820/1090] acc: 0.7932736280487804
val--14/100 [830/1090] acc: 0.793406438253012
val--14/100 [840/1090] acc: 0.7933454241071428
val--14/100 [850/1090] acc: 0.7933823529411764
val--14/100 [860/1090] acc: 0.7936409883720931
val--14/100 [870/1090] acc: 0.7934985632183909
val--14/100 [880/1090] acc: 0.7934747869318182
val--14/100 [890/1090] acc: 0.793627106741573
val--14/100 [900/1090] acc: 0.7936458333333334
val--14/100 [910/1090] acc: 0.7936899038461539
val--14/100 [920/1090] acc: 0.7937160326086956
val--14/100 [930/1090] acc: 0.7937836021505377
val--14/100 [940/1090] acc: 0.7937624667553191
val--14/100 [950/1090] acc: 0.7936759868421053
val--14/100 [960/1090] acc: 0.7935994466145834
val--14/100 [970/1090] acc: 0.7935728092783505
val--14/100 [980/1090] acc: 0.7935586734693878
val--14/100 [990/1090] acc: 0.7934698547979798
val--14/100 [1000/1090] acc: 0.793390625
val--14/100 [1010/1090] acc: 0.7932433477722772
val--14/100 [1020/1090] acc: 0.7933057598039216
val--14/100 [1030/1090] acc: 0.7933366201456311
val--14/100 [1040/1090] acc: 0.7932955228365385
val--14/100 [1050/1090] acc: 0.7933705357142857
val--14/100 [1060/1090] acc: 0.7932967275943397
val--14/100 [1070/1090] acc: 0.793290011682243
val--14/100 [1080/1090] acc: 0.7932183159722223
val--14/100 [1090/1090] acc: 0.7930511754587156
epoch= 14, accuracy= 0.793051, rmse= 0.379134, auc= 0.854239
train--15/100 [9/1090] loss: 0.39507871568202974
train--15/100 [19/1090] loss: 0.4448622643947601
train--15/100 [29/1090] loss: 0.4547884434461594
train--15/100 [39/1090] loss: 0.43680112063884735
train--15/100 [49/1090] loss: 0.4436187922954559
train--15/100 [59/1090] loss: 0.4274988919496536
train--15/100 [69/1090] loss: 0.44270856976509093
train--15/100 [79/1090] loss: 0.4391002058982849
train--15/100 [89/1090] loss: 0.4724250555038452
train--15/100 [99/1090] loss: 0.42290998101234434
train--15/100 [109/1090] loss: 0.4319456607103348
train--15/100 [119/1090] loss: 0.4495473653078079
train--15/100 [129/1090] loss: 0.4572548121213913
train--15/100 [139/1090] loss: 0.45774589776992797
train--15/100 [149/1090] loss: 0.4429792553186417
train--15/100 [159/1090] loss: 0.44352157711982726
train--15/100 [169/1090] loss: 0.4362418383359909
train--15/100 [179/1090] loss: 0.4401793539524078
train--15/100 [189/1090] loss: 0.44545320570468905
train--15/100 [199/1090] loss: 0.4281735301017761
train--15/100 [209/1090] loss: 0.4355277448892593
train--15/100 [219/1090] loss: 0.46517760753631593
train--15/100 [229/1090] loss: 0.4522256970405579
train--15/100 [239/1090] loss: 0.44688183069229126
train--15/100 [249/1090] loss: 0.4388496994972229
train--15/100 [259/1090] loss: 0.4445830374956131
train--15/100 [269/1090] loss: 0.45271522700786593
train--15/100 [279/1090] loss: 0.4284878849983215
train--15/100 [289/1090] loss: 0.46066042184829714
train--15/100 [299/1090] loss: 0.4484593540430069
train--15/100 [309/1090] loss: 0.4536885678768158
train--15/100 [319/1090] loss: 0.43089021146297457
train--15/100 [329/1090] loss: 0.4243157833814621
train--15/100 [339/1090] loss: 0.43938787579536437
train--15/100 [349/1090] loss: 0.4331388533115387
train--15/100 [359/1090] loss: 0.48202234506607056
train--15/100 [369/1090] loss: 0.46444411277770997
train--15/100 [379/1090] loss: 0.4502937763929367
train--15/100 [389/1090] loss: 0.46065875589847566
train--15/100 [399/1090] loss: 0.447576242685318
train--15/100 [409/1090] loss: 0.4617640644311905
train--15/100 [419/1090] loss: 0.4537431299686432
train--15/100 [429/1090] loss: 0.4442023038864136
train--15/100 [439/1090] loss: 0.45758133232593534
train--15/100 [449/1090] loss: 0.4446645349264145
train--15/100 [459/1090] loss: 0.45013315975666046
train--15/100 [469/1090] loss: 0.465362611413002
train--15/100 [479/1090] loss: 0.4360568761825562
train--15/100 [489/1090] loss: 0.47125194072723386
train--15/100 [499/1090] loss: 0.44128373861312864
train--15/100 [509/1090] loss: 0.45264897048473357
train--15/100 [519/1090] loss: 0.4343316316604614
train--15/100 [529/1090] loss: 0.4440815508365631
train--15/100 [539/1090] loss: 0.4449353992938995
train--15/100 [549/1090] loss: 0.45620677769184115
train--15/100 [559/1090] loss: 0.4299339234828949
train--15/100 [569/1090] loss: 0.45372980535030366
train--15/100 [579/1090] loss: 0.4409488022327423
train--15/100 [589/1090] loss: 0.4629384547472
train--15/100 [599/1090] loss: 0.45207142531871797
train--15/100 [609/1090] loss: 0.45018293261528014
train--15/100 [619/1090] loss: 0.476648673415184
train--15/100 [629/1090] loss: 0.4474812626838684
train--15/100 [639/1090] loss: 0.44299455881118777
train--15/100 [649/1090] loss: 0.45462800860404967
train--15/100 [659/1090] loss: 0.4488429695367813
train--15/100 [669/1090] loss: 0.4357719779014587
train--15/100 [679/1090] loss: 0.4778294712305069
train--15/100 [689/1090] loss: 0.4674238920211792
train--15/100 [699/1090] loss: 0.4510024726390839
train--15/100 [709/1090] loss: 0.47245811820030215
train--15/100 [719/1090] loss: 0.43641441166400907
train--15/100 [729/1090] loss: 0.4554793149232864
train--15/100 [739/1090] loss: 0.4528195053339005
train--15/100 [749/1090] loss: 0.44916624426841734
train--15/100 [759/1090] loss: 0.44222908318042753
train--15/100 [769/1090] loss: 0.46036440432071685
train--15/100 [779/1090] loss: 0.4658085316419601
train--15/100 [789/1090] loss: 0.44084430634975436
train--15/100 [799/1090] loss: 0.45740301311016085
train--15/100 [809/1090] loss: 0.45232093930244444
train--15/100 [819/1090] loss: 0.4483011573553085
train--15/100 [829/1090] loss: 0.45541165173053744
train--15/100 [839/1090] loss: 0.46973857581615447
train--15/100 [849/1090] loss: 0.4635375618934631
train--15/100 [859/1090] loss: 0.43257556259632113
train--15/100 [869/1090] loss: 0.44098182022571564
train--15/100 [879/1090] loss: 0.45205060243606565
train--15/100 [889/1090] loss: 0.45928613245487215
train--15/100 [899/1090] loss: 0.4569444328546524
train--15/100 [909/1090] loss: 0.44687595069408415
train--15/100 [919/1090] loss: 0.4455655634403229
train--15/100 [929/1090] loss: 0.4409729719161987
train--15/100 [939/1090] loss: 0.4666039764881134
train--15/100 [949/1090] loss: 0.44610809087753295
train--15/100 [959/1090] loss: 0.4515237003564835
train--15/100 [969/1090] loss: 0.45195373296737673
train--15/100 [979/1090] loss: 0.4405575543642044
train--15/100 [989/1090] loss: 0.44890548288822174
train--15/100 [999/1090] loss: 0.46827776432037355
train--15/100 [1009/1090] loss: 0.447279679775238
train--15/100 [1019/1090] loss: 0.4545880347490311
train--15/100 [1029/1090] loss: 0.44966118037700653
train--15/100 [1039/1090] loss: 0.46702301502227783
train--15/100 [1049/1090] loss: 0.4557845175266266
train--15/100 [1059/1090] loss: 0.4331564664840698
train--15/100 [1069/1090] loss: 0.44055968821048735
train--15/100 [1079/1090] loss: 0.43181760609149933
train--15/100 [1089/1090] loss: 0.4612126052379608
predicting model...
val--15/100 [10/1090] acc: 0.789453125
val--15/100 [20/1090] acc: 0.7916015625
val--15/100 [30/1090] acc: 0.7911458333333333
val--15/100 [40/1090] acc: 0.7912109375
val--15/100 [50/1090] acc: 0.79046875
val--15/100 [60/1090] acc: 0.7899739583333333
val--15/100 [70/1090] acc: 0.7902901785714286
val--15/100 [80/1090] acc: 0.789013671875
val--15/100 [90/1090] acc: 0.7895833333333333
val--15/100 [100/1090] acc: 0.7909375
val--15/100 [110/1090] acc: 0.7913352272727273
val--15/100 [120/1090] acc: 0.7911783854166666
val--15/100 [130/1090] acc: 0.7921274038461539
val--15/100 [140/1090] acc: 0.7922991071428571
val--15/100 [150/1090] acc: 0.7922916666666666
val--15/100 [160/1090] acc: 0.7925537109375
val--15/100 [170/1090] acc: 0.7926240808823529
val--15/100 [180/1090] acc: 0.7921440972222222
val--15/100 [190/1090] acc: 0.7929481907894737
val--15/100 [200/1090] acc: 0.7930859375
val--15/100 [210/1090] acc: 0.7933035714285714
val--15/100 [220/1090] acc: 0.7924538352272728
val--15/100 [230/1090] acc: 0.7931216032608696
val--15/100 [240/1090] acc: 0.7929361979166667
val--15/100 [250/1090] acc: 0.793171875
val--15/100 [260/1090] acc: 0.7931640625
val--15/100 [270/1090] acc: 0.7934751157407407
val--15/100 [280/1090] acc: 0.7934988839285714
val--15/100 [290/1090] acc: 0.7933997844827586
val--15/100 [300/1090] acc: 0.7934244791666667
val--15/100 [310/1090] acc: 0.7931451612903225
val--15/100 [320/1090] acc: 0.79339599609375
val--15/100 [330/1090] acc: 0.793548768939394
val--15/100 [340/1090] acc: 0.79375
val--15/100 [350/1090] acc: 0.7939174107142857
val--15/100 [360/1090] acc: 0.7938042534722223
val--15/100 [370/1090] acc: 0.7939083614864865
val--15/100 [380/1090] acc: 0.7938630756578947
val--15/100 [390/1090] acc: 0.7935897435897435
val--15/100 [400/1090] acc: 0.79349609375
val--15/100 [410/1090] acc: 0.7936261432926829
val--15/100 [420/1090] acc: 0.7936197916666666
val--15/100 [430/1090] acc: 0.7935592296511628
val--15/100 [440/1090] acc: 0.7935546875
val--15/100 [450/1090] acc: 0.7934288194444444
val--15/100 [460/1090] acc: 0.793359375
val--15/100 [470/1090] acc: 0.7932679521276595
val--15/100 [480/1090] acc: 0.793359375
val--15/100 [490/1090] acc: 0.7934948979591837
val--15/100 [500/1090] acc: 0.7937109375
val--15/100 [510/1090] acc: 0.7935891544117647
val--15/100 [520/1090] acc: 0.79375
val--15/100 [530/1090] acc: 0.7937721108490566
val--15/100 [540/1090] acc: 0.7939019097222222
val--15/100 [550/1090] acc: 0.7938139204545455
val--15/100 [560/1090] acc: 0.7936802455357143
val--15/100 [570/1090] acc: 0.7934004934210527
val--15/100 [580/1090] acc: 0.7934401939655172
val--15/100 [590/1090] acc: 0.7934520656779661
val--15/100 [600/1090] acc: 0.7934440104166667
val--15/100 [610/1090] acc: 0.7934170081967213
val--15/100 [620/1090] acc: 0.7932837701612904
val--15/100 [630/1090] acc: 0.7935081845238096
val--15/100 [640/1090] acc: 0.793743896484375
val--15/100 [650/1090] acc: 0.7938040865384616
val--15/100 [660/1090] acc: 0.7936967329545455
val--15/100 [670/1090] acc: 0.7934293376865672
val--15/100 [680/1090] acc: 0.7933019301470589
val--15/100 [690/1090] acc: 0.7935009057971014
val--15/100 [700/1090] acc: 0.7934709821428572
val--15/100 [710/1090] acc: 0.7933043573943662
val--15/100 [720/1090] acc: 0.7931477864583333
val--15/100 [730/1090] acc: 0.7931078767123287
val--15/100 [740/1090] acc: 0.7929793074324324
val--15/100 [750/1090] acc: 0.7930520833333333
val--15/100 [760/1090] acc: 0.7931640625
val--15/100 [770/1090] acc: 0.7931361607142857
val--15/100 [780/1090] acc: 0.7931089743589743
val--15/100 [790/1090] acc: 0.7931368670886076
val--15/100 [800/1090] acc: 0.793369140625
val--15/100 [810/1090] acc: 0.7934461805555556
val--15/100 [820/1090] acc: 0.793578506097561
val--15/100 [830/1090] acc: 0.7936699924698796
val--15/100 [840/1090] acc: 0.7935779389880953
val--15/100 [850/1090] acc: 0.79359375
val--15/100 [860/1090] acc: 0.793836300872093
val--15/100 [870/1090] acc: 0.7937095905172413
val--15/100 [880/1090] acc: 0.7936789772727273
val--15/100 [890/1090] acc: 0.7938070575842696
val--15/100 [900/1090] acc: 0.7938020833333334
val--15/100 [910/1090] acc: 0.7938358516483517
val--15/100 [920/1090] acc: 0.793851902173913
val--15/100 [930/1090] acc: 0.7939180107526882
val--15/100 [940/1090] acc: 0.7939286901595745
val--15/100 [950/1090] acc: 0.7938240131578947
val--15/100 [960/1090] acc: 0.79375
val--15/100 [970/1090] acc: 0.793737918814433
val--15/100 [980/1090] acc: 0.7937220982142857
val--15/100 [990/1090] acc: 0.7936316287878787
val--15/100 [1000/1090] acc: 0.79353125
val--15/100 [1010/1090] acc: 0.7934096534653465
val--15/100 [1020/1090] acc: 0.7934551164215686
val--15/100 [1030/1090] acc: 0.7934845266990291
val--15/100 [1040/1090] acc: 0.7934607872596153
val--15/100 [1050/1090] acc: 0.7935342261904762
val--15/100 [1060/1090] acc: 0.7934478183962265
val--15/100 [1070/1090] acc: 0.7934615946261683
val--15/100 [1080/1090] acc: 0.7933883101851852
val--15/100 [1090/1090] acc: 0.7932088589449541
epoch= 15, accuracy= 0.793209, rmse= 0.379058, auc= 0.854145
train--16/100 [9/1090] loss: 0.4176140785217285
train--16/100 [19/1090] loss: 0.4566245377063751
train--16/100 [29/1090] loss: 0.43025682866573334
train--16/100 [39/1090] loss: 0.44195240139961245
train--16/100 [49/1090] loss: 0.46022040247917173
train--16/100 [59/1090] loss: 0.4488801687955856
train--16/100 [69/1090] loss: 0.43342418372631075
train--16/100 [79/1090] loss: 0.4363770246505737
train--16/100 [89/1090] loss: 0.4211146503686905
train--16/100 [99/1090] loss: 0.43556620478630065
train--16/100 [109/1090] loss: 0.455410298705101
train--16/100 [119/1090] loss: 0.4602380722761154
train--16/100 [129/1090] loss: 0.44931050539016726
train--16/100 [139/1090] loss: 0.44957025051116944
train--16/100 [149/1090] loss: 0.4360984593629837
train--16/100 [159/1090] loss: 0.4325902104377747
train--16/100 [169/1090] loss: 0.4407188594341278
train--16/100 [179/1090] loss: 0.43172594606876374
train--16/100 [189/1090] loss: 0.45604735016822817
train--16/100 [199/1090] loss: 0.45168628394603727
train--16/100 [209/1090] loss: 0.4480997920036316
train--16/100 [219/1090] loss: 0.44720116555690764
train--16/100 [229/1090] loss: 0.45007540583610534
train--16/100 [239/1090] loss: 0.43869059085845946
train--16/100 [249/1090] loss: 0.4811003118753433
train--16/100 [259/1090] loss: 0.45519148409366605
train--16/100 [269/1090] loss: 0.4439439088106155
train--16/100 [279/1090] loss: 0.43347019255161284
train--16/100 [289/1090] loss: 0.43707193732261657
train--16/100 [299/1090] loss: 0.4398246884346008
train--16/100 [309/1090] loss: 0.4450740396976471
train--16/100 [319/1090] loss: 0.43705350160598755
train--16/100 [329/1090] loss: 0.4470054358243942
train--16/100 [339/1090] loss: 0.4467143326997757
train--16/100 [349/1090] loss: 0.46043421626091
train--16/100 [359/1090] loss: 0.437482014298439
train--16/100 [369/1090] loss: 0.4587393760681152
train--16/100 [379/1090] loss: 0.43988376259803774
train--16/100 [389/1090] loss: 0.44398981630802153
train--16/100 [399/1090] loss: 0.43124409317970275
train--16/100 [409/1090] loss: 0.4476750433444977
train--16/100 [419/1090] loss: 0.4568954199552536
train--16/100 [429/1090] loss: 0.465208625793457
train--16/100 [439/1090] loss: 0.44413489699363706
train--16/100 [449/1090] loss: 0.4433943212032318
train--16/100 [459/1090] loss: 0.4562409073114395
train--16/100 [469/1090] loss: 0.4560804098844528
train--16/100 [479/1090] loss: 0.44390139281749724
train--16/100 [489/1090] loss: 0.44048528373241425
train--16/100 [499/1090] loss: 0.45678492188453673
train--16/100 [509/1090] loss: 0.4474342465400696
train--16/100 [519/1090] loss: 0.4568590223789215
train--16/100 [529/1090] loss: 0.4335330128669739
train--16/100 [539/1090] loss: 0.45328690111637115
train--16/100 [549/1090] loss: 0.44618573486804963
train--16/100 [559/1090] loss: 0.45093877911567687
train--16/100 [569/1090] loss: 0.4472822993993759
train--16/100 [579/1090] loss: 0.4486631989479065
train--16/100 [589/1090] loss: 0.43795048296451566
train--16/100 [599/1090] loss: 0.4460099756717682
train--16/100 [609/1090] loss: 0.4438279241323471
train--16/100 [619/1090] loss: 0.44463605284690855
train--16/100 [629/1090] loss: 0.4406070917844772
train--16/100 [639/1090] loss: 0.46878962516784667
train--16/100 [649/1090] loss: 0.44758798480033873
train--16/100 [659/1090] loss: 0.4450828284025192
train--16/100 [669/1090] loss: 0.448129740357399
train--16/100 [679/1090] loss: 0.45997855365276336
train--16/100 [689/1090] loss: 0.45740554928779603
train--16/100 [699/1090] loss: 0.45247348546981814
train--16/100 [709/1090] loss: 0.4484115481376648
train--16/100 [719/1090] loss: 0.4490554630756378
train--16/100 [729/1090] loss: 0.44612970650196077
train--16/100 [739/1090] loss: 0.45166832506656646
train--16/100 [749/1090] loss: 0.4585876941680908
train--16/100 [759/1090] loss: 0.4351848393678665
train--16/100 [769/1090] loss: 0.4639500617980957
train--16/100 [779/1090] loss: 0.46327591836452486
train--16/100 [789/1090] loss: 0.45075408816337587
train--16/100 [799/1090] loss: 0.4531848758459091
train--16/100 [809/1090] loss: 0.439330992102623
train--16/100 [819/1090] loss: 0.44503413140773773
train--16/100 [829/1090] loss: 0.4594289779663086
train--16/100 [839/1090] loss: 0.4403559327125549
train--16/100 [849/1090] loss: 0.4516471356153488
train--16/100 [859/1090] loss: 0.4273850679397583
train--16/100 [869/1090] loss: 0.4400420278310776
train--16/100 [879/1090] loss: 0.4706671446561813
train--16/100 [889/1090] loss: 0.4607823669910431
train--16/100 [899/1090] loss: 0.44608127772808076
train--16/100 [909/1090] loss: 0.4704567313194275
train--16/100 [919/1090] loss: 0.45297445356845856
train--16/100 [929/1090] loss: 0.460584232211113
train--16/100 [939/1090] loss: 0.43902360200881957
train--16/100 [949/1090] loss: 0.46563105583190917
train--16/100 [959/1090] loss: 0.4714111775159836
train--16/100 [969/1090] loss: 0.45201102197170256
train--16/100 [979/1090] loss: 0.45643547773361204
train--16/100 [989/1090] loss: 0.44336826503276827
train--16/100 [999/1090] loss: 0.45861671566963197
train--16/100 [1009/1090] loss: 0.471358048915863
train--16/100 [1019/1090] loss: 0.4396212935447693
train--16/100 [1029/1090] loss: 0.45634257793426514
train--16/100 [1039/1090] loss: 0.4583476155996323
train--16/100 [1049/1090] loss: 0.4504758358001709
train--16/100 [1059/1090] loss: 0.4444888263940811
train--16/100 [1069/1090] loss: 0.4463691532611847
train--16/100 [1079/1090] loss: 0.47775855362415315
train--16/100 [1089/1090] loss: 0.4546895384788513
predicting model...
val--16/100 [10/1090] acc: 0.792578125
val--16/100 [20/1090] acc: 0.7908203125
val--16/100 [30/1090] acc: 0.791015625
val--16/100 [40/1090] acc: 0.79130859375
val--16/100 [50/1090] acc: 0.790703125
val--16/100 [60/1090] acc: 0.7900390625
val--16/100 [70/1090] acc: 0.7907366071428571
val--16/100 [80/1090] acc: 0.789453125
val--16/100 [90/1090] acc: 0.7901041666666667
val--16/100 [100/1090] acc: 0.7913671875
val--16/100 [110/1090] acc: 0.7913352272727273
val--16/100 [120/1090] acc: 0.7907877604166667
val--16/100 [130/1090] acc: 0.7918870192307692
val--16/100 [140/1090] acc: 0.7920758928571429
val--16/100 [150/1090] acc: 0.792265625
val--16/100 [160/1090] acc: 0.79248046875
val--16/100 [170/1090] acc: 0.7924632352941177
val--16/100 [180/1090] acc: 0.7921440972222222
val--16/100 [190/1090] acc: 0.7930715460526315
val--16/100 [200/1090] acc: 0.79328125
val--16/100 [210/1090] acc: 0.7936197916666666
val--16/100 [220/1090] acc: 0.7926491477272727
val--16/100 [230/1090] acc: 0.7932914402173913
val--16/100 [240/1090] acc: 0.7932454427083333
val--16/100 [250/1090] acc: 0.793484375
val--16/100 [260/1090] acc: 0.7935396634615385
val--16/100 [270/1090] acc: 0.7938368055555556
val--16/100 [280/1090] acc: 0.7938197544642858
val--16/100 [290/1090] acc: 0.7937095905172413
val--16/100 [300/1090] acc: 0.7937109375
val--16/100 [310/1090] acc: 0.7933341733870968
val--16/100 [320/1090] acc: 0.79354248046875
val--16/100 [330/1090] acc: 0.7936908143939394
val--16/100 [340/1090] acc: 0.7938878676470589
val--16/100 [350/1090] acc: 0.7941294642857143
val--16/100 [360/1090] acc: 0.7939995659722222
val--16/100 [370/1090] acc: 0.7940983952702703
val--16/100 [380/1090] acc: 0.7940275493421053
val--16/100 [390/1090] acc: 0.793739983974359
val--16/100 [400/1090] acc: 0.79359375
val--16/100 [410/1090] acc: 0.7938357469512195
val--16/100 [420/1090] acc: 0.7938337053571428
val--16/100 [430/1090] acc: 0.7937318313953489
val--16/100 [440/1090] acc: 0.7937144886363636
val--16/100 [450/1090] acc: 0.7935677083333333
val--16/100 [460/1090] acc: 0.7934697690217392
val--16/100 [470/1090] acc: 0.7933676861702128
val--16/100 [480/1090] acc: 0.7934000651041667
val--16/100 [490/1090] acc: 0.7935347576530613
val--16/100 [500/1090] acc: 0.7936953125
val--16/100 [510/1090] acc: 0.7936044730392157
val--16/100 [520/1090] acc: 0.7938326322115384
val--16/100 [530/1090] acc: 0.7938531839622641
val--16/100 [540/1090] acc: 0.7940104166666667
val--16/100 [550/1090] acc: 0.79390625
val--16/100 [560/1090] acc: 0.7937290736607143
val--16/100 [570/1090] acc: 0.7934758771929824
val--16/100 [580/1090] acc: 0.7934738685344828
val--16/100 [590/1090] acc: 0.7934719279661017
val--16/100 [600/1090] acc: 0.7935091145833333
val--16/100 [610/1090] acc: 0.7934170081967213
val--16/100 [620/1090] acc: 0.7932900705645162
val--16/100 [630/1090] acc: 0.7935577876984127
val--16/100 [640/1090] acc: 0.79375
val--16/100 [650/1090] acc: 0.7937439903846154
val--16/100 [660/1090] acc: 0.7936730587121212
val--16/100 [670/1090] acc: 0.7933826958955223
val--16/100 [680/1090] acc: 0.7932846966911765
val--16/100 [690/1090] acc: 0.7934895833333333
val--16/100 [700/1090] acc: 0.7934933035714286
val--16/100 [710/1090] acc: 0.7933208626760564
val--16/100 [720/1090] acc: 0.7931315104166666
val--16/100 [730/1090] acc: 0.7930276113013699
val--16/100 [740/1090] acc: 0.79296875
val--16/100 [750/1090] acc: 0.7930364583333334
val--16/100 [760/1090] acc: 0.7931486430921053
val--16/100 [770/1090] acc: 0.7931260146103896
val--16/100 [780/1090] acc: 0.7930939503205128
val--16/100 [790/1090] acc: 0.7931467563291139
val--16/100 [800/1090] acc: 0.7933349609375
val--16/100 [810/1090] acc: 0.7934172453703704
val--16/100 [820/1090] acc: 0.7935356326219513
val--16/100 [830/1090] acc: 0.7936135165662651
val--16/100 [840/1090] acc: 0.7935221354166667
val--16/100 [850/1090] acc: 0.7934742647058823
val--16/100 [860/1090] acc: 0.7937363735465116
val--16/100 [870/1090] acc: 0.7935569324712644
val--16/100 [880/1090] acc: 0.793505859375
val--16/100 [890/1090] acc: 0.7936534410112359
val--16/100 [900/1090] acc: 0.7936501736111111
val--16/100 [910/1090] acc: 0.7936555631868132
val--16/100 [920/1090] acc: 0.7936863111413044
val--16/100 [930/1090] acc: 0.7937584005376344
val--16/100 [940/1090] acc: 0.7937874002659574
val--16/100 [950/1090] acc: 0.7936800986842105
val--16/100 [960/1090] acc: 0.79361572265625
val--16/100 [970/1090] acc: 0.7935728092783505
val--16/100 [980/1090] acc: 0.7935786033163266
val--16/100 [990/1090] acc: 0.7934895833333333
val--16/100 [1000/1090] acc: 0.79341015625
val--16/100 [1010/1090] acc: 0.7932820235148514
val--16/100 [1020/1090] acc: 0.7933746936274509
val--16/100 [1030/1090] acc: 0.793435224514563
val--16/100 [1040/1090] acc: 0.7934194711538461
val--16/100 [1050/1090] acc: 0.793485863095238
val--16/100 [1060/1090] acc: 0.793444133254717
val--16/100 [1070/1090] acc: 0.7934688960280374
val--16/100 [1080/1090] acc: 0.7933810763888889
val--16/100 [1090/1090] acc: 0.7932052752293578
epoch= 16, accuracy= 0.793205, rmse= 0.379133, auc= 0.854220
train--17/100 [9/1090] loss: 0.40179883539676664
train--17/100 [19/1090] loss: 0.45125173032283783
train--17/100 [29/1090] loss: 0.42523069977760314
train--17/100 [39/1090] loss: 0.45460993647575376
train--17/100 [49/1090] loss: 0.43375265002250674
train--17/100 [59/1090] loss: 0.45739236772060393
train--17/100 [69/1090] loss: 0.44857771396636964
train--17/100 [79/1090] loss: 0.4450338989496231
train--17/100 [89/1090] loss: 0.44942698180675505
train--17/100 [99/1090] loss: 0.46412875056266784
train--17/100 [109/1090] loss: 0.43400259912014005
train--17/100 [119/1090] loss: 0.43403332531452177
train--17/100 [129/1090] loss: 0.4475376129150391
train--17/100 [139/1090] loss: 0.44971045553684236
train--17/100 [149/1090] loss: 0.44448540508747103
train--17/100 [159/1090] loss: 0.44339202642440795
train--17/100 [169/1090] loss: 0.4493179202079773
train--17/100 [179/1090] loss: 0.45346828997135163
train--17/100 [189/1090] loss: 0.4383090972900391
train--17/100 [199/1090] loss: 0.4579932063817978
train--17/100 [209/1090] loss: 0.4425168603658676
train--17/100 [219/1090] loss: 0.43886518478393555
train--17/100 [229/1090] loss: 0.44396335184574126
train--17/100 [239/1090] loss: 0.4389555424451828
train--17/100 [249/1090] loss: 0.44537095725536346
train--17/100 [259/1090] loss: 0.4554001957178116
train--17/100 [269/1090] loss: 0.4469125270843506
train--17/100 [279/1090] loss: 0.45179547369480133
train--17/100 [289/1090] loss: 0.4549527704715729
train--17/100 [299/1090] loss: 0.4461390644311905
train--17/100 [309/1090] loss: 0.4402613461017609
train--17/100 [319/1090] loss: 0.45419775545597074
train--17/100 [329/1090] loss: 0.46075854897499086
train--17/100 [339/1090] loss: 0.46141922771930693
train--17/100 [349/1090] loss: 0.4356447905302048
train--17/100 [359/1090] loss: 0.44551241099834443
train--17/100 [369/1090] loss: 0.4621904820203781
train--17/100 [379/1090] loss: 0.4407117575407028
train--17/100 [389/1090] loss: 0.433560898900032
train--17/100 [399/1090] loss: 0.4310383886098862
train--17/100 [409/1090] loss: 0.46085759401321413
train--17/100 [419/1090] loss: 0.4650088369846344
train--17/100 [429/1090] loss: 0.45638093650341033
train--17/100 [439/1090] loss: 0.4387484222650528
train--17/100 [449/1090] loss: 0.44261561036109925
train--17/100 [459/1090] loss: 0.4602611601352692
train--17/100 [469/1090] loss: 0.4425263464450836
train--17/100 [479/1090] loss: 0.4624908834695816
train--17/100 [489/1090] loss: 0.43987066447734835
train--17/100 [499/1090] loss: 0.4556264728307724
train--17/100 [509/1090] loss: 0.44708665609359743
train--17/100 [519/1090] loss: 0.4360399156808853
train--17/100 [529/1090] loss: 0.4604717314243317
train--17/100 [539/1090] loss: 0.4427872210741043
train--17/100 [549/1090] loss: 0.4546272397041321
train--17/100 [559/1090] loss: 0.4469346463680267
train--17/100 [569/1090] loss: 0.45185858607292173
train--17/100 [579/1090] loss: 0.4739259272813797
train--17/100 [589/1090] loss: 0.43569389283657073
train--17/100 [599/1090] loss: 0.44985693991184234
train--17/100 [609/1090] loss: 0.4517629772424698
train--17/100 [619/1090] loss: 0.4470204323530197
train--17/100 [629/1090] loss: 0.44979814887046815
train--17/100 [639/1090] loss: 0.4479216396808624
train--17/100 [649/1090] loss: 0.4358048766851425
train--17/100 [659/1090] loss: 0.45871399343013763
train--17/100 [669/1090] loss: 0.43484588861465456
train--17/100 [679/1090] loss: 0.46721365451812746
train--17/100 [689/1090] loss: 0.4410095393657684
train--17/100 [699/1090] loss: 0.4568419873714447
train--17/100 [709/1090] loss: 0.46027770042419436
train--17/100 [719/1090] loss: 0.4643284469842911
train--17/100 [729/1090] loss: 0.43332764506340027
train--17/100 [739/1090] loss: 0.45044071674346925
train--17/100 [749/1090] loss: 0.4341763943433762
train--17/100 [759/1090] loss: 0.4541198253631592
train--17/100 [769/1090] loss: 0.4582175076007843
train--17/100 [779/1090] loss: 0.45410206615924836
train--17/100 [789/1090] loss: 0.46170968413352964
train--17/100 [799/1090] loss: 0.4471321374177933
train--17/100 [809/1090] loss: 0.46015174090862276
train--17/100 [819/1090] loss: 0.45900796055793763
train--17/100 [829/1090] loss: 0.41170198619365694
train--17/100 [839/1090] loss: 0.44066697359085083
train--17/100 [849/1090] loss: 0.45254682302474974
train--17/100 [859/1090] loss: 0.4527369260787964
train--17/100 [869/1090] loss: 0.4471889764070511
train--17/100 [879/1090] loss: 0.4536716938018799
train--17/100 [889/1090] loss: 0.4688102066516876
train--17/100 [899/1090] loss: 0.45292830765247344
train--17/100 [909/1090] loss: 0.45499286353588103
train--17/100 [919/1090] loss: 0.45326890647411344
train--17/100 [929/1090] loss: 0.41243124604225156
train--17/100 [939/1090] loss: 0.4719605356454849
train--17/100 [949/1090] loss: 0.44255864918231963
train--17/100 [959/1090] loss: 0.47013209462165834
train--17/100 [969/1090] loss: 0.4387164801359177
train--17/100 [979/1090] loss: 0.4608462333679199
train--17/100 [989/1090] loss: 0.45285632014274596
train--17/100 [999/1090] loss: 0.442605659365654
train--17/100 [1009/1090] loss: 0.4623887211084366
train--17/100 [1019/1090] loss: 0.4471767216920853
train--17/100 [1029/1090] loss: 0.432837051153183
train--17/100 [1039/1090] loss: 0.453463026881218
train--17/100 [1049/1090] loss: 0.45189642906188965
train--17/100 [1059/1090] loss: 0.46332827508449553
train--17/100 [1069/1090] loss: 0.4684743046760559
train--17/100 [1079/1090] loss: 0.44564020037651064
train--17/100 [1089/1090] loss: 0.4388227194547653
predicting model...
val--17/100 [10/1090] acc: 0.79375
val--17/100 [20/1090] acc: 0.7921875
val--17/100 [30/1090] acc: 0.7921875
val--17/100 [40/1090] acc: 0.79169921875
val--17/100 [50/1090] acc: 0.790625
val--17/100 [60/1090] acc: 0.7900390625
val--17/100 [70/1090] acc: 0.7905133928571428
val--17/100 [80/1090] acc: 0.7890625
val--17/100 [90/1090] acc: 0.7900607638888889
val--17/100 [100/1090] acc: 0.791171875
val--17/100 [110/1090] acc: 0.7911221590909091
val--17/100 [120/1090] acc: 0.7909505208333333
val--17/100 [130/1090] acc: 0.7919170673076923
val--17/100 [140/1090] acc: 0.7921037946428572
val--17/100 [150/1090] acc: 0.7921614583333333
val--17/100 [160/1090] acc: 0.7924560546875
val--17/100 [170/1090] acc: 0.7926011029411765
val--17/100 [180/1090] acc: 0.7921875
val--17/100 [190/1090] acc: 0.7931126644736842
val--17/100 [200/1090] acc: 0.793359375
val--17/100 [210/1090] acc: 0.793656994047619
val--17/100 [220/1090] acc: 0.7927734375
val--17/100 [230/1090] acc: 0.7934442934782608
val--17/100 [240/1090] acc: 0.7932942708333334
val--17/100 [250/1090] acc: 0.79346875
val--17/100 [260/1090] acc: 0.7935246394230769
val--17/100 [270/1090] acc: 0.7937789351851852
val--17/100 [280/1090] acc: 0.7938895089285715
val--17/100 [290/1090] acc: 0.793884698275862
val--17/100 [300/1090] acc: 0.793828125
val--17/100 [310/1090] acc: 0.7934097782258065
val--17/100 [320/1090] acc: 0.7937255859375
val--17/100 [330/1090] acc: 0.7939630681818182
val--17/100 [340/1090] acc: 0.7940372242647059
val--17/100 [350/1090] acc: 0.7941964285714286
val--17/100 [360/1090] acc: 0.7940646701388889
val--17/100 [370/1090] acc: 0.7941511824324324
val--17/100 [380/1090] acc: 0.7941509046052632
val--17/100 [390/1090] acc: 0.7939102564102564
val--17/100 [400/1090] acc: 0.79375
val--17/100 [410/1090] acc: 0.7939405487804878
val--17/100 [420/1090] acc: 0.7938988095238095
val--17/100 [430/1090] acc: 0.7938045058139535
val--17/100 [440/1090] acc: 0.7937855113636364
val--17/100 [450/1090] acc: 0.793671875
val--17/100 [460/1090] acc: 0.7936311141304347
val--17/100 [470/1090] acc: 0.7934840425531915
val--17/100 [480/1090] acc: 0.7935465494791667
val--17/100 [490/1090] acc: 0.7936862244897959
val--17/100 [500/1090] acc: 0.7938359375
val--17/100 [510/1090] acc: 0.7937423406862745
val--17/100 [520/1090] acc: 0.7939002403846154
val--17/100 [530/1090] acc: 0.7938531839622641
val--17/100 [540/1090] acc: 0.7940104166666667
val--17/100 [550/1090] acc: 0.7938494318181818
val--17/100 [560/1090] acc: 0.7936872209821428
val--17/100 [570/1090] acc: 0.7934758771929824
val--17/100 [580/1090] acc: 0.7934940732758621
val--17/100 [590/1090] acc: 0.7934851694915255
val--17/100 [600/1090] acc: 0.7935026041666666
val--17/100 [610/1090] acc: 0.7934362192622951
val--17/100 [620/1090] acc: 0.7933215725806452
val--17/100 [630/1090] acc: 0.7935701884920635
val--17/100 [640/1090] acc: 0.79375
val--17/100 [650/1090] acc: 0.7938100961538461
val--17/100 [660/1090] acc: 0.7937085700757576
val--17/100 [670/1090] acc: 0.7934701492537314
val--17/100 [680/1090] acc: 0.7933823529411764
val--17/100 [690/1090] acc: 0.7935348731884058
val--17/100 [700/1090] acc: 0.7935379464285715
val--17/100 [710/1090] acc: 0.7933373679577465
val--17/100 [720/1090] acc: 0.7932074652777777
val--17/100 [730/1090] acc: 0.7931239297945205
val--17/100 [740/1090] acc: 0.7930532094594595
val--17/100 [750/1090] acc: 0.7931041666666667
val--17/100 [760/1090] acc: 0.7932462993421052
val--17/100 [770/1090] acc: 0.7932376217532467
val--17/100 [780/1090] acc: 0.7932191506410257
val--17/100 [790/1090] acc: 0.793240704113924
val--17/100 [800/1090] acc: 0.7934375
val--17/100 [810/1090] acc: 0.7934992283950617
val--17/100 [820/1090] acc: 0.7935975609756097
val--17/100 [830/1090] acc: 0.7936464608433735
val--17/100 [840/1090] acc: 0.7935779389880953
val--17/100 [850/1090] acc: 0.793561580882353
val--17/100 [860/1090] acc: 0.7937772529069768
val--17/100 [870/1090] acc: 0.7936377514367816
val--17/100 [880/1090] acc: 0.7935946377840909
val--17/100 [890/1090] acc: 0.79375
val--17/100 [900/1090] acc: 0.7937196180555556
val--17/100 [910/1090] acc: 0.7937199519230769
val--17/100 [920/1090] acc: 0.7937245244565218
val--17/100 [930/1090] acc: 0.7937920026881721
val--17/100 [940/1090] acc: 0.7937874002659574
val--17/100 [950/1090] acc: 0.7937047697368421
val--17/100 [960/1090] acc: 0.7936604817708334
val--17/100 [970/1090] acc: 0.7936614046391752
val--17/100 [980/1090] acc: 0.7936822385204082
val--17/100 [990/1090] acc: 0.7936197916666666
val--17/100 [1000/1090] acc: 0.79353515625
val--17/100 [1010/1090] acc: 0.7933903155940594
val--17/100 [1020/1090] acc: 0.7934819240196078
val--17/100 [1030/1090] acc: 0.7934921116504854
val--17/100 [1040/1090] acc: 0.7934795673076923
val--17/100 [1050/1090] acc: 0.7935379464285715
val--17/100 [1060/1090] acc: 0.7934736143867924
val--17/100 [1070/1090] acc: 0.7934615946261683
val--17/100 [1080/1090] acc: 0.7933955439814815
val--17/100 [1090/1090] acc: 0.7932124426605505
epoch= 17, accuracy= 0.793212, rmse= 0.379080, auc= 0.854128
train--18/100 [9/1090] loss: 0.40131606459617614
train--18/100 [19/1090] loss: 0.4492881268262863
train--18/100 [29/1090] loss: 0.42473341822624205
train--18/100 [39/1090] loss: 0.43560304343700407
train--18/100 [49/1090] loss: 0.4461658924818039
train--18/100 [59/1090] loss: 0.4351083278656006
train--18/100 [69/1090] loss: 0.4443985909223557
train--18/100 [79/1090] loss: 0.4515033602714539
train--18/100 [89/1090] loss: 0.46061989963054656
train--18/100 [99/1090] loss: 0.46555548906326294
train--18/100 [109/1090] loss: 0.447538161277771
train--18/100 [119/1090] loss: 0.4328806072473526
train--18/100 [129/1090] loss: 0.4588708519935608
train--18/100 [139/1090] loss: 0.43451263308525084
train--18/100 [149/1090] loss: 0.43683563768863676
train--18/100 [159/1090] loss: 0.4349245399236679
train--18/100 [169/1090] loss: 0.42827467024326327
train--18/100 [179/1090] loss: 0.4656699627637863
train--18/100 [189/1090] loss: 0.444193160533905
train--18/100 [199/1090] loss: 0.4269117832183838
train--18/100 [209/1090] loss: 0.4379857242107391
train--18/100 [219/1090] loss: 0.44834962487220764
train--18/100 [229/1090] loss: 0.437059286236763
train--18/100 [239/1090] loss: 0.4650820016860962
train--18/100 [249/1090] loss: 0.46402390897274015
train--18/100 [259/1090] loss: 0.4582138776779175
train--18/100 [269/1090] loss: 0.4518439382314682
train--18/100 [279/1090] loss: 0.4373244851827621
train--18/100 [289/1090] loss: 0.44658908545970916
train--18/100 [299/1090] loss: 0.46162408888339995
train--18/100 [309/1090] loss: 0.4561219781637192
train--18/100 [319/1090] loss: 0.47485698759555817
train--18/100 [329/1090] loss: 0.4680545389652252
train--18/100 [339/1090] loss: 0.4437820762395859
train--18/100 [349/1090] loss: 0.45240154564380647
train--18/100 [359/1090] loss: 0.4523185700178146
train--18/100 [369/1090] loss: 0.4586077332496643
train--18/100 [379/1090] loss: 0.4451374292373657
train--18/100 [389/1090] loss: 0.43129213750362394
train--18/100 [399/1090] loss: 0.4511486619710922
train--18/100 [409/1090] loss: 0.44525101184844973
train--18/100 [419/1090] loss: 0.4383156895637512
train--18/100 [429/1090] loss: 0.46571105122566225
train--18/100 [439/1090] loss: 0.4433042198419571
train--18/100 [449/1090] loss: 0.4340317189693451
train--18/100 [459/1090] loss: 0.4474274039268494
train--18/100 [469/1090] loss: 0.43881785571575166
train--18/100 [479/1090] loss: 0.4295621305704117
train--18/100 [489/1090] loss: 0.4691621661186218
train--18/100 [499/1090] loss: 0.4696968913078308
train--18/100 [509/1090] loss: 0.4479932427406311
train--18/100 [519/1090] loss: 0.45531696975231173
train--18/100 [529/1090] loss: 0.44912540912628174
train--18/100 [539/1090] loss: 0.4439708858728409
train--18/100 [549/1090] loss: 0.4524576425552368
train--18/100 [559/1090] loss: 0.4723769068717957
train--18/100 [569/1090] loss: 0.44127418994903567
train--18/100 [579/1090] loss: 0.4498668223619461
train--18/100 [589/1090] loss: 0.4333464205265045
train--18/100 [599/1090] loss: 0.4514746695756912
train--18/100 [609/1090] loss: 0.4360145807266235
train--18/100 [619/1090] loss: 0.4564744204282761
train--18/100 [629/1090] loss: 0.4423722892999649
train--18/100 [639/1090] loss: 0.4423065364360809
train--18/100 [649/1090] loss: 0.4370376497507095
train--18/100 [659/1090] loss: 0.44459295868873594
train--18/100 [669/1090] loss: 0.44991674721241
train--18/100 [679/1090] loss: 0.4678769588470459
train--18/100 [689/1090] loss: 0.445488378405571
train--18/100 [699/1090] loss: 0.4422160148620605
train--18/100 [709/1090] loss: 0.4749465435743332
train--18/100 [719/1090] loss: 0.4415270447731018
train--18/100 [729/1090] loss: 0.4630944162607193
train--18/100 [739/1090] loss: 0.44828433990478517
train--18/100 [749/1090] loss: 0.45389069616794586
train--18/100 [759/1090] loss: 0.4515606164932251
train--18/100 [769/1090] loss: 0.44999226927757263
train--18/100 [779/1090] loss: 0.4652288556098938
train--18/100 [789/1090] loss: 0.4361427456140518
train--18/100 [799/1090] loss: 0.45171473920345306
train--18/100 [809/1090] loss: 0.44837868511676787
train--18/100 [819/1090] loss: 0.4362636715173721
train--18/100 [829/1090] loss: 0.46609683632850646
train--18/100 [839/1090] loss: 0.45467519462108613
train--18/100 [849/1090] loss: 0.45804897844791415
train--18/100 [859/1090] loss: 0.4523118078708649
train--18/100 [869/1090] loss: 0.4740931481122971
train--18/100 [879/1090] loss: 0.43858813047409057
train--18/100 [889/1090] loss: 0.4325590580701828
train--18/100 [899/1090] loss: 0.44140137135982516
train--18/100 [909/1090] loss: 0.43541793525218964
train--18/100 [919/1090] loss: 0.45164682269096373
train--18/100 [929/1090] loss: 0.4689582347869873
train--18/100 [939/1090] loss: 0.44162931442260744
train--18/100 [949/1090] loss: 0.4411647140979767
train--18/100 [959/1090] loss: 0.44945856332778933
train--18/100 [969/1090] loss: 0.4673248022794724
train--18/100 [979/1090] loss: 0.43856637477874755
train--18/100 [989/1090] loss: 0.46323745846748354
train--18/100 [999/1090] loss: 0.4419604420661926
train--18/100 [1009/1090] loss: 0.4508815824985504
train--18/100 [1019/1090] loss: 0.43252732753753664
train--18/100 [1029/1090] loss: 0.4534976303577423
train--18/100 [1039/1090] loss: 0.4491890847682953
train--18/100 [1049/1090] loss: 0.4501313328742981
train--18/100 [1059/1090] loss: 0.4393788307905197
train--18/100 [1069/1090] loss: 0.4618814647197723
train--18/100 [1079/1090] loss: 0.45851571559906007
train--18/100 [1089/1090] loss: 0.46228590309619905
predicting model...
val--18/100 [10/1090] acc: 0.791796875
val--18/100 [20/1090] acc: 0.792578125
val--18/100 [30/1090] acc: 0.7920572916666667
val--18/100 [40/1090] acc: 0.79248046875
val--18/100 [50/1090] acc: 0.79078125
val--18/100 [60/1090] acc: 0.7901692708333333
val--18/100 [70/1090] acc: 0.7905691964285714
val--18/100 [80/1090] acc: 0.78935546875
val--18/100 [90/1090] acc: 0.7901909722222222
val--18/100 [100/1090] acc: 0.7912890625
val--18/100 [110/1090] acc: 0.7912997159090909
val--18/100 [120/1090] acc: 0.7908854166666667
val--18/100 [130/1090] acc: 0.7919771634615385
val--18/100 [140/1090] acc: 0.7918805803571428
val--18/100 [150/1090] acc: 0.7919010416666666
val--18/100 [160/1090] acc: 0.7921630859375
val--18/100 [170/1090] acc: 0.792141544117647
val--18/100 [180/1090] acc: 0.7918619791666667
val--18/100 [190/1090] acc: 0.792639802631579
val--18/100 [200/1090] acc: 0.79275390625
val--18/100 [210/1090] acc: 0.7930059523809524
val--18/100 [220/1090] acc: 0.7921875
val--18/100 [230/1090] acc: 0.7928158967391304
val--18/100 [240/1090] acc: 0.7926920572916667
val--18/100 [250/1090] acc: 0.792921875
val--18/100 [260/1090] acc: 0.7929537259615385
val--18/100 [270/1090] acc: 0.7932291666666667
val--18/100 [280/1090] acc: 0.7932338169642857
val--18/100 [290/1090] acc: 0.7931303879310345
val--18/100 [300/1090] acc: 0.793125
val--18/100 [310/1090] acc: 0.7929057459677419
val--18/100 [320/1090] acc: 0.79324951171875
val--18/100 [330/1090] acc: 0.7934777462121212
val--18/100 [340/1090] acc: 0.7936580882352942
val--18/100 [350/1090] acc: 0.7938058035714286
val--18/100 [360/1090] acc: 0.7936848958333333
val--18/100 [370/1090] acc: 0.793823902027027
val--18/100 [380/1090] acc: 0.7937911184210527
val--18/100 [390/1090] acc: 0.7935596955128205
val--18/100 [400/1090] acc: 0.79345703125
val--18/100 [410/1090] acc: 0.7936261432926829
val--18/100 [420/1090] acc: 0.7936662946428571
val--18/100 [430/1090] acc: 0.7935683139534884
val--18/100 [440/1090] acc: 0.7935280539772728
val--18/100 [450/1090] acc: 0.7934635416666667
val--18/100 [460/1090] acc: 0.7934188179347826
val--18/100 [470/1090] acc: 0.7933261303191489
val--18/100 [480/1090] acc: 0.7934326171875
val--18/100 [490/1090] acc: 0.7935267857142857
val--18/100 [500/1090] acc: 0.7936796875
val--18/100 [510/1090] acc: 0.7935508578431373
val--18/100 [520/1090] acc: 0.7936974158653847
val--18/100 [530/1090] acc: 0.7937131485849057
val--18/100 [540/1090] acc: 0.7938512731481482
val--18/100 [550/1090] acc: 0.7937855113636364
val--18/100 [560/1090] acc: 0.79365234375
val--18/100 [570/1090] acc: 0.7934279057017544
val--18/100 [580/1090] acc: 0.793426724137931
val--18/100 [590/1090] acc: 0.7934653072033898
val--18/100 [600/1090] acc: 0.7934505208333333
val--18/100 [610/1090] acc: 0.7933401639344262
val--18/100 [620/1090] acc: 0.7932396673387097
val--18/100 [630/1090] acc: 0.7934647817460317
val--18/100 [640/1090] acc: 0.793682861328125
val--18/100 [650/1090] acc: 0.7937259615384615
val--18/100 [660/1090] acc: 0.7935961174242424
val--18/100 [670/1090] acc: 0.7933418843283582
val--18/100 [680/1090] acc: 0.7932215073529412
val--18/100 [690/1090] acc: 0.7934159873188406
val--18/100 [700/1090] acc: 0.7934263392857143
val--18/100 [710/1090] acc: 0.7932493397887324
val--18/100 [720/1090] acc: 0.7930555555555555
val--18/100 [730/1090] acc: 0.7930062071917808
val--18/100 [740/1090] acc: 0.79296875
val--18/100 [750/1090] acc: 0.7930104166666667
val--18/100 [760/1090] acc: 0.793128083881579
val--18/100 [770/1090] acc: 0.7931361607142857
val--18/100 [780/1090] acc: 0.7931089743589743
val--18/100 [790/1090] acc: 0.7931121439873418
val--18/100 [800/1090] acc: 0.79333984375
val--18/100 [810/1090] acc: 0.7933979552469136
val--18/100 [820/1090] acc: 0.7934975228658536
val--18/100 [830/1090] acc: 0.7935711596385542
val--18/100 [840/1090] acc: 0.7935128348214285
val--18/100 [850/1090] acc: 0.7934926470588235
val--18/100 [860/1090] acc: 0.7936909520348837
val--18/100 [870/1090] acc: 0.7935524425287356
val--18/100 [880/1090] acc: 0.793514737215909
val--18/100 [890/1090] acc: 0.7936490519662921
val--18/100 [900/1090] acc: 0.7936501736111111
val--18/100 [910/1090] acc: 0.7936383928571429
val--18/100 [920/1090] acc: 0.7936735733695652
val--18/100 [930/1090] acc: 0.7936953965053763
val--18/100 [940/1090] acc: 0.7937209109042553
val--18/100 [950/1090] acc: 0.7936389802631579
val--18/100 [960/1090] acc: 0.7935709635416667
val--18/100 [970/1090] acc: 0.7935567010309278
val--18/100 [980/1090] acc: 0.7935586734693878
val--18/100 [990/1090] acc: 0.7934816919191919
val--18/100 [1000/1090] acc: 0.79340625
val--18/100 [1010/1090] acc: 0.7932704207920792
val--18/100 [1020/1090] acc: 0.7933517156862745
val--18/100 [1030/1090] acc: 0.7933859223300971
val--18/100 [1040/1090] acc: 0.7933631310096154
val--18/100 [1050/1090] acc: 0.7934263392857143
val--18/100 [1060/1090] acc: 0.7933556898584906
val--18/100 [1070/1090] acc: 0.7933630257009345
val--18/100 [1080/1090] acc: 0.7932870370370371
val--18/100 [1090/1090] acc: 0.7931336009174312
epoch= 18, accuracy= 0.793134, rmse= 0.379023, auc= 0.854198
train--19/100 [9/1090] loss: 0.3951850026845932
train--19/100 [19/1090] loss: 0.4447291374206543
train--19/100 [29/1090] loss: 0.43038136065006255
train--19/100 [39/1090] loss: 0.44988966882228854
train--19/100 [49/1090] loss: 0.4408993571996689
train--19/100 [59/1090] loss: 0.4554476261138916
train--19/100 [69/1090] loss: 0.44833968579769135
train--19/100 [79/1090] loss: 0.4440120100975037
train--19/100 [89/1090] loss: 0.4355898529291153
train--19/100 [99/1090] loss: 0.46391392648220064
train--19/100 [109/1090] loss: 0.45341425240039823
train--19/100 [119/1090] loss: 0.44383156299591064
train--19/100 [129/1090] loss: 0.44460184276103976
train--19/100 [139/1090] loss: 0.4533702492713928
train--19/100 [149/1090] loss: 0.45341236889362335
train--19/100 [159/1090] loss: 0.44207615256309507
train--19/100 [169/1090] loss: 0.4333565831184387
train--19/100 [179/1090] loss: 0.41713799238204957
train--19/100 [189/1090] loss: 0.4624824494123459
train--19/100 [199/1090] loss: 0.432770249247551
train--19/100 [209/1090] loss: 0.44793550968170165
train--19/100 [219/1090] loss: 0.4500367999076843
train--19/100 [229/1090] loss: 0.45410706102848053
train--19/100 [239/1090] loss: 0.44535102844238283
train--19/100 [249/1090] loss: 0.43676514327526095
train--19/100 [259/1090] loss: 0.4299179375171661
train--19/100 [269/1090] loss: 0.4448821395635605
train--19/100 [279/1090] loss: 0.4623866707086563
train--19/100 [289/1090] loss: 0.45422268807888033
train--19/100 [299/1090] loss: 0.448930099606514
train--19/100 [309/1090] loss: 0.44110298752784727
train--19/100 [319/1090] loss: 0.45626087486743927
train--19/100 [329/1090] loss: 0.4456174999475479
train--19/100 [339/1090] loss: 0.4568793445825577
train--19/100 [349/1090] loss: 0.45152671039104464
train--19/100 [359/1090] loss: 0.458341509103775
train--19/100 [369/1090] loss: 0.43498547077178956
train--19/100 [379/1090] loss: 0.4666409969329834
train--19/100 [389/1090] loss: 0.44375750720500945
train--19/100 [399/1090] loss: 0.46354820728302004
train--19/100 [409/1090] loss: 0.44870680272579194
train--19/100 [419/1090] loss: 0.4642988383769989
train--19/100 [429/1090] loss: 0.44543576538562774
train--19/100 [439/1090] loss: 0.4588606029748917
train--19/100 [449/1090] loss: 0.4604725271463394
train--19/100 [459/1090] loss: 0.4575894623994827
train--19/100 [469/1090] loss: 0.4564414948225021
train--19/100 [479/1090] loss: 0.4495930641889572
train--19/100 [489/1090] loss: 0.4456391394138336
train--19/100 [499/1090] loss: 0.44835478365421294
train--19/100 [509/1090] loss: 0.4693944603204727
train--19/100 [519/1090] loss: 0.4567438751459122
train--19/100 [529/1090] loss: 0.42852549254894257
train--19/100 [539/1090] loss: 0.44367048144340515
train--19/100 [549/1090] loss: 0.46239712834358215
train--19/100 [559/1090] loss: 0.4494264662265778
train--19/100 [569/1090] loss: 0.4413711875677109
train--19/100 [579/1090] loss: 0.4375375956296921
train--19/100 [589/1090] loss: 0.448530837893486
train--19/100 [599/1090] loss: 0.45311457216739653
train--19/100 [609/1090] loss: 0.44511387348175047
train--19/100 [619/1090] loss: 0.442596435546875
train--19/100 [629/1090] loss: 0.42623879611492155
train--19/100 [639/1090] loss: 0.44421524107456206
train--19/100 [649/1090] loss: 0.4478610932826996
train--19/100 [659/1090] loss: 0.451108580827713
train--19/100 [669/1090] loss: 0.46306694447994234
train--19/100 [679/1090] loss: 0.4504413366317749
train--19/100 [689/1090] loss: 0.46039282977581025
train--19/100 [699/1090] loss: 0.4597033351659775
train--19/100 [709/1090] loss: 0.4631351470947266
train--19/100 [719/1090] loss: 0.4687810480594635
train--19/100 [729/1090] loss: 0.4627912938594818
train--19/100 [739/1090] loss: 0.4501929521560669
train--19/100 [749/1090] loss: 0.4484220862388611
train--19/100 [759/1090] loss: 0.4488083362579346
train--19/100 [769/1090] loss: 0.4577982038259506
train--19/100 [779/1090] loss: 0.4399669110774994
train--19/100 [789/1090] loss: 0.455404731631279
train--19/100 [799/1090] loss: 0.44237091541290285
train--19/100 [809/1090] loss: 0.43326203227043153
train--19/100 [819/1090] loss: 0.4445022225379944
train--19/100 [829/1090] loss: 0.45885218381881715
train--19/100 [839/1090] loss: 0.4384618610143661
train--19/100 [849/1090] loss: 0.4371039479970932
train--19/100 [859/1090] loss: 0.4602943390607834
train--19/100 [869/1090] loss: 0.44020848274230956
train--19/100 [879/1090] loss: 0.44614870846271515
train--19/100 [889/1090] loss: 0.47739897668361664
train--19/100 [899/1090] loss: 0.4587588280439377
train--19/100 [909/1090] loss: 0.46335886120796205
train--19/100 [919/1090] loss: 0.431142321228981
train--19/100 [929/1090] loss: 0.43503883183002473
train--19/100 [939/1090] loss: 0.4511305719614029
train--19/100 [949/1090] loss: 0.45625045895576477
train--19/100 [959/1090] loss: 0.4484392493963242
train--19/100 [969/1090] loss: 0.4473739504814148
train--19/100 [979/1090] loss: 0.4418326705694199
train--19/100 [989/1090] loss: 0.4593286454677582
train--19/100 [999/1090] loss: 0.4496908813714981
train--19/100 [1009/1090] loss: 0.43339528441429137
train--19/100 [1019/1090] loss: 0.4514125108718872
train--19/100 [1029/1090] loss: 0.4576990962028503
train--19/100 [1039/1090] loss: 0.44060943424701693
train--19/100 [1049/1090] loss: 0.4468034327030182
train--19/100 [1059/1090] loss: 0.45201819837093354
train--19/100 [1069/1090] loss: 0.45082406997680663
train--19/100 [1079/1090] loss: 0.4285426467657089
train--19/100 [1089/1090] loss: 0.4568341076374054
predicting model...
val--19/100 [10/1090] acc: 0.79140625
val--19/100 [20/1090] acc: 0.7927734375
val--19/100 [30/1090] acc: 0.7927083333333333
val--19/100 [40/1090] acc: 0.792578125
val--19/100 [50/1090] acc: 0.791875
val--19/100 [60/1090] acc: 0.7908854166666667
val--19/100 [70/1090] acc: 0.7913504464285714
val--19/100 [80/1090] acc: 0.790625
val--19/100 [90/1090] acc: 0.7910590277777778
val--19/100 [100/1090] acc: 0.7921484375
val--19/100 [110/1090] acc: 0.7921875
val--19/100 [120/1090] acc: 0.7916666666666666
val--19/100 [130/1090] acc: 0.7926682692307693
val--19/100 [140/1090] acc: 0.7927455357142857
val--19/100 [150/1090] acc: 0.7928385416666667
val--19/100 [160/1090] acc: 0.7930908203125
val--19/100 [170/1090] acc: 0.7931985294117647
val--19/100 [180/1090] acc: 0.79296875
val--19/100 [190/1090] acc: 0.7936472039473684
val--19/100 [200/1090] acc: 0.79390625
val--19/100 [210/1090] acc: 0.7941964285714286
val--19/100 [220/1090] acc: 0.793359375
val--19/100 [230/1090] acc: 0.794038722826087
val--19/100 [240/1090] acc: 0.7938151041666667
val--19/100 [250/1090] acc: 0.79390625
val--19/100 [260/1090] acc: 0.7938701923076923
val--19/100 [270/1090] acc: 0.7940248842592592
val--19/100 [280/1090] acc: 0.7939453125
val--19/100 [290/1090] acc: 0.7938038793103448
val--19/100 [300/1090] acc: 0.7937630208333334
val--19/100 [310/1090] acc: 0.7933971774193549
val--19/100 [320/1090] acc: 0.79364013671875
val--19/100 [330/1090] acc: 0.7939157196969697
val--19/100 [340/1090] acc: 0.7940716911764706
val--19/100 [350/1090] acc: 0.7941071428571429
val--19/100 [360/1090] acc: 0.7939344618055556
val--19/100 [370/1090] acc: 0.794066722972973
val--19/100 [380/1090] acc: 0.7939658717105263
val--19/100 [390/1090] acc: 0.7936598557692308
val--19/100 [400/1090] acc: 0.7935546875
val--19/100 [410/1090] acc: 0.7937690548780488
val--19/100 [420/1090] acc: 0.7937965029761904
val--19/100 [430/1090] acc: 0.7936228197674419
val--19/100 [440/1090] acc: 0.7936079545454545
val--19/100 [450/1090] acc: 0.7934635416666667
val--19/100 [460/1090] acc: 0.7933338994565218
val--19/100 [470/1090] acc: 0.793218085106383
val--19/100 [480/1090] acc: 0.7932454427083333
val--19/100 [490/1090] acc: 0.7933354591836734
val--19/100 [500/1090] acc: 0.793546875
val--19/100 [510/1090] acc: 0.7934819240196078
val--19/100 [520/1090] acc: 0.7936373197115385
val--19/100 [530/1090] acc: 0.7937057783018868
val--19/100 [540/1090] acc: 0.7938368055555556
val--19/100 [550/1090] acc: 0.7937215909090909
val--19/100 [560/1090] acc: 0.7935965401785714
val--19/100 [570/1090] acc: 0.7933251096491228
val--19/100 [580/1090] acc: 0.7933257004310345
val--19/100 [590/1090] acc: 0.793359375
val--19/100 [600/1090] acc: 0.7933528645833333
val--19/100 [610/1090] acc: 0.7932889344262295
val--19/100 [620/1090] acc: 0.793227066532258
val--19/100 [630/1090] acc: 0.7934585813492063
val--19/100 [640/1090] acc: 0.79366455078125
val--19/100 [650/1090] acc: 0.7937379807692307
val--19/100 [660/1090] acc: 0.7936138731060606
val--19/100 [670/1090] acc: 0.7933243936567164
val--19/100 [680/1090] acc: 0.7932559742647058
val--19/100 [690/1090] acc: 0.7934159873188406
val--19/100 [700/1090] acc: 0.7934207589285714
val--19/100 [710/1090] acc: 0.7932328345070423
val--19/100 [720/1090] acc: 0.7930447048611111
val--19/100 [730/1090] acc: 0.7929794520547945
val--19/100 [740/1090] acc: 0.7928790118243243
val--19/100 [750/1090] acc: 0.7929739583333333
val--19/100 [760/1090] acc: 0.7930304276315789
val--19/100 [770/1090] acc: 0.7930093344155844
val--19/100 [780/1090] acc: 0.7929837740384615
val--19/100 [790/1090] acc: 0.7930181962025317
val--19/100 [800/1090] acc: 0.793271484375
val--19/100 [810/1090] acc: 0.7933256172839506
val--19/100 [820/1090] acc: 0.7934546493902439
val--19/100 [830/1090] acc: 0.7935335090361446
val--19/100 [840/1090] acc: 0.7934616815476191
val--19/100 [850/1090] acc: 0.7934880514705882
val--19/100 [860/1090] acc: 0.7936818677325581
val--19/100 [870/1090] acc: 0.7935614224137931
val--19/100 [880/1090] acc: 0.7935280539772728
val--19/100 [890/1090] acc: 0.7936622191011236
val--19/100 [900/1090] acc: 0.7936545138888889
val--19/100 [910/1090] acc: 0.7936727335164835
val--19/100 [920/1090] acc: 0.7937117866847826
val--19/100 [930/1090] acc: 0.7937920026881721
val--19/100 [940/1090] acc: 0.7938497340425532
val--19/100 [950/1090] acc: 0.7937376644736842
val--19/100 [960/1090] acc: 0.7936482747395833
val--19/100 [970/1090] acc: 0.7936332152061856
val--19/100 [980/1090] acc: 0.7936264349489796
val--19/100 [990/1090] acc: 0.7935527146464646
val--19/100 [1000/1090] acc: 0.79346875
val--19/100 [1010/1090] acc: 0.7933245668316832
val--19/100 [1020/1090] acc: 0.7934015012254902
val--19/100 [1030/1090] acc: 0.7934769417475728
val--19/100 [1040/1090] acc: 0.7934269831730769
val--19/100 [1050/1090] acc: 0.7935044642857143
val--19/100 [1060/1090] acc: 0.7934183372641509
val--19/100 [1070/1090] acc: 0.7934068341121495
val--19/100 [1080/1090] acc: 0.7933449074074074
val--19/100 [1090/1090] acc: 0.7931766055045871
epoch= 19, accuracy= 0.793177, rmse= 0.379036, auc= 0.854255
train--20/100 [9/1090] loss: 0.39775699079036714
train--20/100 [19/1090] loss: 0.4203680157661438
train--20/100 [29/1090] loss: 0.4506712257862091
train--20/100 [39/1090] loss: 0.4435170590877533
train--20/100 [49/1090] loss: 0.44690781831741333
train--20/100 [59/1090] loss: 0.44079561829566954
train--20/100 [69/1090] loss: 0.4590988278388977
train--20/100 [79/1090] loss: 0.4465021640062332
train--20/100 [89/1090] loss: 0.4415037900209427
train--20/100 [99/1090] loss: 0.426717084646225
train--20/100 [109/1090] loss: 0.44744186103343964
train--20/100 [119/1090] loss: 0.45219422280788424
train--20/100 [129/1090] loss: 0.4342338562011719
train--20/100 [139/1090] loss: 0.45785722732543943
train--20/100 [149/1090] loss: 0.446947306394577
train--20/100 [159/1090] loss: 0.44707563817501067
train--20/100 [169/1090] loss: 0.4481885552406311
train--20/100 [179/1090] loss: 0.4505237013101578
train--20/100 [189/1090] loss: 0.42571163177490234
train--20/100 [199/1090] loss: 0.4543262153863907
train--20/100 [209/1090] loss: 0.43567413091659546
train--20/100 [219/1090] loss: 0.45450000166893006
train--20/100 [229/1090] loss: 0.4542148768901825
train--20/100 [239/1090] loss: 0.44134379625320436
train--20/100 [249/1090] loss: 0.4351087063550949
train--20/100 [259/1090] loss: 0.44788939952850343
train--20/100 [269/1090] loss: 0.45619033873081205
train--20/100 [279/1090] loss: 0.45067429542541504
train--20/100 [289/1090] loss: 0.4306565076112747
train--20/100 [299/1090] loss: 0.4501765549182892
train--20/100 [309/1090] loss: 0.42751928269863126
train--20/100 [319/1090] loss: 0.4438077241182327
train--20/100 [329/1090] loss: 0.4584560006856918
train--20/100 [339/1090] loss: 0.4482052892446518
train--20/100 [349/1090] loss: 0.45867840349674227
train--20/100 [359/1090] loss: 0.44725213944911957
train--20/100 [369/1090] loss: 0.4542523920536041
train--20/100 [379/1090] loss: 0.45870920419692995
train--20/100 [389/1090] loss: 0.4553843319416046
train--20/100 [399/1090] loss: 0.43982797861099243
train--20/100 [409/1090] loss: 0.4418244808912277
train--20/100 [419/1090] loss: 0.4490081280469894
train--20/100 [429/1090] loss: 0.4584448248147964
train--20/100 [439/1090] loss: 0.4446979522705078
train--20/100 [449/1090] loss: 0.46881261467933655
train--20/100 [459/1090] loss: 0.44374674260616304
train--20/100 [469/1090] loss: 0.4488415211439133
train--20/100 [479/1090] loss: 0.4449112921953201
train--20/100 [489/1090] loss: 0.4537572205066681
train--20/100 [499/1090] loss: 0.44443044662475584
train--20/100 [509/1090] loss: 0.46795249581336973
train--20/100 [519/1090] loss: 0.44756139516830445
train--20/100 [529/1090] loss: 0.43523749709129333
train--20/100 [539/1090] loss: 0.4654875069856644
train--20/100 [549/1090] loss: 0.45727161765098573
train--20/100 [559/1090] loss: 0.43579083383083345
train--20/100 [569/1090] loss: 0.44672837257385256
train--20/100 [579/1090] loss: 0.4527623295783997
train--20/100 [589/1090] loss: 0.439788693189621
train--20/100 [599/1090] loss: 0.4749371975660324
train--20/100 [609/1090] loss: 0.4543352097272873
train--20/100 [619/1090] loss: 0.46110279858112335
train--20/100 [629/1090] loss: 0.4466965407133102
train--20/100 [639/1090] loss: 0.4267713099718094
train--20/100 [649/1090] loss: 0.4468035131692886
train--20/100 [659/1090] loss: 0.45116882026195526
train--20/100 [669/1090] loss: 0.42745962738990784
train--20/100 [679/1090] loss: 0.453596305847168
train--20/100 [689/1090] loss: 0.44813223779201505
train--20/100 [699/1090] loss: 0.44954474866390226
train--20/100 [709/1090] loss: 0.4577480286359787
train--20/100 [719/1090] loss: 0.46552411913871766
train--20/100 [729/1090] loss: 0.4458843499422073
train--20/100 [739/1090] loss: 0.4303654581308365
train--20/100 [749/1090] loss: 0.43916783332824705
train--20/100 [759/1090] loss: 0.45175865292549133
train--20/100 [769/1090] loss: 0.4663211524486542
train--20/100 [779/1090] loss: 0.4366290748119354
train--20/100 [789/1090] loss: 0.4411595374345779
train--20/100 [799/1090] loss: 0.4642406016588211
train--20/100 [809/1090] loss: 0.4623434662818909
train--20/100 [819/1090] loss: 0.45495070815086364
train--20/100 [829/1090] loss: 0.4421606123447418
train--20/100 [839/1090] loss: 0.4470102310180664
train--20/100 [849/1090] loss: 0.45736953914165496
train--20/100 [859/1090] loss: 0.43483268916606904
train--20/100 [869/1090] loss: 0.452372869849205
train--20/100 [879/1090] loss: 0.47630296647548676
train--20/100 [889/1090] loss: 0.4478816032409668
train--20/100 [899/1090] loss: 0.4617616832256317
train--20/100 [909/1090] loss: 0.4300393909215927
train--20/100 [919/1090] loss: 0.45017566382884977
train--20/100 [929/1090] loss: 0.44181221127510073
train--20/100 [939/1090] loss: 0.454178124666214
train--20/100 [949/1090] loss: 0.4351810961961746
train--20/100 [959/1090] loss: 0.44095781445503235
train--20/100 [969/1090] loss: 0.46694217920303344
train--20/100 [979/1090] loss: 0.45787146091461184
train--20/100 [989/1090] loss: 0.4498256713151932
train--20/100 [999/1090] loss: 0.46132092773914335
train--20/100 [1009/1090] loss: 0.4392501026391983
train--20/100 [1019/1090] loss: 0.44132268726825713
train--20/100 [1029/1090] loss: 0.43936817049980165
train--20/100 [1039/1090] loss: 0.4623023122549057
train--20/100 [1049/1090] loss: 0.45717709958553315
train--20/100 [1059/1090] loss: 0.461931174993515
train--20/100 [1069/1090] loss: 0.46601502001285555
train--20/100 [1079/1090] loss: 0.4596576005220413
train--20/100 [1089/1090] loss: 0.45907638072967527
predicting model...
val--20/100 [10/1090] acc: 0.790625
val--20/100 [20/1090] acc: 0.79140625
val--20/100 [30/1090] acc: 0.7915364583333333
val--20/100 [40/1090] acc: 0.7916015625
val--20/100 [50/1090] acc: 0.7909375
val--20/100 [60/1090] acc: 0.7899739583333333
val--20/100 [70/1090] acc: 0.790625
val--20/100 [80/1090] acc: 0.7890625
val--20/100 [90/1090] acc: 0.7899739583333333
val--20/100 [100/1090] acc: 0.791015625
val--20/100 [110/1090] acc: 0.7910511363636363
val--20/100 [120/1090] acc: 0.790625
val--20/100 [130/1090] acc: 0.7917367788461539
val--20/100 [140/1090] acc: 0.7919084821428571
val--20/100 [150/1090] acc: 0.7917708333333333
val--20/100 [160/1090] acc: 0.7922119140625
val--20/100 [170/1090] acc: 0.7923483455882353
val--20/100 [180/1090] acc: 0.7920138888888889
val--20/100 [190/1090] acc: 0.7928042763157894
val--20/100 [200/1090] acc: 0.7930078125
val--20/100 [210/1090] acc: 0.793266369047619
val--20/100 [220/1090] acc: 0.7925071022727272
val--20/100 [230/1090] acc: 0.7930366847826087
val--20/100 [240/1090] acc: 0.792822265625
val--20/100 [250/1090] acc: 0.793
val--20/100 [260/1090] acc: 0.7930288461538462
val--20/100 [270/1090] acc: 0.7933738425925926
val--20/100 [280/1090] acc: 0.7933454241071428
val--20/100 [290/1090] acc: 0.7932381465517241
val--20/100 [300/1090] acc: 0.7932421875
val--20/100 [310/1090] acc: 0.7929435483870968
val--20/100 [320/1090] acc: 0.79320068359375
val--20/100 [330/1090] acc: 0.793454071969697
val--20/100 [340/1090] acc: 0.7934627757352941
val--20/100 [350/1090] acc: 0.7935379464285715
val--20/100 [360/1090] acc: 0.7934678819444444
val--20/100 [370/1090] acc: 0.793581081081081
val--20/100 [380/1090] acc: 0.7935238486842106
val--20/100 [390/1090] acc: 0.7932992788461538
val--20/100 [400/1090] acc: 0.79326171875
val--20/100 [410/1090] acc: 0.7934355945121951
val--20/100 [420/1090] acc: 0.7934988839285714
val--20/100 [430/1090] acc: 0.7934047965116279
val--20/100 [440/1090] acc: 0.7933682528409091
val--20/100 [450/1090] acc: 0.7932378472222222
val--20/100 [460/1090] acc: 0.7931216032608696
val--20/100 [470/1090] acc: 0.7929770611702127
val--20/100 [480/1090] acc: 0.7930094401041666
val--20/100 [490/1090] acc: 0.7931361607142857
val--20/100 [500/1090] acc: 0.7933125
val--20/100 [510/1090] acc: 0.7932444852941176
val--20/100 [520/1090] acc: 0.7934119591346154
val--20/100 [530/1090] acc: 0.7934257075471698
val--20/100 [540/1090] acc: 0.7936125578703703
val--20/100 [550/1090] acc: 0.7934303977272728
val--20/100 [560/1090] acc: 0.7932756696428571
val--20/100 [570/1090] acc: 0.7930578399122807
val--20/100 [580/1090] acc: 0.7931034482758621
val--20/100 [590/1090] acc: 0.7931541313559322
val--20/100 [600/1090] acc: 0.7931901041666667
val--20/100 [610/1090] acc: 0.7931288422131147
val--20/100 [620/1090] acc: 0.7930632560483871
val--20/100 [630/1090] acc: 0.7932725694444445
val--20/100 [640/1090] acc: 0.7934814453125
val--20/100 [650/1090] acc: 0.7935817307692308
val--20/100 [660/1090] acc: 0.7934777462121212
val--20/100 [670/1090] acc: 0.7931844682835821
val--20/100 [680/1090] acc: 0.7930032169117647
val--20/100 [690/1090] acc: 0.7932008605072464
val--20/100 [700/1090] acc: 0.7931919642857143
val--20/100 [710/1090] acc: 0.7930237676056338
val--20/100 [720/1090] acc: 0.7928548177083333
val--20/100 [730/1090] acc: 0.7928135702054795
val--20/100 [740/1090] acc: 0.792699535472973
val--20/100 [750/1090] acc: 0.7927395833333334
val--20/100 [760/1090] acc: 0.7928402549342105
val--20/100 [770/1090] acc: 0.7928520698051948
val--20/100 [780/1090] acc: 0.7928335336538461
val--20/100 [790/1090] acc: 0.7928352452531645
val--20/100 [800/1090] acc: 0.79306640625
val--20/100 [810/1090] acc: 0.7931520061728395
val--20/100 [820/1090] acc: 0.7932355182926829
val--20/100 [830/1090] acc: 0.7933311370481928
val--20/100 [840/1090] acc: 0.7932477678571429
val--20/100 [850/1090] acc: 0.7932766544117648
val--20/100 [860/1090] acc: 0.7934865552325582
val--20/100 [870/1090] acc: 0.7933863146551724
val--20/100 [880/1090] acc: 0.7933460582386364
val--20/100 [890/1090] acc: 0.7935173806179775
val--20/100 [900/1090] acc: 0.7935112847222222
val--20/100 [910/1090] acc: 0.7935053228021978
val--20/100 [920/1090] acc: 0.7935377038043478
val--20/100 [930/1090] acc: 0.793607190860215
val--20/100 [940/1090] acc: 0.7936377992021276
val--20/100 [950/1090] acc: 0.7935526315789474
val--20/100 [960/1090] acc: 0.7934733072916667
val--20/100 [970/1090] acc: 0.7934399162371134
val--20/100 [980/1090] acc: 0.7934510522959184
val--20/100 [990/1090] acc: 0.7934027777777778
val--20/100 [1000/1090] acc: 0.7933359375
val--20/100 [1010/1090] acc: 0.7932124071782178
val--20/100 [1020/1090] acc: 0.7932636335784313
val--20/100 [1030/1090] acc: 0.7933442050970874
val--20/100 [1040/1090] acc: 0.7933067908653846
val--20/100 [1050/1090] acc: 0.7933482142857143
val--20/100 [1060/1090] acc: 0.7932856721698113
val--20/100 [1070/1090] acc: 0.7932790595794392
val--20/100 [1080/1090] acc: 0.7932219328703703
val--20/100 [1090/1090] acc: 0.7930583428899083
epoch= 20, accuracy= 0.793058, rmse= 0.379105, auc= 0.854301
train--21/100 [9/1090] loss: 0.41525204181671144
train--21/100 [19/1090] loss: 0.4398890346288681
train--21/100 [29/1090] loss: 0.45196978449821473
train--21/100 [39/1090] loss: 0.44407974779605863
train--21/100 [49/1090] loss: 0.4327214568853378
train--21/100 [59/1090] loss: 0.4710953712463379
train--21/100 [69/1090] loss: 0.4664257824420929
train--21/100 [79/1090] loss: 0.4315501809120178
train--21/100 [89/1090] loss: 0.4508828788995743
train--21/100 [99/1090] loss: 0.4546220064163208
train--21/100 [109/1090] loss: 0.43802588284015653
train--21/100 [119/1090] loss: 0.44437751173973083
train--21/100 [129/1090] loss: 0.4391480445861816
train--21/100 [139/1090] loss: 0.44673539102077486
train--21/100 [149/1090] loss: 0.44507751166820525
train--21/100 [159/1090] loss: 0.4245645195245743
train--21/100 [169/1090] loss: 0.4490349978208542
train--21/100 [179/1090] loss: 0.47363132834434507
train--21/100 [189/1090] loss: 0.44637922644615174
train--21/100 [199/1090] loss: 0.4291624963283539
train--21/100 [209/1090] loss: 0.436929914355278
train--21/100 [219/1090] loss: 0.44538294076919555
train--21/100 [229/1090] loss: 0.43357848227024076
train--21/100 [239/1090] loss: 0.46253147423267366
train--21/100 [249/1090] loss: 0.44201705455780027
train--21/100 [259/1090] loss: 0.4292337954044342
train--21/100 [269/1090] loss: 0.43439458310604095
train--21/100 [279/1090] loss: 0.44728533625602723
train--21/100 [289/1090] loss: 0.4378272742033005
train--21/100 [299/1090] loss: 0.43791798651218417
train--21/100 [309/1090] loss: 0.44485750794410706
train--21/100 [319/1090] loss: 0.4361184984445572
train--21/100 [329/1090] loss: 0.4305091589689255
train--21/100 [339/1090] loss: 0.45742892324924467
train--21/100 [349/1090] loss: 0.44707539975643157
train--21/100 [359/1090] loss: 0.45368856489658355
train--21/100 [369/1090] loss: 0.432309165596962
train--21/100 [379/1090] loss: 0.4359737455844879
train--21/100 [389/1090] loss: 0.43710525929927824
train--21/100 [399/1090] loss: 0.42867382168769835
train--21/100 [409/1090] loss: 0.4536236166954041
train--21/100 [419/1090] loss: 0.4449626088142395
train--21/100 [429/1090] loss: 0.43666105568408964
train--21/100 [439/1090] loss: 0.4453767865896225
train--21/100 [449/1090] loss: 0.45019960403442383
train--21/100 [459/1090] loss: 0.4297693192958832
train--21/100 [469/1090] loss: 0.4550720304250717
train--21/100 [479/1090] loss: 0.43695756793022156
train--21/100 [489/1090] loss: 0.46025499403476716
train--21/100 [499/1090] loss: 0.44471081495285036
train--21/100 [509/1090] loss: 0.4313055008649826
train--21/100 [519/1090] loss: 0.4639469802379608
train--21/100 [529/1090] loss: 0.4593736231327057
train--21/100 [539/1090] loss: 0.4459646314382553
train--21/100 [549/1090] loss: 0.44746692180633546
train--21/100 [559/1090] loss: 0.45568427741527556
train--21/100 [569/1090] loss: 0.42656988799571993
train--21/100 [579/1090] loss: 0.45070027410984037
train--21/100 [589/1090] loss: 0.45759219229221343
train--21/100 [599/1090] loss: 0.45909012854099274
train--21/100 [609/1090] loss: 0.4643526166677475
train--21/100 [619/1090] loss: 0.44618579745292664
train--21/100 [629/1090] loss: 0.4424364626407623
train--21/100 [639/1090] loss: 0.4548332989215851
train--21/100 [649/1090] loss: 0.45963669419288633
train--21/100 [659/1090] loss: 0.42874155640602113
train--21/100 [669/1090] loss: 0.4685615301132202
train--21/100 [679/1090] loss: 0.4522570759057999
train--21/100 [689/1090] loss: 0.436731818318367
train--21/100 [699/1090] loss: 0.45694519877433776
train--21/100 [709/1090] loss: 0.44231256246566775
train--21/100 [719/1090] loss: 0.4600324183702469
train--21/100 [729/1090] loss: 0.4598629862070084
train--21/100 [739/1090] loss: 0.45612245202064516
train--21/100 [749/1090] loss: 0.43790111839771273
train--21/100 [759/1090] loss: 0.4720929592847824
train--21/100 [769/1090] loss: 0.4481996476650238
train--21/100 [779/1090] loss: 0.46832149624824526
train--21/100 [789/1090] loss: 0.43874133825302125
train--21/100 [799/1090] loss: 0.4384067326784134
train--21/100 [809/1090] loss: 0.45501708984375
train--21/100 [819/1090] loss: 0.45536077618598936
train--21/100 [829/1090] loss: 0.4428243637084961
train--21/100 [839/1090] loss: 0.45236656069755554
train--21/100 [849/1090] loss: 0.4672708958387375
train--21/100 [859/1090] loss: 0.4538783699274063
train--21/100 [869/1090] loss: 0.4641646325588226
train--21/100 [879/1090] loss: 0.45318967998027804
train--21/100 [889/1090] loss: 0.45783194303512575
train--21/100 [899/1090] loss: 0.453301939368248
train--21/100 [909/1090] loss: 0.43985015749931333
train--21/100 [919/1090] loss: 0.4646323174238205
train--21/100 [929/1090] loss: 0.4419372081756592
train--21/100 [939/1090] loss: 0.45831915736198425
train--21/100 [949/1090] loss: 0.4633786529302597
train--21/100 [959/1090] loss: 0.4474992722272873
train--21/100 [969/1090] loss: 0.4331733375787735
train--21/100 [979/1090] loss: 0.4426897644996643
train--21/100 [989/1090] loss: 0.47113227248191836
train--21/100 [999/1090] loss: 0.44221711754798887
train--21/100 [1009/1090] loss: 0.4526626139879227
train--21/100 [1019/1090] loss: 0.4541619926691055
train--21/100 [1029/1090] loss: 0.46597486436367036
train--21/100 [1039/1090] loss: 0.4721630871295929
train--21/100 [1049/1090] loss: 0.45144490003585813
train--21/100 [1059/1090] loss: 0.4592360079288483
train--21/100 [1069/1090] loss: 0.4542107194662094
train--21/100 [1079/1090] loss: 0.451969513297081
train--21/100 [1089/1090] loss: 0.4534893691539764
predicting model...
val--21/100 [10/1090] acc: 0.790234375
val--21/100 [20/1090] acc: 0.7916015625
val--21/100 [30/1090] acc: 0.7924479166666667
val--21/100 [40/1090] acc: 0.7919921875
val--21/100 [50/1090] acc: 0.791171875
val--21/100 [60/1090] acc: 0.7901692708333333
val--21/100 [70/1090] acc: 0.7907366071428571
val--21/100 [80/1090] acc: 0.78974609375
val--21/100 [90/1090] acc: 0.7904947916666667
val--21/100 [100/1090] acc: 0.7917578125
val--21/100 [110/1090] acc: 0.7917613636363636
val--21/100 [120/1090] acc: 0.79140625
val--21/100 [130/1090] acc: 0.7924278846153846
val--21/100 [140/1090] acc: 0.7924944196428572
val--21/100 [150/1090] acc: 0.7926822916666667
val--21/100 [160/1090] acc: 0.7928955078125
val--21/100 [170/1090] acc: 0.7928079044117647
val--21/100 [180/1090] acc: 0.7924262152777778
val--21/100 [190/1090] acc: 0.7932565789473685
val--21/100 [200/1090] acc: 0.79337890625
val--21/100 [210/1090] acc: 0.793656994047619
val--21/100 [220/1090] acc: 0.7928267045454546
val--21/100 [230/1090] acc: 0.7934103260869565
val--21/100 [240/1090] acc: 0.7933756510416666
val--21/100 [250/1090] acc: 0.79359375
val--21/100 [260/1090] acc: 0.7934645432692308
val--21/100 [270/1090] acc: 0.7937355324074075
val--21/100 [280/1090] acc: 0.7935686383928572
val--21/100 [290/1090] acc: 0.7934536637931034
val--21/100 [300/1090] acc: 0.7934895833333333
val--21/100 [310/1090] acc: 0.7931829637096774
val--21/100 [320/1090] acc: 0.79346923828125
val--21/100 [330/1090] acc: 0.7937973484848485
val--21/100 [340/1090] acc: 0.7939682904411764
val--21/100 [350/1090] acc: 0.7940401785714286
val--21/100 [360/1090] acc: 0.7939995659722222
val--21/100 [370/1090] acc: 0.7941300675675675
val--21/100 [380/1090] acc: 0.7940892269736842
val--21/100 [390/1090] acc: 0.7938201121794872
val--21/100 [400/1090] acc: 0.79369140625
val--21/100 [410/1090] acc: 0.7938452743902439
val--21/100 [420/1090] acc: 0.7939453125
val--21/100 [430/1090] acc: 0.7937954215116279
val--21/100 [440/1090] acc: 0.7937855113636364
val--21/100 [450/1090] acc: 0.7936371527777778
val--21/100 [460/1090] acc: 0.7935122282608695
val--21/100 [470/1090] acc: 0.7933759973404255
val--21/100 [480/1090] acc: 0.793505859375
val--21/100 [490/1090] acc: 0.7935985331632653
val--21/100 [500/1090] acc: 0.793796875
val--21/100 [510/1090] acc: 0.793734681372549
val--21/100 [520/1090] acc: 0.7939002403846154
val--21/100 [530/1090] acc: 0.7939563679245283
val--21/100 [540/1090] acc: 0.7940755208333333
val--21/100 [550/1090] acc: 0.7939275568181818
val--21/100 [560/1090] acc: 0.7937709263392857
val--21/100 [570/1090] acc: 0.7935649671052631
val--21/100 [580/1090] acc: 0.7935344827586207
val--21/100 [590/1090] acc: 0.793604343220339
val--21/100 [600/1090] acc: 0.7936002604166666
val--21/100 [610/1090] acc: 0.7935002561475409
val--21/100 [620/1090] acc: 0.7934349798387097
val--21/100 [630/1090] acc: 0.7936445932539683
val--21/100 [640/1090] acc: 0.793853759765625
val--21/100 [650/1090] acc: 0.7938942307692308
val--21/100 [660/1090] acc: 0.7937263257575757
val--21/100 [670/1090] acc: 0.7934001865671642
val--21/100 [680/1090] acc: 0.793307674632353
val--21/100 [690/1090] acc: 0.7934839221014492
val--21/100 [700/1090] acc: 0.7934598214285714
val--21/100 [710/1090] acc: 0.7933043573943662
val--21/100 [720/1090] acc: 0.7931315104166666
val--21/100 [730/1090] acc: 0.7930864726027397
val--21/100 [740/1090] acc: 0.7929845861486486
val--21/100 [750/1090] acc: 0.7930729166666667
val--21/100 [760/1090] acc: 0.7931794819078948
val--21/100 [770/1090] acc: 0.7931412337662338
val--21/100 [780/1090] acc: 0.7931089743589743
val--21/100 [790/1090] acc: 0.793151700949367
val--21/100 [800/1090] acc: 0.793359375
val--21/100 [810/1090] acc: 0.793431712962963
val--21/100 [820/1090] acc: 0.7935451600609756
val--21/100 [830/1090] acc: 0.7936088102409639
val--21/100 [840/1090] acc: 0.793559337797619
val--21/100 [850/1090] acc: 0.7935569852941177
val--21/100 [860/1090] acc: 0.7938317587209303
val--21/100 [870/1090] acc: 0.7937006106321839
val--21/100 [880/1090] acc: 0.7936612215909091
val--21/100 [890/1090] acc: 0.7938114466292134
val--21/100 [900/1090] acc: 0.7938194444444444
val--21/100 [910/1090] acc: 0.7938186813186813
val--21/100 [920/1090] acc: 0.793839164402174
val--21/100 [930/1090] acc: 0.7939264112903226
val--21/100 [940/1090] acc: 0.7939453125
val--21/100 [950/1090] acc: 0.7938322368421052
val--21/100 [960/1090] acc: 0.7937296549479167
val--21/100 [970/1090] acc: 0.7937097293814434
val--21/100 [980/1090] acc: 0.7937141262755102
val--21/100 [990/1090] acc: 0.7936276830808081
val--21/100 [1000/1090] acc: 0.79353125
val--21/100 [1010/1090] acc: 0.7934135210396039
val--21/100 [1020/1090] acc: 0.7934742647058823
val--21/100 [1030/1090] acc: 0.7935148665048544
val--21/100 [1040/1090] acc: 0.7934945913461539
val--21/100 [1050/1090] acc: 0.7935342261904762
val--21/100 [1060/1090] acc: 0.7934625589622641
val--21/100 [1070/1090] acc: 0.79344699182243
val--21/100 [1080/1090] acc: 0.7933810763888889
val--21/100 [1090/1090] acc: 0.7932088589449541
epoch= 21, accuracy= 0.793209, rmse= 0.378977, auc= 0.854384
train--22/100 [9/1090] loss: 0.4001938760280609
train--22/100 [19/1090] loss: 0.43815755248069765
train--22/100 [29/1090] loss: 0.4553508013486862
train--22/100 [39/1090] loss: 0.43005711436271665
train--22/100 [49/1090] loss: 0.4580620974302292
train--22/100 [59/1090] loss: 0.4301728785037994
train--22/100 [69/1090] loss: 0.44943395256996155
train--22/100 [79/1090] loss: 0.44705760180950166
train--22/100 [89/1090] loss: 0.42762952148914335
train--22/100 [99/1090] loss: 0.4496412754058838
train--22/100 [109/1090] loss: 0.4544144690036774
train--22/100 [119/1090] loss: 0.44048717319965364
train--22/100 [129/1090] loss: 0.43376811742782595
train--22/100 [139/1090] loss: 0.44692879021167753
train--22/100 [149/1090] loss: 0.4633668601512909
train--22/100 [159/1090] loss: 0.4448994904756546
train--22/100 [169/1090] loss: 0.46871035993099214
train--22/100 [179/1090] loss: 0.440889248251915
train--22/100 [189/1090] loss: 0.4318381637334824
train--22/100 [199/1090] loss: 0.4461320787668228
train--22/100 [209/1090] loss: 0.4530326634645462
train--22/100 [219/1090] loss: 0.4525918006896973
train--22/100 [229/1090] loss: 0.44619692862033844
train--22/100 [239/1090] loss: 0.4485675454139709
train--22/100 [249/1090] loss: 0.44354609251022337
train--22/100 [259/1090] loss: 0.4428836166858673
train--22/100 [269/1090] loss: 0.4480344861745834
train--22/100 [279/1090] loss: 0.44111478328704834
train--22/100 [289/1090] loss: 0.4579175442457199
train--22/100 [299/1090] loss: 0.44561007916927337
train--22/100 [309/1090] loss: 0.4531338304281235
train--22/100 [319/1090] loss: 0.43807408809661863
train--22/100 [329/1090] loss: 0.4382962048053741
train--22/100 [339/1090] loss: 0.44230712950229645
train--22/100 [349/1090] loss: 0.4600259155035019
train--22/100 [359/1090] loss: 0.4402346253395081
train--22/100 [369/1090] loss: 0.43649289608001707
train--22/100 [379/1090] loss: 0.44907949268817904
train--22/100 [389/1090] loss: 0.4393536150455475
train--22/100 [399/1090] loss: 0.4413753718137741
train--22/100 [409/1090] loss: 0.42882135808467864
train--22/100 [419/1090] loss: 0.43294294476509093
train--22/100 [429/1090] loss: 0.42005905508995056
train--22/100 [439/1090] loss: 0.45084557831287386
train--22/100 [449/1090] loss: 0.4335051357746124
train--22/100 [459/1090] loss: 0.4464118927717209
train--22/100 [469/1090] loss: 0.445885968208313
train--22/100 [479/1090] loss: 0.4503335267305374
train--22/100 [489/1090] loss: 0.46374701857566836
train--22/100 [499/1090] loss: 0.4485703080892563
train--22/100 [509/1090] loss: 0.45673937499523165
train--22/100 [519/1090] loss: 0.45868353843688964
train--22/100 [529/1090] loss: 0.44053073823451994
train--22/100 [539/1090] loss: 0.4571294128894806
train--22/100 [549/1090] loss: 0.4446383208036423
train--22/100 [559/1090] loss: 0.4521755754947662
train--22/100 [569/1090] loss: 0.4583589851856232
train--22/100 [579/1090] loss: 0.44630748927593233
train--22/100 [589/1090] loss: 0.46207405626773834
train--22/100 [599/1090] loss: 0.433861643075943
train--22/100 [609/1090] loss: 0.44407038688659667
train--22/100 [619/1090] loss: 0.4348396062850952
train--22/100 [629/1090] loss: 0.4511078208684921
train--22/100 [639/1090] loss: 0.4428019165992737
train--22/100 [649/1090] loss: 0.4599131256341934
train--22/100 [659/1090] loss: 0.4349800258874893
train--22/100 [669/1090] loss: 0.4543586105108261
train--22/100 [679/1090] loss: 0.43390520811080935
train--22/100 [689/1090] loss: 0.4352003693580627
train--22/100 [699/1090] loss: 0.44449999928474426
train--22/100 [709/1090] loss: 0.4470250070095062
train--22/100 [719/1090] loss: 0.46564328074455263
train--22/100 [729/1090] loss: 0.4724211812019348
train--22/100 [739/1090] loss: 0.45229966640472413
train--22/100 [749/1090] loss: 0.44471207559108733
train--22/100 [759/1090] loss: 0.4473431408405304
train--22/100 [769/1090] loss: 0.4566161662340164
train--22/100 [779/1090] loss: 0.44438097476959226
train--22/100 [789/1090] loss: 0.45306248366832735
train--22/100 [799/1090] loss: 0.4575818985700607
train--22/100 [809/1090] loss: 0.4679775327444077
train--22/100 [819/1090] loss: 0.4546397924423218
train--22/100 [829/1090] loss: 0.4572328418493271
train--22/100 [839/1090] loss: 0.44490817487239837
train--22/100 [849/1090] loss: 0.45148603320121766
train--22/100 [859/1090] loss: 0.4466530382633209
train--22/100 [869/1090] loss: 0.43012644052505494
train--22/100 [879/1090] loss: 0.4650284916162491
train--22/100 [889/1090] loss: 0.44600197970867156
train--22/100 [899/1090] loss: 0.44600907266139983
train--22/100 [909/1090] loss: 0.4460802644491196
train--22/100 [919/1090] loss: 0.43867612779140475
train--22/100 [929/1090] loss: 0.45720332860946655
train--22/100 [939/1090] loss: 0.47533641159534457
train--22/100 [949/1090] loss: 0.47270492017269133
train--22/100 [959/1090] loss: 0.45558052361011503
train--22/100 [969/1090] loss: 0.47765958607196807
train--22/100 [979/1090] loss: 0.4545412868261337
train--22/100 [989/1090] loss: 0.45833298563957214
train--22/100 [999/1090] loss: 0.44640337526798246
train--22/100 [1009/1090] loss: 0.452612841129303
train--22/100 [1019/1090] loss: 0.4570223957300186
train--22/100 [1029/1090] loss: 0.45319617092609404
train--22/100 [1039/1090] loss: 0.4482442378997803
train--22/100 [1049/1090] loss: 0.4691766381263733
train--22/100 [1059/1090] loss: 0.4552230030298233
train--22/100 [1069/1090] loss: 0.44615532755851744
train--22/100 [1079/1090] loss: 0.44319884181022645
train--22/100 [1089/1090] loss: 0.4527110576629639
predicting model...
val--22/100 [10/1090] acc: 0.791015625
val--22/100 [20/1090] acc: 0.7923828125
val--22/100 [30/1090] acc: 0.7912760416666667
val--22/100 [40/1090] acc: 0.7916015625
val--22/100 [50/1090] acc: 0.79046875
val--22/100 [60/1090] acc: 0.7896484375
val--22/100 [70/1090] acc: 0.7901785714285714
val--22/100 [80/1090] acc: 0.789306640625
val--22/100 [90/1090] acc: 0.7899305555555556
val--22/100 [100/1090] acc: 0.79109375
val--22/100 [110/1090] acc: 0.791015625
val--22/100 [120/1090] acc: 0.7904947916666667
val--22/100 [130/1090] acc: 0.7915564903846154
val--22/100 [140/1090] acc: 0.791796875
val--22/100 [150/1090] acc: 0.791875
val--22/100 [160/1090] acc: 0.7921875
val--22/100 [170/1090] acc: 0.7923023897058824
val--22/100 [180/1090] acc: 0.7920355902777778
val--22/100 [190/1090] acc: 0.7927014802631579
val--22/100 [200/1090] acc: 0.79298828125
val--22/100 [210/1090] acc: 0.793266369047619
val--22/100 [220/1090] acc: 0.7924715909090909
val--22/100 [230/1090] acc: 0.7931555706521739
val--22/100 [240/1090] acc: 0.7929524739583333
val--22/100 [250/1090] acc: 0.793234375
val--22/100 [260/1090] acc: 0.7932241586538461
val--22/100 [270/1090] acc: 0.7934461805555556
val--22/100 [280/1090] acc: 0.7933733258928571
val--22/100 [290/1090] acc: 0.7933054956896551
val--22/100 [300/1090] acc: 0.793359375
val--22/100 [310/1090] acc: 0.7929309475806452
val--22/100 [320/1090] acc: 0.7930908203125
val--22/100 [330/1090] acc: 0.7934303977272728
val--22/100 [340/1090] acc: 0.7934857536764706
val--22/100 [350/1090] acc: 0.79359375
val--22/100 [360/1090] acc: 0.7935655381944444
val--22/100 [370/1090] acc: 0.7937288851351352
val--22/100 [380/1090] acc: 0.793616365131579
val--22/100 [390/1090] acc: 0.7933293269230769
val--22/100 [400/1090] acc: 0.793330078125
val--22/100 [410/1090] acc: 0.793483231707317
val--22/100 [420/1090] acc: 0.793545386904762
val--22/100 [430/1090] acc: 0.7934411337209303
val--22/100 [440/1090] acc: 0.7933771306818181
val--22/100 [450/1090] acc: 0.7932378472222222
val--22/100 [460/1090] acc: 0.7931640625
val--22/100 [470/1090] acc: 0.7930684840425531
val--22/100 [480/1090] acc: 0.7931233723958333
val--22/100 [490/1090] acc: 0.793359375
val--22/100 [500/1090] acc: 0.793578125
val--22/100 [510/1090] acc: 0.7935049019607843
val--22/100 [520/1090] acc: 0.7936448317307693
val--22/100 [530/1090] acc: 0.7936468160377359
val--22/100 [540/1090] acc: 0.7937789351851852
val--22/100 [550/1090] acc: 0.7936150568181818
val--22/100 [560/1090] acc: 0.7934640066964286
val--22/100 [570/1090] acc: 0.7931400767543859
val--22/100 [580/1090] acc: 0.7931438577586207
val--22/100 [590/1090] acc: 0.7931408898305085
val--22/100 [600/1090] acc: 0.79314453125
val--22/100 [610/1090] acc: 0.7931160348360655
val--22/100 [620/1090] acc: 0.7930191532258064
val--22/100 [630/1090] acc: 0.7932477678571429
val--22/100 [640/1090] acc: 0.7934814453125
val--22/100 [650/1090] acc: 0.793515625
val--22/100 [660/1090] acc: 0.7934126420454546
val--22/100 [670/1090] acc: 0.7931494869402985
val--22/100 [680/1090] acc: 0.7930434283088236
val--22/100 [690/1090] acc: 0.7932744565217391
val--22/100 [700/1090] acc: 0.7932924107142857
val--22/100 [710/1090] acc: 0.7931227992957747
val--22/100 [720/1090] acc: 0.7929416232638888
val--22/100 [730/1090] acc: 0.792888484589041
val--22/100 [740/1090] acc: 0.7927839949324325
val--22/100 [750/1090] acc: 0.7928697916666667
val--22/100 [760/1090] acc: 0.7929379111842105
val--22/100 [770/1090] acc: 0.7928926542207793
val--22/100 [780/1090] acc: 0.7928485576923077
val--22/100 [790/1090] acc: 0.7928698575949367
val--22/100 [800/1090] acc: 0.79310546875
val--22/100 [810/1090] acc: 0.7931471836419753
val--22/100 [820/1090] acc: 0.7932259908536585
val--22/100 [830/1090] acc: 0.7933028990963855
val--22/100 [840/1090] acc: 0.7932384672619047
val--22/100 [850/1090] acc: 0.7932306985294117
val--22/100 [860/1090] acc: 0.7934774709302326
val--22/100 [870/1090] acc: 0.7933459051724138
val--22/100 [880/1090] acc: 0.7933194247159091
val--22/100 [890/1090] acc: 0.7934998244382022
val--22/100 [900/1090] acc: 0.793515625
val--22/100 [910/1090] acc: 0.7935139079670329
val--22/100 [920/1090] acc: 0.7935716711956522
val--22/100 [930/1090] acc: 0.7936491935483871
val--22/100 [940/1090] acc: 0.7936668882978724
val--22/100 [950/1090] acc: 0.7935690789473684
val--22/100 [960/1090] acc: 0.7934773763020834
val--22/100 [970/1090] acc: 0.7934681056701031
val--22/100 [980/1090] acc: 0.7934749681122449
val--22/100 [990/1090] acc: 0.7934343434343434
val--22/100 [1000/1090] acc: 0.79333984375
val--22/100 [1010/1090] acc: 0.7932240099009901
val--22/100 [1020/1090] acc: 0.7933057598039216
val--22/100 [1030/1090] acc: 0.7933707524271845
val--22/100 [1040/1090] acc: 0.7933368389423077
val--22/100 [1050/1090] acc: 0.7933891369047619
val--22/100 [1060/1090] acc: 0.793359375
val--22/100 [1070/1090] acc: 0.793359375
val--22/100 [1080/1090] acc: 0.7932942708333334
val--22/100 [1090/1090] acc: 0.7931264334862386
epoch= 22, accuracy= 0.793126, rmse= 0.379071, auc= 0.854190
train--23/100 [9/1090] loss: 0.38897521793842316
train--23/100 [19/1090] loss: 0.44710114896297454
train--23/100 [29/1090] loss: 0.42795991003513334
train--23/100 [39/1090] loss: 0.44377738833427427
train--23/100 [49/1090] loss: 0.44882004857063296
train--23/100 [59/1090] loss: 0.42966988384723664
train--23/100 [69/1090] loss: 0.42756005227565763
train--23/100 [79/1090] loss: 0.4320992738008499
train--23/100 [89/1090] loss: 0.4247443437576294
train--23/100 [99/1090] loss: 0.45304069817066195
train--23/100 [109/1090] loss: 0.4411178886890411
train--23/100 [119/1090] loss: 0.4514300674200058
train--23/100 [129/1090] loss: 0.4509199023246765
train--23/100 [139/1090] loss: 0.4513615757226944
train--23/100 [149/1090] loss: 0.4398361325263977
train--23/100 [159/1090] loss: 0.4470740854740143
train--23/100 [169/1090] loss: 0.45844468772411345
train--23/100 [179/1090] loss: 0.4385888516902924
train--23/100 [189/1090] loss: 0.44260936677455903
train--23/100 [199/1090] loss: 0.460817763209343
train--23/100 [209/1090] loss: 0.45527682900428773
train--23/100 [219/1090] loss: 0.45363636016845704
train--23/100 [229/1090] loss: 0.4401495337486267
train--23/100 [239/1090] loss: 0.4575332462787628
train--23/100 [249/1090] loss: 0.44613262712955476
train--23/100 [259/1090] loss: 0.4635792702436447
train--23/100 [269/1090] loss: 0.4728602856397629
train--23/100 [279/1090] loss: 0.4569620698690414
train--23/100 [289/1090] loss: 0.4459885537624359
train--23/100 [299/1090] loss: 0.4584511280059814
train--23/100 [309/1090] loss: 0.4530812740325928
train--23/100 [319/1090] loss: 0.4548586577177048
train--23/100 [329/1090] loss: 0.45465738475322726
train--23/100 [339/1090] loss: 0.44206006824970245
train--23/100 [349/1090] loss: 0.43391419351100924
train--23/100 [359/1090] loss: 0.43901521563529966
train--23/100 [369/1090] loss: 0.44315316081047057
train--23/100 [379/1090] loss: 0.43601824939250944
train--23/100 [389/1090] loss: 0.44637079536914825
train--23/100 [399/1090] loss: 0.4477576971054077
train--23/100 [409/1090] loss: 0.4254899680614471
train--23/100 [419/1090] loss: 0.434289687871933
train--23/100 [429/1090] loss: 0.44698078036308286
train--23/100 [439/1090] loss: 0.42690851390361784
train--23/100 [449/1090] loss: 0.4466977506875992
train--23/100 [459/1090] loss: 0.4581828087568283
train--23/100 [469/1090] loss: 0.4476993530988693
train--23/100 [479/1090] loss: 0.44703874588012693
train--23/100 [489/1090] loss: 0.437390074133873
train--23/100 [499/1090] loss: 0.4569631278514862
train--23/100 [509/1090] loss: 0.44307335615158083
train--23/100 [519/1090] loss: 0.4552838444709778
train--23/100 [529/1090] loss: 0.4584932863712311
train--23/100 [539/1090] loss: 0.43822127878665923
train--23/100 [549/1090] loss: 0.44734864234924315
train--23/100 [559/1090] loss: 0.4473164796829224
train--23/100 [569/1090] loss: 0.4436992883682251
train--23/100 [579/1090] loss: 0.4462237775325775
train--23/100 [589/1090] loss: 0.46558299362659455
train--23/100 [599/1090] loss: 0.4389352649450302
train--23/100 [609/1090] loss: 0.44117228388786317
train--23/100 [619/1090] loss: 0.4538877606391907
train--23/100 [629/1090] loss: 0.449916398525238
train--23/100 [639/1090] loss: 0.45004006028175353
train--23/100 [649/1090] loss: 0.4441273123025894
train--23/100 [659/1090] loss: 0.4628853589296341
train--23/100 [669/1090] loss: 0.4495352327823639
train--23/100 [679/1090] loss: 0.43718141317367554
train--23/100 [689/1090] loss: 0.45903256833553313
train--23/100 [699/1090] loss: 0.4401461273431778
train--23/100 [709/1090] loss: 0.4437594324350357
train--23/100 [719/1090] loss: 0.4701305627822876
train--23/100 [729/1090] loss: 0.45361988842487333
train--23/100 [739/1090] loss: 0.4312445461750031
train--23/100 [749/1090] loss: 0.4547269016504288
train--23/100 [759/1090] loss: 0.46340411007404325
train--23/100 [769/1090] loss: 0.45248947143554685
train--23/100 [779/1090] loss: 0.4662174880504608
train--23/100 [789/1090] loss: 0.43529969453811646
train--23/100 [799/1090] loss: 0.45895408391952514
train--23/100 [809/1090] loss: 0.44588610231876374
train--23/100 [819/1090] loss: 0.4563872963190079
train--23/100 [829/1090] loss: 0.4390681445598602
train--23/100 [839/1090] loss: 0.4356043219566345
train--23/100 [849/1090] loss: 0.4671542763710022
train--23/100 [859/1090] loss: 0.44736201465129855
train--23/100 [869/1090] loss: 0.4239335596561432
train--23/100 [879/1090] loss: 0.45327687859535215
train--23/100 [889/1090] loss: 0.43067874014377594
train--23/100 [899/1090] loss: 0.45719241797924043
train--23/100 [909/1090] loss: 0.4438671410083771
train--23/100 [919/1090] loss: 0.46922547221183775
train--23/100 [929/1090] loss: 0.4514210015535355
train--23/100 [939/1090] loss: 0.46646865606307986
train--23/100 [949/1090] loss: 0.45955511927604675
train--23/100 [959/1090] loss: 0.4608646720647812
train--23/100 [969/1090] loss: 0.45421463847160337
train--23/100 [979/1090] loss: 0.4507417380809784
train--23/100 [989/1090] loss: 0.4542929619550705
train--23/100 [999/1090] loss: 0.4463813275098801
train--23/100 [1009/1090] loss: 0.46828397512435915
train--23/100 [1019/1090] loss: 0.4532550185918808
train--23/100 [1029/1090] loss: 0.44277495741844175
train--23/100 [1039/1090] loss: 0.4754422247409821
train--23/100 [1049/1090] loss: 0.44882344305515287
train--23/100 [1059/1090] loss: 0.46366155445575713
train--23/100 [1069/1090] loss: 0.4510431170463562
train--23/100 [1079/1090] loss: 0.4458808064460754
train--23/100 [1089/1090] loss: 0.4536048799753189
predicting model...
val--23/100 [10/1090] acc: 0.791796875
val--23/100 [20/1090] acc: 0.7921875
val--23/100 [30/1090] acc: 0.7927083333333333
val--23/100 [40/1090] acc: 0.7927734375
val--23/100 [50/1090] acc: 0.7915625
val--23/100 [60/1090] acc: 0.7904947916666667
val--23/100 [70/1090] acc: 0.7908482142857143
val--23/100 [80/1090] acc: 0.789404296875
val--23/100 [90/1090] acc: 0.7898871527777778
val--23/100 [100/1090] acc: 0.7910546875
val--23/100 [110/1090] acc: 0.7915127840909091
val--23/100 [120/1090] acc: 0.7912109375
val--23/100 [130/1090] acc: 0.7923076923076923
val--23/100 [140/1090] acc: 0.7923828125
val--23/100 [150/1090] acc: 0.7925260416666666
val--23/100 [160/1090] acc: 0.7927001953125
val--23/100 [170/1090] acc: 0.7928079044117647
val--23/100 [180/1090] acc: 0.7923394097222223
val--23/100 [190/1090] acc: 0.7931949013157895
val--23/100 [200/1090] acc: 0.79341796875
val--23/100 [210/1090] acc: 0.7937313988095238
val--23/100 [220/1090] acc: 0.7928977272727272
val--23/100 [230/1090] acc: 0.7937160326086956
val--23/100 [240/1090] acc: 0.7935384114583334
val--23/100 [250/1090] acc: 0.793859375
val--23/100 [260/1090] acc: 0.7939302884615385
val--23/100 [270/1090] acc: 0.7941116898148148
val--23/100 [280/1090] acc: 0.7939592633928572
val--23/100 [290/1090] acc: 0.7938308189655172
val--23/100 [300/1090] acc: 0.79390625
val--23/100 [310/1090] acc: 0.793586189516129
val--23/100 [320/1090] acc: 0.79381103515625
val--23/100 [330/1090] acc: 0.7940222537878788
val--23/100 [340/1090] acc: 0.7940831801470588
val--23/100 [350/1090] acc: 0.79421875
val--23/100 [360/1090] acc: 0.7940646701388889
val--23/100 [370/1090] acc: 0.7942356418918919
val--23/100 [380/1090] acc: 0.7941714638157895
val--23/100 [390/1090] acc: 0.7939302884615385
val--23/100 [400/1090] acc: 0.79380859375
val--23/100 [410/1090] acc: 0.7939881859756097
val--23/100 [420/1090] acc: 0.794047619047619
val--23/100 [430/1090] acc: 0.7939044331395348
val--23/100 [440/1090] acc: 0.7939098011363637
val--23/100 [450/1090] acc: 0.7937673611111111
val--23/100 [460/1090] acc: 0.79375
val--23/100 [470/1090] acc: 0.7936502659574468
val--23/100 [480/1090] acc: 0.7937174479166667
val--23/100 [490/1090] acc: 0.7938695790816327
val--23/100 [500/1090] acc: 0.79409375
val--23/100 [510/1090] acc: 0.7940180759803922
val--23/100 [520/1090] acc: 0.7942232572115384
val--23/100 [530/1090] acc: 0.7941848466981132
val--23/100 [540/1090] acc: 0.7943287037037037
val--23/100 [550/1090] acc: 0.7942400568181818
val--23/100 [560/1090] acc: 0.7940778459821428
val--23/100 [570/1090] acc: 0.7938733552631579
val--23/100 [580/1090] acc: 0.7938577586206896
val--23/100 [590/1090] acc: 0.793895656779661
val--23/100 [600/1090] acc: 0.79390625
val--23/100 [610/1090] acc: 0.7938012295081968
val--23/100 [620/1090] acc: 0.7937058971774194
val--23/100 [630/1090] acc: 0.7939608134920635
val--23/100 [640/1090] acc: 0.79415283203125
val--23/100 [650/1090] acc: 0.7941766826923077
val--23/100 [660/1090] acc: 0.7940814393939394
val--23/100 [670/1090] acc: 0.7937908115671641
val--23/100 [680/1090] acc: 0.7936925551470588
val--23/100 [690/1090] acc: 0.793851902173913
val--23/100 [700/1090] acc: 0.7938113839285714
val--23/100 [710/1090] acc: 0.7936289612676056
val--23/100 [720/1090] acc: 0.7934787326388889
val--23/100 [730/1090] acc: 0.7934289383561643
val--23/100 [740/1090] acc: 0.7933118665540541
val--23/100 [750/1090] acc: 0.7933802083333333
val--23/100 [760/1090] acc: 0.7934930098684211
val--23/100 [770/1090] acc: 0.793450689935065
val--23/100 [780/1090] acc: 0.7934344951923077
val--23/100 [790/1090] acc: 0.7934829905063291
val--23/100 [800/1090] acc: 0.7937158203125
val--23/100 [810/1090] acc: 0.7938175154320988
val--23/100 [820/1090] acc: 0.7938786204268292
val--23/100 [830/1090] acc: 0.7939429593373494
val--23/100 [840/1090] acc: 0.7938988095238095
val--23/100 [850/1090] acc: 0.7938556985294117
val--23/100 [860/1090] acc: 0.7940997456395349
val--23/100 [870/1090] acc: 0.7939340876436781
val--23/100 [880/1090] acc: 0.7939275568181818
val--23/100 [890/1090] acc: 0.7940704002808989
val--23/100 [900/1090] acc: 0.7940625
val--23/100 [910/1090] acc: 0.7940547733516483
val--23/100 [920/1090] acc: 0.7941066576086957
val--23/100 [930/1090] acc: 0.7941784274193548
val--23/100 [940/1090] acc: 0.7942071143617021
val--23/100 [950/1090] acc: 0.7941077302631578
val--23/100 [960/1090] acc: 0.7940104166666667
val--23/100 [970/1090] acc: 0.7939795425257732
val--23/100 [980/1090] acc: 0.793977200255102
val--23/100 [990/1090] acc: 0.7939038825757576
val--23/100 [1000/1090] acc: 0.79380078125
val--23/100 [1010/1090] acc: 0.7936919863861386
val--23/100 [1020/1090] acc: 0.7937768075980393
val--23/100 [1030/1090] acc: 0.7938106796116505
val--23/100 [1040/1090] acc: 0.7937650240384615
val--23/100 [1050/1090] acc: 0.7938318452380952
val--23/100 [1060/1090] acc: 0.7937831662735849
val--23/100 [1070/1090] acc: 0.7937828563084112
val--23/100 [1080/1090] acc: 0.7937102141203703
val--23/100 [1090/1090] acc: 0.7935600630733946
epoch= 23, accuracy= 0.793560, rmse= 0.378994, auc= 0.854301
train--24/100 [9/1090] loss: 0.3835844725370407
train--24/100 [19/1090] loss: 0.433440038561821
train--24/100 [29/1090] loss: 0.45367359817028047
train--24/100 [39/1090] loss: 0.4515589654445648
train--24/100 [49/1090] loss: 0.45541137754917144
train--24/100 [59/1090] loss: 0.4411130160093307
train--24/100 [69/1090] loss: 0.43608547151088717
train--24/100 [79/1090] loss: 0.4437259167432785
train--24/100 [89/1090] loss: 0.45506046414375306
train--24/100 [99/1090] loss: 0.4468288868665695
train--24/100 [109/1090] loss: 0.43504934906959536
train--24/100 [119/1090] loss: 0.4409852296113968
train--24/100 [129/1090] loss: 0.4598183035850525
train--24/100 [139/1090] loss: 0.4467740446329117
train--24/100 [149/1090] loss: 0.4394050508737564
train--24/100 [159/1090] loss: 0.4468458890914917
train--24/100 [169/1090] loss: 0.46381962597370147
train--24/100 [179/1090] loss: 0.4685993105173111
train--24/100 [189/1090] loss: 0.4538563907146454
train--24/100 [199/1090] loss: 0.43559580147266386
train--24/100 [209/1090] loss: 0.43600027859210966
train--24/100 [219/1090] loss: 0.469342839717865
train--24/100 [229/1090] loss: 0.4466883361339569
train--24/100 [239/1090] loss: 0.451568078994751
train--24/100 [249/1090] loss: 0.4649715691804886
train--24/100 [259/1090] loss: 0.4328275412321091
train--24/100 [269/1090] loss: 0.44757969081401827
train--24/100 [279/1090] loss: 0.4514549136161804
train--24/100 [289/1090] loss: 0.44724762439727783
train--24/100 [299/1090] loss: 0.43569555580616
train--24/100 [309/1090] loss: 0.4354099839925766
train--24/100 [319/1090] loss: 0.4554803311824799
train--24/100 [329/1090] loss: 0.4471897125244141
train--24/100 [339/1090] loss: 0.46227529644966125
train--24/100 [349/1090] loss: 0.46111387610435484
train--24/100 [359/1090] loss: 0.4490769535303116
train--24/100 [369/1090] loss: 0.44373242259025575
train--24/100 [379/1090] loss: 0.4534376561641693
train--24/100 [389/1090] loss: 0.44497963786125183
train--24/100 [399/1090] loss: 0.4485554754734039
train--24/100 [409/1090] loss: 0.4438922435045242
train--24/100 [419/1090] loss: 0.4393113285303116
train--24/100 [429/1090] loss: 0.4554925709962845
train--24/100 [439/1090] loss: 0.45340096652507783
train--24/100 [449/1090] loss: 0.463938769698143
train--24/100 [459/1090] loss: 0.4578456163406372
train--24/100 [469/1090] loss: 0.44840027689933776
train--24/100 [479/1090] loss: 0.4598381191492081
train--24/100 [489/1090] loss: 0.46128498315811156
train--24/100 [499/1090] loss: 0.46541754305362704
train--24/100 [509/1090] loss: 0.44399701058864594
train--24/100 [519/1090] loss: 0.44801576137542726
train--24/100 [529/1090] loss: 0.4568037807941437
train--24/100 [539/1090] loss: 0.4625871956348419
train--24/100 [549/1090] loss: 0.4233170300722122
train--24/100 [559/1090] loss: 0.47842336297035215
train--24/100 [569/1090] loss: 0.45862447619438174
train--24/100 [579/1090] loss: 0.4406933426856995
train--24/100 [589/1090] loss: 0.43262763023376466
train--24/100 [599/1090] loss: 0.4428457707166672
train--24/100 [609/1090] loss: 0.4640432745218277
train--24/100 [619/1090] loss: 0.4387345939874649
train--24/100 [629/1090] loss: 0.4372165441513062
train--24/100 [639/1090] loss: 0.4433679699897766
train--24/100 [649/1090] loss: 0.4341401278972626
train--24/100 [659/1090] loss: 0.43449451625347135
train--24/100 [669/1090] loss: 0.44209136962890627
train--24/100 [679/1090] loss: 0.46459136307239535
train--24/100 [689/1090] loss: 0.448282989859581
train--24/100 [699/1090] loss: 0.44519470632076263
train--24/100 [709/1090] loss: 0.45852777659893035
train--24/100 [719/1090] loss: 0.4434781074523926
train--24/100 [729/1090] loss: 0.45430923998355865
train--24/100 [739/1090] loss: 0.45071848332881925
train--24/100 [749/1090] loss: 0.4494690984487534
train--24/100 [759/1090] loss: 0.45322011709213256
train--24/100 [769/1090] loss: 0.45971099436283114
train--24/100 [779/1090] loss: 0.4514813870191574
train--24/100 [789/1090] loss: 0.43471028804779055
train--24/100 [799/1090] loss: 0.42817253470420835
train--24/100 [809/1090] loss: 0.4478160053491592
train--24/100 [819/1090] loss: 0.44801586866378784
train--24/100 [829/1090] loss: 0.42833702862262724
train--24/100 [839/1090] loss: 0.446495047211647
train--24/100 [849/1090] loss: 0.4573014616966248
train--24/100 [859/1090] loss: 0.4443429887294769
train--24/100 [869/1090] loss: 0.44595466554164886
train--24/100 [879/1090] loss: 0.44545485973358157
train--24/100 [889/1090] loss: 0.45109870135784147
train--24/100 [899/1090] loss: 0.4627207100391388
train--24/100 [909/1090] loss: 0.44202845394611356
train--24/100 [919/1090] loss: 0.4595224827528
train--24/100 [929/1090] loss: 0.44473135471343994
train--24/100 [939/1090] loss: 0.449242627620697
train--24/100 [949/1090] loss: 0.4483675420284271
train--24/100 [959/1090] loss: 0.45309175848960875
train--24/100 [969/1090] loss: 0.4363734394311905
train--24/100 [979/1090] loss: 0.4413714736700058
train--24/100 [989/1090] loss: 0.4573411554098129
train--24/100 [999/1090] loss: 0.4353881895542145
train--24/100 [1009/1090] loss: 0.44846816956996916
train--24/100 [1019/1090] loss: 0.4412519305944443
train--24/100 [1029/1090] loss: 0.4488840878009796
train--24/100 [1039/1090] loss: 0.4492111444473267
train--24/100 [1049/1090] loss: 0.46411614418029784
train--24/100 [1059/1090] loss: 0.450254288315773
train--24/100 [1069/1090] loss: 0.43976275324821473
train--24/100 [1079/1090] loss: 0.452156138420105
train--24/100 [1089/1090] loss: 0.4545503228902817
predicting model...
val--24/100 [10/1090] acc: 0.791796875
val--24/100 [20/1090] acc: 0.7919921875
val--24/100 [30/1090] acc: 0.7916666666666666
val--24/100 [40/1090] acc: 0.79228515625
val--24/100 [50/1090] acc: 0.791171875
val--24/100 [60/1090] acc: 0.790234375
val--24/100 [70/1090] acc: 0.7908482142857143
val--24/100 [80/1090] acc: 0.789501953125
val--24/100 [90/1090] acc: 0.7901909722222222
val--24/100 [100/1090] acc: 0.79109375
val--24/100 [110/1090] acc: 0.7909801136363637
val--24/100 [120/1090] acc: 0.7906901041666666
val--24/100 [130/1090] acc: 0.7916165865384616
val--24/100 [140/1090] acc: 0.791796875
val--24/100 [150/1090] acc: 0.791953125
val--24/100 [160/1090] acc: 0.79228515625
val--24/100 [170/1090] acc: 0.7922794117647058
val--24/100 [180/1090] acc: 0.7919053819444445
val--24/100 [190/1090] acc: 0.7927220394736842
val--24/100 [200/1090] acc: 0.793125
val--24/100 [210/1090] acc: 0.7933779761904762
val--24/100 [220/1090] acc: 0.7924715909090909
val--24/100 [230/1090] acc: 0.7932744565217391
val--24/100 [240/1090] acc: 0.7930338541666667
val--24/100 [250/1090] acc: 0.793234375
val--24/100 [260/1090] acc: 0.7932692307692307
val--24/100 [270/1090] acc: 0.7935185185185185
val--24/100 [280/1090] acc: 0.7936104910714286
val--24/100 [290/1090] acc: 0.7935479525862069
val--24/100 [300/1090] acc: 0.7935677083333333
val--24/100 [310/1090] acc: 0.7932207661290323
val--24/100 [320/1090] acc: 0.79354248046875
val--24/100 [330/1090] acc: 0.7937973484848485
val--24/100 [340/1090] acc: 0.7939108455882353
val--24/100 [350/1090] acc: 0.7940959821428571
val--24/100 [360/1090] acc: 0.7940212673611111
val--24/100 [370/1090] acc: 0.7941511824324324
val--24/100 [380/1090] acc: 0.7940378289473684
val--24/100 [390/1090] acc: 0.793739983974359
val--24/100 [400/1090] acc: 0.79361328125
val--24/100 [410/1090] acc: 0.7938071646341464
val--24/100 [420/1090] acc: 0.7937686011904762
val--24/100 [430/1090] acc: 0.7936409883720931
val--24/100 [440/1090] acc: 0.7935990767045454
val--24/100 [450/1090] acc: 0.7934201388888888
val--24/100 [460/1090] acc: 0.7933423913043478
val--24/100 [470/1090] acc: 0.7932679521276595
val--24/100 [480/1090] acc: 0.7933430989583333
val--24/100 [490/1090] acc: 0.7934789540816326
val--24/100 [500/1090] acc: 0.7936328125
val--24/100 [510/1090] acc: 0.7935431985294118
val--24/100 [520/1090] acc: 0.7937274639423076
val--24/100 [530/1090] acc: 0.7937131485849057
val--24/100 [540/1090] acc: 0.7938874421296296
val--24/100 [550/1090] acc: 0.7937357954545454
val--24/100 [560/1090] acc: 0.7935198102678571
val--24/100 [570/1090] acc: 0.7933388157894737
val--24/100 [580/1090] acc: 0.7933459051724138
val--24/100 [590/1090] acc: 0.7933726165254237
val--24/100 [600/1090] acc: 0.7934505208333333
val--24/100 [610/1090] acc: 0.7933401639344262
val--24/100 [620/1090] acc: 0.793258568548387
val--24/100 [630/1090] acc: 0.7934647817460317
val--24/100 [640/1090] acc: 0.793695068359375
val--24/100 [650/1090] acc: 0.7937139423076923
val--24/100 [660/1090] acc: 0.7936138731060606
val--24/100 [670/1090] acc: 0.7933418843283582
val--24/100 [680/1090] acc: 0.7933134191176471
val--24/100 [690/1090] acc: 0.7934895833333333
val--24/100 [700/1090] acc: 0.7934598214285714
val--24/100 [710/1090] acc: 0.7933208626760564
val--24/100 [720/1090] acc: 0.7931315104166666
val--24/100 [730/1090] acc: 0.7930650684931507
val--24/100 [740/1090] acc: 0.7929634712837837
val--24/100 [750/1090] acc: 0.793015625
val--24/100 [760/1090] acc: 0.7931383634868421
val--24/100 [770/1090] acc: 0.7930905032467532
val--24/100 [780/1090] acc: 0.7930739182692308
val--24/100 [790/1090] acc: 0.7931071993670886
val--24/100 [800/1090] acc: 0.7933251953125
val--24/100 [810/1090] acc: 0.7933786651234568
val--24/100 [820/1090] acc: 0.7934689405487805
val--24/100 [830/1090] acc: 0.7935335090361446
val--24/100 [840/1090] acc: 0.7934709821428572
val--24/100 [850/1090] acc: 0.7934742647058823
val--24/100 [860/1090] acc: 0.7937409156976745
val--24/100 [870/1090] acc: 0.7936018318965518
val--24/100 [880/1090] acc: 0.793603515625
val--24/100 [890/1090] acc: 0.7937807233146067
val--24/100 [900/1090] acc: 0.7937934027777778
val--24/100 [910/1090] acc: 0.7937929258241758
val--24/100 [920/1090] acc: 0.7938221807065218
val--24/100 [930/1090] acc: 0.793892809139785
val--24/100 [940/1090] acc: 0.7938871343085107
val--24/100 [950/1090] acc: 0.7938075657894736
val--24/100 [960/1090] acc: 0.7937459309895833
val--24/100 [970/1090] acc: 0.7936976481958763
val--24/100 [980/1090] acc: 0.7937101403061224
val--24/100 [990/1090] acc: 0.7936316287878787
val--24/100 [1000/1090] acc: 0.79355078125
val--24/100 [1010/1090] acc: 0.7934135210396039
val--24/100 [1020/1090] acc: 0.7934819240196078
val--24/100 [1030/1090] acc: 0.793530036407767
val--24/100 [1040/1090] acc: 0.7935208834134615
val--24/100 [1050/1090] acc: 0.7935714285714286
val--24/100 [1060/1090] acc: 0.7934957252358491
val--24/100 [1070/1090] acc: 0.7935127044392524
val--24/100 [1080/1090] acc: 0.7934389467592593
val--24/100 [1090/1090] acc: 0.7933020355504588
epoch= 24, accuracy= 0.793302, rmse= 0.378930, auc= 0.854380
train--25/100 [9/1090] loss: 0.3860507130622864
train--25/100 [19/1090] loss: 0.4473108500242233
train--25/100 [29/1090] loss: 0.44064819514751435
train--25/100 [39/1090] loss: 0.4400881201028824
train--25/100 [49/1090] loss: 0.46267114877700805
train--25/100 [59/1090] loss: 0.44257591366767884
train--25/100 [69/1090] loss: 0.4394889444112778
train--25/100 [79/1090] loss: 0.44102156162261963
train--25/100 [89/1090] loss: 0.4589000642299652
train--25/100 [99/1090] loss: 0.4526980459690094
train--25/100 [109/1090] loss: 0.4327494531869888
train--25/100 [119/1090] loss: 0.44772579073905944
train--25/100 [129/1090] loss: 0.4523294448852539
train--25/100 [139/1090] loss: 0.4427140951156616
train--25/100 [149/1090] loss: 0.43837360441684725
train--25/100 [159/1090] loss: 0.4323515325784683
train--25/100 [169/1090] loss: 0.4384892135858536
train--25/100 [179/1090] loss: 0.44296797811985017
train--25/100 [189/1090] loss: 0.45263081789016724
train--25/100 [199/1090] loss: 0.4398196697235107
train--25/100 [209/1090] loss: 0.44941514134407046
train--25/100 [219/1090] loss: 0.45935857594013213
train--25/100 [229/1090] loss: 0.42825967371463775
train--25/100 [239/1090] loss: 0.43031311631202696
train--25/100 [249/1090] loss: 0.44835847020149233
train--25/100 [259/1090] loss: 0.4398063749074936
train--25/100 [269/1090] loss: 0.45617803633213044
train--25/100 [279/1090] loss: 0.45138914585113527
train--25/100 [289/1090] loss: 0.4564703553915024
train--25/100 [299/1090] loss: 0.425085774064064
train--25/100 [309/1090] loss: 0.4509290963411331
train--25/100 [319/1090] loss: 0.46566319465637207
train--25/100 [329/1090] loss: 0.4506734848022461
train--25/100 [339/1090] loss: 0.4349725693464279
train--25/100 [349/1090] loss: 0.458260577917099
train--25/100 [359/1090] loss: 0.4287028223276138
train--25/100 [369/1090] loss: 0.4368542909622192
train--25/100 [379/1090] loss: 0.43268458247184755
train--25/100 [389/1090] loss: 0.45845262706279755
train--25/100 [399/1090] loss: 0.4672458827495575
train--25/100 [409/1090] loss: 0.45376344919204714
train--25/100 [419/1090] loss: 0.45371928811073303
train--25/100 [429/1090] loss: 0.44966367483139036
train--25/100 [439/1090] loss: 0.44779821336269376
train--25/100 [449/1090] loss: 0.44942775666713713
train--25/100 [459/1090] loss: 0.4300510108470917
train--25/100 [469/1090] loss: 0.4504404038190842
train--25/100 [479/1090] loss: 0.4320645719766617
train--25/100 [489/1090] loss: 0.4392097949981689
train--25/100 [499/1090] loss: 0.4333336174488068
train--25/100 [509/1090] loss: 0.45930625796318053
train--25/100 [519/1090] loss: 0.43407095074653623
train--25/100 [529/1090] loss: 0.4655925363302231
train--25/100 [539/1090] loss: 0.45149717628955843
train--25/100 [549/1090] loss: 0.44274587333202364
train--25/100 [559/1090] loss: 0.43954028487205504
train--25/100 [569/1090] loss: 0.4375058948993683
train--25/100 [579/1090] loss: 0.45989031791687013
train--25/100 [589/1090] loss: 0.4623680830001831
train--25/100 [599/1090] loss: 0.46079601943492887
train--25/100 [609/1090] loss: 0.45588651299476624
train--25/100 [619/1090] loss: 0.45606098473072054
train--25/100 [629/1090] loss: 0.438181871175766
train--25/100 [639/1090] loss: 0.4613380551338196
train--25/100 [649/1090] loss: 0.43894544541835784
train--25/100 [659/1090] loss: 0.44373035728931426
train--25/100 [669/1090] loss: 0.4617996871471405
train--25/100 [679/1090] loss: 0.46274309456348417
train--25/100 [689/1090] loss: 0.4693572461605072
train--25/100 [699/1090] loss: 0.44447562396526336
train--25/100 [709/1090] loss: 0.4384226232767105
train--25/100 [719/1090] loss: 0.45872418880462645
train--25/100 [729/1090] loss: 0.4539279639720917
train--25/100 [739/1090] loss: 0.4624188870191574
train--25/100 [749/1090] loss: 0.44048239290714264
train--25/100 [759/1090] loss: 0.46423530876636504
train--25/100 [769/1090] loss: 0.44676141142845155
train--25/100 [779/1090] loss: 0.44991361498832705
train--25/100 [789/1090] loss: 0.45103268027305604
train--25/100 [799/1090] loss: 0.44036793112754824
train--25/100 [809/1090] loss: 0.4459011614322662
train--25/100 [819/1090] loss: 0.4216673731803894
train--25/100 [829/1090] loss: 0.43583460748195646
train--25/100 [839/1090] loss: 0.4788580000400543
train--25/100 [849/1090] loss: 0.45660472512245176
train--25/100 [859/1090] loss: 0.4336618363857269
train--25/100 [869/1090] loss: 0.4428127557039261
train--25/100 [879/1090] loss: 0.43609155118465426
train--25/100 [889/1090] loss: 0.4489172577857971
train--25/100 [899/1090] loss: 0.4643640726804733
train--25/100 [909/1090] loss: 0.46949034333229067
train--25/100 [919/1090] loss: 0.4496134430170059
train--25/100 [929/1090] loss: 0.46341449916362765
train--25/100 [939/1090] loss: 0.4546963721513748
train--25/100 [949/1090] loss: 0.4587946146726608
train--25/100 [959/1090] loss: 0.4451616495847702
train--25/100 [969/1090] loss: 0.4450509876012802
train--25/100 [979/1090] loss: 0.46323093473911287
train--25/100 [989/1090] loss: 0.4551033556461334
train--25/100 [999/1090] loss: 0.46322294473648074
train--25/100 [1009/1090] loss: 0.452327299118042
train--25/100 [1019/1090] loss: 0.4509722203016281
train--25/100 [1029/1090] loss: 0.4610630929470062
train--25/100 [1039/1090] loss: 0.4575057476758957
train--25/100 [1049/1090] loss: 0.4471560150384903
train--25/100 [1059/1090] loss: 0.4462639629840851
train--25/100 [1069/1090] loss: 0.4446607917547226
train--25/100 [1079/1090] loss: 0.4411994516849518
train--25/100 [1089/1090] loss: 0.4362184822559357
predicting model...
val--25/100 [10/1090] acc: 0.793359375
val--25/100 [20/1090] acc: 0.79375
val--25/100 [30/1090] acc: 0.79296875
val--25/100 [40/1090] acc: 0.79345703125
val--25/100 [50/1090] acc: 0.79171875
val--25/100 [60/1090] acc: 0.7912109375
val--25/100 [70/1090] acc: 0.7919084821428571
val--25/100 [80/1090] acc: 0.7904296875
val--25/100 [90/1090] acc: 0.7907118055555555
val--25/100 [100/1090] acc: 0.7919921875
val--25/100 [110/1090] acc: 0.7920809659090909
val--25/100 [120/1090] acc: 0.7915690104166667
val--25/100 [130/1090] acc: 0.7925180288461539
val--25/100 [140/1090] acc: 0.7926897321428571
val--25/100 [150/1090] acc: 0.7928645833333333
val--25/100 [160/1090] acc: 0.7931640625
val--25/100 [170/1090] acc: 0.7931755514705883
val--25/100 [180/1090] acc: 0.7927951388888889
val--25/100 [190/1090] acc: 0.7935444078947368
val--25/100 [200/1090] acc: 0.79380859375
val--25/100 [210/1090] acc: 0.794047619047619
val--25/100 [220/1090] acc: 0.7932173295454545
val--25/100 [230/1090] acc: 0.7938349184782608
val--25/100 [240/1090] acc: 0.7935872395833333
val--25/100 [250/1090] acc: 0.7936875
val--25/100 [260/1090] acc: 0.7936598557692308
val--25/100 [270/1090] acc: 0.7938946759259259
val--25/100 [280/1090] acc: 0.7938895089285715
val--25/100 [290/1090] acc: 0.7937365301724137
val--25/100 [300/1090] acc: 0.7938151041666667
val--25/100 [310/1090] acc: 0.7934853830645161
val--25/100 [320/1090] acc: 0.79365234375
val--25/100 [330/1090] acc: 0.7937973484848485
val--25/100 [340/1090] acc: 0.7938763786764705
val--25/100 [350/1090] acc: 0.7939732142857143
val--25/100 [360/1090] acc: 0.7938910590277778
val--25/100 [370/1090] acc: 0.7940456081081081
val--25/100 [380/1090] acc: 0.7939761513157895
val--25/100 [390/1090] acc: 0.793729967948718
val--25/100 [400/1090] acc: 0.793603515625
val--25/100 [410/1090] acc: 0.7938548018292683
val--25/100 [420/1090] acc: 0.7938988095238095
val--25/100 [430/1090] acc: 0.7937590843023256
val--25/100 [440/1090] acc: 0.793643465909091
val--25/100 [450/1090] acc: 0.7935329861111111
val--25/100 [460/1090] acc: 0.7933848505434783
val--25/100 [470/1090] acc: 0.7932845744680851
val--25/100 [480/1090] acc: 0.7933919270833333
val--25/100 [490/1090] acc: 0.7935028698979592
val--25/100 [500/1090] acc: 0.7936875
val--25/100 [510/1090] acc: 0.7936580882352942
val--25/100 [520/1090] acc: 0.793780048076923
val--25/100 [530/1090] acc: 0.7937794811320755
val--25/100 [540/1090] acc: 0.7938874421296296
val--25/100 [550/1090] acc: 0.7937215909090909
val--25/100 [560/1090] acc: 0.7935825892857142
val--25/100 [570/1090] acc: 0.7933730811403509
val--25/100 [580/1090] acc: 0.7933728448275862
val--25/100 [590/1090] acc: 0.7934189618644067
val--25/100 [600/1090] acc: 0.7934635416666667
val--25/100 [610/1090] acc: 0.7933657786885245
val--25/100 [620/1090] acc: 0.7932396673387097
val--25/100 [630/1090] acc: 0.7934709821428572
val--25/100 [640/1090] acc: 0.793682861328125
val--25/100 [650/1090] acc: 0.7937019230769231
val--25/100 [660/1090] acc: 0.7935901988636364
val--25/100 [670/1090] acc: 0.7933127332089552
val--25/100 [680/1090] acc: 0.7932157628676471
val--25/100 [690/1090] acc: 0.7933876811594203
val--25/100 [700/1090] acc: 0.7933872767857143
val--25/100 [710/1090] acc: 0.7931943221830986
val--25/100 [720/1090] acc: 0.7930772569444444
val--25/100 [730/1090] acc: 0.7930276113013699
val--25/100 [740/1090] acc: 0.7929265202702702
val--25/100 [750/1090] acc: 0.7930104166666667
val--25/100 [760/1090] acc: 0.793128083881579
val--25/100 [770/1090] acc: 0.7930905032467532
val--25/100 [780/1090] acc: 0.7930588942307693
val--25/100 [790/1090] acc: 0.7931170886075949
val--25/100 [800/1090] acc: 0.7932958984375
val--25/100 [810/1090] acc: 0.7933545524691358
val--25/100 [820/1090] acc: 0.7934975228658536
val--25/100 [830/1090] acc: 0.793566453313253
val--25/100 [840/1090] acc: 0.7935128348214285
val--25/100 [850/1090] acc: 0.7935661764705882
val--25/100 [860/1090] acc: 0.7937863372093024
val--25/100 [870/1090] acc: 0.7936422413793104
val--25/100 [880/1090] acc: 0.793603515625
val--25/100 [890/1090] acc: 0.7937895014044943
val--25/100 [900/1090] acc: 0.7938237847222223
val--25/100 [910/1090] acc: 0.793853021978022
val--25/100 [920/1090] acc: 0.7938773777173913
val--25/100 [930/1090] acc: 0.7939432123655914
val--25/100 [940/1090] acc: 0.7939827127659574
val--25/100 [950/1090] acc: 0.7938445723684211
val--25/100 [960/1090] acc: 0.7937906901041667
val--25/100 [970/1090] acc: 0.7937661082474227
val--25/100 [980/1090] acc: 0.7937699298469387
val--25/100 [990/1090] acc: 0.7937144886363636
val--25/100 [1000/1090] acc: 0.7936328125
val--25/100 [1010/1090] acc: 0.7934599319306931
val--25/100 [1020/1090] acc: 0.7935431985294118
val--25/100 [1030/1090] acc: 0.7935983009708738
val--25/100 [1040/1090] acc: 0.7935659555288461
val--25/100 [1050/1090] acc: 0.7936049107142857
val--25/100 [1060/1090] acc: 0.7935620577830189
val--25/100 [1070/1090] acc: 0.7935711156542056
val--25/100 [1080/1090] acc: 0.793482349537037
val--25/100 [1090/1090] acc: 0.7933092029816514
epoch= 25, accuracy= 0.793309, rmse= 0.378985, auc= 0.854289
train--26/100 [9/1090] loss: 0.39820204973220824
train--26/100 [19/1090] loss: 0.4561198681592941
train--26/100 [29/1090] loss: 0.4546897768974304
train--26/100 [39/1090] loss: 0.4330489695072174
train--26/100 [49/1090] loss: 0.4348679929971695
train--26/100 [59/1090] loss: 0.4437527656555176
train--26/100 [69/1090] loss: 0.42882282435894015
train--26/100 [79/1090] loss: 0.4416525483131409
train--26/100 [89/1090] loss: 0.4588407874107361
train--26/100 [99/1090] loss: 0.42125543057918546
train--26/100 [109/1090] loss: 0.4416417837142944
train--26/100 [119/1090] loss: 0.42250465750694277
train--26/100 [129/1090] loss: 0.45459120273590087
train--26/100 [139/1090] loss: 0.44637569785118103
train--26/100 [149/1090] loss: 0.44428844153881075
train--26/100 [159/1090] loss: 0.4473263531923294
train--26/100 [169/1090] loss: 0.4522873848676682
train--26/100 [179/1090] loss: 0.45563828349113467
train--26/100 [189/1090] loss: 0.451741498708725
train--26/100 [199/1090] loss: 0.44388186037540434
train--26/100 [209/1090] loss: 0.4538503438234329
train--26/100 [219/1090] loss: 0.448767414689064
train--26/100 [229/1090] loss: 0.4501921385526657
train--26/100 [239/1090] loss: 0.4515139162540436
train--26/100 [249/1090] loss: 0.43076234459877016
train--26/100 [259/1090] loss: 0.4429129004478455
train--26/100 [269/1090] loss: 0.4517034232616425
train--26/100 [279/1090] loss: 0.45750778913497925
train--26/100 [289/1090] loss: 0.4440417915582657
train--26/100 [299/1090] loss: 0.43749722838401794
train--26/100 [309/1090] loss: 0.42763808071613313
train--26/100 [319/1090] loss: 0.44678656458854676
train--26/100 [329/1090] loss: 0.4553069472312927
train--26/100 [339/1090] loss: 0.4498618125915527
train--26/100 [349/1090] loss: 0.43955854177474973
train--26/100 [359/1090] loss: 0.45201143324375154
train--26/100 [369/1090] loss: 0.44167850315570834
train--26/100 [379/1090] loss: 0.4433888286352158
train--26/100 [389/1090] loss: 0.4548131972551346
train--26/100 [399/1090] loss: 0.46226249933242797
train--26/100 [409/1090] loss: 0.441977259516716
train--26/100 [419/1090] loss: 0.4341154515743256
train--26/100 [429/1090] loss: 0.43438681662082673
train--26/100 [439/1090] loss: 0.4578130155801773
train--26/100 [449/1090] loss: 0.4589486509561539
train--26/100 [459/1090] loss: 0.43600605726242064
train--26/100 [469/1090] loss: 0.4635925769805908
train--26/100 [479/1090] loss: 0.4427355915307999
train--26/100 [489/1090] loss: 0.4647639334201813
train--26/100 [499/1090] loss: 0.4431403994560242
train--26/100 [509/1090] loss: 0.44894275069236755
train--26/100 [519/1090] loss: 0.4396318346261978
train--26/100 [529/1090] loss: 0.46157981753349303
train--26/100 [539/1090] loss: 0.4613923609256744
train--26/100 [549/1090] loss: 0.4456321358680725
train--26/100 [559/1090] loss: 0.4379025101661682
train--26/100 [569/1090] loss: 0.4423922598361969
train--26/100 [579/1090] loss: 0.4413427263498306
train--26/100 [589/1090] loss: 0.44227721095085143
train--26/100 [599/1090] loss: 0.45146590769290923
train--26/100 [609/1090] loss: 0.4431249737739563
train--26/100 [619/1090] loss: 0.458427295088768
train--26/100 [629/1090] loss: 0.45421184301376344
train--26/100 [639/1090] loss: 0.46088778376579287
train--26/100 [649/1090] loss: 0.45000567436218264
train--26/100 [659/1090] loss: 0.44921564161777494
train--26/100 [669/1090] loss: 0.450839963555336
train--26/100 [679/1090] loss: 0.45321869254112246
train--26/100 [689/1090] loss: 0.4434262812137604
train--26/100 [699/1090] loss: 0.4421572476625443
train--26/100 [709/1090] loss: 0.4655223459005356
train--26/100 [719/1090] loss: 0.43255946040153503
train--26/100 [729/1090] loss: 0.45685082077980044
train--26/100 [739/1090] loss: 0.4524388939142227
train--26/100 [749/1090] loss: 0.4569624125957489
train--26/100 [759/1090] loss: 0.4432225972414017
train--26/100 [769/1090] loss: 0.4496666342020035
train--26/100 [779/1090] loss: 0.43967423439025877
train--26/100 [789/1090] loss: 0.4358304738998413
train--26/100 [799/1090] loss: 0.4603809714317322
train--26/100 [809/1090] loss: 0.44278751909732816
train--26/100 [819/1090] loss: 0.4648903667926788
train--26/100 [829/1090] loss: 0.4367626756429672
train--26/100 [839/1090] loss: 0.44659776985645294
train--26/100 [849/1090] loss: 0.4617951899766922
train--26/100 [859/1090] loss: 0.4463445723056793
train--26/100 [869/1090] loss: 0.4589362382888794
train--26/100 [879/1090] loss: 0.4463956207036972
train--26/100 [889/1090] loss: 0.4380245268344879
train--26/100 [899/1090] loss: 0.4519311398267746
train--26/100 [909/1090] loss: 0.4386046975851059
train--26/100 [919/1090] loss: 0.4583033829927444
train--26/100 [929/1090] loss: 0.4624487727880478
train--26/100 [939/1090] loss: 0.45664131343364717
train--26/100 [949/1090] loss: 0.44926863014698026
train--26/100 [959/1090] loss: 0.45276573598384856
train--26/100 [969/1090] loss: 0.4436285704374313
train--26/100 [979/1090] loss: 0.44097467958927156
train--26/100 [989/1090] loss: 0.4484948873519897
train--26/100 [999/1090] loss: 0.45092958211898804
train--26/100 [1009/1090] loss: 0.46313167810440065
train--26/100 [1019/1090] loss: 0.46711731553077696
train--26/100 [1029/1090] loss: 0.46231281459331514
train--26/100 [1039/1090] loss: 0.45391681492328645
train--26/100 [1049/1090] loss: 0.4470379114151001
train--26/100 [1059/1090] loss: 0.4436429351568222
train--26/100 [1069/1090] loss: 0.45192470848560334
train--26/100 [1079/1090] loss: 0.4519741475582123
train--26/100 [1089/1090] loss: 0.45474872291088103
predicting model...
val--26/100 [10/1090] acc: 0.79296875
val--26/100 [20/1090] acc: 0.79375
val--26/100 [30/1090] acc: 0.7921875
val--26/100 [40/1090] acc: 0.7923828125
val--26/100 [50/1090] acc: 0.791015625
val--26/100 [60/1090] acc: 0.7903645833333334
val--26/100 [70/1090] acc: 0.7909598214285715
val--26/100 [80/1090] acc: 0.789892578125
val--26/100 [90/1090] acc: 0.7905815972222222
val--26/100 [100/1090] acc: 0.791484375
val--26/100 [110/1090] acc: 0.7913352272727273
val--26/100 [120/1090] acc: 0.7909505208333333
val--26/100 [130/1090] acc: 0.7920072115384615
val--26/100 [140/1090] acc: 0.7921595982142857
val--26/100 [150/1090] acc: 0.7922135416666667
val--26/100 [160/1090] acc: 0.792431640625
val--26/100 [170/1090] acc: 0.7924632352941177
val--26/100 [180/1090] acc: 0.7922743055555556
val--26/100 [190/1090] acc: 0.7931743421052632
val--26/100 [200/1090] acc: 0.79359375
val--26/100 [210/1090] acc: 0.7939360119047619
val--26/100 [220/1090] acc: 0.7929865056818182
val--26/100 [230/1090] acc: 0.7936311141304347
val--26/100 [240/1090] acc: 0.7935546875
val--26/100 [250/1090] acc: 0.793671875
val--26/100 [260/1090] acc: 0.7938551682692307
val--26/100 [270/1090] acc: 0.7941261574074074
val--26/100 [280/1090] acc: 0.7940987723214286
val--26/100 [290/1090] acc: 0.7940193965517242
val--26/100 [300/1090] acc: 0.793984375
val--26/100 [310/1090] acc: 0.793686995967742
val--26/100 [320/1090] acc: 0.7939453125
val--26/100 [330/1090] acc: 0.7940932765151515
val--26/100 [340/1090] acc: 0.7941636029411765
val--26/100 [350/1090] acc: 0.7942633928571429
val--26/100 [360/1090] acc: 0.7942165798611112
val--26/100 [370/1090] acc: 0.7943728885135135
val--26/100 [380/1090] acc: 0.7944181743421053
val--26/100 [390/1090] acc: 0.794140625
val--26/100 [400/1090] acc: 0.793994140625
val--26/100 [410/1090] acc: 0.7941120426829268
val--26/100 [420/1090] acc: 0.7941871279761905
val--26/100 [430/1090] acc: 0.7940588662790697
val--26/100 [440/1090] acc: 0.7940340909090909
val--26/100 [450/1090] acc: 0.79390625
val--26/100 [460/1090] acc: 0.7938179347826086
val--26/100 [470/1090] acc: 0.7937416888297872
val--26/100 [480/1090] acc: 0.7938232421875
val--26/100 [490/1090] acc: 0.7939572704081632
val--26/100 [500/1090] acc: 0.7941171875
val--26/100 [510/1090] acc: 0.7940487132352941
val--26/100 [520/1090] acc: 0.794268329326923
val--26/100 [530/1090] acc: 0.7942585495283019
val--26/100 [540/1090] acc: 0.7943793402777778
val--26/100 [550/1090] acc: 0.7941974431818182
val--26/100 [560/1090] acc: 0.7940987723214286
val--26/100 [570/1090] acc: 0.7938253837719298
val--26/100 [580/1090] acc: 0.7937904094827586
val--26/100 [590/1090] acc: 0.7938228283898305
val--26/100 [600/1090] acc: 0.7938020833333334
val--26/100 [610/1090] acc: 0.7937115778688525
val--26/100 [620/1090] acc: 0.7935798891129032
val--26/100 [630/1090] acc: 0.7937996031746032
val--26/100 [640/1090] acc: 0.794024658203125
val--26/100 [650/1090] acc: 0.7940865384615384
val--26/100 [660/1090] acc: 0.7939571496212121
val--26/100 [670/1090] acc: 0.7936567164179105
val--26/100 [680/1090] acc: 0.7935431985294118
val--26/100 [690/1090] acc: 0.7937103713768116
val--26/100 [700/1090] acc: 0.7936941964285714
val--26/100 [710/1090] acc: 0.7935299295774648
val--26/100 [720/1090] acc: 0.7933702256944445
val--26/100 [730/1090] acc: 0.7932898116438356
val--26/100 [740/1090] acc: 0.7931798986486487
val--26/100 [750/1090] acc: 0.7932552083333333
val--26/100 [760/1090] acc: 0.7933696546052632
val--26/100 [770/1090] acc: 0.7933340097402597
val--26/100 [780/1090] acc: 0.7932892628205128
val--26/100 [790/1090] acc: 0.7933445411392405
val--26/100 [800/1090] acc: 0.7935791015625
val--26/100 [810/1090] acc: 0.7936583719135802
val--26/100 [820/1090] acc: 0.7937547637195121
val--26/100 [830/1090] acc: 0.793797063253012
val--26/100 [840/1090] acc: 0.7937686011904762
val--26/100 [850/1090] acc: 0.793795955882353
val--26/100 [860/1090] acc: 0.7939907340116279
val--26/100 [870/1090] acc: 0.793853268678161
val--26/100 [880/1090] acc: 0.7937943892045455
val--26/100 [890/1090] acc: 0.7939387289325842
val--26/100 [900/1090] acc: 0.7939366319444444
val--26/100 [910/1090] acc: 0.7939646291208792
val--26/100 [920/1090] acc: 0.7939707880434783
val--26/100 [930/1090] acc: 0.7940608198924731
val--26/100 [940/1090] acc: 0.7940741356382979
val--26/100 [950/1090] acc: 0.793984375
val--26/100 [960/1090] acc: 0.79388427734375
val--26/100 [970/1090] acc: 0.7938426224226804
val--26/100 [980/1090] acc: 0.7938735650510204
val--26/100 [990/1090] acc: 0.7938328598484848
val--26/100 [1000/1090] acc: 0.79376171875
val--26/100 [1010/1090] acc: 0.7936068997524752
val--26/100 [1020/1090] acc: 0.7936695772058824
val--26/100 [1030/1090] acc: 0.7936703580097088
val--26/100 [1040/1090] acc: 0.7936147836538462
val--26/100 [1050/1090] acc: 0.7937127976190477
val--26/100 [1060/1090] acc: 0.7936468160377359
val--26/100 [1070/1090] acc: 0.7936258761682243
val--26/100 [1080/1090] acc: 0.7935510706018518
val--26/100 [1090/1090] acc: 0.7933665424311926
epoch= 26, accuracy= 0.793367, rmse= 0.379054, auc= 0.854373
train--27/100 [9/1090] loss: 0.38603197038173676
train--27/100 [19/1090] loss: 0.43292248249053955
train--27/100 [29/1090] loss: 0.45506938695907595
train--27/100 [39/1090] loss: 0.45327311754226685
train--27/100 [49/1090] loss: 0.44977129697799684
train--27/100 [59/1090] loss: 0.43530432879924774
train--27/100 [69/1090] loss: 0.4577220529317856
train--27/100 [79/1090] loss: 0.43916915357112885
train--27/100 [89/1090] loss: 0.43766688704490664
train--27/100 [99/1090] loss: 0.4364872694015503
train--27/100 [109/1090] loss: 0.43620871305465697
train--27/100 [119/1090] loss: 0.43829916715621947
train--27/100 [129/1090] loss: 0.4437693923711777
train--27/100 [139/1090] loss: 0.4497635304927826
train--27/100 [149/1090] loss: 0.44471235871315
train--27/100 [159/1090] loss: 0.4571942150592804
train--27/100 [169/1090] loss: 0.4488068401813507
train--27/100 [179/1090] loss: 0.45122153759002687
train--27/100 [189/1090] loss: 0.41795781850814817
train--27/100 [199/1090] loss: 0.45145393908023834
train--27/100 [209/1090] loss: 0.44820407032966614
train--27/100 [219/1090] loss: 0.43153164684772494
train--27/100 [229/1090] loss: 0.4422904908657074
train--27/100 [239/1090] loss: 0.44131205081939695
train--27/100 [249/1090] loss: 0.43433272540569307
train--27/100 [259/1090] loss: 0.46387265622615814
train--27/100 [269/1090] loss: 0.43982895016670226
train--27/100 [279/1090] loss: 0.45492242872714994
train--27/100 [289/1090] loss: 0.419288769364357
train--27/100 [299/1090] loss: 0.4415778249502182
train--27/100 [309/1090] loss: 0.4351934760808945
train--27/100 [319/1090] loss: 0.45665194392204284
train--27/100 [329/1090] loss: 0.46964915096759796
train--27/100 [339/1090] loss: 0.4188679039478302
train--27/100 [349/1090] loss: 0.44381070137023926
train--27/100 [359/1090] loss: 0.42898373305797577
train--27/100 [369/1090] loss: 0.46194855570793153
train--27/100 [379/1090] loss: 0.44037906229496004
train--27/100 [389/1090] loss: 0.466649729013443
train--27/100 [399/1090] loss: 0.4637112855911255
train--27/100 [409/1090] loss: 0.42874535322189333
train--27/100 [419/1090] loss: 0.45289053320884703
train--27/100 [429/1090] loss: 0.4571066975593567
train--27/100 [439/1090] loss: 0.46640952825546267
train--27/100 [449/1090] loss: 0.43957228362560274
train--27/100 [459/1090] loss: 0.44371738731861116
train--27/100 [469/1090] loss: 0.4450125187635422
train--27/100 [479/1090] loss: 0.44197745621204376
train--27/100 [489/1090] loss: 0.4376302808523178
train--27/100 [499/1090] loss: 0.4541877269744873
train--27/100 [509/1090] loss: 0.4362973153591156
train--27/100 [519/1090] loss: 0.4589053064584732
train--27/100 [529/1090] loss: 0.4309388637542725
train--27/100 [539/1090] loss: 0.43618168532848356
train--27/100 [549/1090] loss: 0.4621713846921921
train--27/100 [559/1090] loss: 0.44695614874362943
train--27/100 [569/1090] loss: 0.44931511878967284
train--27/100 [579/1090] loss: 0.4467225819826126
train--27/100 [589/1090] loss: 0.4275135397911072
train--27/100 [599/1090] loss: 0.4571284979581833
train--27/100 [609/1090] loss: 0.45685072541236876
train--27/100 [619/1090] loss: 0.4623163670301437
train--27/100 [629/1090] loss: 0.43464850783348086
train--27/100 [639/1090] loss: 0.4623943865299225
train--27/100 [649/1090] loss: 0.4577698945999146
train--27/100 [659/1090] loss: 0.451875364780426
train--27/100 [669/1090] loss: 0.45681340992450714
train--27/100 [679/1090] loss: 0.448499470949173
train--27/100 [689/1090] loss: 0.45652438700199127
train--27/100 [699/1090] loss: 0.4777527987957001
train--27/100 [709/1090] loss: 0.4395090937614441
train--27/100 [719/1090] loss: 0.45164395272731783
train--27/100 [729/1090] loss: 0.46324190199375154
train--27/100 [739/1090] loss: 0.455923867225647
train--27/100 [749/1090] loss: 0.4340300500392914
train--27/100 [759/1090] loss: 0.44604977667331697
train--27/100 [769/1090] loss: 0.44435209333896636
train--27/100 [779/1090] loss: 0.42940553426742556
train--27/100 [789/1090] loss: 0.4548964262008667
train--27/100 [799/1090] loss: 0.4717202872037888
train--27/100 [809/1090] loss: 0.46565452218055725
train--27/100 [819/1090] loss: 0.4537092447280884
train--27/100 [829/1090] loss: 0.44220335483551027
train--27/100 [839/1090] loss: 0.46420417726039886
train--27/100 [849/1090] loss: 0.43746040761470795
train--27/100 [859/1090] loss: 0.4423464357852936
train--27/100 [869/1090] loss: 0.4631849884986877
train--27/100 [879/1090] loss: 0.43987311124801637
train--27/100 [889/1090] loss: 0.44794521331787107
train--27/100 [899/1090] loss: 0.4394201099872589
train--27/100 [909/1090] loss: 0.4497333258390427
train--27/100 [919/1090] loss: 0.4471723914146423
train--27/100 [929/1090] loss: 0.4396813243627548
train--27/100 [939/1090] loss: 0.467413654923439
train--27/100 [949/1090] loss: 0.46749592423439024
train--27/100 [959/1090] loss: 0.44828300178050995
train--27/100 [969/1090] loss: 0.4415701538324356
train--27/100 [979/1090] loss: 0.45169327557086947
train--27/100 [989/1090] loss: 0.44079158306121824
train--27/100 [999/1090] loss: 0.4434110313653946
train--27/100 [1009/1090] loss: 0.4631683319807053
train--27/100 [1019/1090] loss: 0.46641688942909243
train--27/100 [1029/1090] loss: 0.4563938707113266
train--27/100 [1039/1090] loss: 0.4571225196123123
train--27/100 [1049/1090] loss: 0.4581473350524902
train--27/100 [1059/1090] loss: 0.44450902938842773
train--27/100 [1069/1090] loss: 0.4440139889717102
train--27/100 [1079/1090] loss: 0.45176892578601835
train--27/100 [1089/1090] loss: 0.46938067078590395
predicting model...
val--27/100 [10/1090] acc: 0.79375
val--27/100 [20/1090] acc: 0.79375
val--27/100 [30/1090] acc: 0.7934895833333333
val--27/100 [40/1090] acc: 0.79306640625
val--27/100 [50/1090] acc: 0.791796875
val--27/100 [60/1090] acc: 0.791015625
val--27/100 [70/1090] acc: 0.7916294642857142
val--27/100 [80/1090] acc: 0.79072265625
val--27/100 [90/1090] acc: 0.7912326388888888
val--27/100 [100/1090] acc: 0.7925
val--27/100 [110/1090] acc: 0.7921519886363636
val--27/100 [120/1090] acc: 0.7918294270833334
val--27/100 [130/1090] acc: 0.7928786057692307
val--27/100 [140/1090] acc: 0.7930803571428572
val--27/100 [150/1090] acc: 0.793046875
val--27/100 [160/1090] acc: 0.793359375
val--27/100 [170/1090] acc: 0.7933823529411764
val--27/100 [180/1090] acc: 0.7928819444444445
val--27/100 [190/1090] acc: 0.7935855263157895
val--27/100 [200/1090] acc: 0.79375
val--27/100 [210/1090] acc: 0.7940662202380953
val--27/100 [220/1090] acc: 0.7932173295454545
val--27/100 [230/1090] acc: 0.79375
val--27/100 [240/1090] acc: 0.7936360677083333
val--27/100 [250/1090] acc: 0.793765625
val--27/100 [260/1090] acc: 0.79375
val--27/100 [270/1090] acc: 0.7939670138888889
val--27/100 [280/1090] acc: 0.7939871651785714
val--27/100 [290/1090] acc: 0.7938577586206896
val--27/100 [300/1090] acc: 0.79390625
val--27/100 [310/1090] acc: 0.7936365927419354
val--27/100 [320/1090] acc: 0.7939697265625
val--27/100 [330/1090] acc: 0.7941761363636364
val--27/100 [340/1090] acc: 0.7942670036764706
val--27/100 [350/1090] acc: 0.7943861607142857
val--27/100 [360/1090] acc: 0.7943033854166667
val--27/100 [370/1090] acc: 0.7944362331081081
val--27/100 [380/1090] acc: 0.7943359375
val--27/100 [390/1090] acc: 0.7940404647435897
val--27/100 [400/1090] acc: 0.79388671875
val--27/100 [410/1090] acc: 0.794140625
val--27/100 [420/1090] acc: 0.7941685267857143
val--27/100 [430/1090] acc: 0.7940406976744186
val--27/100 [440/1090] acc: 0.7939808238636363
val--27/100 [450/1090] acc: 0.7938975694444445
val--27/100 [460/1090] acc: 0.7938688858695652
val--27/100 [470/1090] acc: 0.793783244680851
val--27/100 [480/1090] acc: 0.793896484375
val--27/100 [490/1090] acc: 0.7940130739795919
val--27/100 [500/1090] acc: 0.7941484375
val--27/100 [510/1090] acc: 0.7941176470588235
val--27/100 [520/1090] acc: 0.7942608173076923
val--27/100 [530/1090] acc: 0.794251179245283
val--27/100 [540/1090] acc: 0.7943504050925926
val--27/100 [550/1090] acc: 0.7942045454545454
val--27/100 [560/1090] acc: 0.7940987723214286
val--27/100 [570/1090] acc: 0.793859649122807
val--27/100 [580/1090] acc: 0.7938644935344827
val--27/100 [590/1090] acc: 0.7938625529661016
val--27/100 [600/1090] acc: 0.7938411458333333
val--27/100 [610/1090] acc: 0.7937243852459016
val--27/100 [620/1090] acc: 0.7936050907258064
val--27/100 [630/1090] acc: 0.793812003968254
val--27/100 [640/1090] acc: 0.79400634765625
val--27/100 [650/1090] acc: 0.7940805288461539
val--27/100 [660/1090] acc: 0.7939630681818182
val--27/100 [670/1090] acc: 0.7936683768656716
val--27/100 [680/1090] acc: 0.7936006433823529
val--27/100 [690/1090] acc: 0.7937726449275362
val--27/100 [700/1090] acc: 0.7937946428571429
val--27/100 [710/1090] acc: 0.7936674735915493
val--27/100 [720/1090] acc: 0.79345703125
val--27/100 [730/1090] acc: 0.7934075342465754
val--27/100 [740/1090] acc: 0.7933277027027027
val--27/100 [750/1090] acc: 0.7933802083333333
val--27/100 [760/1090] acc: 0.79345703125
val--27/100 [770/1090] acc: 0.7934253246753247
val--27/100 [780/1090] acc: 0.7934395032051282
val--27/100 [790/1090] acc: 0.7934632120253164
val--27/100 [800/1090] acc: 0.793681640625
val--27/100 [810/1090] acc: 0.7937355324074075
val--27/100 [820/1090] acc: 0.7938214557926829
val--27/100 [830/1090] acc: 0.7939288403614457
val--27/100 [840/1090] acc: 0.7938755580357143
val--27/100 [850/1090] acc: 0.7938511029411764
val--27/100 [860/1090] acc: 0.7940815770348837
val--27/100 [870/1090] acc: 0.7939206178160919
val--27/100 [880/1090] acc: 0.7938920454545455
val--27/100 [890/1090] acc: 0.7940484550561798
val--27/100 [900/1090] acc: 0.7940581597222223
val--27/100 [910/1090] acc: 0.794089114010989
val--27/100 [920/1090] acc: 0.7941109035326087
val--27/100 [930/1090] acc: 0.7941742271505376
val--27/100 [940/1090] acc: 0.7942071143617021
val--27/100 [950/1090] acc: 0.7940748355263157
val--27/100 [960/1090] acc: 0.7940022786458333
val--27/100 [970/1090] acc: 0.7939916237113402
val--27/100 [980/1090] acc: 0.7939971301020409
val--27/100 [990/1090] acc: 0.7939275568181818
val--27/100 [1000/1090] acc: 0.7938359375
val--27/100 [1010/1090] acc: 0.7936842512376238
val--27/100 [1020/1090] acc: 0.7937768075980393
val--27/100 [1030/1090] acc: 0.7938410194174758
val--27/100 [1040/1090] acc: 0.7937950721153846
val--27/100 [1050/1090] acc: 0.7938467261904761
val--27/100 [1060/1090] acc: 0.7937979068396226
val--27/100 [1070/1090] acc: 0.793819363317757
val--27/100 [1080/1090] acc: 0.79375
val--27/100 [1090/1090] acc: 0.7935708142201835
epoch= 27, accuracy= 0.793571, rmse= 0.378884, auc= 0.854334
train--28/100 [9/1090] loss: 0.4173731178045273
train--28/100 [19/1090] loss: 0.46777828931808474
train--28/100 [29/1090] loss: 0.435410812497139
train--28/100 [39/1090] loss: 0.43632570207118987
train--28/100 [49/1090] loss: 0.43070749640464784
train--28/100 [59/1090] loss: 0.45739684998989105
train--28/100 [69/1090] loss: 0.43846156001091
train--28/100 [79/1090] loss: 0.4496183514595032
train--28/100 [89/1090] loss: 0.4501519501209259
train--28/100 [99/1090] loss: 0.44062647223472595
train--28/100 [109/1090] loss: 0.43976699709892275
train--28/100 [119/1090] loss: 0.4423794955015182
train--28/100 [129/1090] loss: 0.4423043727874756
train--28/100 [139/1090] loss: 0.43331687450408934
train--28/100 [149/1090] loss: 0.44376041293144225
train--28/100 [159/1090] loss: 0.44387792646884916
train--28/100 [169/1090] loss: 0.43103751838207244
train--28/100 [179/1090] loss: 0.4468382090330124
train--28/100 [189/1090] loss: 0.4761112093925476
train--28/100 [199/1090] loss: 0.4560095459222794
train--28/100 [209/1090] loss: 0.4535903036594391
train--28/100 [219/1090] loss: 0.4582092583179474
train--28/100 [229/1090] loss: 0.44357641935348513
train--28/100 [239/1090] loss: 0.4403307527303696
train--28/100 [249/1090] loss: 0.4447634816169739
train--28/100 [259/1090] loss: 0.4547915369272232
train--28/100 [269/1090] loss: 0.4501664638519287
train--28/100 [279/1090] loss: 0.43192199170589446
train--28/100 [289/1090] loss: 0.4546359986066818
train--28/100 [299/1090] loss: 0.4558428585529327
train--28/100 [309/1090] loss: 0.4416003942489624
train--28/100 [319/1090] loss: 0.4319546580314636
train--28/100 [329/1090] loss: 0.4891892492771149
train--28/100 [339/1090] loss: 0.4362528085708618
train--28/100 [349/1090] loss: 0.448713681101799
train--28/100 [359/1090] loss: 0.44791958928108216
train--28/100 [369/1090] loss: 0.459799188375473
train--28/100 [379/1090] loss: 0.4454104363918304
train--28/100 [389/1090] loss: 0.4474404752254486
train--28/100 [399/1090] loss: 0.43553270399570465
train--28/100 [409/1090] loss: 0.418186229467392
train--28/100 [419/1090] loss: 0.44268383681774137
train--28/100 [429/1090] loss: 0.43700682520866396
train--28/100 [439/1090] loss: 0.443780380487442
train--28/100 [449/1090] loss: 0.45398584604263303
train--28/100 [459/1090] loss: 0.4634281575679779
train--28/100 [469/1090] loss: 0.4233764797449112
train--28/100 [479/1090] loss: 0.45877457559108736
train--28/100 [489/1090] loss: 0.45048591792583464
train--28/100 [499/1090] loss: 0.4249777138233185
train--28/100 [509/1090] loss: 0.4591996043920517
train--28/100 [519/1090] loss: 0.450557604432106
train--28/100 [529/1090] loss: 0.46540050208568573
train--28/100 [539/1090] loss: 0.45250104665756224
train--28/100 [549/1090] loss: 0.4393896162509918
train--28/100 [559/1090] loss: 0.44022093415260316
train--28/100 [569/1090] loss: 0.44784526228904725
train--28/100 [579/1090] loss: 0.4395445466041565
train--28/100 [589/1090] loss: 0.4365475207567215
train--28/100 [599/1090] loss: 0.43807093501091005
train--28/100 [609/1090] loss: 0.43299990296363833
train--28/100 [619/1090] loss: 0.46333723664283755
train--28/100 [629/1090] loss: 0.44691101610660555
train--28/100 [639/1090] loss: 0.43699599206447604
train--28/100 [649/1090] loss: 0.4567573517560959
train--28/100 [659/1090] loss: 0.44999449849128725
train--28/100 [669/1090] loss: 0.45030813217163085
train--28/100 [679/1090] loss: 0.4491610646247864
train--28/100 [689/1090] loss: 0.4461379736661911
train--28/100 [699/1090] loss: 0.44744049608707426
train--28/100 [709/1090] loss: 0.46183173060417176
train--28/100 [719/1090] loss: 0.44239506125450134
train--28/100 [729/1090] loss: 0.4578251034021378
train--28/100 [739/1090] loss: 0.4512637287378311
train--28/100 [749/1090] loss: 0.4827629178762436
train--28/100 [759/1090] loss: 0.457991623878479
train--28/100 [769/1090] loss: 0.4483299970626831
train--28/100 [779/1090] loss: 0.45119909942150116
train--28/100 [789/1090] loss: 0.4580611944198608
train--28/100 [799/1090] loss: 0.43423008620738984
train--28/100 [809/1090] loss: 0.4584915816783905
train--28/100 [819/1090] loss: 0.44518961012363434
train--28/100 [829/1090] loss: 0.45323688387870786
train--28/100 [839/1090] loss: 0.4575414776802063
train--28/100 [849/1090] loss: 0.4563721537590027
train--28/100 [859/1090] loss: 0.45008268654346467
train--28/100 [869/1090] loss: 0.44729250073432925
train--28/100 [879/1090] loss: 0.4386037588119507
train--28/100 [889/1090] loss: 0.44460212290287016
train--28/100 [899/1090] loss: 0.4620427697896957
train--28/100 [909/1090] loss: 0.44006659984588625
train--28/100 [919/1090] loss: 0.4444404661655426
train--28/100 [929/1090] loss: 0.45385517179965973
train--28/100 [939/1090] loss: 0.4458617568016052
train--28/100 [949/1090] loss: 0.4483616292476654
train--28/100 [959/1090] loss: 0.45199127197265626
train--28/100 [969/1090] loss: 0.4557826578617096
train--28/100 [979/1090] loss: 0.44112986922264097
train--28/100 [989/1090] loss: 0.4531386762857437
train--28/100 [999/1090] loss: 0.4438635617494583
train--28/100 [1009/1090] loss: 0.4452038675546646
train--28/100 [1019/1090] loss: 0.475104621052742
train--28/100 [1029/1090] loss: 0.4420366585254669
train--28/100 [1039/1090] loss: 0.4416655123233795
train--28/100 [1049/1090] loss: 0.4576529085636139
train--28/100 [1059/1090] loss: 0.4260376840829849
train--28/100 [1069/1090] loss: 0.46121964752674105
train--28/100 [1079/1090] loss: 0.443148797750473
train--28/100 [1089/1090] loss: 0.44682454168796537
predicting model...
val--28/100 [10/1090] acc: 0.79140625
val--28/100 [20/1090] acc: 0.79296875
val--28/100 [30/1090] acc: 0.7924479166666667
val--28/100 [40/1090] acc: 0.79228515625
val--28/100 [50/1090] acc: 0.79171875
val--28/100 [60/1090] acc: 0.7908203125
val--28/100 [70/1090] acc: 0.79140625
val--28/100 [80/1090] acc: 0.790087890625
val--28/100 [90/1090] acc: 0.790625
val--28/100 [100/1090] acc: 0.791796875
val--28/100 [110/1090] acc: 0.7918678977272727
val--28/100 [120/1090] acc: 0.7916015625
val--28/100 [130/1090] acc: 0.7928786057692307
val--28/100 [140/1090] acc: 0.79296875
val--28/100 [150/1090] acc: 0.793125
val--28/100 [160/1090] acc: 0.7934326171875
val--28/100 [170/1090] acc: 0.793405330882353
val--28/100 [180/1090] acc: 0.7932074652777777
val--28/100 [190/1090] acc: 0.7939555921052631
val--28/100 [200/1090] acc: 0.79416015625
val--28/100 [210/1090] acc: 0.7944382440476191
val--28/100 [220/1090] acc: 0.7934836647727272
val--28/100 [230/1090] acc: 0.7940726902173914
val--28/100 [240/1090] acc: 0.7939453125
val--28/100 [250/1090] acc: 0.794140625
val--28/100 [260/1090] acc: 0.7940955528846154
val--28/100 [270/1090] acc: 0.7943865740740741
val--28/100 [280/1090] acc: 0.7943498883928571
val--28/100 [290/1090] acc: 0.7942349137931034
val--28/100 [300/1090] acc: 0.7942838541666667
val--28/100 [310/1090] acc: 0.793976814516129
val--28/100 [320/1090] acc: 0.79429931640625
val--28/100 [330/1090] acc: 0.7945194128787879
val--28/100 [340/1090] acc: 0.7946346507352942
val--28/100 [350/1090] acc: 0.7946875
val--28/100 [360/1090] acc: 0.7945746527777777
val--28/100 [370/1090] acc: 0.7947529560810811
val--28/100 [380/1090] acc: 0.794664884868421
val--28/100 [390/1090] acc: 0.7944210737179487
val--28/100 [400/1090] acc: 0.79427734375
val--28/100 [410/1090] acc: 0.7945884146341463
val--28/100 [420/1090] acc: 0.7945870535714286
val--28/100 [430/1090] acc: 0.7945130813953488
val--28/100 [440/1090] acc: 0.7944957386363637
val--28/100 [450/1090] acc: 0.7943315972222222
val--28/100 [460/1090] acc: 0.7942255434782609
val--28/100 [470/1090] acc: 0.7941156914893617
val--28/100 [480/1090] acc: 0.794140625
val--28/100 [490/1090] acc: 0.7942602040816327
val--28/100 [500/1090] acc: 0.7944609375
val--28/100 [510/1090] acc: 0.7943397671568627
val--28/100 [520/1090] acc: 0.7945237379807693
val--28/100 [530/1090] acc: 0.7945091391509433
val--28/100 [540/1090] acc: 0.7946469907407407
val--28/100 [550/1090] acc: 0.7945170454545455
val--28/100 [560/1090] acc: 0.7943638392857143
val--28/100 [570/1090] acc: 0.7941611842105263
val--28/100 [580/1090] acc: 0.794140625
val--28/100 [590/1090] acc: 0.7941273834745762
val--28/100 [600/1090] acc: 0.79419921875
val--28/100 [610/1090] acc: 0.7940829918032787
val--28/100 [620/1090] acc: 0.7939957157258064
val--28/100 [630/1090] acc: 0.7942150297619047
val--28/100 [640/1090] acc: 0.7944091796875
val--28/100 [650/1090] acc: 0.7944471153846154
val--28/100 [660/1090] acc: 0.7943773674242425
val--28/100 [670/1090] acc: 0.7940881529850746
val--28/100 [680/1090] acc: 0.7940085018382353
val--28/100 [690/1090] acc: 0.7941745923913044
val--28/100 [700/1090] acc: 0.7940848214285714
val--28/100 [710/1090] acc: 0.7938820422535211
val--28/100 [720/1090] acc: 0.7936794704861111
val--28/100 [730/1090] acc: 0.7936001712328767
val--28/100 [740/1090] acc: 0.7934649493243243
val--28/100 [750/1090] acc: 0.7935260416666666
val--28/100 [760/1090] acc: 0.7936215049342106
val--28/100 [770/1090] acc: 0.7935978084415585
val--28/100 [780/1090] acc: 0.7935997596153846
val--28/100 [790/1090] acc: 0.793660996835443
val--28/100 [800/1090] acc: 0.79388671875
val--28/100 [810/1090] acc: 0.7939429012345679
val--28/100 [820/1090] acc: 0.7940501143292683
val--28/100 [830/1090] acc: 0.794117093373494
val--28/100 [840/1090] acc: 0.7940150669642857
val--28/100 [850/1090] acc: 0.7940211397058824
val--28/100 [860/1090] acc: 0.7942632630813954
val--28/100 [870/1090] acc: 0.7941271551724138
val--28/100 [880/1090] acc: 0.7941006747159091
val--28/100 [890/1090] acc: 0.7942722963483146
val--28/100 [900/1090] acc: 0.7942447916666666
val--28/100 [910/1090] acc: 0.7942479395604396
val--28/100 [920/1090] acc: 0.7942934782608696
val--28/100 [930/1090] acc: 0.7943758400537635
val--28/100 [940/1090] acc: 0.7943774933510638
val--28/100 [950/1090] acc: 0.794296875
val--28/100 [960/1090] acc: 0.79423828125
val--28/100 [970/1090] acc: 0.7942292203608248
val--28/100 [980/1090] acc: 0.7942362882653061
val--28/100 [990/1090] acc: 0.7941564078282828
val--28/100 [1000/1090] acc: 0.79407421875
val--28/100 [1010/1090] acc: 0.7939395111386138
val--28/100 [1020/1090] acc: 0.7940104166666667
val--28/100 [1030/1090] acc: 0.7940306432038835
val--28/100 [1040/1090] acc: 0.7940279447115385
val--28/100 [1050/1090] acc: 0.7940997023809524
val--28/100 [1060/1090] acc: 0.7940337558962264
val--28/100 [1070/1090] acc: 0.7940201518691589
val--28/100 [1080/1090] acc: 0.7939344618055556
val--28/100 [1090/1090] acc: 0.793793004587156
epoch= 28, accuracy= 0.793793, rmse= 0.378818, auc= 0.854335
train--29/100 [9/1090] loss: 0.41588779985904695
train--29/100 [19/1090] loss: 0.4547334462404251
train--29/100 [29/1090] loss: 0.44560982584953307
train--29/100 [39/1090] loss: 0.42739066779613494
train--29/100 [49/1090] loss: 0.4440775990486145
train--29/100 [59/1090] loss: 0.4474711030721664
train--29/100 [69/1090] loss: 0.45069755613803864
train--29/100 [79/1090] loss: 0.442183318734169
train--29/100 [89/1090] loss: 0.4425742983818054
train--29/100 [99/1090] loss: 0.43296987414360044
train--29/100 [109/1090] loss: 0.44736074209213256
train--29/100 [119/1090] loss: 0.45299738347530366
train--29/100 [129/1090] loss: 0.44435852468013765
train--29/100 [139/1090] loss: 0.43260653913021085
train--29/100 [149/1090] loss: 0.45782996714115143
train--29/100 [159/1090] loss: 0.4415933579206467
train--29/100 [169/1090] loss: 0.4248321533203125
train--29/100 [179/1090] loss: 0.4485225796699524
train--29/100 [189/1090] loss: 0.4418067753314972
train--29/100 [199/1090] loss: 0.43198410868644715
train--29/100 [209/1090] loss: 0.4489037573337555
train--29/100 [219/1090] loss: 0.4417715907096863
train--29/100 [229/1090] loss: 0.42593846321105955
train--29/100 [239/1090] loss: 0.4366075903177261
train--29/100 [249/1090] loss: 0.43864124119281767
train--29/100 [259/1090] loss: 0.4458345800638199
train--29/100 [269/1090] loss: 0.4462890475988388
train--29/100 [279/1090] loss: 0.4604649007320404
train--29/100 [289/1090] loss: 0.44140230119228363
train--29/100 [299/1090] loss: 0.4468312650918961
train--29/100 [309/1090] loss: 0.4468143582344055
train--29/100 [319/1090] loss: 0.445173379778862
train--29/100 [329/1090] loss: 0.44908257722854616
train--29/100 [339/1090] loss: 0.46178812980651857
train--29/100 [349/1090] loss: 0.43068957328796387
train--29/100 [359/1090] loss: 0.4466275364160538
train--29/100 [369/1090] loss: 0.4359560370445251
train--29/100 [379/1090] loss: 0.4663234770298004
train--29/100 [389/1090] loss: 0.46155995726585386
train--29/100 [399/1090] loss: 0.4587209612131119
train--29/100 [409/1090] loss: 0.4310885727405548
train--29/100 [419/1090] loss: 0.44974247813224794
train--29/100 [429/1090] loss: 0.44586704671382904
train--29/100 [439/1090] loss: 0.44411568343639374
train--29/100 [449/1090] loss: 0.4482471138238907
train--29/100 [459/1090] loss: 0.4292812943458557
train--29/100 [469/1090] loss: 0.4606738775968552
train--29/100 [479/1090] loss: 0.4560595691204071
train--29/100 [489/1090] loss: 0.44230072796344755
train--29/100 [499/1090] loss: 0.44329973459243777
train--29/100 [509/1090] loss: 0.4517357796430588
train--29/100 [519/1090] loss: 0.43113293349742887
train--29/100 [529/1090] loss: 0.431888484954834
train--29/100 [539/1090] loss: 0.45209482312202454
train--29/100 [549/1090] loss: 0.4556957632303238
train--29/100 [559/1090] loss: 0.4324177920818329
train--29/100 [569/1090] loss: 0.4501363098621368
train--29/100 [579/1090] loss: 0.45491025745868685
train--29/100 [589/1090] loss: 0.45371073782444
train--29/100 [599/1090] loss: 0.45443165600299834
train--29/100 [609/1090] loss: 0.4439438432455063
train--29/100 [619/1090] loss: 0.44031769037246704
train--29/100 [629/1090] loss: 0.4534226059913635
train--29/100 [639/1090] loss: 0.4536607265472412
train--29/100 [649/1090] loss: 0.44599978923797606
train--29/100 [659/1090] loss: 0.4510254919528961
train--29/100 [669/1090] loss: 0.4582463353872299
train--29/100 [679/1090] loss: 0.4504176825284958
train--29/100 [689/1090] loss: 0.44004984200000763
train--29/100 [699/1090] loss: 0.46243437826633454
train--29/100 [709/1090] loss: 0.46380371153354644
train--29/100 [719/1090] loss: 0.4450084775686264
train--29/100 [729/1090] loss: 0.4334862768650055
train--29/100 [739/1090] loss: 0.45761272609233855
train--29/100 [749/1090] loss: 0.47444418668746946
train--29/100 [759/1090] loss: 0.45614237189292905
train--29/100 [769/1090] loss: 0.4693571388721466
train--29/100 [779/1090] loss: 0.45215791165828706
train--29/100 [789/1090] loss: 0.44382333755493164
train--29/100 [799/1090] loss: 0.42786464691162107
train--29/100 [809/1090] loss: 0.4363215774297714
train--29/100 [819/1090] loss: 0.4473862648010254
train--29/100 [829/1090] loss: 0.4658267587423325
train--29/100 [839/1090] loss: 0.464337095618248
train--29/100 [849/1090] loss: 0.4504969000816345
train--29/100 [859/1090] loss: 0.4500779002904892
train--29/100 [869/1090] loss: 0.4479624629020691
train--29/100 [879/1090] loss: 0.4503786116838455
train--29/100 [889/1090] loss: 0.4396758109331131
train--29/100 [899/1090] loss: 0.4578548014163971
train--29/100 [909/1090] loss: 0.44192142486572267
train--29/100 [919/1090] loss: 0.45358623266220094
train--29/100 [929/1090] loss: 0.4471408039331436
train--29/100 [939/1090] loss: 0.48271992802619934
train--29/100 [949/1090] loss: 0.4474155604839325
train--29/100 [959/1090] loss: 0.4506161093711853
train--29/100 [969/1090] loss: 0.4455068498849869
train--29/100 [979/1090] loss: 0.4704985022544861
train--29/100 [989/1090] loss: 0.431368488073349
train--29/100 [999/1090] loss: 0.44016089737415315
train--29/100 [1009/1090] loss: 0.44817044734954836
train--29/100 [1019/1090] loss: 0.4692770838737488
train--29/100 [1029/1090] loss: 0.4437029451131821
train--29/100 [1039/1090] loss: 0.44545498192310334
train--29/100 [1049/1090] loss: 0.4649721086025238
train--29/100 [1059/1090] loss: 0.4391385018825531
train--29/100 [1069/1090] loss: 0.4478739589452744
train--29/100 [1079/1090] loss: 0.4488396465778351
train--29/100 [1089/1090] loss: 0.4483001857995987
predicting model...
val--29/100 [10/1090] acc: 0.790625
val--29/100 [20/1090] acc: 0.7916015625
val--29/100 [30/1090] acc: 0.7916666666666666
val--29/100 [40/1090] acc: 0.7921875
val--29/100 [50/1090] acc: 0.79125
val--29/100 [60/1090] acc: 0.7903645833333334
val--29/100 [70/1090] acc: 0.791015625
val--29/100 [80/1090] acc: 0.789697265625
val--29/100 [90/1090] acc: 0.790234375
val--29/100 [100/1090] acc: 0.7915234375
val--29/100 [110/1090] acc: 0.7914772727272728
val--29/100 [120/1090] acc: 0.7908854166666667
val--29/100 [130/1090] acc: 0.7916766826923077
val--29/100 [140/1090] acc: 0.7917689732142857
val--29/100 [150/1090] acc: 0.7918229166666667
val--29/100 [160/1090] acc: 0.7921875
val--29/100 [170/1090] acc: 0.7923483455882353
val--29/100 [180/1090] acc: 0.7919487847222222
val--29/100 [190/1090] acc: 0.7928453947368421
val--29/100 [200/1090] acc: 0.79310546875
val--29/100 [210/1090] acc: 0.7935081845238096
val--29/100 [220/1090] acc: 0.7925426136363637
val--29/100 [230/1090] acc: 0.7933254076086956
val--29/100 [240/1090] acc: 0.7931966145833333
val--29/100 [250/1090] acc: 0.793421875
val--29/100 [260/1090] acc: 0.7934194711538461
val--29/100 [270/1090] acc: 0.793677662037037
val--29/100 [280/1090] acc: 0.7935825892857142
val--29/100 [290/1090] acc: 0.7934401939655172
val--29/100 [300/1090] acc: 0.7934375
val--29/100 [310/1090] acc: 0.7930317540322581
val--29/100 [320/1090] acc: 0.793310546875
val--29/100 [330/1090] acc: 0.7935724431818182
val--29/100 [340/1090] acc: 0.7936695772058824
val--29/100 [350/1090] acc: 0.7938616071428571
val--29/100 [360/1090] acc: 0.7937608506944445
val--29/100 [370/1090] acc: 0.7938555743243243
val--29/100 [380/1090] acc: 0.7938630756578947
val--29/100 [390/1090] acc: 0.7935697115384616
val--29/100 [400/1090] acc: 0.7935546875
val--29/100 [410/1090] acc: 0.7937404725609756
val--29/100 [420/1090] acc: 0.7937686011904762
val--29/100 [430/1090] acc: 0.7936500726744186
val--29/100 [440/1090] acc: 0.7937056107954545
val--29/100 [450/1090] acc: 0.7935329861111111
val--29/100 [460/1090] acc: 0.793452785326087
val--29/100 [470/1090] acc: 0.793359375
val--29/100 [480/1090] acc: 0.7933919270833333
val--29/100 [490/1090] acc: 0.7935427295918367
val--29/100 [500/1090] acc: 0.7937109375
val--29/100 [510/1090] acc: 0.7936197916666666
val--29/100 [520/1090] acc: 0.7938551682692307
val--29/100 [530/1090] acc: 0.7938237028301887
val--29/100 [540/1090] acc: 0.7939670138888889
val--29/100 [550/1090] acc: 0.7938423295454545
val--29/100 [560/1090] acc: 0.793701171875
val--29/100 [570/1090] acc: 0.7934484649122807
val--29/100 [580/1090] acc: 0.7934401939655172
val--29/100 [590/1090] acc: 0.7934189618644067
val--29/100 [600/1090] acc: 0.79341796875
val--29/100 [610/1090] acc: 0.7933529713114754
val--29/100 [620/1090] acc: 0.7931766633064516
val--29/100 [630/1090] acc: 0.7933965773809524
val--29/100 [640/1090] acc: 0.7935791015625
val--29/100 [650/1090] acc: 0.7935997596153846
val--29/100 [660/1090] acc: 0.7935132575757575
val--29/100 [670/1090] acc: 0.793242770522388
val--29/100 [680/1090] acc: 0.7931755514705883
val--29/100 [690/1090] acc: 0.793365036231884
val--29/100 [700/1090] acc: 0.7933091517857143
val--29/100 [710/1090] acc: 0.793084286971831
val--29/100 [720/1090] acc: 0.792919921875
val--29/100 [730/1090] acc: 0.7928724315068493
val--29/100 [740/1090] acc: 0.7927998310810811
val--29/100 [750/1090] acc: 0.7928645833333333
val--29/100 [760/1090] acc: 0.7929584703947369
val--29/100 [770/1090] acc: 0.7929180194805194
val--29/100 [780/1090] acc: 0.7928635817307692
val--29/100 [790/1090] acc: 0.7929143591772152
val--29/100 [800/1090] acc: 0.7931201171875
val--29/100 [810/1090] acc: 0.7932050540123456
val--29/100 [820/1090] acc: 0.7933165015243903
val--29/100 [830/1090] acc: 0.7934111445783133
val--29/100 [840/1090] acc: 0.7933314732142858
val--29/100 [850/1090] acc: 0.7933134191176471
val--29/100 [860/1090] acc: 0.7935728561046511
val--29/100 [870/1090] acc: 0.7934536637931034
val--29/100 [880/1090] acc: 0.793408203125
val--29/100 [890/1090] acc: 0.7935568820224719
val--29/100 [900/1090] acc: 0.7935763888888889
val--29/100 [910/1090] acc: 0.7935740041208791
val--29/100 [920/1090] acc: 0.7936226222826087
val--29/100 [930/1090] acc: 0.7936995967741935
val--29/100 [940/1090] acc: 0.793716755319149
val--29/100 [950/1090] acc: 0.7936266447368421
val--29/100 [960/1090] acc: 0.7936075846354167
val--29/100 [970/1090] acc: 0.7935768363402061
val--29/100 [980/1090] acc: 0.7935786033163266
val--29/100 [990/1090] acc: 0.7935053661616162
val--29/100 [1000/1090] acc: 0.79337890625
val--29/100 [1010/1090] acc: 0.793251082920792
val--29/100 [1020/1090] acc: 0.793344056372549
val--29/100 [1030/1090] acc: 0.7934086771844661
val--29/100 [1040/1090] acc: 0.7933931790865385
val--29/100 [1050/1090] acc: 0.7934672619047619
val--29/100 [1060/1090] acc: 0.7934072818396226
val--29/100 [1070/1090] acc: 0.7934177862149533
val--29/100 [1080/1090] acc: 0.7933521412037037
val--29/100 [1090/1090] acc: 0.7932016915137615
epoch= 29, accuracy= 0.793202, rmse= 0.378826, auc= 0.854361
train--30/100 [9/1090] loss: 0.4054747670888901
train--30/100 [19/1090] loss: 0.4547682225704193
train--30/100 [29/1090] loss: 0.4381727993488312
train--30/100 [39/1090] loss: 0.4387019008398056
train--30/100 [49/1090] loss: 0.4606620281934738
train--30/100 [59/1090] loss: 0.43185360431671144
train--30/100 [69/1090] loss: 0.4488945245742798
train--30/100 [79/1090] loss: 0.446885347366333
train--30/100 [89/1090] loss: 0.43254904448986053
train--30/100 [99/1090] loss: 0.43518862724304197
train--30/100 [109/1090] loss: 0.45437008142471313
train--30/100 [119/1090] loss: 0.440848371386528
train--30/100 [129/1090] loss: 0.4397400259971619
train--30/100 [139/1090] loss: 0.43798507153987887
train--30/100 [149/1090] loss: 0.43630482256412506
train--30/100 [159/1090] loss: 0.4453094869852066
train--30/100 [169/1090] loss: 0.43564614057540896
train--30/100 [179/1090] loss: 0.4511764943599701
train--30/100 [189/1090] loss: 0.4508479505777359
train--30/100 [199/1090] loss: 0.44236328899860383
train--30/100 [209/1090] loss: 0.4532943665981293
train--30/100 [219/1090] loss: 0.4416885733604431
train--30/100 [229/1090] loss: 0.46538639068603516
train--30/100 [239/1090] loss: 0.44833748042583466
train--30/100 [249/1090] loss: 0.43457152843475344
train--30/100 [259/1090] loss: 0.4448111534118652
train--30/100 [269/1090] loss: 0.43887061178684234
train--30/100 [279/1090] loss: 0.4359664887189865
train--30/100 [289/1090] loss: 0.437411230802536
train--30/100 [299/1090] loss: 0.452309912443161
train--30/100 [309/1090] loss: 0.43301245868206023
train--30/100 [319/1090] loss: 0.4458466976881027
train--30/100 [329/1090] loss: 0.42866546511650083
train--30/100 [339/1090] loss: 0.48152811229228976
train--30/100 [349/1090] loss: 0.43910517990589143
train--30/100 [359/1090] loss: 0.4481537342071533
train--30/100 [369/1090] loss: 0.4431347638368607
train--30/100 [379/1090] loss: 0.43241346180438994
train--30/100 [389/1090] loss: 0.4635139375925064
train--30/100 [399/1090] loss: 0.46277823150157926
train--30/100 [409/1090] loss: 0.46191284358501433
train--30/100 [419/1090] loss: 0.45198726952075957
train--30/100 [429/1090] loss: 0.44315178990364074
train--30/100 [439/1090] loss: 0.45230998992919924
train--30/100 [449/1090] loss: 0.44915143549442293
train--30/100 [459/1090] loss: 0.46102877557277677
train--30/100 [469/1090] loss: 0.4544171005487442
train--30/100 [479/1090] loss: 0.43700292706489563
train--30/100 [489/1090] loss: 0.44728386402130127
train--30/100 [499/1090] loss: 0.4501053512096405
train--30/100 [509/1090] loss: 0.438328418135643
train--30/100 [519/1090] loss: 0.4407031536102295
train--30/100 [529/1090] loss: 0.44309147298336027
train--30/100 [539/1090] loss: 0.45437649786472323
train--30/100 [549/1090] loss: 0.4617304623126984
train--30/100 [559/1090] loss: 0.45504955649375917
train--30/100 [569/1090] loss: 0.4593907117843628
train--30/100 [579/1090] loss: 0.4481242895126343
train--30/100 [589/1090] loss: 0.438904681801796
train--30/100 [599/1090] loss: 0.44970986247062683
train--30/100 [609/1090] loss: 0.4470004439353943
train--30/100 [619/1090] loss: 0.43496777713298795
train--30/100 [629/1090] loss: 0.4447218060493469
train--30/100 [639/1090] loss: 0.44386880099773407
train--30/100 [649/1090] loss: 0.450669065117836
train--30/100 [659/1090] loss: 0.4436591535806656
train--30/100 [669/1090] loss: 0.4480952501296997
train--30/100 [679/1090] loss: 0.4477594643831253
train--30/100 [689/1090] loss: 0.45276356637477877
train--30/100 [699/1090] loss: 0.4719738781452179
train--30/100 [709/1090] loss: 0.4424555391073227
train--30/100 [719/1090] loss: 0.4405915379524231
train--30/100 [729/1090] loss: 0.45303701758384707
train--30/100 [739/1090] loss: 0.44923965632915497
train--30/100 [749/1090] loss: 0.4630432933568954
train--30/100 [759/1090] loss: 0.4591618269681931
train--30/100 [769/1090] loss: 0.43331165313720704
train--30/100 [779/1090] loss: 0.4424580127000809
train--30/100 [789/1090] loss: 0.43632685840129853
train--30/100 [799/1090] loss: 0.4519744455814362
train--30/100 [809/1090] loss: 0.44945052862167356
train--30/100 [819/1090] loss: 0.45443484783172605
train--30/100 [829/1090] loss: 0.45823602080345155
train--30/100 [839/1090] loss: 0.44813748598098757
train--30/100 [849/1090] loss: 0.44124798774719237
train--30/100 [859/1090] loss: 0.45118514001369475
train--30/100 [869/1090] loss: 0.43809789717197417
train--30/100 [879/1090] loss: 0.453228297829628
train--30/100 [889/1090] loss: 0.4291818797588348
train--30/100 [899/1090] loss: 0.4397860407829285
train--30/100 [909/1090] loss: 0.4342637896537781
train--30/100 [919/1090] loss: 0.4426912486553192
train--30/100 [929/1090] loss: 0.45137143433094024
train--30/100 [939/1090] loss: 0.44848839938640594
train--30/100 [949/1090] loss: 0.46551826894283294
train--30/100 [959/1090] loss: 0.43807992339134216
train--30/100 [969/1090] loss: 0.4573046028614044
train--30/100 [979/1090] loss: 0.4381479561328888
train--30/100 [989/1090] loss: 0.4637692242860794
train--30/100 [999/1090] loss: 0.44991169571876527
train--30/100 [1009/1090] loss: 0.4615641236305237
train--30/100 [1019/1090] loss: 0.46050882041454316
train--30/100 [1029/1090] loss: 0.4486312806606293
train--30/100 [1039/1090] loss: 0.4570795327425003
train--30/100 [1049/1090] loss: 0.4546669840812683
train--30/100 [1059/1090] loss: 0.45379439890384676
train--30/100 [1069/1090] loss: 0.46764396131038666
train--30/100 [1079/1090] loss: 0.4414135605096817
train--30/100 [1089/1090] loss: 0.4551674246788025
predicting model...
val--30/100 [10/1090] acc: 0.79375
val--30/100 [20/1090] acc: 0.7943359375
val--30/100 [30/1090] acc: 0.7940104166666667
val--30/100 [40/1090] acc: 0.79345703125
val--30/100 [50/1090] acc: 0.792265625
val--30/100 [60/1090] acc: 0.7908854166666667
val--30/100 [70/1090] acc: 0.7915736607142857
val--30/100 [80/1090] acc: 0.79052734375
val--30/100 [90/1090] acc: 0.791015625
val--30/100 [100/1090] acc: 0.79203125
val--30/100 [110/1090] acc: 0.7921519886363636
val--30/100 [120/1090] acc: 0.7918294270833334
val--30/100 [130/1090] acc: 0.7926081730769231
val--30/100 [140/1090] acc: 0.7926897321428571
val--30/100 [150/1090] acc: 0.79265625
val--30/100 [160/1090] acc: 0.7929931640625
val--30/100 [170/1090] acc: 0.7929917279411764
val--30/100 [180/1090] acc: 0.7926649305555555
val--30/100 [190/1090] acc: 0.7935238486842106
val--30/100 [200/1090] acc: 0.79392578125
val--30/100 [210/1090] acc: 0.7942522321428571
val--30/100 [220/1090] acc: 0.793359375
val--30/100 [230/1090] acc: 0.794038722826087
val--30/100 [240/1090] acc: 0.7938802083333333
val--30/100 [250/1090] acc: 0.794078125
val--30/100 [260/1090] acc: 0.7940955528846154
val--30/100 [270/1090] acc: 0.794285300925926
val--30/100 [280/1090] acc: 0.79423828125
val--30/100 [290/1090] acc: 0.794005926724138
val--30/100 [300/1090] acc: 0.7940755208333333
val--30/100 [310/1090] acc: 0.7938382056451613
val--30/100 [320/1090] acc: 0.794091796875
val--30/100 [330/1090] acc: 0.7943655303030303
val--30/100 [340/1090] acc: 0.7945082720588236
val--30/100 [350/1090] acc: 0.7946316964285715
val--30/100 [360/1090] acc: 0.7945638020833333
val--30/100 [370/1090] acc: 0.7947001689189189
val--30/100 [380/1090] acc: 0.7946443256578948
val--30/100 [390/1090] acc: 0.7944010416666667
val--30/100 [400/1090] acc: 0.794267578125
val--30/100 [410/1090] acc: 0.794483612804878
val--30/100 [420/1090] acc: 0.7944754464285714
val--30/100 [430/1090] acc: 0.7943404796511628
val--30/100 [440/1090] acc: 0.7943980823863637
val--30/100 [450/1090] acc: 0.79421875
val--30/100 [460/1090] acc: 0.794140625
val--30/100 [470/1090] acc: 0.7940408909574468
val--30/100 [480/1090] acc: 0.7940755208333333
val--30/100 [490/1090] acc: 0.7942203443877551
val--30/100 [500/1090] acc: 0.794390625
val--30/100 [510/1090] acc: 0.7943014705882353
val--30/100 [520/1090] acc: 0.7944786658653846
val--30/100 [530/1090] acc: 0.7944428066037735
val--30/100 [540/1090] acc: 0.7946035879629629
val--30/100 [550/1090] acc: 0.7945170454545455
val--30/100 [560/1090] acc: 0.7943568638392857
val--30/100 [570/1090] acc: 0.7940926535087719
val--30/100 [580/1090] acc: 0.7940934806034483
val--30/100 [590/1090] acc: 0.794186970338983
val--30/100 [600/1090] acc: 0.7942122395833333
val--30/100 [610/1090] acc: 0.7940957991803279
val--30/100 [620/1090] acc: 0.7940083165322581
val--30/100 [630/1090] acc: 0.7942212301587301
val--30/100 [640/1090] acc: 0.79439697265625
val--30/100 [650/1090] acc: 0.7943990384615385
val--30/100 [660/1090] acc: 0.7942589962121213
val--30/100 [670/1090] acc: 0.7939598880597015
val--30/100 [680/1090] acc: 0.7938763786764705
val--30/100 [690/1090] acc: 0.794033061594203
val--30/100 [700/1090] acc: 0.7940513392857143
val--30/100 [710/1090] acc: 0.7938160211267605
val--30/100 [720/1090] acc: 0.7936686197916667
val--30/100 [730/1090] acc: 0.793626926369863
val--30/100 [740/1090] acc: 0.7935335726351351
val--30/100 [750/1090] acc: 0.7935885416666667
val--30/100 [760/1090] acc: 0.7936831825657895
val--30/100 [770/1090] acc: 0.7936941964285714
val--30/100 [780/1090] acc: 0.7936748798076924
val--30/100 [790/1090] acc: 0.7937401107594937
val--30/100 [800/1090] acc: 0.793974609375
val--30/100 [810/1090] acc: 0.7940393518518518
val--30/100 [820/1090] acc: 0.794116806402439
val--30/100 [830/1090] acc: 0.7942018072289156
val--30/100 [840/1090] acc: 0.794135974702381
val--30/100 [850/1090] acc: 0.7941360294117648
val--30/100 [860/1090] acc: 0.7943859011627907
val--30/100 [870/1090] acc: 0.7942663433908046
val--30/100 [880/1090] acc: 0.7942205255681818
val--30/100 [890/1090] acc: 0.794360077247191
val--30/100 [900/1090] acc: 0.7943663194444445
val--30/100 [910/1090] acc: 0.7943895947802198
val--30/100 [920/1090] acc: 0.7944166100543478
val--30/100 [930/1090] acc: 0.7944808467741935
val--30/100 [940/1090] acc: 0.7945021609042553
val--30/100 [950/1090] acc: 0.7944078947368421
val--30/100 [960/1090] acc: 0.7943074544270833
val--30/100 [970/1090] acc: 0.7943097615979381
val--30/100 [980/1090] acc: 0.794304049744898
val--30/100 [990/1090] acc: 0.7942392676767677
val--30/100 [1000/1090] acc: 0.794140625
val--30/100 [1010/1090] acc: 0.7940207301980198
val--30/100 [1020/1090] acc: 0.7940984987745098
val--30/100 [1030/1090] acc: 0.7941444174757282
val--30/100 [1040/1090] acc: 0.7941068209134615
val--30/100 [1050/1090] acc: 0.7941592261904762
val--30/100 [1060/1090] acc: 0.7941037735849057
val--30/100 [1070/1090] acc: 0.7941260221962617
val--30/100 [1080/1090] acc: 0.7940646701388889
val--30/100 [1090/1090] acc: 0.7939040997706422
epoch= 30, accuracy= 0.793904, rmse= 0.378676, auc= 0.854587
train--31/100 [9/1090] loss: 0.4005125015974045
train--31/100 [19/1090] loss: 0.44212793111801146
train--31/100 [29/1090] loss: 0.46201248168945314
train--31/100 [39/1090] loss: 0.44158912599086764
train--31/100 [49/1090] loss: 0.434657683968544
train--31/100 [59/1090] loss: 0.44347348213195803
train--31/100 [69/1090] loss: 0.45793922543525695
train--31/100 [79/1090] loss: 0.4503464251756668
train--31/100 [89/1090] loss: 0.4277331680059433
train--31/100 [99/1090] loss: 0.44392660558223723
train--31/100 [109/1090] loss: 0.4496842622756958
train--31/100 [119/1090] loss: 0.4247753322124481
train--31/100 [129/1090] loss: 0.4441671520471573
train--31/100 [139/1090] loss: 0.4446899712085724
train--31/100 [149/1090] loss: 0.44014506936073305
train--31/100 [159/1090] loss: 0.4399936556816101
train--31/100 [169/1090] loss: 0.44861547350883485
train--31/100 [179/1090] loss: 0.43310488760471344
train--31/100 [189/1090] loss: 0.44166635274887084
train--31/100 [199/1090] loss: 0.4530069470405579
train--31/100 [209/1090] loss: 0.4418180018663406
train--31/100 [219/1090] loss: 0.4429438889026642
train--31/100 [229/1090] loss: 0.43371089100837706
train--31/100 [239/1090] loss: 0.42496457397937776
train--31/100 [249/1090] loss: 0.4388905853033066
train--31/100 [259/1090] loss: 0.45789186656475067
train--31/100 [269/1090] loss: 0.45534846782684324
train--31/100 [279/1090] loss: 0.436148864030838
train--31/100 [289/1090] loss: 0.4485313564538956
train--31/100 [299/1090] loss: 0.45297113060951233
train--31/100 [309/1090] loss: 0.43391975164413454
train--31/100 [319/1090] loss: 0.4520731925964355
train--31/100 [329/1090] loss: 0.4426823228597641
train--31/100 [339/1090] loss: 0.456744322180748
train--31/100 [349/1090] loss: 0.4415776401758194
train--31/100 [359/1090] loss: 0.4642378896474838
train--31/100 [369/1090] loss: 0.41418718695640566
train--31/100 [379/1090] loss: 0.4260084480047226
train--31/100 [389/1090] loss: 0.45805807411670685
train--31/100 [399/1090] loss: 0.444127032160759
train--31/100 [409/1090] loss: 0.44449523091316223
train--31/100 [419/1090] loss: 0.4771424889564514
train--31/100 [429/1090] loss: 0.46207418739795686
train--31/100 [439/1090] loss: 0.4392713516950607
train--31/100 [449/1090] loss: 0.44493111968040466
train--31/100 [459/1090] loss: 0.44770489931106566
train--31/100 [469/1090] loss: 0.44622951149940493
train--31/100 [479/1090] loss: 0.4490367352962494
train--31/100 [489/1090] loss: 0.4588433295488358
train--31/100 [499/1090] loss: 0.45893183052539827
train--31/100 [509/1090] loss: 0.4479410707950592
train--31/100 [519/1090] loss: 0.44529313743114474
train--31/100 [529/1090] loss: 0.4529706001281738
train--31/100 [539/1090] loss: 0.44209719598293307
train--31/100 [549/1090] loss: 0.46319203078746796
train--31/100 [559/1090] loss: 0.43760002851486207
train--31/100 [569/1090] loss: 0.44495888948440554
train--31/100 [579/1090] loss: 0.43881853222846984
train--31/100 [589/1090] loss: 0.4541635632514954
train--31/100 [599/1090] loss: 0.47148061990737916
train--31/100 [609/1090] loss: 0.44961021840572357
train--31/100 [619/1090] loss: 0.44509429633617403
train--31/100 [629/1090] loss: 0.45961550176143645
train--31/100 [639/1090] loss: 0.4543945252895355
train--31/100 [649/1090] loss: 0.4405471533536911
train--31/100 [659/1090] loss: 0.4587841957807541
train--31/100 [669/1090] loss: 0.44370058476924895
train--31/100 [679/1090] loss: 0.4630196005105972
train--31/100 [689/1090] loss: 0.45023661851882935
train--31/100 [699/1090] loss: 0.4504327714443207
train--31/100 [709/1090] loss: 0.43950462639331817
train--31/100 [719/1090] loss: 0.4400065243244171
train--31/100 [729/1090] loss: 0.43954735398292544
train--31/100 [739/1090] loss: 0.46414702832698823
train--31/100 [749/1090] loss: 0.457964152097702
train--31/100 [759/1090] loss: 0.4369826287031174
train--31/100 [769/1090] loss: 0.43901072442531586
train--31/100 [779/1090] loss: 0.4432227939367294
train--31/100 [789/1090] loss: 0.4345680564641953
train--31/100 [799/1090] loss: 0.4593504071235657
train--31/100 [809/1090] loss: 0.42835468947887423
train--31/100 [819/1090] loss: 0.4537991017103195
train--31/100 [829/1090] loss: 0.4520742803812027
train--31/100 [839/1090] loss: 0.45926296412944795
train--31/100 [849/1090] loss: 0.4443901300430298
train--31/100 [859/1090] loss: 0.47317807376384735
train--31/100 [869/1090] loss: 0.4405741482973099
train--31/100 [879/1090] loss: 0.45076222717761993
train--31/100 [889/1090] loss: 0.4389188289642334
train--31/100 [899/1090] loss: 0.4737002342939377
train--31/100 [909/1090] loss: 0.45400797128677367
train--31/100 [919/1090] loss: 0.4617037087678909
train--31/100 [929/1090] loss: 0.44136751890182496
train--31/100 [939/1090] loss: 0.44632679522037505
train--31/100 [949/1090] loss: 0.4499401330947876
train--31/100 [959/1090] loss: 0.4368507444858551
train--31/100 [969/1090] loss: 0.43606380224227903
train--31/100 [979/1090] loss: 0.45557290613651275
train--31/100 [989/1090] loss: 0.46639678478240965
train--31/100 [999/1090] loss: 0.4468589544296265
train--31/100 [1009/1090] loss: 0.45688939094543457
train--31/100 [1019/1090] loss: 0.4613859444856644
train--31/100 [1029/1090] loss: 0.4522035151720047
train--31/100 [1039/1090] loss: 0.4583420008420944
train--31/100 [1049/1090] loss: 0.4613204896450043
train--31/100 [1059/1090] loss: 0.4386703222990036
train--31/100 [1069/1090] loss: 0.4418875902891159
train--31/100 [1079/1090] loss: 0.4298575550317764
train--31/100 [1089/1090] loss: 0.456977504491806
predicting model...
val--31/100 [10/1090] acc: 0.792578125
val--31/100 [20/1090] acc: 0.7939453125
val--31/100 [30/1090] acc: 0.7944010416666667
val--31/100 [40/1090] acc: 0.794140625
val--31/100 [50/1090] acc: 0.79328125
val--31/100 [60/1090] acc: 0.7919270833333333
val--31/100 [70/1090] acc: 0.7923549107142858
val--31/100 [80/1090] acc: 0.791162109375
val--31/100 [90/1090] acc: 0.7915798611111111
val--31/100 [100/1090] acc: 0.7927734375
val--31/100 [110/1090] acc: 0.7927201704545455
val--31/100 [120/1090] acc: 0.7921875
val--31/100 [130/1090] acc: 0.7930588942307693
val--31/100 [140/1090] acc: 0.7931640625
val--31/100 [150/1090] acc: 0.79328125
val--31/100 [160/1090] acc: 0.7935302734375
val--31/100 [170/1090] acc: 0.7936580882352942
val--31/100 [180/1090] acc: 0.7932942708333334
val--31/100 [190/1090] acc: 0.7941200657894737
val--31/100 [200/1090] acc: 0.79439453125
val--31/100 [210/1090] acc: 0.7946614583333333
val--31/100 [220/1090] acc: 0.7938210227272727
val--31/100 [230/1090] acc: 0.7945142663043478
val--31/100 [240/1090] acc: 0.7943033854166667
val--31/100 [250/1090] acc: 0.794515625
val--31/100 [260/1090] acc: 0.7945612980769231
val--31/100 [270/1090] acc: 0.7947771990740741
val--31/100 [280/1090] acc: 0.7946847098214286
val--31/100 [290/1090] acc: 0.7945177801724138
val--31/100 [300/1090] acc: 0.7945442708333333
val--31/100 [310/1090] acc: 0.7941532258064516
val--31/100 [320/1090] acc: 0.79437255859375
val--31/100 [330/1090] acc: 0.7946614583333333
val--31/100 [340/1090] acc: 0.7948069852941176
val--31/100 [350/1090] acc: 0.7948660714285715
val--31/100 [360/1090] acc: 0.7948459201388889
val--31/100 [370/1090] acc: 0.7949746621621622
val--31/100 [380/1090] acc: 0.7949629934210526
val--31/100 [390/1090] acc: 0.7946714743589743
val--31/100 [400/1090] acc: 0.79458984375
val--31/100 [410/1090] acc: 0.7947980182926829
val--31/100 [420/1090] acc: 0.794819568452381
val--31/100 [430/1090] acc: 0.7947129360465116
val--31/100 [440/1090] acc: 0.7947887073863636
val--31/100 [450/1090] acc: 0.7946267361111111
val--31/100 [460/1090] acc: 0.79453125
val--31/100 [470/1090] acc: 0.7944148936170212
val--31/100 [480/1090] acc: 0.7944742838541666
val--31/100 [490/1090] acc: 0.7945870535714286
val--31/100 [500/1090] acc: 0.79478125
val--31/100 [510/1090] acc: 0.7946308210784314
val--31/100 [520/1090] acc: 0.79482421875
val--31/100 [530/1090] acc: 0.7948039504716982
val--31/100 [540/1090] acc: 0.7949291087962963
val--31/100 [550/1090] acc: 0.7948082386363636
val--31/100 [560/1090] acc: 0.7946498325892857
val--31/100 [570/1090] acc: 0.7944147478070176
val--31/100 [580/1090] acc: 0.7943898168103448
val--31/100 [590/1090] acc: 0.7944054555084745
val--31/100 [600/1090] acc: 0.794375
val--31/100 [610/1090] acc: 0.7942558913934427
val--31/100 [620/1090] acc: 0.7941469254032258
val--31/100 [630/1090] acc: 0.7943700396825397
val--31/100 [640/1090] acc: 0.79456787109375
val--31/100 [650/1090] acc: 0.794579326923077
val--31/100 [660/1090] acc: 0.7944779829545454
val--31/100 [670/1090] acc: 0.7941814365671642
val--31/100 [680/1090] acc: 0.794094669117647
val--31/100 [690/1090] acc: 0.7942538496376812
val--31/100 [700/1090] acc: 0.7942466517857143
val--31/100 [710/1090] acc: 0.794052596830986
val--31/100 [720/1090] acc: 0.7939019097222222
val--31/100 [730/1090] acc: 0.7938623715753425
val--31/100 [740/1090] acc: 0.7937816722972973
val--31/100 [750/1090] acc: 0.7938645833333333
val--31/100 [760/1090] acc: 0.7939453125
val--31/100 [770/1090] acc: 0.7939174107142857
val--31/100 [780/1090] acc: 0.7939052483974359
val--31/100 [790/1090] acc: 0.7939675632911393
val--31/100 [800/1090] acc: 0.79416015625
val--31/100 [810/1090] acc: 0.794212962962963
val--31/100 [820/1090] acc: 0.7942978277439025
val--31/100 [830/1090] acc: 0.7943618222891566
val--31/100 [840/1090] acc: 0.7943033854166667
val--31/100 [850/1090] acc: 0.7943336397058823
val--31/100 [860/1090] acc: 0.7945267078488372
val--31/100 [870/1090] acc: 0.7943785919540229
val--31/100 [880/1090] acc: 0.7943536931818181
val--31/100 [890/1090] acc: 0.7945049157303371
val--31/100 [900/1090] acc: 0.7945008680555555
val--31/100 [910/1090] acc: 0.7945054945054945
val--31/100 [920/1090] acc: 0.79453125
val--31/100 [930/1090] acc: 0.7945984543010752
val--31/100 [940/1090] acc: 0.7946268284574468
val--31/100 [950/1090] acc: 0.7945148026315789
val--31/100 [960/1090] acc: 0.7944376627604167
val--31/100 [970/1090] acc: 0.7944144652061855
val--31/100 [980/1090] acc: 0.7944236288265306
val--31/100 [990/1090] acc: 0.7943458017676768
val--31/100 [1000/1090] acc: 0.79425390625
val--31/100 [1010/1090] acc: 0.7941058168316831
val--31/100 [1020/1090] acc: 0.7941865808823529
val--31/100 [1030/1090] acc: 0.794261984223301
val--31/100 [1040/1090] acc: 0.7942307692307692
val--31/100 [1050/1090] acc: 0.794296875
val--31/100 [1060/1090] acc: 0.794225383254717
val--31/100 [1070/1090] acc: 0.7942318925233645
val--31/100 [1080/1090] acc: 0.794165943287037
val--31/100 [1090/1090] acc: 0.7940151949541284
epoch= 31, accuracy= 0.794015, rmse= 0.378687, auc= 0.854490
train--32/100 [9/1090] loss: 0.40223451554775236
train--32/100 [19/1090] loss: 0.4425325125455856
train--32/100 [29/1090] loss: 0.4567242592573166
train--32/100 [39/1090] loss: 0.45310899913311004
train--32/100 [49/1090] loss: 0.43867730498313906
train--32/100 [59/1090] loss: 0.4573182463645935
train--32/100 [69/1090] loss: 0.4410326063632965
train--32/100 [79/1090] loss: 0.4530444025993347
train--32/100 [89/1090] loss: 0.4447339981794357
train--32/100 [99/1090] loss: 0.45218818783760073
train--32/100 [109/1090] loss: 0.4382843941450119
train--32/100 [119/1090] loss: 0.4481077343225479
train--32/100 [129/1090] loss: 0.4416161447763443
train--32/100 [139/1090] loss: 0.4538335680961609
train--32/100 [149/1090] loss: 0.4502640932798386
train--32/100 [159/1090] loss: 0.45096527338027953
train--32/100 [169/1090] loss: 0.4388089507818222
train--32/100 [179/1090] loss: 0.4479219764471054
train--32/100 [189/1090] loss: 0.43858094811439513
train--32/100 [199/1090] loss: 0.4320549428462982
train--32/100 [209/1090] loss: 0.46605141162872316
train--32/100 [219/1090] loss: 0.44735167622566224
train--32/100 [229/1090] loss: 0.4389872521162033
train--32/100 [239/1090] loss: 0.4332540899515152
train--32/100 [249/1090] loss: 0.44376581013202665
train--32/100 [259/1090] loss: 0.44427967369556426
train--32/100 [269/1090] loss: 0.4508216917514801
train--32/100 [279/1090] loss: 0.4498951852321625
train--32/100 [289/1090] loss: 0.43635667860507965
train--32/100 [299/1090] loss: 0.4653490424156189
train--32/100 [309/1090] loss: 0.435199910402298
train--32/100 [319/1090] loss: 0.44059959053993225
train--32/100 [329/1090] loss: 0.4366439253091812
train--32/100 [339/1090] loss: 0.44094241559505465
train--32/100 [349/1090] loss: 0.4283205568790436
train--32/100 [359/1090] loss: 0.4540532797574997
train--32/100 [369/1090] loss: 0.44461465775966647
train--32/100 [379/1090] loss: 0.4338549554347992
train--32/100 [389/1090] loss: 0.45112721621990204
train--32/100 [399/1090] loss: 0.44336897432804107
train--32/100 [409/1090] loss: 0.4522951304912567
train--32/100 [419/1090] loss: 0.46695250272750854
train--32/100 [429/1090] loss: 0.4531967878341675
train--32/100 [439/1090] loss: 0.451469412446022
train--32/100 [449/1090] loss: 0.4338735699653625
train--32/100 [459/1090] loss: 0.4496972650289536
train--32/100 [469/1090] loss: 0.43968364894390105
train--32/100 [479/1090] loss: 0.46566269397735593
train--32/100 [489/1090] loss: 0.4331238329410553
train--32/100 [499/1090] loss: 0.4400066524744034
train--32/100 [509/1090] loss: 0.4500405967235565
train--32/100 [519/1090] loss: 0.4307982802391052
train--32/100 [529/1090] loss: 0.4396195739507675
train--32/100 [539/1090] loss: 0.46071513891220095
train--32/100 [549/1090] loss: 0.4623998552560806
train--32/100 [559/1090] loss: 0.44247935712337494
train--32/100 [569/1090] loss: 0.4516929030418396
train--32/100 [579/1090] loss: 0.42980996072292327
train--32/100 [589/1090] loss: 0.4425922423601151
train--32/100 [599/1090] loss: 0.45451684296131134
train--32/100 [609/1090] loss: 0.44296811819076537
train--32/100 [619/1090] loss: 0.4498878687620163
train--32/100 [629/1090] loss: 0.43412422835826875
train--32/100 [639/1090] loss: 0.4441828280687332
train--32/100 [649/1090] loss: 0.4411700814962387
train--32/100 [659/1090] loss: 0.44191886484622955
train--32/100 [669/1090] loss: 0.4523349434137344
train--32/100 [679/1090] loss: 0.4415632843971252
train--32/100 [689/1090] loss: 0.4625684887170792
train--32/100 [699/1090] loss: 0.4411246359348297
train--32/100 [709/1090] loss: 0.44996899366378784
train--32/100 [719/1090] loss: 0.4552546709775925
train--32/100 [729/1090] loss: 0.4457861363887787
train--32/100 [739/1090] loss: 0.45083244144916534
train--32/100 [749/1090] loss: 0.4534051388502121
train--32/100 [759/1090] loss: 0.4449927806854248
train--32/100 [769/1090] loss: 0.44794511795043945
train--32/100 [779/1090] loss: 0.43820697367191314
train--32/100 [789/1090] loss: 0.464023357629776
train--32/100 [799/1090] loss: 0.43876676857471464
train--32/100 [809/1090] loss: 0.4427304983139038
train--32/100 [819/1090] loss: 0.451700821518898
train--32/100 [829/1090] loss: 0.45226729214191436
train--32/100 [839/1090] loss: 0.45560139417648315
train--32/100 [849/1090] loss: 0.44269223511219025
train--32/100 [859/1090] loss: 0.4728529006242752
train--32/100 [869/1090] loss: 0.4623943030834198
train--32/100 [879/1090] loss: 0.46492773592472075
train--32/100 [889/1090] loss: 0.43945578038692473
train--32/100 [899/1090] loss: 0.44113513827323914
train--32/100 [909/1090] loss: 0.46668686866760256
train--32/100 [919/1090] loss: 0.4570208966732025
train--32/100 [929/1090] loss: 0.44767766296863554
train--32/100 [939/1090] loss: 0.44796860218048096
train--32/100 [949/1090] loss: 0.4491123229265213
train--32/100 [959/1090] loss: 0.45227764546871185
train--32/100 [969/1090] loss: 0.46749100387096404
train--32/100 [979/1090] loss: 0.4563701540231705
train--32/100 [989/1090] loss: 0.43280206620693207
train--32/100 [999/1090] loss: 0.4367067515850067
train--32/100 [1009/1090] loss: 0.4592969000339508
train--32/100 [1019/1090] loss: 0.4463093489408493
train--32/100 [1029/1090] loss: 0.45473079979419706
train--32/100 [1039/1090] loss: 0.4261944055557251
train--32/100 [1049/1090] loss: 0.4632531702518463
train--32/100 [1059/1090] loss: 0.43207048177719115
train--32/100 [1069/1090] loss: 0.45593453049659727
train--32/100 [1079/1090] loss: 0.457589727640152
train--32/100 [1089/1090] loss: 0.45322164297103884
predicting model...
val--32/100 [10/1090] acc: 0.791796875
val--32/100 [20/1090] acc: 0.792578125
val--32/100 [30/1090] acc: 0.7919270833333333
val--32/100 [40/1090] acc: 0.7921875
val--32/100 [50/1090] acc: 0.7915625
val--32/100 [60/1090] acc: 0.790625
val--32/100 [70/1090] acc: 0.7915736607142857
val--32/100 [80/1090] acc: 0.790234375
val--32/100 [90/1090] acc: 0.7907552083333333
val--32/100 [100/1090] acc: 0.79203125
val--32/100 [110/1090] acc: 0.7923650568181818
val--32/100 [120/1090] acc: 0.7919921875
val--32/100 [130/1090] acc: 0.7929987980769231
val--32/100 [140/1090] acc: 0.7931640625
val--32/100 [150/1090] acc: 0.7933072916666667
val--32/100 [160/1090] acc: 0.7935302734375
val--32/100 [170/1090] acc: 0.7934742647058823
val--32/100 [180/1090] acc: 0.7930338541666667
val--32/100 [190/1090] acc: 0.7939144736842105
val--32/100 [200/1090] acc: 0.79408203125
val--32/100 [210/1090] acc: 0.7943824404761904
val--32/100 [220/1090] acc: 0.7935014204545454
val--32/100 [230/1090] acc: 0.7941576086956522
val--32/100 [240/1090] acc: 0.7939615885416667
val--32/100 [250/1090] acc: 0.79415625
val--32/100 [260/1090] acc: 0.7940354567307693
val--32/100 [270/1090] acc: 0.7942997685185185
val--32/100 [280/1090] acc: 0.7942243303571429
val--32/100 [290/1090] acc: 0.7941540948275863
val--32/100 [300/1090] acc: 0.7941796875
val--32/100 [310/1090] acc: 0.7938130040322581
val--32/100 [320/1090] acc: 0.79400634765625
val--32/100 [330/1090] acc: 0.7942234848484848
val--32/100 [340/1090] acc: 0.7943704044117647
val--32/100 [350/1090] acc: 0.7945535714285714
val--32/100 [360/1090] acc: 0.7944878472222222
val--32/100 [370/1090] acc: 0.7945945945945946
val--32/100 [380/1090] acc: 0.7946032072368421
val--32/100 [390/1090] acc: 0.7944010416666667
val--32/100 [400/1090] acc: 0.79427734375
val--32/100 [410/1090] acc: 0.7945407774390244
val--32/100 [420/1090] acc: 0.7945591517857142
val--32/100 [430/1090] acc: 0.7943859011627907
val--32/100 [440/1090] acc: 0.7944158380681818
val--32/100 [450/1090] acc: 0.7942621527777778
val--32/100 [460/1090] acc: 0.7941830842391304
val--32/100 [470/1090] acc: 0.7940741356382979
val--32/100 [480/1090] acc: 0.7941487630208334
val--32/100 [490/1090] acc: 0.7943000637755102
val--32/100 [500/1090] acc: 0.7945234375
val--32/100 [510/1090] acc: 0.7944087009803922
val--32/100 [520/1090] acc: 0.7945913461538462
val--32/100 [530/1090] acc: 0.7945902122641509
val--32/100 [540/1090] acc: 0.7947771990740741
val--32/100 [550/1090] acc: 0.7947017045454545
val--32/100 [560/1090] acc: 0.7945521763392858
val--32/100 [570/1090] acc: 0.794311951754386
val--32/100 [580/1090] acc: 0.7942820581896551
val--32/100 [590/1090] acc: 0.794332627118644
val--32/100 [600/1090] acc: 0.7943359375
val--32/100 [610/1090] acc: 0.7942238729508196
val--32/100 [620/1090] acc: 0.7940776209677419
val--32/100 [630/1090] acc: 0.7943204365079365
val--32/100 [640/1090] acc: 0.794500732421875
val--32/100 [650/1090] acc: 0.7945252403846154
val--32/100 [660/1090] acc: 0.7943714488636363
val--32/100 [670/1090] acc: 0.794053171641791
val--32/100 [680/1090] acc: 0.7939740349264706
val--32/100 [690/1090] acc: 0.7941293025362319
val--32/100 [700/1090] acc: 0.7941294642857143
val--32/100 [710/1090] acc: 0.7939315580985915
val--32/100 [720/1090] acc: 0.7937554253472222
val--32/100 [730/1090] acc: 0.7937232448630137
val--32/100 [740/1090] acc: 0.7935969172297297
val--32/100 [750/1090] acc: 0.7936458333333334
val--32/100 [760/1090] acc: 0.7937602796052632
val--32/100 [770/1090] acc: 0.7937601461038961
val--32/100 [780/1090] acc: 0.7937550080128205
val--32/100 [790/1090] acc: 0.7938241693037975
val--32/100 [800/1090] acc: 0.7940380859375
val--32/100 [810/1090] acc: 0.7940827546296296
val--32/100 [820/1090] acc: 0.7941787347560976
val--32/100 [830/1090] acc: 0.7942488704819277
val--32/100 [840/1090] acc: 0.7942010788690477
val--32/100 [850/1090] acc: 0.7942325367647058
val--32/100 [860/1090] acc: 0.7944722020348837
val--32/100 [870/1090] acc: 0.7942977729885058
val--32/100 [880/1090] acc: 0.7942515980113637
val--32/100 [890/1090] acc: 0.7943951896067416
val--32/100 [900/1090] acc: 0.7944270833333333
val--32/100 [910/1090] acc: 0.7944325206043956
val--32/100 [920/1090] acc: 0.7944718070652174
val--32/100 [930/1090] acc: 0.79453125
val--32/100 [940/1090] acc: 0.7945478723404256
val--32/100 [950/1090] acc: 0.7944654605263158
val--32/100 [960/1090] acc: 0.7944010416666667
val--32/100 [970/1090] acc: 0.7943661404639175
val--32/100 [980/1090] acc: 0.7943678252551021
val--32/100 [990/1090] acc: 0.7942708333333334
val--32/100 [1000/1090] acc: 0.7941796875
val--32/100 [1010/1090] acc: 0.7940400680693069
val--32/100 [1020/1090] acc: 0.7941023284313725
val--32/100 [1030/1090] acc: 0.7941482099514563
val--32/100 [1040/1090] acc: 0.7941180889423077
val--32/100 [1050/1090] acc: 0.7941592261904762
val--32/100 [1060/1090] acc: 0.7941185141509434
val--32/100 [1070/1090] acc: 0.7941260221962617
val--32/100 [1080/1090] acc: 0.7940502025462963
val--32/100 [1090/1090] acc: 0.7938969323394496
epoch= 32, accuracy= 0.793897, rmse= 0.378685, auc= 0.854519
train--33/100 [9/1090] loss: 0.3918605297803879
train--33/100 [19/1090] loss: 0.44123855531215667
train--33/100 [29/1090] loss: 0.44458727538585663
train--33/100 [39/1090] loss: 0.4470223069190979
train--33/100 [49/1090] loss: 0.44694429337978364
train--33/100 [59/1090] loss: 0.44083367586135863
train--33/100 [69/1090] loss: 0.44645269513130187
train--33/100 [79/1090] loss: 0.4381254851818085
train--33/100 [89/1090] loss: 0.4443507492542267
train--33/100 [99/1090] loss: 0.4482094496488571
train--33/100 [109/1090] loss: 0.43495217263698577
train--33/100 [119/1090] loss: 0.43154672980308534
train--33/100 [129/1090] loss: 0.4472039133310318
train--33/100 [139/1090] loss: 0.4616368800401688
train--33/100 [149/1090] loss: 0.4449495702981949
train--33/100 [159/1090] loss: 0.4512793391942978
train--33/100 [169/1090] loss: 0.4625454515218735
train--33/100 [179/1090] loss: 0.4455282956361771
train--33/100 [189/1090] loss: 0.4468606740236282
train--33/100 [199/1090] loss: 0.44292439222335817
train--33/100 [209/1090] loss: 0.42205106317996977
train--33/100 [219/1090] loss: 0.44749336540699003
train--33/100 [229/1090] loss: 0.4464069575071335
train--33/100 [239/1090] loss: 0.4477684646844864
train--33/100 [249/1090] loss: 0.44111700654029845
train--33/100 [259/1090] loss: 0.45297740399837494
train--33/100 [269/1090] loss: 0.44732626080513
train--33/100 [279/1090] loss: 0.4438803493976593
train--33/100 [289/1090] loss: 0.4303858906030655
train--33/100 [299/1090] loss: 0.45393225848674773
train--33/100 [309/1090] loss: 0.4588360756635666
train--33/100 [319/1090] loss: 0.4371855825185776
train--33/100 [329/1090] loss: 0.4346400111913681
train--33/100 [339/1090] loss: 0.44527268409729004
train--33/100 [349/1090] loss: 0.43758883476257326
train--33/100 [359/1090] loss: 0.4746770769357681
train--33/100 [369/1090] loss: 0.42891068756580353
train--33/100 [379/1090] loss: 0.4578329622745514
train--33/100 [389/1090] loss: 0.43739706575870513
train--33/100 [399/1090] loss: 0.45277594923973086
train--33/100 [409/1090] loss: 0.43606618642807005
train--33/100 [419/1090] loss: 0.43676181733608244
train--33/100 [429/1090] loss: 0.44921176731586454
train--33/100 [439/1090] loss: 0.44736561477184295
train--33/100 [449/1090] loss: 0.46382255256175997
train--33/100 [459/1090] loss: 0.4444508582353592
train--33/100 [469/1090] loss: 0.4699524611234665
train--33/100 [479/1090] loss: 0.4463495135307312
train--33/100 [489/1090] loss: 0.4542801260948181
train--33/100 [499/1090] loss: 0.45525040328502653
train--33/100 [509/1090] loss: 0.45654832422733305
train--33/100 [519/1090] loss: 0.4525851786136627
train--33/100 [529/1090] loss: 0.4493057608604431
train--33/100 [539/1090] loss: 0.4530071020126343
train--33/100 [549/1090] loss: 0.4577623397111893
train--33/100 [559/1090] loss: 0.43777322173118594
train--33/100 [569/1090] loss: 0.45063396394252775
train--33/100 [579/1090] loss: 0.4666126757860184
train--33/100 [589/1090] loss: 0.4367159605026245
train--33/100 [599/1090] loss: 0.43504875898361206
train--33/100 [609/1090] loss: 0.43421045541763303
train--33/100 [619/1090] loss: 0.4573818951845169
train--33/100 [629/1090] loss: 0.4626434803009033
train--33/100 [639/1090] loss: 0.4394330084323883
train--33/100 [649/1090] loss: 0.45961020290851595
train--33/100 [659/1090] loss: 0.46437055468559263
train--33/100 [669/1090] loss: 0.4538057804107666
train--33/100 [679/1090] loss: 0.4544264853000641
train--33/100 [689/1090] loss: 0.445136159658432
train--33/100 [699/1090] loss: 0.4327902257442474
train--33/100 [709/1090] loss: 0.4410426110029221
train--33/100 [719/1090] loss: 0.4528121381998062
train--33/100 [729/1090] loss: 0.4523161560297012
train--33/100 [739/1090] loss: 0.47258618772029876
train--33/100 [749/1090] loss: 0.4495613396167755
train--33/100 [759/1090] loss: 0.4400176823139191
train--33/100 [769/1090] loss: 0.44709488153457644
train--33/100 [779/1090] loss: 0.44454519748687743
train--33/100 [789/1090] loss: 0.43600721657276154
train--33/100 [799/1090] loss: 0.45831871032714844
train--33/100 [809/1090] loss: 0.4531991809606552
train--33/100 [819/1090] loss: 0.43978739678859713
train--33/100 [829/1090] loss: 0.4496254831552505
train--33/100 [839/1090] loss: 0.45651442408561704
train--33/100 [849/1090] loss: 0.45190208554267886
train--33/100 [859/1090] loss: 0.435921186208725
train--33/100 [869/1090] loss: 0.4529989928007126
train--33/100 [879/1090] loss: 0.4438078969717026
train--33/100 [889/1090] loss: 0.4495523363351822
train--33/100 [899/1090] loss: 0.4347145199775696
train--33/100 [909/1090] loss: 0.45363521873950957
train--33/100 [919/1090] loss: 0.41459502279758453
train--33/100 [929/1090] loss: 0.44366771876811983
train--33/100 [939/1090] loss: 0.44029706716537476
train--33/100 [949/1090] loss: 0.4363807886838913
train--33/100 [959/1090] loss: 0.4565366059541702
train--33/100 [969/1090] loss: 0.44957922101020814
train--33/100 [979/1090] loss: 0.460633647441864
train--33/100 [989/1090] loss: 0.45727098286151885
train--33/100 [999/1090] loss: 0.4641492158174515
train--33/100 [1009/1090] loss: 0.4603120893239975
train--33/100 [1019/1090] loss: 0.44524734914302827
train--33/100 [1029/1090] loss: 0.4483260750770569
train--33/100 [1039/1090] loss: 0.43966731131076814
train--33/100 [1049/1090] loss: 0.4407565951347351
train--33/100 [1059/1090] loss: 0.4451242983341217
train--33/100 [1069/1090] loss: 0.45344928205013274
train--33/100 [1079/1090] loss: 0.45244911015033723
train--33/100 [1089/1090] loss: 0.44579250514507296
predicting model...
val--33/100 [10/1090] acc: 0.793359375
val--33/100 [20/1090] acc: 0.79375
val--33/100 [30/1090] acc: 0.793359375
val--33/100 [40/1090] acc: 0.79287109375
val--33/100 [50/1090] acc: 0.79265625
val--33/100 [60/1090] acc: 0.7919270833333333
val--33/100 [70/1090] acc: 0.7924665178571428
val--33/100 [80/1090] acc: 0.79130859375
val--33/100 [90/1090] acc: 0.7919270833333333
val--33/100 [100/1090] acc: 0.793046875
val--33/100 [110/1090] acc: 0.7933238636363636
val--33/100 [120/1090] acc: 0.7929036458333333
val--33/100 [130/1090] acc: 0.7937199519230769
val--33/100 [140/1090] acc: 0.7938616071428571
val--33/100 [150/1090] acc: 0.79390625
val--33/100 [160/1090] acc: 0.7941162109375
val--33/100 [170/1090] acc: 0.7940716911764706
val--33/100 [180/1090] acc: 0.7937934027777778
val--33/100 [190/1090] acc: 0.7947162828947368
val--33/100 [200/1090] acc: 0.794921875
val--33/100 [210/1090] acc: 0.795219494047619
val--33/100 [220/1090] acc: 0.7943181818181818
val--33/100 [230/1090] acc: 0.7949388586956522
val--33/100 [240/1090] acc: 0.7947102864583333
val--33/100 [250/1090] acc: 0.794796875
val--33/100 [260/1090] acc: 0.7947415865384615
val--33/100 [270/1090] acc: 0.7948784722222222
val--33/100 [280/1090] acc: 0.7948102678571428
val--33/100 [290/1090] acc: 0.7947737068965517
val--33/100 [300/1090] acc: 0.7947526041666667
val--33/100 [310/1090] acc: 0.7945186491935484
val--33/100 [320/1090] acc: 0.7947021484375
val--33/100 [330/1090] acc: 0.7949692234848484
val--33/100 [340/1090] acc: 0.7951171875
val--33/100 [350/1090] acc: 0.7952566964285714
val--33/100 [360/1090] acc: 0.7951171875
val--33/100 [370/1090] acc: 0.7952174831081081
val--33/100 [380/1090] acc: 0.7951583059210526
val--33/100 [390/1090] acc: 0.794921875
val--33/100 [400/1090] acc: 0.794853515625
val--33/100 [410/1090] acc: 0.7950838414634146
val--33/100 [420/1090] acc: 0.7950892857142857
val--33/100 [430/1090] acc: 0.7949309593023256
val--33/100 [440/1090] acc: 0.7949485085227272
val--33/100 [450/1090] acc: 0.7948090277777777
val--33/100 [460/1090] acc: 0.7946756114130434
val--33/100 [470/1090] acc: 0.7945644946808511
val--33/100 [480/1090] acc: 0.7946126302083333
val--33/100 [490/1090] acc: 0.7947066326530612
val--33/100 [500/1090] acc: 0.794890625
val--33/100 [510/1090] acc: 0.7947993259803922
val--33/100 [520/1090] acc: 0.7949819711538462
val--33/100 [530/1090] acc: 0.7949292452830189
val--33/100 [540/1090] acc: 0.795044849537037
val--33/100 [550/1090] acc: 0.7948934659090909
val--33/100 [560/1090] acc: 0.7947265625
val--33/100 [570/1090] acc: 0.7944969846491228
val--33/100 [580/1090] acc: 0.7945110452586207
val--33/100 [590/1090] acc: 0.7945444915254237
val--33/100 [600/1090] acc: 0.7945768229166666
val--33/100 [610/1090] acc: 0.794499231557377
val--33/100 [620/1090] acc: 0.7943863407258065
val--33/100 [630/1090] acc: 0.794624255952381
val--33/100 [640/1090] acc: 0.794830322265625
val--33/100 [650/1090] acc: 0.7948076923076923
val--33/100 [660/1090] acc: 0.7946969696969697
val--33/100 [670/1090] acc: 0.7944088152985075
val--33/100 [680/1090] acc: 0.7943187040441176
val--33/100 [690/1090] acc: 0.7945199275362319
val--33/100 [700/1090] acc: 0.7945200892857143
val--33/100 [710/1090] acc: 0.7942946742957746
val--33/100 [720/1090] acc: 0.7941189236111111
val--33/100 [730/1090] acc: 0.7940603595890411
val--33/100 [740/1090] acc: 0.7939611486486486
val--33/100 [750/1090] acc: 0.7940208333333333
val--33/100 [760/1090] acc: 0.7940892269736842
val--33/100 [770/1090] acc: 0.7940543831168831
val--33/100 [780/1090] acc: 0.7940254407051283
val--33/100 [790/1090] acc: 0.7940862341772152
val--33/100 [800/1090] acc: 0.79431640625
val--33/100 [810/1090] acc: 0.7943672839506173
val--33/100 [820/1090] acc: 0.7944455030487805
val--33/100 [830/1090] acc: 0.7945359563253012
val--33/100 [840/1090] acc: 0.7944800967261905
val--33/100 [850/1090] acc: 0.7945082720588236
val--33/100 [860/1090] acc: 0.7947311046511628
val--33/100 [870/1090] acc: 0.7945896192528735
val--33/100 [880/1090] acc: 0.7945268110795455
val--33/100 [890/1090] acc: 0.7946716994382023
val--33/100 [900/1090] acc: 0.7946961805555556
val--33/100 [910/1090] acc: 0.7947115384615384
val--33/100 [920/1090] acc: 0.7947308084239131
val--33/100 [930/1090] acc: 0.7947874663978495
val--33/100 [940/1090] acc: 0.7948055186170213
val--33/100 [950/1090] acc: 0.7946833881578947
val--33/100 [960/1090] acc: 0.7946329752604167
val--33/100 [970/1090] acc: 0.7946319265463917
val--33/100 [980/1090] acc: 0.7946468431122449
val--33/100 [990/1090] acc: 0.7945628156565656
val--33/100 [1000/1090] acc: 0.79446875
val--33/100 [1010/1090] acc: 0.7943456064356436
val--33/100 [1020/1090] acc: 0.7944125306372549
val--33/100 [1030/1090] acc: 0.7944667779126213
val--33/100 [1040/1090] acc: 0.7944373497596153
val--33/100 [1050/1090] acc: 0.7944605654761905
val--33/100 [1060/1090] acc: 0.7943838443396226
val--33/100 [1070/1090] acc: 0.7943742698598131
val--33/100 [1080/1090] acc: 0.7943178530092593
val--33/100 [1090/1090] acc: 0.7941442087155963
epoch= 33, accuracy= 0.794144, rmse= 0.378587, auc= 0.854589
train--34/100 [9/1090] loss: 0.38557509183883665
train--34/100 [19/1090] loss: 0.45129122734069826
train--34/100 [29/1090] loss: 0.4462195932865143
train--34/100 [39/1090] loss: 0.43781309127807616
train--34/100 [49/1090] loss: 0.44017110466957093
train--34/100 [59/1090] loss: 0.4494509130716324
train--34/100 [69/1090] loss: 0.4399766236543655
train--34/100 [79/1090] loss: 0.4353300124406815
train--34/100 [89/1090] loss: 0.4419576436281204
train--34/100 [99/1090] loss: 0.44859127700328827
train--34/100 [109/1090] loss: 0.4486006796360016
train--34/100 [119/1090] loss: 0.44109441339969635
train--34/100 [129/1090] loss: 0.46040152907371523
train--34/100 [139/1090] loss: 0.4603807508945465
train--34/100 [149/1090] loss: 0.4376735955476761
train--34/100 [159/1090] loss: 0.4527232348918915
train--34/100 [169/1090] loss: 0.43070423901081084
train--34/100 [179/1090] loss: 0.4488204210996628
train--34/100 [189/1090] loss: 0.4511339426040649
train--34/100 [199/1090] loss: 0.4511824697256088
train--34/100 [209/1090] loss: 0.44861898720264437
train--34/100 [219/1090] loss: 0.44071739017963407
train--34/100 [229/1090] loss: 0.44250525534152985
train--34/100 [239/1090] loss: 0.44355896711349485
train--34/100 [249/1090] loss: 0.44614926874637606
train--34/100 [259/1090] loss: 0.4407840847969055
train--34/100 [269/1090] loss: 0.4553292453289032
train--34/100 [279/1090] loss: 0.45594907701015475
train--34/100 [289/1090] loss: 0.4472110837697983
train--34/100 [299/1090] loss: 0.4637203574180603
train--34/100 [309/1090] loss: 0.44191944897174834
train--34/100 [319/1090] loss: 0.4419109165668488
train--34/100 [329/1090] loss: 0.43953933119773864
train--34/100 [339/1090] loss: 0.4565699487924576
train--34/100 [349/1090] loss: 0.4324083775281906
train--34/100 [359/1090] loss: 0.4433943271636963
train--34/100 [369/1090] loss: 0.4524182379245758
train--34/100 [379/1090] loss: 0.43911156356334685
train--34/100 [389/1090] loss: 0.4364468097686768
train--34/100 [399/1090] loss: 0.4453772783279419
train--34/100 [409/1090] loss: 0.4490070015192032
train--34/100 [419/1090] loss: 0.4472543835639954
train--34/100 [429/1090] loss: 0.44193527698516843
train--34/100 [439/1090] loss: 0.43506400287151337
train--34/100 [449/1090] loss: 0.4588946372270584
train--34/100 [459/1090] loss: 0.45516821146011355
train--34/100 [469/1090] loss: 0.43390794694423673
train--34/100 [479/1090] loss: 0.4573260694742203
train--34/100 [489/1090] loss: 0.4435789316892624
train--34/100 [499/1090] loss: 0.457268151640892
train--34/100 [509/1090] loss: 0.42640728652477267
train--34/100 [519/1090] loss: 0.4384735435247421
train--34/100 [529/1090] loss: 0.4401297867298126
train--34/100 [539/1090] loss: 0.438152676820755
train--34/100 [549/1090] loss: 0.4555723249912262
train--34/100 [559/1090] loss: 0.4462372392416
train--34/100 [569/1090] loss: 0.46051791310310364
train--34/100 [579/1090] loss: 0.42934450507164
train--34/100 [589/1090] loss: 0.43569439351558686
train--34/100 [599/1090] loss: 0.44425705075263977
train--34/100 [609/1090] loss: 0.4472543954849243
train--34/100 [619/1090] loss: 0.44471090137958524
train--34/100 [629/1090] loss: 0.44785404205322266
train--34/100 [639/1090] loss: 0.45011377036571504
train--34/100 [649/1090] loss: 0.453880575299263
train--34/100 [659/1090] loss: 0.460965970158577
train--34/100 [669/1090] loss: 0.45005625784397124
train--34/100 [679/1090] loss: 0.4568445771932602
train--34/100 [689/1090] loss: 0.444669297337532
train--34/100 [699/1090] loss: 0.459758123755455
train--34/100 [709/1090] loss: 0.45575190484523775
train--34/100 [719/1090] loss: 0.4636112004518509
train--34/100 [729/1090] loss: 0.47514636516571046
train--34/100 [739/1090] loss: 0.4289555013179779
train--34/100 [749/1090] loss: 0.4335912883281708
train--34/100 [759/1090] loss: 0.43736213743686675
train--34/100 [769/1090] loss: 0.4516962021589279
train--34/100 [779/1090] loss: 0.4582295149564743
train--34/100 [789/1090] loss: 0.4374393194913864
train--34/100 [799/1090] loss: 0.44014075100421907
train--34/100 [809/1090] loss: 0.43830802142620084
train--34/100 [819/1090] loss: 0.45875257849693296
train--34/100 [829/1090] loss: 0.4464601337909698
train--34/100 [839/1090] loss: 0.4338931918144226
train--34/100 [849/1090] loss: 0.4491362482309341
train--34/100 [859/1090] loss: 0.45252168774604795
train--34/100 [869/1090] loss: 0.4719275951385498
train--34/100 [879/1090] loss: 0.4756765365600586
train--34/100 [889/1090] loss: 0.46670606136322024
train--34/100 [899/1090] loss: 0.4469709455966949
train--34/100 [909/1090] loss: 0.44974740743637087
train--34/100 [919/1090] loss: 0.4403274953365326
train--34/100 [929/1090] loss: 0.42762103378772737
train--34/100 [939/1090] loss: 0.44844151437282564
train--34/100 [949/1090] loss: 0.4372147023677826
train--34/100 [959/1090] loss: 0.45093809366226195
train--34/100 [969/1090] loss: 0.4498263269662857
train--34/100 [979/1090] loss: 0.4446143627166748
train--34/100 [989/1090] loss: 0.43701307475566864
train--34/100 [999/1090] loss: 0.44429450035095214
train--34/100 [1009/1090] loss: 0.45664898455142977
train--34/100 [1019/1090] loss: 0.4699774205684662
train--34/100 [1029/1090] loss: 0.4458447456359863
train--34/100 [1039/1090] loss: 0.4459125757217407
train--34/100 [1049/1090] loss: 0.45752145648002623
train--34/100 [1059/1090] loss: 0.46284658908843995
train--34/100 [1069/1090] loss: 0.4460979104042053
train--34/100 [1079/1090] loss: 0.45746231377124785
train--34/100 [1089/1090] loss: 0.4414063900709152
predicting model...
val--34/100 [10/1090] acc: 0.79453125
val--34/100 [20/1090] acc: 0.79375
val--34/100 [30/1090] acc: 0.793359375
val--34/100 [40/1090] acc: 0.79326171875
val--34/100 [50/1090] acc: 0.792578125
val--34/100 [60/1090] acc: 0.7911458333333333
val--34/100 [70/1090] acc: 0.7919642857142857
val--34/100 [80/1090] acc: 0.791015625
val--34/100 [90/1090] acc: 0.7914496527777778
val--34/100 [100/1090] acc: 0.7925390625
val--34/100 [110/1090] acc: 0.7927201704545455
val--34/100 [120/1090] acc: 0.7923828125
val--34/100 [130/1090] acc: 0.7934194711538461
val--34/100 [140/1090] acc: 0.7936104910714286
val--34/100 [150/1090] acc: 0.7936197916666666
val--34/100 [160/1090] acc: 0.7939453125
val--34/100 [170/1090] acc: 0.7939108455882353
val--34/100 [180/1090] acc: 0.7936631944444444
val--34/100 [190/1090] acc: 0.79453125
val--34/100 [200/1090] acc: 0.7946875
val--34/100 [210/1090] acc: 0.7949776785714285
val--34/100 [220/1090] acc: 0.7941228693181818
val--34/100 [230/1090] acc: 0.7947860054347826
val--34/100 [240/1090] acc: 0.7945149739583334
val--34/100 [250/1090] acc: 0.794671875
val--34/100 [260/1090] acc: 0.7946213942307693
val--34/100 [270/1090] acc: 0.7948495370370371
val--34/100 [280/1090] acc: 0.7947823660714286
val--34/100 [290/1090] acc: 0.7946390086206897
val--34/100 [300/1090] acc: 0.7946354166666667
val--34/100 [310/1090] acc: 0.7942666330645162
val--34/100 [320/1090] acc: 0.79449462890625
val--34/100 [330/1090] acc: 0.7947443181818182
val--34/100 [340/1090] acc: 0.7948759191176471
val--34/100 [350/1090] acc: 0.7948995535714286
val--34/100 [360/1090] acc: 0.7948025173611111
val--34/100 [370/1090] acc: 0.7948796452702702
val--34/100 [380/1090] acc: 0.7948499177631579
val--34/100 [390/1090] acc: 0.7946414262820513
val--34/100 [400/1090] acc: 0.794501953125
val--34/100 [410/1090] acc: 0.7947313262195121
val--34/100 [420/1090] acc: 0.7947358630952381
val--34/100 [430/1090] acc: 0.7945857558139535
val--34/100 [440/1090] acc: 0.7945933948863636
val--34/100 [450/1090] acc: 0.7943836805555555
val--34/100 [460/1090] acc: 0.7942255434782609
val--34/100 [470/1090] acc: 0.7940907579787234
val--34/100 [480/1090] acc: 0.7941080729166666
val--34/100 [490/1090] acc: 0.7942841198979592
val--34/100 [500/1090] acc: 0.794515625
val--34/100 [510/1090] acc: 0.7943857230392157
val--34/100 [520/1090] acc: 0.7945913461538462
val--34/100 [530/1090] acc: 0.7945975825471698
val--34/100 [540/1090] acc: 0.7947410300925926
val--34/100 [550/1090] acc: 0.7946377840909091
val--34/100 [560/1090] acc: 0.7944126674107143
val--34/100 [570/1090] acc: 0.7941680372807017
val--34/100 [580/1090] acc: 0.7941810344827587
val--34/100 [590/1090] acc: 0.7942002118644068
val--34/100 [600/1090] acc: 0.7942643229166667
val--34/100 [610/1090] acc: 0.7941470286885246
val--34/100 [620/1090] acc: 0.7940650201612903
val--34/100 [630/1090] acc: 0.7942770337301587
val--34/100 [640/1090] acc: 0.794464111328125
val--34/100 [650/1090] acc: 0.7944891826923077
val--34/100 [660/1090] acc: 0.7943655303030303
val--34/100 [670/1090] acc: 0.7940706623134328
val--34/100 [680/1090] acc: 0.7940142463235295
val--34/100 [690/1090] acc: 0.7941915760869566
val--34/100 [700/1090] acc: 0.7941796875
val--34/100 [710/1090] acc: 0.7940030809859155
val--34/100 [720/1090] acc: 0.7938530815972222
val--34/100 [730/1090] acc: 0.7938463184931507
val--34/100 [740/1090] acc: 0.7937658361486486
val--34/100 [750/1090] acc: 0.7938020833333334
val--34/100 [760/1090] acc: 0.7938939144736842
val--34/100 [770/1090] acc: 0.7938768262987013
val--34/100 [780/1090] acc: 0.7938601762820513
val--34/100 [790/1090] acc: 0.7939131724683545
val--34/100 [800/1090] acc: 0.7941357421875
val--34/100 [810/1090] acc: 0.7942081404320988
val--34/100 [820/1090] acc: 0.7942883003048781
val--34/100 [830/1090] acc: 0.7943618222891566
val--34/100 [840/1090] acc: 0.7943080357142858
val--34/100 [850/1090] acc: 0.7943474264705882
val--34/100 [860/1090] acc: 0.7946039244186046
val--34/100 [870/1090] acc: 0.7944549209770115
val--34/100 [880/1090] acc: 0.7943980823863637
val--34/100 [890/1090] acc: 0.7945356390449438
val--34/100 [900/1090] acc: 0.7945746527777777
val--34/100 [910/1090] acc: 0.7945956387362637
val--34/100 [920/1090] acc: 0.7945949388586957
val--34/100 [930/1090] acc: 0.7946698588709677
val--34/100 [940/1090] acc: 0.7946891622340425
val--34/100 [950/1090] acc: 0.7946011513157895
val--34/100 [960/1090] acc: 0.7945515950520833
val--34/100 [970/1090] acc: 0.7945393041237113
val--34/100 [980/1090] acc: 0.7945551658163266
val--34/100 [990/1090] acc: 0.794491792929293
val--34/100 [1000/1090] acc: 0.7943828125
val--34/100 [1010/1090] acc: 0.7942450495049505
val--34/100 [1020/1090] acc: 0.7942976409313726
val--34/100 [1030/1090] acc: 0.7943340412621359
val--34/100 [1040/1090] acc: 0.7943021334134616
val--34/100 [1050/1090] acc: 0.7943377976190477
val--34/100 [1060/1090] acc: 0.7942954009433962
val--34/100 [1070/1090] acc: 0.7943158586448598
val--34/100 [1080/1090] acc: 0.7942491319444445
val--34/100 [1090/1090] acc: 0.7941012041284403
epoch= 34, accuracy= 0.794101, rmse= 0.378528, auc= 0.854619
train--35/100 [9/1090] loss: 0.3897164732217789
train--35/100 [19/1090] loss: 0.45244555175304413
train--35/100 [29/1090] loss: 0.4390712708234787
train--35/100 [39/1090] loss: 0.44888300597667696
train--35/100 [49/1090] loss: 0.4337981343269348
train--35/100 [59/1090] loss: 0.4513891369104385
train--35/100 [69/1090] loss: 0.4357154995203018
train--35/100 [79/1090] loss: 0.4591419517993927
train--35/100 [89/1090] loss: 0.4274294674396515
train--35/100 [99/1090] loss: 0.4297176420688629
train--35/100 [109/1090] loss: 0.45223470628261564
train--35/100 [119/1090] loss: 0.4412171095609665
train--35/100 [129/1090] loss: 0.44193472862243655
train--35/100 [139/1090] loss: 0.4316590875387192
train--35/100 [149/1090] loss: 0.4554061651229858
train--35/100 [159/1090] loss: 0.44028457403182986
train--35/100 [169/1090] loss: 0.44248817563056947
train--35/100 [179/1090] loss: 0.4509696066379547
train--35/100 [189/1090] loss: 0.45586403608322146
train--35/100 [199/1090] loss: 0.44167772829532626
train--35/100 [209/1090] loss: 0.4526520699262619
train--35/100 [219/1090] loss: 0.4543188214302063
train--35/100 [229/1090] loss: 0.43050919473171234
train--35/100 [239/1090] loss: 0.4558998644351959
train--35/100 [249/1090] loss: 0.452902153134346
train--35/100 [259/1090] loss: 0.443731027841568
train--35/100 [269/1090] loss: 0.4268238067626953
train--35/100 [279/1090] loss: 0.42678973376750945
train--35/100 [289/1090] loss: 0.45750993490219116
train--35/100 [299/1090] loss: 0.4484919458627701
train--35/100 [309/1090] loss: 0.44640723764896395
train--35/100 [319/1090] loss: 0.4566636770963669
train--35/100 [329/1090] loss: 0.44836788177490233
train--35/100 [339/1090] loss: 0.451653853058815
train--35/100 [349/1090] loss: 0.43140019178390504
train--35/100 [359/1090] loss: 0.44978013038635256
train--35/100 [369/1090] loss: 0.42812053561210633
train--35/100 [379/1090] loss: 0.4368468701839447
train--35/100 [389/1090] loss: 0.4345957159996033
train--35/100 [399/1090] loss: 0.4364017337560654
train--35/100 [409/1090] loss: 0.4430836111307144
train--35/100 [419/1090] loss: 0.4365504771471024
train--35/100 [429/1090] loss: 0.4465830326080322
train--35/100 [439/1090] loss: 0.4310198247432709
train--35/100 [449/1090] loss: 0.44271270036697385
train--35/100 [459/1090] loss: 0.4439850956201553
train--35/100 [469/1090] loss: 0.46365738809108736
train--35/100 [479/1090] loss: 0.45731220245361326
train--35/100 [489/1090] loss: 0.4615750640630722
train--35/100 [499/1090] loss: 0.4352338522672653
train--35/100 [509/1090] loss: 0.4571715921163559
train--35/100 [519/1090] loss: 0.47054343521595
train--35/100 [529/1090] loss: 0.4446119278669357
train--35/100 [539/1090] loss: 0.4299401223659515
train--35/100 [549/1090] loss: 0.4481003314256668
train--35/100 [559/1090] loss: 0.43542260229587554
train--35/100 [569/1090] loss: 0.47064046561717987
train--35/100 [579/1090] loss: 0.4660416513681412
train--35/100 [589/1090] loss: 0.43859972059726715
train--35/100 [599/1090] loss: 0.45358970761299133
train--35/100 [609/1090] loss: 0.44137643575668334
train--35/100 [619/1090] loss: 0.4472692131996155
train--35/100 [629/1090] loss: 0.4555830001831055
train--35/100 [639/1090] loss: 0.44599231481552126
train--35/100 [649/1090] loss: 0.4412126153707504
train--35/100 [659/1090] loss: 0.4421534240245819
train--35/100 [669/1090] loss: 0.43360337913036345
train--35/100 [679/1090] loss: 0.4472038269042969
train--35/100 [689/1090] loss: 0.451075479388237
train--35/100 [699/1090] loss: 0.43999325633049013
train--35/100 [709/1090] loss: 0.44502834379673006
train--35/100 [719/1090] loss: 0.4557425856590271
train--35/100 [729/1090] loss: 0.45234312415122985
train--35/100 [739/1090] loss: 0.4513555407524109
train--35/100 [749/1090] loss: 0.4503918468952179
train--35/100 [759/1090] loss: 0.4618216693401337
train--35/100 [769/1090] loss: 0.46171362698078156
train--35/100 [779/1090] loss: 0.47106395959854125
train--35/100 [789/1090] loss: 0.44101942181587217
train--35/100 [799/1090] loss: 0.4487709790468216
train--35/100 [809/1090] loss: 0.45734394192695615
train--35/100 [819/1090] loss: 0.4388140678405762
train--35/100 [829/1090] loss: 0.4715963900089264
train--35/100 [839/1090] loss: 0.4499883532524109
train--35/100 [849/1090] loss: 0.4560127228498459
train--35/100 [859/1090] loss: 0.45346657633781434
train--35/100 [869/1090] loss: 0.43571220636367797
train--35/100 [879/1090] loss: 0.45852776169776915
train--35/100 [889/1090] loss: 0.45042704939842226
train--35/100 [899/1090] loss: 0.45284531712532045
train--35/100 [909/1090] loss: 0.4435639500617981
train--35/100 [919/1090] loss: 0.43330730199813844
train--35/100 [929/1090] loss: 0.4375430017709732
train--35/100 [939/1090] loss: 0.4501029133796692
train--35/100 [949/1090] loss: 0.46445643305778506
train--35/100 [959/1090] loss: 0.430261155962944
train--35/100 [969/1090] loss: 0.4623031854629517
train--35/100 [979/1090] loss: 0.45896587073802947
train--35/100 [989/1090] loss: 0.4395254075527191
train--35/100 [999/1090] loss: 0.4391183465719223
train--35/100 [1009/1090] loss: 0.45524106323719027
train--35/100 [1019/1090] loss: 0.4530907690525055
train--35/100 [1029/1090] loss: 0.46193028390407564
train--35/100 [1039/1090] loss: 0.45639978647232055
train--35/100 [1049/1090] loss: 0.4376831740140915
train--35/100 [1059/1090] loss: 0.4620687335729599
train--35/100 [1069/1090] loss: 0.44926598370075227
train--35/100 [1079/1090] loss: 0.4480614006519318
train--35/100 [1089/1090] loss: 0.4530114412307739
predicting model...
val--35/100 [10/1090] acc: 0.794921875
val--35/100 [20/1090] acc: 0.7955078125
val--35/100 [30/1090] acc: 0.79453125
val--35/100 [40/1090] acc: 0.7939453125
val--35/100 [50/1090] acc: 0.793046875
val--35/100 [60/1090] acc: 0.7922526041666667
val--35/100 [70/1090] acc: 0.7928013392857143
val--35/100 [80/1090] acc: 0.791748046875
val--35/100 [90/1090] acc: 0.7920138888888889
val--35/100 [100/1090] acc: 0.793046875
val--35/100 [110/1090] acc: 0.7932883522727273
val--35/100 [120/1090] acc: 0.7927734375
val--35/100 [130/1090] acc: 0.7939002403846154
val--35/100 [140/1090] acc: 0.7939453125
val--35/100 [150/1090] acc: 0.7939322916666667
val--35/100 [160/1090] acc: 0.794189453125
val--35/100 [170/1090] acc: 0.7940257352941177
val--35/100 [180/1090] acc: 0.7934895833333333
val--35/100 [190/1090] acc: 0.7944695723684211
val--35/100 [200/1090] acc: 0.7946484375
val--35/100 [210/1090] acc: 0.7949404761904761
val--35/100 [220/1090] acc: 0.7940518465909091
val--35/100 [230/1090] acc: 0.7947860054347826
val--35/100 [240/1090] acc: 0.79453125
val--35/100 [250/1090] acc: 0.79471875
val--35/100 [260/1090] acc: 0.7946063701923077
val--35/100 [270/1090] acc: 0.7948640046296296
val--35/100 [280/1090] acc: 0.7947823660714286
val--35/100 [290/1090] acc: 0.7946120689655173
val--35/100 [300/1090] acc: 0.7945572916666667
val--35/100 [310/1090] acc: 0.794203629032258
val--35/100 [320/1090] acc: 0.7944580078125
val--35/100 [330/1090] acc: 0.794732481060606
val--35/100 [340/1090] acc: 0.7948299632352941
val--35/100 [350/1090] acc: 0.795
val--35/100 [360/1090] acc: 0.794921875
val--35/100 [370/1090] acc: 0.7950380067567567
val--35/100 [380/1090] acc: 0.7949424342105263
val--35/100 [390/1090] acc: 0.7946714743589743
val--35/100 [400/1090] acc: 0.794521484375
val--35/100 [410/1090] acc: 0.794702743902439
val--35/100 [420/1090] acc: 0.7947451636904762
val--35/100 [430/1090] acc: 0.7946493459302325
val--35/100 [440/1090] acc: 0.7946555397727273
val--35/100 [450/1090] acc: 0.7944270833333333
val--35/100 [460/1090] acc: 0.7942170516304348
val--35/100 [470/1090] acc: 0.7941988031914894
val--35/100 [480/1090] acc: 0.7942708333333334
val--35/100 [490/1090] acc: 0.7943558673469387
val--35/100 [500/1090] acc: 0.7945546875
val--35/100 [510/1090] acc: 0.7944240196078431
val--35/100 [520/1090] acc: 0.7946138822115385
val--35/100 [530/1090] acc: 0.7945902122641509
val--35/100 [540/1090] acc: 0.7947193287037037
val--35/100 [550/1090] acc: 0.7945525568181818
val--35/100 [560/1090] acc: 0.7943289620535714
val--35/100 [570/1090] acc: 0.7940515350877193
val--35/100 [580/1090] acc: 0.7940665409482759
val--35/100 [590/1090] acc: 0.7940876588983051
val--35/100 [600/1090] acc: 0.7941927083333333
val--35/100 [610/1090] acc: 0.7940509733606558
val--35/100 [620/1090] acc: 0.7939264112903226
val--35/100 [630/1090] acc: 0.7941592261904762
val--35/100 [640/1090] acc: 0.79434814453125
val--35/100 [650/1090] acc: 0.7943629807692307
val--35/100 [660/1090] acc: 0.7942708333333334
val--35/100 [670/1090] acc: 0.7939890391791045
val--35/100 [680/1090] acc: 0.7939510569852941
val--35/100 [690/1090] acc: 0.794140625
val--35/100 [700/1090] acc: 0.7941350446428571
val--35/100 [710/1090] acc: 0.7939975792253521
val--35/100 [720/1090] acc: 0.7938585069444445
val--35/100 [730/1090] acc: 0.7938356164383562
val--35/100 [740/1090] acc: 0.7937341638513513
val--35/100 [750/1090] acc: 0.7938229166666667
val--35/100 [760/1090] acc: 0.7939144736842105
val--35/100 [770/1090] acc: 0.7938920454545455
val--35/100 [780/1090] acc: 0.7938952323717948
val--35/100 [790/1090] acc: 0.7939428401898734
val--35/100 [800/1090] acc: 0.7941650390625
val--35/100 [810/1090] acc: 0.794212962962963
val--35/100 [820/1090] acc: 0.7943073551829268
val--35/100 [830/1090] acc: 0.7944088855421687
val--35/100 [840/1090] acc: 0.794345238095238
val--35/100 [850/1090] acc: 0.7943841911764706
val--35/100 [860/1090] acc: 0.7946720566860465
val--35/100 [870/1090] acc: 0.7945043103448276
val--35/100 [880/1090] acc: 0.7944735440340909
val--35/100 [890/1090] acc: 0.7946102528089888
val--35/100 [900/1090] acc: 0.7946050347222222
val--35/100 [910/1090] acc: 0.7946213942307693
val--35/100 [920/1090] acc: 0.79462890625
val--35/100 [930/1090] acc: 0.7947244623655914
val--35/100 [940/1090] acc: 0.7947265625
val--35/100 [950/1090] acc: 0.7946175986842106
val--35/100 [960/1090] acc: 0.7945515950520833
val--35/100 [970/1090] acc: 0.7945272229381444
val--35/100 [980/1090] acc: 0.7945192920918367
val--35/100 [990/1090] acc: 0.7944602272727272
val--35/100 [1000/1090] acc: 0.79436328125
val--35/100 [1010/1090] acc: 0.7942257116336634
val--35/100 [1020/1090] acc: 0.7942823223039216
val--35/100 [1030/1090] acc: 0.7943188713592233
val--35/100 [1040/1090] acc: 0.7943021334134616
val--35/100 [1050/1090] acc: 0.7943526785714285
val--35/100 [1060/1090] acc: 0.7943101415094339
val--35/100 [1070/1090] acc: 0.7943523656542056
val--35/100 [1080/1090] acc: 0.7943070023148148
val--35/100 [1090/1090] acc: 0.7941657110091743
epoch= 35, accuracy= 0.794166, rmse= 0.378529, auc= 0.854731
train--36/100 [9/1090] loss: 0.39817036092281344
train--36/100 [19/1090] loss: 0.4492963492870331
train--36/100 [29/1090] loss: 0.4469591051340103
train--36/100 [39/1090] loss: 0.4426686644554138
train--36/100 [49/1090] loss: 0.4550033509731293
train--36/100 [59/1090] loss: 0.46029471457004545
train--36/100 [69/1090] loss: 0.4488515257835388
train--36/100 [79/1090] loss: 0.44463783502578735
train--36/100 [89/1090] loss: 0.4551277458667755
train--36/100 [99/1090] loss: 0.4350516229867935
train--36/100 [109/1090] loss: 0.43360756933689115
train--36/100 [119/1090] loss: 0.42606901228427885
train--36/100 [129/1090] loss: 0.4357303440570831
train--36/100 [139/1090] loss: 0.4600818604230881
train--36/100 [149/1090] loss: 0.4261251002550125
train--36/100 [159/1090] loss: 0.44923071265220643
train--36/100 [169/1090] loss: 0.44417999386787416
train--36/100 [179/1090] loss: 0.4437779724597931
train--36/100 [189/1090] loss: 0.42902434766292574
train--36/100 [199/1090] loss: 0.4539501637220383
train--36/100 [209/1090] loss: 0.4425943613052368
train--36/100 [219/1090] loss: 0.44655102491378784
train--36/100 [229/1090] loss: 0.4309524208307266
train--36/100 [239/1090] loss: 0.4556232690811157
train--36/100 [249/1090] loss: 0.4525414973497391
train--36/100 [259/1090] loss: 0.4581264078617096
train--36/100 [269/1090] loss: 0.43683441281318663
train--36/100 [279/1090] loss: 0.45671787559986116
train--36/100 [289/1090] loss: 0.4302498310804367
train--36/100 [299/1090] loss: 0.43589219748973845
train--36/100 [309/1090] loss: 0.44549804329872134
train--36/100 [319/1090] loss: 0.45432485044002535
train--36/100 [329/1090] loss: 0.4716120332479477
train--36/100 [339/1090] loss: 0.4556622415781021
train--36/100 [349/1090] loss: 0.42495611011981965
train--36/100 [359/1090] loss: 0.4459800660610199
train--36/100 [369/1090] loss: 0.43613662123680114
train--36/100 [379/1090] loss: 0.4450413167476654
train--36/100 [389/1090] loss: 0.45450618863105774
train--36/100 [399/1090] loss: 0.44755984246730807
train--36/100 [409/1090] loss: 0.4571502864360809
train--36/100 [419/1090] loss: 0.4375686526298523
train--36/100 [429/1090] loss: 0.4436916559934616
train--36/100 [439/1090] loss: 0.4270286589860916
train--36/100 [449/1090] loss: 0.44974636733531953
train--36/100 [459/1090] loss: 0.4455423504114151
train--36/100 [469/1090] loss: 0.4522290974855423
train--36/100 [479/1090] loss: 0.4502898335456848
train--36/100 [489/1090] loss: 0.4505776733160019
train--36/100 [499/1090] loss: 0.4592240065336227
train--36/100 [509/1090] loss: 0.44696725010871885
train--36/100 [519/1090] loss: 0.45955302715301516
train--36/100 [529/1090] loss: 0.4361394613981247
train--36/100 [539/1090] loss: 0.4543594568967819
train--36/100 [549/1090] loss: 0.4370376706123352
train--36/100 [559/1090] loss: 0.4276667684316635
train--36/100 [569/1090] loss: 0.4411462008953094
train--36/100 [579/1090] loss: 0.44915907382965087
train--36/100 [589/1090] loss: 0.43549333810806273
train--36/100 [599/1090] loss: 0.4576706051826477
train--36/100 [609/1090] loss: 0.41969436407089233
train--36/100 [619/1090] loss: 0.44024378061294556
train--36/100 [629/1090] loss: 0.4498404264450073
train--36/100 [639/1090] loss: 0.43436084389686586
train--36/100 [649/1090] loss: 0.4707132190465927
train--36/100 [659/1090] loss: 0.4435736894607544
train--36/100 [669/1090] loss: 0.4536339730024338
train--36/100 [679/1090] loss: 0.4361004441976547
train--36/100 [689/1090] loss: 0.4505345493555069
train--36/100 [699/1090] loss: 0.45904620885849
train--36/100 [709/1090] loss: 0.457266503572464
train--36/100 [719/1090] loss: 0.4457859605550766
train--36/100 [729/1090] loss: 0.45519022047519686
train--36/100 [739/1090] loss: 0.44377484917640686
train--36/100 [749/1090] loss: 0.45583586394786835
train--36/100 [759/1090] loss: 0.4326054215431213
train--36/100 [769/1090] loss: 0.4459998428821564
train--36/100 [779/1090] loss: 0.47123720645904543
train--36/100 [789/1090] loss: 0.4473635762929916
train--36/100 [799/1090] loss: 0.4453177094459534
train--36/100 [809/1090] loss: 0.45457918047904966
train--36/100 [819/1090] loss: 0.4617811769247055
train--36/100 [829/1090] loss: 0.45591187179088594
train--36/100 [839/1090] loss: 0.44875332415103913
train--36/100 [849/1090] loss: 0.4222681224346161
train--36/100 [859/1090] loss: 0.44696723222732543
train--36/100 [869/1090] loss: 0.4378406584262848
train--36/100 [879/1090] loss: 0.44651549160480497
train--36/100 [889/1090] loss: 0.45966480672359467
train--36/100 [899/1090] loss: 0.4648797601461411
train--36/100 [909/1090] loss: 0.43435257375240327
train--36/100 [919/1090] loss: 0.4489430069923401
train--36/100 [929/1090] loss: 0.4581382811069489
train--36/100 [939/1090] loss: 0.43219770193099977
train--36/100 [949/1090] loss: 0.4700600117444992
train--36/100 [959/1090] loss: 0.44534404277801515
train--36/100 [969/1090] loss: 0.4481938600540161
train--36/100 [979/1090] loss: 0.47300522327423095
train--36/100 [989/1090] loss: 0.4644142150878906
train--36/100 [999/1090] loss: 0.45438204407691957
train--36/100 [1009/1090] loss: 0.4432356208562851
train--36/100 [1019/1090] loss: 0.4591042995452881
train--36/100 [1029/1090] loss: 0.46602965891361237
train--36/100 [1039/1090] loss: 0.44537738859653475
train--36/100 [1049/1090] loss: 0.4454030156135559
train--36/100 [1059/1090] loss: 0.44431298673152925
train--36/100 [1069/1090] loss: 0.45784429311752317
train--36/100 [1079/1090] loss: 0.43041429817676546
train--36/100 [1089/1090] loss: 0.4364686250686646
predicting model...
val--36/100 [10/1090] acc: 0.793359375
val--36/100 [20/1090] acc: 0.794921875
val--36/100 [30/1090] acc: 0.7942708333333334
val--36/100 [40/1090] acc: 0.79365234375
val--36/100 [50/1090] acc: 0.7928125
val--36/100 [60/1090] acc: 0.7920572916666667
val--36/100 [70/1090] acc: 0.7926339285714286
val--36/100 [80/1090] acc: 0.79150390625
val--36/100 [90/1090] acc: 0.7919270833333333
val--36/100 [100/1090] acc: 0.7926953125
val--36/100 [110/1090] acc: 0.7928622159090909
val--36/100 [120/1090] acc: 0.79248046875
val--36/100 [130/1090] acc: 0.7934194711538461
val--36/100 [140/1090] acc: 0.7936383928571429
val--36/100 [150/1090] acc: 0.7935677083333333
val--36/100 [160/1090] acc: 0.793896484375
val--36/100 [170/1090] acc: 0.7938189338235294
val--36/100 [180/1090] acc: 0.7935329861111111
val--36/100 [190/1090] acc: 0.79453125
val--36/100 [200/1090] acc: 0.79474609375
val--36/100 [210/1090] acc: 0.7951078869047619
val--36/100 [220/1090] acc: 0.7940873579545454
val--36/100 [230/1090] acc: 0.7947860054347826
val--36/100 [240/1090] acc: 0.7945963541666666
val--36/100 [250/1090] acc: 0.794765625
val--36/100 [260/1090] acc: 0.7947265625
val--36/100 [270/1090] acc: 0.7948206018518519
val--36/100 [280/1090] acc: 0.7947684151785714
val--36/100 [290/1090] acc: 0.7946524784482759
val--36/100 [300/1090] acc: 0.7946223958333334
val--36/100 [310/1090] acc: 0.7942792338709678
val--36/100 [320/1090] acc: 0.79451904296875
val--36/100 [330/1090] acc: 0.7947443181818182
val--36/100 [340/1090] acc: 0.7948529411764705
val--36/100 [350/1090] acc: 0.7950223214285714
val--36/100 [360/1090] acc: 0.7950086805555555
val--36/100 [370/1090] acc: 0.7951224662162162
val--36/100 [380/1090] acc: 0.7950760690789473
val--36/100 [390/1090] acc: 0.7947816506410257
val--36/100 [400/1090] acc: 0.794619140625
val--36/100 [410/1090] acc: 0.7948456554878048
val--36/100 [420/1090] acc: 0.7948102678571428
val--36/100 [430/1090] acc: 0.7946220930232558
val--36/100 [440/1090] acc: 0.79462890625
val--36/100 [450/1090] acc: 0.794453125
val--36/100 [460/1090] acc: 0.7943189538043478
val--36/100 [470/1090] acc: 0.7941904920212766
val--36/100 [480/1090] acc: 0.7942626953125
val--36/100 [490/1090] acc: 0.7944036989795918
val--36/100 [500/1090] acc: 0.794625
val--36/100 [510/1090] acc: 0.7945159313725491
val--36/100 [520/1090] acc: 0.7947265625
val--36/100 [530/1090] acc: 0.7947302476415095
val--36/100 [540/1090] acc: 0.7948712384259259
val--36/100 [550/1090] acc: 0.794765625
val--36/100 [560/1090] acc: 0.7945591517857142
val--36/100 [570/1090] acc: 0.7943393640350878
val--36/100 [580/1090] acc: 0.7943089978448276
val--36/100 [590/1090] acc: 0.7943657309322034
val--36/100 [600/1090] acc: 0.7943880208333334
val--36/100 [610/1090] acc: 0.794281506147541
val--36/100 [620/1090] acc: 0.794203629032258
val--36/100 [630/1090] acc: 0.7944320436507937
val--36/100 [640/1090] acc: 0.794647216796875
val--36/100 [650/1090] acc: 0.7946694711538461
val--36/100 [660/1090] acc: 0.7946081912878787
val--36/100 [670/1090] acc: 0.7943155317164179
val--36/100 [680/1090] acc: 0.7942325367647058
val--36/100 [690/1090] acc: 0.7944236865942029
val--36/100 [700/1090] acc: 0.7944252232142858
val--36/100 [710/1090] acc: 0.7942616637323944
val--36/100 [720/1090] acc: 0.794091796875
val--36/100 [730/1090] acc: 0.7940550085616438
val--36/100 [740/1090] acc: 0.7939241976351351
val--36/100 [750/1090] acc: 0.793984375
val--36/100 [760/1090] acc: 0.7940481085526315
val--36/100 [770/1090] acc: 0.7939935064935065
val--36/100 [780/1090] acc: 0.7939653445512821
val--36/100 [790/1090] acc: 0.7940071202531646
val--36/100 [800/1090] acc: 0.794248046875
val--36/100 [810/1090] acc: 0.7943190586419753
val--36/100 [820/1090] acc: 0.7944169207317073
val--36/100 [830/1090] acc: 0.794507718373494
val--36/100 [840/1090] acc: 0.7944614955357143
val--36/100 [850/1090] acc: 0.7944669117647059
val--36/100 [860/1090] acc: 0.7946856831395349
val--36/100 [870/1090] acc: 0.79453125
val--36/100 [880/1090] acc: 0.7945001775568182
val--36/100 [890/1090] acc: 0.7946497542134832
val--36/100 [900/1090] acc: 0.7946614583333333
val--36/100 [910/1090] acc: 0.7946814903846153
val--36/100 [920/1090] acc: 0.7947265625
val--36/100 [930/1090] acc: 0.7948420698924731
val--36/100 [940/1090] acc: 0.7948346077127659
val--36/100 [950/1090] acc: 0.7946792763157895
val--36/100 [960/1090] acc: 0.7946085611979167
val--36/100 [970/1090] acc: 0.794603737113402
val--36/100 [980/1090] acc: 0.7946388711734694
val--36/100 [990/1090] acc: 0.7945430871212121
val--36/100 [1000/1090] acc: 0.79444140625
val--36/100 [1010/1090] acc: 0.7942991955445544
val--36/100 [1020/1090] acc: 0.7943550857843137
val--36/100 [1030/1090] acc: 0.7944212682038835
val--36/100 [1040/1090] acc: 0.7944148137019231
val--36/100 [1050/1090] acc: 0.7944419642857142
val--36/100 [1060/1090] acc: 0.7943875294811321
val--36/100 [1070/1090] acc: 0.7943961740654205
val--36/100 [1080/1090] acc: 0.7943250868055556
val--36/100 [1090/1090] acc: 0.7941692947247706
epoch= 36, accuracy= 0.794169, rmse= 0.378440, auc= 0.854662
train--37/100 [9/1090] loss: 0.39114985764026644
train--37/100 [19/1090] loss: 0.4390711307525635
train--37/100 [29/1090] loss: 0.4388081729412079
train--37/100 [39/1090] loss: 0.4631832271814346
train--37/100 [49/1090] loss: 0.45807271301746366
train--37/100 [59/1090] loss: 0.4539863675832748
train--37/100 [69/1090] loss: 0.44362635016441343
train--37/100 [79/1090] loss: 0.4364453375339508
train--37/100 [89/1090] loss: 0.43508506417274473
train--37/100 [99/1090] loss: 0.4219131588935852
train--37/100 [109/1090] loss: 0.45105490684509275
train--37/100 [119/1090] loss: 0.4490645706653595
train--37/100 [129/1090] loss: 0.4439320683479309
train--37/100 [139/1090] loss: 0.4428535610437393
train--37/100 [149/1090] loss: 0.46598165929317475
train--37/100 [159/1090] loss: 0.4354442209005356
train--37/100 [169/1090] loss: 0.45615772902965546
train--37/100 [179/1090] loss: 0.4536849677562714
train--37/100 [189/1090] loss: 0.4611773669719696
train--37/100 [199/1090] loss: 0.439704954624176
train--37/100 [209/1090] loss: 0.46010472178459166
train--37/100 [219/1090] loss: 0.44693236649036405
train--37/100 [229/1090] loss: 0.4240794599056244
train--37/100 [239/1090] loss: 0.4508304387331009
train--37/100 [249/1090] loss: 0.46113923490047454
train--37/100 [259/1090] loss: 0.4544997334480286
train--37/100 [269/1090] loss: 0.44730561077594755
train--37/100 [279/1090] loss: 0.44962330162525177
train--37/100 [289/1090] loss: 0.4301435470581055
train--37/100 [299/1090] loss: 0.449013689160347
train--37/100 [309/1090] loss: 0.43309990763664247
train--37/100 [319/1090] loss: 0.4544489711523056
train--37/100 [329/1090] loss: 0.4328978180885315
train--37/100 [339/1090] loss: 0.4546755999326706
train--37/100 [349/1090] loss: 0.4457526057958603
train--37/100 [359/1090] loss: 0.4217821717262268
train--37/100 [369/1090] loss: 0.4644029915332794
train--37/100 [379/1090] loss: 0.45901117026805877
train--37/100 [389/1090] loss: 0.4398693710565567
train--37/100 [399/1090] loss: 0.43531517386436464
train--37/100 [409/1090] loss: 0.43394373953342436
train--37/100 [419/1090] loss: 0.4342534810304642
train--37/100 [429/1090] loss: 0.4414974391460419
train--37/100 [439/1090] loss: 0.461862850189209
train--37/100 [449/1090] loss: 0.44692172706127165
train--37/100 [459/1090] loss: 0.44354740977287294
train--37/100 [469/1090] loss: 0.4486995697021484
train--37/100 [479/1090] loss: 0.4385435491800308
train--37/100 [489/1090] loss: 0.46330028474330903
train--37/100 [499/1090] loss: 0.44672365486621857
train--37/100 [509/1090] loss: 0.45805245339870454
train--37/100 [519/1090] loss: 0.44238558113574983
train--37/100 [529/1090] loss: 0.4561030685901642
train--37/100 [539/1090] loss: 0.44815550148487093
train--37/100 [549/1090] loss: 0.4578151017427444
train--37/100 [559/1090] loss: 0.43595203161239626
train--37/100 [569/1090] loss: 0.45672760009765623
train--37/100 [579/1090] loss: 0.4210646390914917
train--37/100 [589/1090] loss: 0.44385017454624176
train--37/100 [599/1090] loss: 0.4469332188367844
train--37/100 [609/1090] loss: 0.43985176980495455
train--37/100 [619/1090] loss: 0.46194804310798643
train--37/100 [629/1090] loss: 0.44396051168441775
train--37/100 [639/1090] loss: 0.44623527824878695
train--37/100 [649/1090] loss: 0.45298934876918795
train--37/100 [659/1090] loss: 0.4304114580154419
train--37/100 [669/1090] loss: 0.4409031063318253
train--37/100 [679/1090] loss: 0.47294401228427885
train--37/100 [689/1090] loss: 0.41888966262340543
train--37/100 [699/1090] loss: 0.4562920182943344
train--37/100 [709/1090] loss: 0.4422132521867752
train--37/100 [719/1090] loss: 0.46259347498416903
train--37/100 [729/1090] loss: 0.449470129609108
train--37/100 [739/1090] loss: 0.4685573399066925
train--37/100 [749/1090] loss: 0.43315514326095583
train--37/100 [759/1090] loss: 0.4437039792537689
train--37/100 [769/1090] loss: 0.4411679208278656
train--37/100 [779/1090] loss: 0.44371441304683684
train--37/100 [789/1090] loss: 0.43771317005157473
train--37/100 [799/1090] loss: 0.43916575610637665
train--37/100 [809/1090] loss: 0.4525904029607773
train--37/100 [819/1090] loss: 0.4571692109107971
train--37/100 [829/1090] loss: 0.42447698414325713
train--37/100 [839/1090] loss: 0.4549034029245377
train--37/100 [849/1090] loss: 0.4498394846916199
train--37/100 [859/1090] loss: 0.46192402839660646
train--37/100 [869/1090] loss: 0.4613416850566864
train--37/100 [879/1090] loss: 0.44964373409748076
train--37/100 [889/1090] loss: 0.4537270039319992
train--37/100 [899/1090] loss: 0.4505039632320404
train--37/100 [909/1090] loss: 0.45194253921508787
train--37/100 [919/1090] loss: 0.44173761904239656
train--37/100 [929/1090] loss: 0.44658368825912476
train--37/100 [939/1090] loss: 0.4502048552036285
train--37/100 [949/1090] loss: 0.45213664174079893
train--37/100 [959/1090] loss: 0.4538088798522949
train--37/100 [969/1090] loss: 0.45142277181148527
train--37/100 [979/1090] loss: 0.447942191362381
train--37/100 [989/1090] loss: 0.4513995677232742
train--37/100 [999/1090] loss: 0.4450349748134613
train--37/100 [1009/1090] loss: 0.4390211582183838
train--37/100 [1019/1090] loss: 0.4398889571428299
train--37/100 [1029/1090] loss: 0.4538608491420746
train--37/100 [1039/1090] loss: 0.44581020176410674
train--37/100 [1049/1090] loss: 0.4349263608455658
train--37/100 [1059/1090] loss: 0.46597860455513
train--37/100 [1069/1090] loss: 0.46106661260128023
train--37/100 [1079/1090] loss: 0.43755823969841
train--37/100 [1089/1090] loss: 0.4598896712064743
predicting model...
val--37/100 [10/1090] acc: 0.794140625
val--37/100 [20/1090] acc: 0.7947265625
val--37/100 [30/1090] acc: 0.7932291666666667
val--37/100 [40/1090] acc: 0.79296875
val--37/100 [50/1090] acc: 0.791953125
val--37/100 [60/1090] acc: 0.7908854166666667
val--37/100 [70/1090] acc: 0.7912946428571429
val--37/100 [80/1090] acc: 0.790576171875
val--37/100 [90/1090] acc: 0.7912760416666667
val--37/100 [100/1090] acc: 0.7924609375
val--37/100 [110/1090] acc: 0.7925426136363637
val--37/100 [120/1090] acc: 0.7923828125
val--37/100 [130/1090] acc: 0.7932091346153847
val--37/100 [140/1090] acc: 0.7933035714285714
val--37/100 [150/1090] acc: 0.7933072916666667
val--37/100 [160/1090] acc: 0.79365234375
val--37/100 [170/1090] acc: 0.7935661764705882
val--37/100 [180/1090] acc: 0.7933376736111111
val--37/100 [190/1090] acc: 0.794140625
val--37/100 [200/1090] acc: 0.7944140625
val--37/100 [210/1090] acc: 0.7948474702380952
val--37/100 [220/1090] acc: 0.7939630681818182
val--37/100 [230/1090] acc: 0.7946161684782609
val--37/100 [240/1090] acc: 0.7945149739583334
val--37/100 [250/1090] acc: 0.794734375
val--37/100 [260/1090] acc: 0.7946063701923077
val--37/100 [270/1090] acc: 0.7948495370370371
val--37/100 [280/1090] acc: 0.7947544642857143
val--37/100 [290/1090] acc: 0.7945447198275862
val--37/100 [300/1090] acc: 0.7946614583333333
val--37/100 [310/1090] acc: 0.7943800403225807
val--37/100 [320/1090] acc: 0.79464111328125
val--37/100 [330/1090] acc: 0.7948982007575758
val--37/100 [340/1090] acc: 0.7950482536764706
val--37/100 [350/1090] acc: 0.7952120535714285
val--37/100 [360/1090] acc: 0.7951497395833333
val--37/100 [370/1090] acc: 0.7952702702702703
val--37/100 [380/1090] acc: 0.7952405427631579
val--37/100 [390/1090] acc: 0.7950220352564102
val--37/100 [400/1090] acc: 0.79486328125
val--37/100 [410/1090] acc: 0.795093368902439
val--37/100 [420/1090] acc: 0.7951171875
val--37/100 [430/1090] acc: 0.7949582122093023
val--37/100 [440/1090] acc: 0.7948863636363637
val--37/100 [450/1090] acc: 0.7948177083333333
val--37/100 [460/1090] acc: 0.7947095788043478
val--37/100 [470/1090] acc: 0.7946642287234043
val--37/100 [480/1090] acc: 0.7947509765625
val--37/100 [490/1090] acc: 0.794905931122449
val--37/100 [500/1090] acc: 0.795109375
val--37/100 [510/1090] acc: 0.7950367647058824
val--37/100 [520/1090] acc: 0.7952524038461538
val--37/100 [530/1090] acc: 0.7952682783018868
val--37/100 [540/1090] acc: 0.7953993055555556
val--37/100 [550/1090] acc: 0.7952769886363636
val--37/100 [560/1090] acc: 0.7951032366071429
val--37/100 [570/1090] acc: 0.7948533442982456
val--37/100 [580/1090] acc: 0.7948208512931034
val--37/100 [590/1090] acc: 0.7948291843220339
val--37/100 [600/1090] acc: 0.7947981770833333
val--37/100 [610/1090] acc: 0.7947041495901639
val--37/100 [620/1090] acc: 0.7946131552419354
val--37/100 [630/1090] acc: 0.7948164682539682
val--37/100 [640/1090] acc: 0.795068359375
val--37/100 [650/1090] acc: 0.795108173076923
val--37/100 [660/1090] acc: 0.7949692234848484
val--37/100 [670/1090] acc: 0.7946361940298508
val--37/100 [680/1090] acc: 0.7945427389705882
val--37/100 [690/1090] acc: 0.7947180706521739
val--37/100 [700/1090] acc: 0.7947600446428571
val--37/100 [710/1090] acc: 0.7945367517605634
val--37/100 [720/1090] acc: 0.7943739149305555
val--37/100 [730/1090] acc: 0.7943546660958904
val--37/100 [740/1090] acc: 0.7942778716216217
val--37/100 [750/1090] acc: 0.7943125
val--37/100 [760/1090] acc: 0.7944027549342105
val--37/100 [770/1090] acc: 0.7943638392857143
val--37/100 [780/1090] acc: 0.7943459535256411
val--37/100 [790/1090] acc: 0.7944224683544304
val--37/100 [800/1090] acc: 0.794609375
val--37/100 [810/1090] acc: 0.7946903935185186
val--37/100 [820/1090] acc: 0.7948170731707317
val--37/100 [830/1090] acc: 0.7948795180722892
val--37/100 [840/1090] acc: 0.7948149181547619
val--37/100 [850/1090] acc: 0.79484375
val--37/100 [860/1090] acc: 0.7950490552325581
val--37/100 [870/1090] acc: 0.7948904454022988
val--37/100 [880/1090] acc: 0.7948153409090909
val--37/100 [890/1090] acc: 0.7949350421348315
val--37/100 [900/1090] acc: 0.7949045138888889
val--37/100 [910/1090] acc: 0.7949004120879121
val--37/100 [920/1090] acc: 0.7949006453804348
val--37/100 [930/1090] acc: 0.7949764784946236
val--37/100 [940/1090] acc: 0.7949966755319149
val--37/100 [950/1090] acc: 0.7948643092105263
val--37/100 [960/1090] acc: 0.7947998046875
val--37/100 [970/1090] acc: 0.7947930090206186
val--37/100 [980/1090] acc: 0.7947783801020408
val--37/100 [990/1090] acc: 0.7946930239898989
val--37/100 [1000/1090] acc: 0.794625
val--37/100 [1010/1090] acc: 0.7944887066831683
val--37/100 [1020/1090] acc: 0.7945350796568628
val--37/100 [1030/1090] acc: 0.7945502123786408
val--37/100 [1040/1090] acc: 0.7945237379807693
val--37/100 [1050/1090] acc: 0.7945833333333333
val--37/100 [1060/1090] acc: 0.7945091391509433
val--37/100 [1070/1090] acc: 0.7945166471962617
val--37/100 [1080/1090] acc: 0.7944661458333333
val--37/100 [1090/1090] acc: 0.7943018922018349
epoch= 37, accuracy= 0.794302, rmse= 0.378420, auc= 0.854724
train--38/100 [9/1090] loss: 0.3891208916902542
train--38/100 [19/1090] loss: 0.43351131975650786
train--38/100 [29/1090] loss: 0.43475416898727415
train--38/100 [39/1090] loss: 0.44071062505245207
train--38/100 [49/1090] loss: 0.43609043657779695
train--38/100 [59/1090] loss: 0.43682801723480225
train--38/100 [69/1090] loss: 0.4433746308088303
train--38/100 [79/1090] loss: 0.42874839901924133
train--38/100 [89/1090] loss: 0.43436543345451356
train--38/100 [99/1090] loss: 0.4474023222923279
train--38/100 [109/1090] loss: 0.44281780123710635
train--38/100 [119/1090] loss: 0.44768112897872925
train--38/100 [129/1090] loss: 0.42625955641269686
train--38/100 [139/1090] loss: 0.45792520940303805
train--38/100 [149/1090] loss: 0.44353470504283904
train--38/100 [159/1090] loss: 0.44284091889858246
train--38/100 [169/1090] loss: 0.436313596367836
train--38/100 [179/1090] loss: 0.47648613452911376
train--38/100 [189/1090] loss: 0.4588142573833466
train--38/100 [199/1090] loss: 0.43247591853141787
train--38/100 [209/1090] loss: 0.44482134878635404
train--38/100 [219/1090] loss: 0.446434012055397
train--38/100 [229/1090] loss: 0.4418183833360672
train--38/100 [239/1090] loss: 0.44516911804676057
train--38/100 [249/1090] loss: 0.4316632002592087
train--38/100 [259/1090] loss: 0.44250225722789766
train--38/100 [269/1090] loss: 0.4375822514295578
train--38/100 [279/1090] loss: 0.4411743074655533
train--38/100 [289/1090] loss: 0.42292380928993223
train--38/100 [299/1090] loss: 0.45594996213912964
train--38/100 [309/1090] loss: 0.47846406102180483
train--38/100 [319/1090] loss: 0.46814413368701935
train--38/100 [329/1090] loss: 0.46683391034603117
train--38/100 [339/1090] loss: 0.4339375555515289
train--38/100 [349/1090] loss: 0.45184521079063417
train--38/100 [359/1090] loss: 0.4513404995203018
train--38/100 [369/1090] loss: 0.4533092677593231
train--38/100 [379/1090] loss: 0.4386166870594025
train--38/100 [389/1090] loss: 0.4496310889720917
train--38/100 [399/1090] loss: 0.45011788606643677
train--38/100 [409/1090] loss: 0.4447489231824875
train--38/100 [419/1090] loss: 0.4341886341571808
train--38/100 [429/1090] loss: 0.45694737136363983
train--38/100 [439/1090] loss: 0.43271754384040834
train--38/100 [449/1090] loss: 0.43522044718265535
train--38/100 [459/1090] loss: 0.4412091612815857
train--38/100 [469/1090] loss: 0.45419169366359713
train--38/100 [479/1090] loss: 0.4202365279197693
train--38/100 [489/1090] loss: 0.442777481675148
train--38/100 [499/1090] loss: 0.44212493896484373
train--38/100 [509/1090] loss: 0.4382428854703903
train--38/100 [519/1090] loss: 0.44792939722537994
train--38/100 [529/1090] loss: 0.44364915788173676
train--38/100 [539/1090] loss: 0.43367178440093995
train--38/100 [549/1090] loss: 0.45738466680049894
train--38/100 [559/1090] loss: 0.4482932657003403
train--38/100 [569/1090] loss: 0.46594427824020385
train--38/100 [579/1090] loss: 0.44457698464393614
train--38/100 [589/1090] loss: 0.44200972020626067
train--38/100 [599/1090] loss: 0.4443866699934006
train--38/100 [609/1090] loss: 0.46811117231845856
train--38/100 [619/1090] loss: 0.4586603224277496
train--38/100 [629/1090] loss: 0.4426601409912109
train--38/100 [639/1090] loss: 0.45162285268306734
train--38/100 [649/1090] loss: 0.4571706622838974
train--38/100 [659/1090] loss: 0.46191082894802094
train--38/100 [669/1090] loss: 0.44999576508998873
train--38/100 [679/1090] loss: 0.4379951298236847
train--38/100 [689/1090] loss: 0.43625066578388216
train--38/100 [699/1090] loss: 0.43635419607162473
train--38/100 [709/1090] loss: 0.4422250121831894
train--38/100 [719/1090] loss: 0.45186730921268464
train--38/100 [729/1090] loss: 0.43058042526245116
train--38/100 [739/1090] loss: 0.4673062443733215
train--38/100 [749/1090] loss: 0.4569028228521347
train--38/100 [759/1090] loss: 0.4554201543331146
train--38/100 [769/1090] loss: 0.4371966630220413
train--38/100 [779/1090] loss: 0.435944664478302
train--38/100 [789/1090] loss: 0.47083536386489866
train--38/100 [799/1090] loss: 0.43741242587566376
train--38/100 [809/1090] loss: 0.4475662916898727
train--38/100 [819/1090] loss: 0.4556027203798294
train--38/100 [829/1090] loss: 0.43987504541873934
train--38/100 [839/1090] loss: 0.4496701091527939
train--38/100 [849/1090] loss: 0.46542527377605436
train--38/100 [859/1090] loss: 0.4447301596403122
train--38/100 [869/1090] loss: 0.4493029713630676
train--38/100 [879/1090] loss: 0.46414628624916077
train--38/100 [889/1090] loss: 0.4598238080739975
train--38/100 [899/1090] loss: 0.435760298371315
train--38/100 [909/1090] loss: 0.46147806346416476
train--38/100 [919/1090] loss: 0.4369098871946335
train--38/100 [929/1090] loss: 0.44371221363544466
train--38/100 [939/1090] loss: 0.4652494668960571
train--38/100 [949/1090] loss: 0.4511477053165436
train--38/100 [959/1090] loss: 0.46148393452167513
train--38/100 [969/1090] loss: 0.4336954981088638
train--38/100 [979/1090] loss: 0.4430684596300125
train--38/100 [989/1090] loss: 0.45219002962112426
train--38/100 [999/1090] loss: 0.4367690980434418
train--38/100 [1009/1090] loss: 0.4570748805999756
train--38/100 [1019/1090] loss: 0.4554186135530472
train--38/100 [1029/1090] loss: 0.44969783425331117
train--38/100 [1039/1090] loss: 0.45449957251548767
train--38/100 [1049/1090] loss: 0.4518579840660095
train--38/100 [1059/1090] loss: 0.4457890808582306
train--38/100 [1069/1090] loss: 0.4341531753540039
train--38/100 [1079/1090] loss: 0.47037830352783205
train--38/100 [1089/1090] loss: 0.45886347591876986
predicting model...
val--38/100 [10/1090] acc: 0.795703125
val--38/100 [20/1090] acc: 0.7943359375
val--38/100 [30/1090] acc: 0.79453125
val--38/100 [40/1090] acc: 0.79384765625
val--38/100 [50/1090] acc: 0.792890625
val--38/100 [60/1090] acc: 0.7914713541666667
val--38/100 [70/1090] acc: 0.792578125
val--38/100 [80/1090] acc: 0.791162109375
val--38/100 [90/1090] acc: 0.7914930555555556
val--38/100 [100/1090] acc: 0.7927734375
val--38/100 [110/1090] acc: 0.79296875
val--38/100 [120/1090] acc: 0.7927408854166667
val--38/100 [130/1090] acc: 0.793780048076923
val--38/100 [140/1090] acc: 0.7940011160714285
val--38/100 [150/1090] acc: 0.7940885416666666
val--38/100 [160/1090] acc: 0.7944580078125
val--38/100 [170/1090] acc: 0.7943933823529412
val--38/100 [180/1090] acc: 0.7941840277777777
val--38/100 [190/1090] acc: 0.7949424342105263
val--38/100 [200/1090] acc: 0.79509765625
val--38/100 [210/1090] acc: 0.7954799107142857
val--38/100 [220/1090] acc: 0.7946732954545455
val--38/100 [230/1090] acc: 0.7953464673913043
val--38/100 [240/1090] acc: 0.7950846354166666
val--38/100 [250/1090] acc: 0.79528125
val--38/100 [260/1090] acc: 0.7952524038461538
val--38/100 [270/1090] acc: 0.7954716435185185
val--38/100 [280/1090] acc: 0.7954241071428572
val--38/100 [290/1090] acc: 0.7952451508620689
val--38/100 [300/1090] acc: 0.7951822916666667
val--38/100 [310/1090] acc: 0.7949092741935484
val--38/100 [320/1090] acc: 0.7951904296875
val--38/100 [330/1090] acc: 0.795407196969697
val--38/100 [340/1090] acc: 0.7954848345588236
val--38/100 [350/1090] acc: 0.7956696428571428
val--38/100 [360/1090] acc: 0.7955729166666666
val--38/100 [370/1090] acc: 0.795703125
val--38/100 [380/1090] acc: 0.795641447368421
val--38/100 [390/1090] acc: 0.7954126602564102
val--38/100 [400/1090] acc: 0.795283203125
val--38/100 [410/1090] acc: 0.7955125762195122
val--38/100 [420/1090] acc: 0.7954706101190476
val--38/100 [430/1090] acc: 0.7953579215116279
val--38/100 [440/1090] acc: 0.7953036221590909
val--38/100 [450/1090] acc: 0.7951388888888888
val--38/100 [460/1090] acc: 0.7950407608695652
val--38/100 [470/1090] acc: 0.7949883643617022
val--38/100 [480/1090] acc: 0.7950276692708333
val--38/100 [490/1090] acc: 0.7951291454081633
val--38/100 [500/1090] acc: 0.79528125
val--38/100 [510/1090] acc: 0.7951976102941176
val--38/100 [520/1090] acc: 0.7953350360576923
val--38/100 [530/1090] acc: 0.7953125
val--38/100 [540/1090] acc: 0.7954716435185185
val--38/100 [550/1090] acc: 0.7953764204545455
val--38/100 [560/1090] acc: 0.7951241629464286
val--38/100 [570/1090] acc: 0.7948876096491229
val--38/100 [580/1090] acc: 0.7948679956896552
val--38/100 [590/1090] acc: 0.794921875
val--38/100 [600/1090] acc: 0.7949609375
val--38/100 [610/1090] acc: 0.7948322233606557
val--38/100 [620/1090] acc: 0.7947202620967742
val--38/100 [630/1090] acc: 0.7949404761904761
val--38/100 [640/1090] acc: 0.7951171875
val--38/100 [650/1090] acc: 0.7951141826923077
val--38/100 [660/1090] acc: 0.7949751420454545
val--38/100 [670/1090] acc: 0.7946711753731344
val--38/100 [680/1090] acc: 0.7946174172794118
val--38/100 [690/1090] acc: 0.7947973278985507
val--38/100 [700/1090] acc: 0.7947823660714286
val--38/100 [710/1090] acc: 0.7945587588028169
val--38/100 [720/1090] acc: 0.7943630642361111
val--38/100 [730/1090] acc: 0.7943332619863014
val--38/100 [740/1090] acc: 0.7941986908783784
val--38/100 [750/1090] acc: 0.7942239583333334
val--38/100 [760/1090] acc: 0.7943307976973685
val--38/100 [770/1090] acc: 0.7942978896103896
val--38/100 [780/1090] acc: 0.7942708333333334
val--38/100 [790/1090] acc: 0.7943433544303797
val--38/100 [800/1090] acc: 0.7945458984375
val--38/100 [810/1090] acc: 0.7946132330246913
val--38/100 [820/1090] acc: 0.7947122713414634
val--38/100 [830/1090] acc: 0.7948136295180723
val--38/100 [840/1090] acc: 0.7947544642857143
val--38/100 [850/1090] acc: 0.7947564338235295
val--38/100 [860/1090] acc: 0.7949900072674418
val--38/100 [870/1090] acc: 0.7948455459770115
val--38/100 [880/1090] acc: 0.7948109019886364
val--38/100 [890/1090] acc: 0.7949482092696629
val--38/100 [900/1090] acc: 0.7949565972222222
val--38/100 [910/1090] acc: 0.7949562156593407
val--38/100 [920/1090] acc: 0.7949813179347827
val--38/100 [930/1090] acc: 0.7950856854838709
val--38/100 [940/1090] acc: 0.795096409574468
val--38/100 [950/1090] acc: 0.7949958881578948
val--38/100 [960/1090] acc: 0.7949503580729167
val--38/100 [970/1090] acc: 0.7949339561855671
val--38/100 [980/1090] acc: 0.7949338329081632
val--38/100 [990/1090] acc: 0.794854797979798
val--38/100 [1000/1090] acc: 0.79475390625
val--38/100 [1010/1090] acc: 0.7946163366336634
val--38/100 [1020/1090] acc: 0.794695925245098
val--38/100 [1030/1090] acc: 0.7947398361650485
val--38/100 [1040/1090] acc: 0.7947040264423076
val--38/100 [1050/1090] acc: 0.7947581845238095
val--38/100 [1060/1090] acc: 0.7947155070754717
val--38/100 [1070/1090] acc: 0.7947539427570094
val--38/100 [1080/1090] acc: 0.7947157118055556
val--38/100 [1090/1090] acc: 0.794542001146789
epoch= 38, accuracy= 0.794542, rmse= 0.378317, auc= 0.854858
train--39/100 [9/1090] loss: 0.39463360905647277
train--39/100 [19/1090] loss: 0.43395363390445707
train--39/100 [29/1090] loss: 0.4394438475370407
train--39/100 [39/1090] loss: 0.4389096826314926
train--39/100 [49/1090] loss: 0.4373417109251022
train--39/100 [59/1090] loss: 0.4327336221933365
train--39/100 [69/1090] loss: 0.46197591722011566
train--39/100 [79/1090] loss: 0.44662627279758454
train--39/100 [89/1090] loss: 0.4518697917461395
train--39/100 [99/1090] loss: 0.4279583066701889
train--39/100 [109/1090] loss: 0.4479228347539902
train--39/100 [119/1090] loss: 0.45849124193191526
train--39/100 [129/1090] loss: 0.42962025105953217
train--39/100 [139/1090] loss: 0.4466068297624588
train--39/100 [149/1090] loss: 0.44390669465065
train--39/100 [159/1090] loss: 0.44747897088527677
train--39/100 [169/1090] loss: 0.4558092266321182
train--39/100 [179/1090] loss: 0.4571956187486649
train--39/100 [189/1090] loss: 0.42323535978794097
train--39/100 [199/1090] loss: 0.445333194732666
train--39/100 [209/1090] loss: 0.4165445566177368
train--39/100 [219/1090] loss: 0.453555291891098
train--39/100 [229/1090] loss: 0.4249091684818268
train--39/100 [239/1090] loss: 0.4237311244010925
train--39/100 [249/1090] loss: 0.4500094324350357
train--39/100 [259/1090] loss: 0.44409210085868833
train--39/100 [269/1090] loss: 0.44851355254650116
train--39/100 [279/1090] loss: 0.44414353668689727
train--39/100 [289/1090] loss: 0.450910946726799
train--39/100 [299/1090] loss: 0.4658812940120697
train--39/100 [309/1090] loss: 0.42795256674289706
train--39/100 [319/1090] loss: 0.44223234951496126
train--39/100 [329/1090] loss: 0.44081268906593324
train--39/100 [339/1090] loss: 0.44728205502033236
train--39/100 [349/1090] loss: 0.4266070067882538
train--39/100 [359/1090] loss: 0.4616665869951248
train--39/100 [369/1090] loss: 0.45219568312168124
train--39/100 [379/1090] loss: 0.45664686858654024
train--39/100 [389/1090] loss: 0.4533593118190765
train--39/100 [399/1090] loss: 0.45752995312213895
train--39/100 [409/1090] loss: 0.433635938167572
train--39/100 [419/1090] loss: 0.4524449646472931
train--39/100 [429/1090] loss: 0.4644263118505478
train--39/100 [439/1090] loss: 0.462422513961792
train--39/100 [449/1090] loss: 0.44558132588863375
train--39/100 [459/1090] loss: 0.45673114359378814
train--39/100 [469/1090] loss: 0.447966605424881
train--39/100 [479/1090] loss: 0.4558413803577423
train--39/100 [489/1090] loss: 0.45427314937114716
train--39/100 [499/1090] loss: 0.4368052512407303
train--39/100 [509/1090] loss: 0.4492340892553329
train--39/100 [519/1090] loss: 0.4320105642080307
train--39/100 [529/1090] loss: 0.4725811094045639
train--39/100 [539/1090] loss: 0.45633654296398163
train--39/100 [549/1090] loss: 0.4411264270544052
train--39/100 [559/1090] loss: 0.46012818813323975
train--39/100 [569/1090] loss: 0.43464434146881104
train--39/100 [579/1090] loss: 0.44341816306114196
train--39/100 [589/1090] loss: 0.4427087366580963
train--39/100 [599/1090] loss: 0.438995835185051
train--39/100 [609/1090] loss: 0.4616802394390106
train--39/100 [619/1090] loss: 0.4424924314022064
train--39/100 [629/1090] loss: 0.448613116145134
train--39/100 [639/1090] loss: 0.43407760858535765
train--39/100 [649/1090] loss: 0.4278641134500504
train--39/100 [659/1090] loss: 0.4347922891378403
train--39/100 [669/1090] loss: 0.4367678493261337
train--39/100 [679/1090] loss: 0.45408242046833036
train--39/100 [689/1090] loss: 0.4373167037963867
train--39/100 [699/1090] loss: 0.4407657325267792
train--39/100 [709/1090] loss: 0.45328218936920167
train--39/100 [719/1090] loss: 0.45236795842647554
train--39/100 [729/1090] loss: 0.4587706446647644
train--39/100 [739/1090] loss: 0.4321230471134186
train--39/100 [749/1090] loss: 0.4385598361492157
train--39/100 [759/1090] loss: 0.4632876217365265
train--39/100 [769/1090] loss: 0.4449184983968735
train--39/100 [779/1090] loss: 0.4556545466184616
train--39/100 [789/1090] loss: 0.4665814697742462
train--39/100 [799/1090] loss: 0.45244907438755033
train--39/100 [809/1090] loss: 0.4470216631889343
train--39/100 [819/1090] loss: 0.4441162168979645
train--39/100 [829/1090] loss: 0.42869619429111483
train--39/100 [839/1090] loss: 0.4353238850831985
train--39/100 [849/1090] loss: 0.4312522172927856
train--39/100 [859/1090] loss: 0.443534255027771
train--39/100 [869/1090] loss: 0.4440691649913788
train--39/100 [879/1090] loss: 0.453068333864212
train--39/100 [889/1090] loss: 0.4597078740596771
train--39/100 [899/1090] loss: 0.4530661016702652
train--39/100 [909/1090] loss: 0.44838091135025027
train--39/100 [919/1090] loss: 0.44632461071014407
train--39/100 [929/1090] loss: 0.4489127814769745
train--39/100 [939/1090] loss: 0.4664043664932251
train--39/100 [949/1090] loss: 0.4457633376121521
train--39/100 [959/1090] loss: 0.4407518059015274
train--39/100 [969/1090] loss: 0.44188985228538513
train--39/100 [979/1090] loss: 0.45433287918567655
train--39/100 [989/1090] loss: 0.4697275638580322
train--39/100 [999/1090] loss: 0.46190144419670104
train--39/100 [1009/1090] loss: 0.450717830657959
train--39/100 [1019/1090] loss: 0.4620606780052185
train--39/100 [1029/1090] loss: 0.4383202433586121
train--39/100 [1039/1090] loss: 0.4501073479652405
train--39/100 [1049/1090] loss: 0.44695607721805575
train--39/100 [1059/1090] loss: 0.4584783881902695
train--39/100 [1069/1090] loss: 0.4466384291648865
train--39/100 [1079/1090] loss: 0.4728762686252594
train--39/100 [1089/1090] loss: 0.44592334032058717
predicting model...
val--39/100 [10/1090] acc: 0.792578125
val--39/100 [20/1090] acc: 0.79375
val--39/100 [30/1090] acc: 0.7938802083333333
val--39/100 [40/1090] acc: 0.79404296875
val--39/100 [50/1090] acc: 0.79265625
val--39/100 [60/1090] acc: 0.7914713541666667
val--39/100 [70/1090] acc: 0.7918526785714286
val--39/100 [80/1090] acc: 0.791162109375
val--39/100 [90/1090] acc: 0.7916232638888889
val--39/100 [100/1090] acc: 0.7927734375
val--39/100 [110/1090] acc: 0.7931463068181818
val--39/100 [120/1090] acc: 0.7925455729166667
val--39/100 [130/1090] acc: 0.7936298076923077
val--39/100 [140/1090] acc: 0.79375
val--39/100 [150/1090] acc: 0.793984375
val--39/100 [160/1090] acc: 0.7943115234375
val--39/100 [170/1090] acc: 0.7942555147058824
val--39/100 [180/1090] acc: 0.7940104166666667
val--39/100 [190/1090] acc: 0.7949424342105263
val--39/100 [200/1090] acc: 0.79513671875
val--39/100 [210/1090] acc: 0.7955543154761905
val--39/100 [220/1090] acc: 0.7946732954545455
val--39/100 [230/1090] acc: 0.7953804347826087
val--39/100 [240/1090] acc: 0.7951985677083333
val--39/100 [250/1090] acc: 0.795375
val--39/100 [260/1090] acc: 0.7953425480769231
val--39/100 [270/1090] acc: 0.7954861111111111
val--39/100 [280/1090] acc: 0.7954520089285714
val--39/100 [290/1090] acc: 0.7952855603448276
val--39/100 [300/1090] acc: 0.7952994791666667
val--39/100 [310/1090] acc: 0.7950226814516129
val--39/100 [320/1090] acc: 0.7951904296875
val--39/100 [330/1090] acc: 0.795407196969697
val--39/100 [340/1090] acc: 0.7954963235294118
val--39/100 [350/1090] acc: 0.7956026785714285
val--39/100 [360/1090] acc: 0.7955403645833333
val--39/100 [370/1090] acc: 0.7957136824324325
val--39/100 [380/1090] acc: 0.7956208881578948
val--39/100 [390/1090] acc: 0.7953425480769231
val--39/100 [400/1090] acc: 0.79521484375
val--39/100 [410/1090] acc: 0.7954173018292683
val--39/100 [420/1090] acc: 0.7954055059523809
val--39/100 [430/1090] acc: 0.7953215843023256
val--39/100 [440/1090] acc: 0.7953036221590909
val--39/100 [450/1090] acc: 0.7952256944444445
val--39/100 [460/1090] acc: 0.7951256793478261
val--39/100 [470/1090] acc: 0.7950548537234042
val--39/100 [480/1090] acc: 0.7951334635416667
val--39/100 [490/1090] acc: 0.795280612244898
val--39/100 [500/1090] acc: 0.795453125
val--39/100 [510/1090] acc: 0.795358455882353
val--39/100 [520/1090] acc: 0.7955378605769231
val--39/100 [530/1090] acc: 0.7955557193396227
val--39/100 [540/1090] acc: 0.7956958912037037
val--39/100 [550/1090] acc: 0.7955610795454545
val--39/100 [560/1090] acc: 0.7953055245535714
val--39/100 [570/1090] acc: 0.7950589364035088
val--39/100 [580/1090] acc: 0.7950363685344828
val--39/100 [590/1090] acc: 0.7950807733050848
val--39/100 [600/1090] acc: 0.7951236979166667
val--39/100 [610/1090] acc: 0.794998719262295
val--39/100 [620/1090] acc: 0.7949092741935484
val--39/100 [630/1090] acc: 0.7951264880952381
val--39/100 [640/1090] acc: 0.795306396484375
val--39/100 [650/1090] acc: 0.7953245192307692
val--39/100 [660/1090] acc: 0.7951941287878788
val--39/100 [670/1090] acc: 0.7948868936567164
val--39/100 [680/1090] acc: 0.7947840073529412
val--39/100 [690/1090] acc: 0.7949841485507246
val--39/100 [700/1090] acc: 0.7950055803571429
val--39/100 [710/1090] acc: 0.7947953345070422
val--39/100 [720/1090] acc: 0.7946343315972222
val--39/100 [730/1090] acc: 0.7946222174657535
val--39/100 [740/1090] acc: 0.79453125
val--39/100 [750/1090] acc: 0.79459375
val--39/100 [760/1090] acc: 0.7946803042763158
val--39/100 [770/1090] acc: 0.7946631493506493
val--39/100 [780/1090] acc: 0.7946514423076924
val--39/100 [790/1090] acc: 0.7947240901898734
val--39/100 [800/1090] acc: 0.794951171875
val--39/100 [810/1090] acc: 0.7950279706790123
val--39/100 [820/1090] acc: 0.7951076600609757
val--39/100 [830/1090] acc: 0.7951618975903615
val--39/100 [840/1090] acc: 0.7950706845238096
val--39/100 [850/1090] acc: 0.7951011029411764
val--39/100 [860/1090] acc: 0.7953397529069768
val--39/100 [870/1090] acc: 0.7952002514367816
val--39/100 [880/1090] acc: 0.7951393821022728
val--39/100 [890/1090] acc: 0.7952686095505618
val--39/100 [900/1090] acc: 0.7952430555555555
val--39/100 [910/1090] acc: 0.7952524038461538
val--39/100 [920/1090] acc: 0.7952233355978261
val--39/100 [930/1090] acc: 0.7952998991935484
val--39/100 [940/1090] acc: 0.7953083444148936
val--39/100 [950/1090] acc: 0.7951932565789473
val--39/100 [960/1090] acc: 0.7951416015625
val--39/100 [970/1090] acc: 0.7951272551546392
val--39/100 [980/1090] acc: 0.7951251594387755
val--39/100 [990/1090] acc: 0.7950363005050505
val--39/100 [1000/1090] acc: 0.7949453125
val--39/100 [1010/1090] acc: 0.7948174504950495
val--39/100 [1020/1090] acc: 0.7948720894607844
val--39/100 [1030/1090] acc: 0.7949104975728155
val--39/100 [1040/1090] acc: 0.7948918269230769
val--39/100 [1050/1090] acc: 0.7949553571428571
val--39/100 [1060/1090] acc: 0.7948960790094339
val--39/100 [1070/1090] acc: 0.7949036214953271
val--39/100 [1080/1090] acc: 0.7948640046296296
val--39/100 [1090/1090] acc: 0.7946889334862385
epoch= 39, accuracy= 0.794689, rmse= 0.378282, auc= 0.854820
train--40/100 [9/1090] loss: 0.3929055333137512
train--40/100 [19/1090] loss: 0.44477408528327944
train--40/100 [29/1090] loss: 0.4496529012918472
train--40/100 [39/1090] loss: 0.43957614302635195
train--40/100 [49/1090] loss: 0.4373145461082458
train--40/100 [59/1090] loss: 0.4547511011362076
train--40/100 [69/1090] loss: 0.4461542904376984
train--40/100 [79/1090] loss: 0.43496772944927214
train--40/100 [89/1090] loss: 0.4425956130027771
train--40/100 [99/1090] loss: 0.4542407333850861
train--40/100 [109/1090] loss: 0.43383494913578036
train--40/100 [119/1090] loss: 0.43917541205883026
train--40/100 [129/1090] loss: 0.43618875443935395
train--40/100 [139/1090] loss: 0.44225568771362306
train--40/100 [149/1090] loss: 0.45399240851402284
train--40/100 [159/1090] loss: 0.4358681350946426
train--40/100 [169/1090] loss: 0.43142499327659606
train--40/100 [179/1090] loss: 0.4562347263097763
train--40/100 [189/1090] loss: 0.4612568080425262
train--40/100 [199/1090] loss: 0.43877473175525666
train--40/100 [209/1090] loss: 0.45475654006004335
train--40/100 [219/1090] loss: 0.4412920504808426
train--40/100 [229/1090] loss: 0.446661975979805
train--40/100 [239/1090] loss: 0.4580137372016907
train--40/100 [249/1090] loss: 0.45931157767772673
train--40/100 [259/1090] loss: 0.4525167286396027
train--40/100 [269/1090] loss: 0.4246306359767914
train--40/100 [279/1090] loss: 0.44366910457611086
train--40/100 [289/1090] loss: 0.4405122846364975
train--40/100 [299/1090] loss: 0.4578536510467529
train--40/100 [309/1090] loss: 0.43464415073394774
train--40/100 [319/1090] loss: 0.4529533386230469
train--40/100 [329/1090] loss: 0.438036173582077
train--40/100 [339/1090] loss: 0.445978632569313
train--40/100 [349/1090] loss: 0.42340614199638366
train--40/100 [359/1090] loss: 0.4620883733034134
train--40/100 [369/1090] loss: 0.452109095454216
train--40/100 [379/1090] loss: 0.435854172706604
train--40/100 [389/1090] loss: 0.4545039892196655
train--40/100 [399/1090] loss: 0.44052724838256835
train--40/100 [409/1090] loss: 0.44953770041465757
train--40/100 [419/1090] loss: 0.4280374556779861
train--40/100 [429/1090] loss: 0.44319799840450286
train--40/100 [439/1090] loss: 0.4671222984790802
train--40/100 [449/1090] loss: 0.443056246638298
train--40/100 [459/1090] loss: 0.45089648067951205
train--40/100 [469/1090] loss: 0.44648794233798983
train--40/100 [479/1090] loss: 0.43369280695915224
train--40/100 [489/1090] loss: 0.445154482126236
train--40/100 [499/1090] loss: 0.4417507380247116
train--40/100 [509/1090] loss: 0.4345479667186737
train--40/100 [519/1090] loss: 0.4546251088380814
train--40/100 [529/1090] loss: 0.44668520987033844
train--40/100 [539/1090] loss: 0.4580440253019333
train--40/100 [549/1090] loss: 0.44672049582004547
train--40/100 [559/1090] loss: 0.4442546427249908
train--40/100 [569/1090] loss: 0.44962951838970183
train--40/100 [579/1090] loss: 0.4750561058521271
train--40/100 [589/1090] loss: 0.44685161411762236
train--40/100 [599/1090] loss: 0.4397064208984375
train--40/100 [609/1090] loss: 0.45388689637184143
train--40/100 [619/1090] loss: 0.4482020616531372
train--40/100 [629/1090] loss: 0.4729452580213547
train--40/100 [639/1090] loss: 0.4342366993427277
train--40/100 [649/1090] loss: 0.43610675632953644
train--40/100 [659/1090] loss: 0.45897934436798093
train--40/100 [669/1090] loss: 0.44245382249355314
train--40/100 [679/1090] loss: 0.43977213799953463
train--40/100 [689/1090] loss: 0.42455627024173737
train--40/100 [699/1090] loss: 0.4451224595308304
train--40/100 [709/1090] loss: 0.45671066641807556
train--40/100 [719/1090] loss: 0.4569151759147644
train--40/100 [729/1090] loss: 0.43106757998466494
train--40/100 [739/1090] loss: 0.4502887099981308
train--40/100 [749/1090] loss: 0.44001494646072387
train--40/100 [759/1090] loss: 0.45180792212486265
train--40/100 [769/1090] loss: 0.4469629466533661
train--40/100 [779/1090] loss: 0.459712877869606
train--40/100 [789/1090] loss: 0.4549513399600983
train--40/100 [799/1090] loss: 0.45489577054977415
train--40/100 [809/1090] loss: 0.45352830588817594
train--40/100 [819/1090] loss: 0.4479367733001709
train--40/100 [829/1090] loss: 0.439191997051239
train--40/100 [839/1090] loss: 0.456189826130867
train--40/100 [849/1090] loss: 0.44983249604701997
train--40/100 [859/1090] loss: 0.4467921108007431
train--40/100 [869/1090] loss: 0.45258708000183107
train--40/100 [879/1090] loss: 0.45619587004184725
train--40/100 [889/1090] loss: 0.45098649263381957
train--40/100 [899/1090] loss: 0.4562320113182068
train--40/100 [909/1090] loss: 0.4433990329504013
train--40/100 [919/1090] loss: 0.4502354234457016
train--40/100 [929/1090] loss: 0.4464325666427612
train--40/100 [939/1090] loss: 0.4552947223186493
train--40/100 [949/1090] loss: 0.4468243896961212
train--40/100 [959/1090] loss: 0.4628611087799072
train--40/100 [969/1090] loss: 0.43512155711650846
train--40/100 [979/1090] loss: 0.45783146619796755
train--40/100 [989/1090] loss: 0.41605210304260254
train--40/100 [999/1090] loss: 0.44463413655757905
train--40/100 [1009/1090] loss: 0.44740512371063235
train--40/100 [1019/1090] loss: 0.43727642893791197
train--40/100 [1029/1090] loss: 0.4364080011844635
train--40/100 [1039/1090] loss: 0.4536535620689392
train--40/100 [1049/1090] loss: 0.46897895634174347
train--40/100 [1059/1090] loss: 0.44328026175498964
train--40/100 [1069/1090] loss: 0.4499212771654129
train--40/100 [1079/1090] loss: 0.4487872749567032
train--40/100 [1089/1090] loss: 0.4490146040916443
predicting model...
val--40/100 [10/1090] acc: 0.793359375
val--40/100 [20/1090] acc: 0.7935546875
val--40/100 [30/1090] acc: 0.79375
val--40/100 [40/1090] acc: 0.79375
val--40/100 [50/1090] acc: 0.79265625
val--40/100 [60/1090] acc: 0.7917317708333333
val--40/100 [70/1090] acc: 0.7923549107142858
val--40/100 [80/1090] acc: 0.791259765625
val--40/100 [90/1090] acc: 0.7918402777777778
val--40/100 [100/1090] acc: 0.7928515625
val--40/100 [110/1090] acc: 0.7932173295454545
val--40/100 [120/1090] acc: 0.7928059895833334
val--40/100 [130/1090] acc: 0.7936298076923077
val--40/100 [140/1090] acc: 0.7936662946428571
val--40/100 [150/1090] acc: 0.79359375
val--40/100 [160/1090] acc: 0.7938720703125
val--40/100 [170/1090] acc: 0.7937729779411765
val--40/100 [180/1090] acc: 0.7933376736111111
val--40/100 [190/1090] acc: 0.7943462171052632
val--40/100 [200/1090] acc: 0.7945703125
val--40/100 [210/1090] acc: 0.7949776785714285
val--40/100 [220/1090] acc: 0.7940873579545454
val--40/100 [230/1090] acc: 0.7947860054347826
val--40/100 [240/1090] acc: 0.7946614583333333
val--40/100 [250/1090] acc: 0.794890625
val--40/100 [260/1090] acc: 0.7948317307692307
val--40/100 [270/1090] acc: 0.7950520833333333
val--40/100 [280/1090] acc: 0.7949637276785714
val--40/100 [290/1090] acc: 0.7947602370689655
val--40/100 [300/1090] acc: 0.79484375
val--40/100 [310/1090] acc: 0.7945060483870968
val--40/100 [320/1090] acc: 0.79473876953125
val--40/100 [330/1090] acc: 0.795016571969697
val--40/100 [340/1090] acc: 0.7950597426470588
val--40/100 [350/1090] acc: 0.7951897321428572
val--40/100 [360/1090] acc: 0.7951822916666667
val--40/100 [370/1090] acc: 0.7952913851351351
val--40/100 [380/1090] acc: 0.7952405427631579
val--40/100 [390/1090] acc: 0.7949919871794872
val--40/100 [400/1090] acc: 0.79486328125
val--40/100 [410/1090] acc: 0.7950552591463415
val--40/100 [420/1090] acc: 0.7950148809523809
val--40/100 [430/1090] acc: 0.7949037063953488
val--40/100 [440/1090] acc: 0.7949129971590909
val--40/100 [450/1090] acc: 0.7948177083333333
val--40/100 [460/1090] acc: 0.7946671195652174
val--40/100 [470/1090] acc: 0.7945728058510638
val--40/100 [480/1090] acc: 0.7945475260416667
val--40/100 [490/1090] acc: 0.7947066326530612
val--40/100 [500/1090] acc: 0.794890625
val--40/100 [510/1090] acc: 0.7948376225490196
val--40/100 [520/1090] acc: 0.7950420673076923
val--40/100 [530/1090] acc: 0.7950397995283018
val--40/100 [540/1090] acc: 0.7952039930555556
val--40/100 [550/1090] acc: 0.7950994318181818
val--40/100 [560/1090] acc: 0.7949567522321429
val--40/100 [570/1090] acc: 0.7946820175438597
val--40/100 [580/1090] acc: 0.7946794181034482
val--40/100 [590/1090] acc: 0.7947298728813559
val--40/100 [600/1090] acc: 0.7946875
val--40/100 [610/1090] acc: 0.7945952868852459
val--40/100 [620/1090] acc: 0.7945060483870968
val--40/100 [630/1090] acc: 0.7947172619047619
val--40/100 [640/1090] acc: 0.794921875
val--40/100 [650/1090] acc: 0.7949158653846153
val--40/100 [660/1090] acc: 0.7947857481060606
val--40/100 [670/1090] acc: 0.7945487406716418
val--40/100 [680/1090] acc: 0.7944680606617647
val--40/100 [690/1090] acc: 0.7946784420289855
val--40/100 [700/1090] acc: 0.7947265625
val--40/100 [710/1090] acc: 0.7945477552816902
val--40/100 [720/1090] acc: 0.7943684895833333
val--40/100 [730/1090] acc: 0.7943546660958904
val--40/100 [740/1090] acc: 0.7942778716216217
val--40/100 [750/1090] acc: 0.7943385416666666
val--40/100 [760/1090] acc: 0.7943821957236842
val--40/100 [770/1090] acc: 0.7943435470779221
val--40/100 [780/1090] acc: 0.7943058894230769
val--40/100 [790/1090] acc: 0.7943680775316456
val--40/100 [800/1090] acc: 0.7945849609375
val--40/100 [810/1090] acc: 0.7946566358024691
val--40/100 [820/1090] acc: 0.7947360899390243
val--40/100 [830/1090] acc: 0.7948042168674698
val--40/100 [840/1090] acc: 0.7947498139880952
val--40/100 [850/1090] acc: 0.7947840073529412
val--40/100 [860/1090] acc: 0.7950218023255814
val--40/100 [870/1090] acc: 0.7948769755747126
val--40/100 [880/1090] acc: 0.7947931463068182
val--40/100 [890/1090] acc: 0.7949613764044944
val--40/100 [900/1090] acc: 0.7949522569444445
val--40/100 [910/1090] acc: 0.7949562156593407
val--40/100 [920/1090] acc: 0.7949898097826087
val--40/100 [930/1090] acc: 0.7950772849462365
val--40/100 [940/1090] acc: 0.7950880984042553
val--40/100 [950/1090] acc: 0.794967105263158
val--40/100 [960/1090] acc: 0.794921875
val--40/100 [970/1090] acc: 0.794921875
val--40/100 [980/1090] acc: 0.794937818877551
val--40/100 [990/1090] acc: 0.7948508522727272
val--40/100 [1000/1090] acc: 0.7947578125
val--40/100 [1010/1090] acc: 0.7946163366336634
val--40/100 [1020/1090] acc: 0.794695925245098
val--40/100 [1030/1090] acc: 0.7947436286407767
val--40/100 [1040/1090] acc: 0.7947378305288462
val--40/100 [1050/1090] acc: 0.7947805059523809
val--40/100 [1060/1090] acc: 0.7947228773584906
val--40/100 [1070/1090] acc: 0.794713785046729
val--40/100 [1080/1090] acc: 0.7946578414351851
val--40/100 [1090/1090] acc: 0.7944954128440367
epoch= 40, accuracy= 0.794495, rmse= 0.378302, auc= 0.854749
train--41/100 [9/1090] loss: 0.4085111081600189
train--41/100 [19/1090] loss: 0.4434902310371399
train--41/100 [29/1090] loss: 0.4264035910367966
train--41/100 [39/1090] loss: 0.4355625331401825
train--41/100 [49/1090] loss: 0.4422887831926346
train--41/100 [59/1090] loss: 0.4374639570713043
train--41/100 [69/1090] loss: 0.4312614530324936
train--41/100 [79/1090] loss: 0.4395199328660965
train--41/100 [89/1090] loss: 0.42761015295982363
train--41/100 [99/1090] loss: 0.43714825212955477
train--41/100 [109/1090] loss: 0.4367181330919266
train--41/100 [119/1090] loss: 0.43835831582546236
train--41/100 [129/1090] loss: 0.44849141538143156
train--41/100 [139/1090] loss: 0.44276503324508665
train--41/100 [149/1090] loss: 0.4281657189130783
train--41/100 [159/1090] loss: 0.43467003107070923
train--41/100 [169/1090] loss: 0.4575772315263748
train--41/100 [179/1090] loss: 0.4508133590221405
train--41/100 [189/1090] loss: 0.4346824258565903
train--41/100 [199/1090] loss: 0.45910834074020385
train--41/100 [209/1090] loss: 0.45324483811855315
train--41/100 [219/1090] loss: 0.42979282736778257
train--41/100 [229/1090] loss: 0.4421629041433334
train--41/100 [239/1090] loss: 0.4348895579576492
train--41/100 [249/1090] loss: 0.43335574865341187
train--41/100 [259/1090] loss: 0.4487439185380936
train--41/100 [269/1090] loss: 0.42836126387119294
train--41/100 [279/1090] loss: 0.4419703483581543
train--41/100 [289/1090] loss: 0.43873284161090853
train--41/100 [299/1090] loss: 0.4632587283849716
train--41/100 [309/1090] loss: 0.4383126527070999
train--41/100 [319/1090] loss: 0.44715675711631775
train--41/100 [329/1090] loss: 0.4638878434896469
train--41/100 [339/1090] loss: 0.4643524795770645
train--41/100 [349/1090] loss: 0.44165083169937136
train--41/100 [359/1090] loss: 0.4378170967102051
train--41/100 [369/1090] loss: 0.45220058858394624
train--41/100 [379/1090] loss: 0.45333299338817595
train--41/100 [389/1090] loss: 0.44024198055267333
train--41/100 [399/1090] loss: 0.44669547080993655
train--41/100 [409/1090] loss: 0.4377074807882309
train--41/100 [419/1090] loss: 0.451100218296051
train--41/100 [429/1090] loss: 0.45436997413635255
train--41/100 [439/1090] loss: 0.471326208114624
train--41/100 [449/1090] loss: 0.42037123441696167
train--41/100 [459/1090] loss: 0.4512973964214325
train--41/100 [469/1090] loss: 0.4349805474281311
train--41/100 [479/1090] loss: 0.45317301750183103
train--41/100 [489/1090] loss: 0.42568921446800234
train--41/100 [499/1090] loss: 0.4398005485534668
train--41/100 [509/1090] loss: 0.4629927933216095
train--41/100 [519/1090] loss: 0.44190881848335267
train--41/100 [529/1090] loss: 0.45133275389671323
train--41/100 [539/1090] loss: 0.4373264670372009
train--41/100 [549/1090] loss: 0.45331862270832063
train--41/100 [559/1090] loss: 0.4454492300748825
train--41/100 [569/1090] loss: 0.45371017754077914
train--41/100 [579/1090] loss: 0.4477251172065735
train--41/100 [589/1090] loss: 0.4407597541809082
train--41/100 [599/1090] loss: 0.45717850923538206
train--41/100 [609/1090] loss: 0.448256117105484
train--41/100 [619/1090] loss: 0.4695288896560669
train--41/100 [629/1090] loss: 0.4405852764844894
train--41/100 [639/1090] loss: 0.4221749186515808
train--41/100 [649/1090] loss: 0.4478266775608063
train--41/100 [659/1090] loss: 0.46005888283252716
train--41/100 [669/1090] loss: 0.45399350523948667
train--41/100 [679/1090] loss: 0.4432291179895401
train--41/100 [689/1090] loss: 0.45199416279792787
train--41/100 [699/1090] loss: 0.44600113332271574
train--41/100 [709/1090] loss: 0.44149091839790344
train--41/100 [719/1090] loss: 0.4600983440876007
train--41/100 [729/1090] loss: 0.4547108173370361
train--41/100 [739/1090] loss: 0.44876463115215304
train--41/100 [749/1090] loss: 0.4530079811811447
train--41/100 [759/1090] loss: 0.44710971117019654
train--41/100 [769/1090] loss: 0.44946998357772827
train--41/100 [779/1090] loss: 0.45300074815750124
train--41/100 [789/1090] loss: 0.4378219097852707
train--41/100 [799/1090] loss: 0.4533334463834763
train--41/100 [809/1090] loss: 0.4512150526046753
train--41/100 [819/1090] loss: 0.4356900542974472
train--41/100 [829/1090] loss: 0.4457554131746292
train--41/100 [839/1090] loss: 0.472944113612175
train--41/100 [849/1090] loss: 0.43321168422698975
train--41/100 [859/1090] loss: 0.43690951764583585
train--41/100 [869/1090] loss: 0.43690218925476076
train--41/100 [879/1090] loss: 0.4599891394376755
train--41/100 [889/1090] loss: 0.46094058752059935
train--41/100 [899/1090] loss: 0.47007515132427213
train--41/100 [909/1090] loss: 0.4406615287065506
train--41/100 [919/1090] loss: 0.45771586894989014
train--41/100 [929/1090] loss: 0.4571760505437851
train--41/100 [939/1090] loss: 0.4626561373472214
train--41/100 [949/1090] loss: 0.42888745963573455
train--41/100 [959/1090] loss: 0.4630918562412262
train--41/100 [969/1090] loss: 0.4619017720222473
train--41/100 [979/1090] loss: 0.44033866226673124
train--41/100 [989/1090] loss: 0.4446204215288162
train--41/100 [999/1090] loss: 0.4541399091482162
train--41/100 [1009/1090] loss: 0.45983934700489043
train--41/100 [1019/1090] loss: 0.448973560333252
train--41/100 [1029/1090] loss: 0.45068581998348234
train--41/100 [1039/1090] loss: 0.4440296620130539
train--41/100 [1049/1090] loss: 0.45626349449157716
train--41/100 [1059/1090] loss: 0.46062824726104734
train--41/100 [1069/1090] loss: 0.44502400159835814
train--41/100 [1079/1090] loss: 0.4228776663541794
train--41/100 [1089/1090] loss: 0.4719746559858322
predicting model...
val--41/100 [10/1090] acc: 0.79296875
val--41/100 [20/1090] acc: 0.7939453125
val--41/100 [30/1090] acc: 0.79296875
val--41/100 [40/1090] acc: 0.79287109375
val--41/100 [50/1090] acc: 0.79203125
val--41/100 [60/1090] acc: 0.7912760416666667
val--41/100 [70/1090] acc: 0.791796875
val--41/100 [80/1090] acc: 0.790576171875
val--41/100 [90/1090] acc: 0.7915364583333333
val--41/100 [100/1090] acc: 0.7927734375
val--41/100 [110/1090] acc: 0.7928977272727272
val--41/100 [120/1090] acc: 0.7923828125
val--41/100 [130/1090] acc: 0.7934795673076923
val--41/100 [140/1090] acc: 0.7937220982142857
val--41/100 [150/1090] acc: 0.793828125
val--41/100 [160/1090] acc: 0.794140625
val--41/100 [170/1090] acc: 0.7941176470588235
val--41/100 [180/1090] acc: 0.7938802083333333
val--41/100 [190/1090] acc: 0.7946134868421053
val--41/100 [200/1090] acc: 0.7948828125
val--41/100 [210/1090] acc: 0.7952380952380952
val--41/100 [220/1090] acc: 0.7942826704545455
val--41/100 [230/1090] acc: 0.794921875
val--41/100 [240/1090] acc: 0.7948079427083333
val--41/100 [250/1090] acc: 0.795
val--41/100 [260/1090] acc: 0.7949519230769231
val--41/100 [270/1090] acc: 0.7952112268518519
val--41/100 [280/1090] acc: 0.7951590401785714
val--41/100 [290/1090] acc: 0.7949622844827586
val--41/100 [300/1090] acc: 0.7950390625
val--41/100 [310/1090] acc: 0.7947706653225807
val--41/100 [320/1090] acc: 0.79493408203125
val--41/100 [330/1090] acc: 0.7952296401515152
val--41/100 [340/1090] acc: 0.7952780330882353
val--41/100 [350/1090] acc: 0.7953794642857143
val--41/100 [360/1090] acc: 0.7953233506944445
val--41/100 [370/1090] acc: 0.7954497466216216
val--41/100 [380/1090] acc: 0.7953947368421053
val--41/100 [390/1090] acc: 0.7951322115384616
val--41/100 [400/1090] acc: 0.795048828125
val--41/100 [410/1090] acc: 0.7951981707317073
val--41/100 [420/1090] acc: 0.7951729910714286
val--41/100 [430/1090] acc: 0.7950581395348837
val--41/100 [440/1090] acc: 0.7950639204545454
val--41/100 [450/1090] acc: 0.7949739583333333
val--41/100 [460/1090] acc: 0.7948624320652173
val--41/100 [470/1090] acc: 0.7947972074468085
val--41/100 [480/1090] acc: 0.7948079427083333
val--41/100 [490/1090] acc: 0.7950255102040816
val--41/100 [500/1090] acc: 0.7951796875
val--41/100 [510/1090] acc: 0.7950520833333333
val--41/100 [520/1090] acc: 0.7952298677884615
val--41/100 [530/1090] acc: 0.795201945754717
val--41/100 [540/1090] acc: 0.7953486689814815
val--41/100 [550/1090] acc: 0.7952556818181818
val--41/100 [560/1090] acc: 0.7950753348214286
val--41/100 [570/1090] acc: 0.7948807565789474
val--41/100 [580/1090] acc: 0.794861260775862
val--41/100 [590/1090] acc: 0.7948490466101695
val--41/100 [600/1090] acc: 0.7947981770833333
val--41/100 [610/1090] acc: 0.7947297643442623
val--41/100 [620/1090] acc: 0.7946446572580645
val--41/100 [630/1090] acc: 0.7948412698412698
val--41/100 [640/1090] acc: 0.795025634765625
val--41/100 [650/1090] acc: 0.7950360576923077
val--41/100 [660/1090] acc: 0.7949041193181818
val--41/100 [670/1090] acc: 0.7946012126865671
val--41/100 [680/1090] acc: 0.7944795496323529
val--41/100 [690/1090] acc: 0.7946727807971015
val--41/100 [700/1090] acc: 0.7946875
val--41/100 [710/1090] acc: 0.7945477552816902
val--41/100 [720/1090] acc: 0.7944010416666667
val--41/100 [730/1090] acc: 0.7943600171232876
val--41/100 [740/1090] acc: 0.7942989864864864
val--41/100 [750/1090] acc: 0.794359375
val--41/100 [760/1090] acc: 0.7944490131578947
val--41/100 [770/1090] acc: 0.7944703733766234
val--41/100 [780/1090] acc: 0.7944060496794871
val--41/100 [790/1090] acc: 0.7944620253164557
val--41/100 [800/1090] acc: 0.7946875
val--41/100 [810/1090] acc: 0.7947579089506173
val--41/100 [820/1090] acc: 0.7948361280487805
val--41/100 [830/1090] acc: 0.7948936370481928
val--41/100 [840/1090] acc: 0.7948614211309524
val--41/100 [850/1090] acc: 0.794889705882353
val--41/100 [860/1090] acc: 0.7950808502906976
val--41/100 [870/1090] acc: 0.7949173850574712
val--41/100 [880/1090] acc: 0.794864169034091
val--41/100 [890/1090] acc: 0.7949964887640449
val--41/100 [900/1090] acc: 0.7949479166666666
val--41/100 [910/1090] acc: 0.7949047046703297
val--41/100 [920/1090] acc: 0.7948963994565217
val--41/100 [930/1090] acc: 0.7949722782258064
val--41/100 [940/1090] acc: 0.7950174534574468
val--41/100 [950/1090] acc: 0.7949013157894737
val--41/100 [960/1090] acc: 0.7948323567708333
val--41/100 [970/1090] acc: 0.7948252255154639
val--41/100 [980/1090] acc: 0.7948182397959184
val--41/100 [990/1090] acc: 0.7947285353535354
val--41/100 [1000/1090] acc: 0.79466015625
val--41/100 [1010/1090] acc: 0.7945235148514852
val--41/100 [1020/1090] acc: 0.7945886948529411
val--41/100 [1030/1090] acc: 0.7946222694174757
val--41/100 [1040/1090] acc: 0.7946101262019231
val--41/100 [1050/1090] acc: 0.7946726190476191
val--41/100 [1060/1090] acc: 0.7946049528301887
val--41/100 [1070/1090] acc: 0.7945714077102803
val--41/100 [1080/1090] acc: 0.7945167824074074
val--41/100 [1090/1090] acc: 0.7943950688073395
epoch= 41, accuracy= 0.794395, rmse= 0.378321, auc= 0.854731
train--42/100 [9/1090] loss: 0.3994443237781525
train--42/100 [19/1090] loss: 0.44928704500198363
train--42/100 [29/1090] loss: 0.46400700211524964
train--42/100 [39/1090] loss: 0.4460276931524277
train--42/100 [49/1090] loss: 0.4601624310016632
train--42/100 [59/1090] loss: 0.4269927114248276
train--42/100 [69/1090] loss: 0.4387559533119202
train--42/100 [79/1090] loss: 0.4462649017572403
train--42/100 [89/1090] loss: 0.4472276359796524
train--42/100 [99/1090] loss: 0.43409275710582734
train--42/100 [109/1090] loss: 0.4585836470127106
train--42/100 [119/1090] loss: 0.43357037007808685
train--42/100 [129/1090] loss: 0.4415204882621765
train--42/100 [139/1090] loss: 0.426581209897995
train--42/100 [149/1090] loss: 0.4587628185749054
train--42/100 [159/1090] loss: 0.4309671401977539
train--42/100 [169/1090] loss: 0.4441248744726181
train--42/100 [179/1090] loss: 0.4437349051237106
train--42/100 [189/1090] loss: 0.4378780335187912
train--42/100 [199/1090] loss: 0.4390924572944641
train--42/100 [209/1090] loss: 0.4375070661306381
train--42/100 [219/1090] loss: 0.4367215037345886
train--42/100 [229/1090] loss: 0.4359097480773926
train--42/100 [239/1090] loss: 0.4433988660573959
train--42/100 [249/1090] loss: 0.432535320520401
train--42/100 [259/1090] loss: 0.4408575654029846
train--42/100 [269/1090] loss: 0.4664670318365097
train--42/100 [279/1090] loss: 0.44494002759456636
train--42/100 [289/1090] loss: 0.43787840008735657
train--42/100 [299/1090] loss: 0.45519431233406066
train--42/100 [309/1090] loss: 0.4461503028869629
train--42/100 [319/1090] loss: 0.47010843753814696
train--42/100 [329/1090] loss: 0.42921743392944334
train--42/100 [339/1090] loss: 0.44125779569149015
train--42/100 [349/1090] loss: 0.44605274200439454
train--42/100 [359/1090] loss: 0.43146897554397584
train--42/100 [369/1090] loss: 0.45239650905132295
train--42/100 [379/1090] loss: 0.4349547028541565
train--42/100 [389/1090] loss: 0.42963042855262756
train--42/100 [399/1090] loss: 0.4314525932073593
train--42/100 [409/1090] loss: 0.4367195636034012
train--42/100 [419/1090] loss: 0.4520882278680801
train--42/100 [429/1090] loss: 0.4473150223493576
train--42/100 [439/1090] loss: 0.4453271120786667
train--42/100 [449/1090] loss: 0.4536110877990723
train--42/100 [459/1090] loss: 0.4377833753824234
train--42/100 [469/1090] loss: 0.41657941937446596
train--42/100 [479/1090] loss: 0.4464252978563309
train--42/100 [489/1090] loss: 0.438516891002655
train--42/100 [499/1090] loss: 0.4470458537340164
train--42/100 [509/1090] loss: 0.456245419383049
train--42/100 [519/1090] loss: 0.4410017430782318
train--42/100 [529/1090] loss: 0.4501559793949127
train--42/100 [539/1090] loss: 0.4424352914094925
train--42/100 [549/1090] loss: 0.45026820302009585
train--42/100 [559/1090] loss: 0.4470961332321167
train--42/100 [569/1090] loss: 0.456172040104866
train--42/100 [579/1090] loss: 0.4377144753932953
train--42/100 [589/1090] loss: 0.4500967115163803
train--42/100 [599/1090] loss: 0.4741087883710861
train--42/100 [609/1090] loss: 0.4382501423358917
train--42/100 [619/1090] loss: 0.4527885615825653
train--42/100 [629/1090] loss: 0.4605648726224899
train--42/100 [639/1090] loss: 0.44202483892440797
train--42/100 [649/1090] loss: 0.44944396913051604
train--42/100 [659/1090] loss: 0.44526396691799164
train--42/100 [669/1090] loss: 0.45555858314037323
train--42/100 [679/1090] loss: 0.44987495243549347
train--42/100 [689/1090] loss: 0.4578709125518799
train--42/100 [699/1090] loss: 0.45189960300922394
train--42/100 [709/1090] loss: 0.451625794172287
train--42/100 [719/1090] loss: 0.4460233271121979
train--42/100 [729/1090] loss: 0.45595163106918335
train--42/100 [739/1090] loss: 0.4474260717630386
train--42/100 [749/1090] loss: 0.4256257176399231
train--42/100 [759/1090] loss: 0.42740061283111574
train--42/100 [769/1090] loss: 0.4342807918787003
train--42/100 [779/1090] loss: 0.44534766376018525
train--42/100 [789/1090] loss: 0.4570727735757828
train--42/100 [799/1090] loss: 0.45907593965530397
train--42/100 [809/1090] loss: 0.445012828707695
train--42/100 [819/1090] loss: 0.4389482200145721
train--42/100 [829/1090] loss: 0.4339937925338745
train--42/100 [839/1090] loss: 0.4399262070655823
train--42/100 [849/1090] loss: 0.4634923428297043
train--42/100 [859/1090] loss: 0.435402649641037
train--42/100 [869/1090] loss: 0.4574894100427628
train--42/100 [879/1090] loss: 0.44931442439556124
train--42/100 [889/1090] loss: 0.4574603945016861
train--42/100 [899/1090] loss: 0.46619141697883604
train--42/100 [909/1090] loss: 0.4541064023971558
train--42/100 [919/1090] loss: 0.44539250135421754
train--42/100 [929/1090] loss: 0.4546519070863724
train--42/100 [939/1090] loss: 0.4644240468740463
train--42/100 [949/1090] loss: 0.44512724578380586
train--42/100 [959/1090] loss: 0.44738746881484986
train--42/100 [969/1090] loss: 0.45093537867069244
train--42/100 [979/1090] loss: 0.46190189719200136
train--42/100 [989/1090] loss: 0.4585627645254135
train--42/100 [999/1090] loss: 0.4695742666721344
train--42/100 [1009/1090] loss: 0.4514553636312485
train--42/100 [1019/1090] loss: 0.4503982990980148
train--42/100 [1029/1090] loss: 0.4562465101480484
train--42/100 [1039/1090] loss: 0.4486279398202896
train--42/100 [1049/1090] loss: 0.422135654091835
train--42/100 [1059/1090] loss: 0.4498119652271271
train--42/100 [1069/1090] loss: 0.4525100409984589
train--42/100 [1079/1090] loss: 0.45864546298980713
train--42/100 [1089/1090] loss: 0.4444965451955795
predicting model...
val--42/100 [10/1090] acc: 0.796875
val--42/100 [20/1090] acc: 0.7966796875
val--42/100 [30/1090] acc: 0.7951822916666667
val--42/100 [40/1090] acc: 0.79521484375
val--42/100 [50/1090] acc: 0.79421875
val--42/100 [60/1090] acc: 0.79296875
val--42/100 [70/1090] acc: 0.7935267857142857
val--42/100 [80/1090] acc: 0.7919921875
val--42/100 [90/1090] acc: 0.792578125
val--42/100 [100/1090] acc: 0.7934375
val--42/100 [110/1090] acc: 0.7938920454545455
val--42/100 [120/1090] acc: 0.7932942708333334
val--42/100 [130/1090] acc: 0.7942608173076923
val--42/100 [140/1090] acc: 0.7944754464285714
val--42/100 [150/1090] acc: 0.7945052083333334
val--42/100 [160/1090] acc: 0.794677734375
val--42/100 [170/1090] acc: 0.7946231617647059
val--42/100 [180/1090] acc: 0.7943359375
val--42/100 [190/1090] acc: 0.795250822368421
val--42/100 [200/1090] acc: 0.79537109375
val--42/100 [210/1090] acc: 0.7957775297619047
val--42/100 [220/1090] acc: 0.7948153409090909
val--42/100 [230/1090] acc: 0.795414402173913
val--42/100 [240/1090] acc: 0.7952799479166667
val--42/100 [250/1090] acc: 0.795359375
val--42/100 [260/1090] acc: 0.7952974759615384
val--42/100 [270/1090] acc: 0.7955295138888889
val--42/100 [280/1090] acc: 0.7954241071428572
val--42/100 [290/1090] acc: 0.7951912715517241
val--42/100 [300/1090] acc: 0.79515625
val--42/100 [310/1090] acc: 0.7948966733870968
val--42/100 [320/1090] acc: 0.7951171875
val--42/100 [330/1090] acc: 0.7953480113636363
val--42/100 [340/1090] acc: 0.7954848345588236
val--42/100 [350/1090] acc: 0.7955915178571429
val--42/100 [360/1090] acc: 0.7954969618055555
val--42/100 [370/1090] acc: 0.7956925675675676
val--42/100 [380/1090] acc: 0.7956620065789474
val--42/100 [390/1090] acc: 0.795352564102564
val--42/100 [400/1090] acc: 0.795244140625
val--42/100 [410/1090] acc: 0.7954649390243902
val--42/100 [420/1090] acc: 0.7954706101190476
val--42/100 [430/1090] acc: 0.7953942587209303
val--42/100 [440/1090] acc: 0.7953391335227272
val--42/100 [450/1090] acc: 0.7951996527777778
val--42/100 [460/1090] acc: 0.7951002038043479
val--42/100 [470/1090] acc: 0.7950465425531915
val--42/100 [480/1090] acc: 0.7950520833333333
val--42/100 [490/1090] acc: 0.7952088647959183
val--42/100 [500/1090] acc: 0.795421875
val--42/100 [510/1090] acc: 0.7953278186274509
val--42/100 [520/1090] acc: 0.7954702524038462
val--42/100 [530/1090] acc: 0.7954156839622641
val--42/100 [540/1090] acc: 0.7955439814814815
val--42/100 [550/1090] acc: 0.7954829545454546
val--42/100 [560/1090] acc: 0.7952915736607142
val--42/100 [570/1090] acc: 0.7950452302631579
val--42/100 [580/1090] acc: 0.795049838362069
val--42/100 [590/1090] acc: 0.7951337394067797
val--42/100 [600/1090] acc: 0.79513671875
val--42/100 [610/1090] acc: 0.7950179303278688
val--42/100 [620/1090] acc: 0.794953377016129
val--42/100 [630/1090] acc: 0.7951264880952381
val--42/100 [640/1090] acc: 0.795269775390625
val--42/100 [650/1090] acc: 0.7952704326923077
val--42/100 [660/1090] acc: 0.7951586174242424
val--42/100 [670/1090] acc: 0.7948694029850746
val--42/100 [680/1090] acc: 0.7947323069852941
val--42/100 [690/1090] acc: 0.7948765851449275
val--42/100 [700/1090] acc: 0.7949274553571428
val--42/100 [710/1090] acc: 0.7947183098591549
val--42/100 [720/1090] acc: 0.7945529513888889
val--42/100 [730/1090] acc: 0.7945151969178083
val--42/100 [740/1090] acc: 0.7944679054054054
val--42/100 [750/1090] acc: 0.79453125
val--42/100 [760/1090] acc: 0.7945518092105263
val--42/100 [770/1090] acc: 0.7945008116883117
val--42/100 [780/1090] acc: 0.7944811698717948
val--42/100 [790/1090] acc: 0.7945559731012658
val--42/100 [800/1090] acc: 0.79478515625
val--42/100 [810/1090] acc: 0.7948495370370371
val--42/100 [820/1090] acc: 0.7949552210365853
val--42/100 [830/1090] acc: 0.7950442394578313
val--42/100 [840/1090] acc: 0.7949683779761905
val--42/100 [850/1090] acc: 0.7950183823529412
val--42/100 [860/1090] acc: 0.7952579941860465
val--42/100 [870/1090] acc: 0.795141882183908
val--42/100 [880/1090] acc: 0.7950949928977272
val--42/100 [890/1090] acc: 0.7952027738764045
val--42/100 [900/1090] acc: 0.7951953125
val--42/100 [910/1090] acc: 0.7952223557692307
val--42/100 [920/1090] acc: 0.79521484375
val--42/100 [930/1090] acc: 0.7953293010752688
val--42/100 [940/1090] acc: 0.7953582114361702
val--42/100 [950/1090] acc: 0.795217927631579
val--42/100 [960/1090] acc: 0.7951131184895833
val--42/100 [970/1090] acc: 0.7950910115979382
val--42/100 [980/1090] acc: 0.7950892857142857
val--42/100 [990/1090] acc: 0.7950007891414141
val--42/100 [1000/1090] acc: 0.79491015625
val--42/100 [1010/1090] acc: 0.7947787747524753
val--42/100 [1020/1090] acc: 0.7948337928921568
val--42/100 [1030/1090] acc: 0.7948422330097087
val--42/100 [1040/1090] acc: 0.7948016826923077
val--42/100 [1050/1090] acc: 0.79484375
val--42/100 [1060/1090] acc: 0.7947781544811321
val--42/100 [1070/1090] acc: 0.7947867990654206
val--42/100 [1080/1090] acc: 0.7946903935185186
val--42/100 [1090/1090] acc: 0.794552752293578
epoch= 42, accuracy= 0.794553, rmse= 0.378194, auc= 0.854900
train--43/100 [9/1090] loss: 0.40027100443840025
train--43/100 [19/1090] loss: 0.44515026807785035
train--43/100 [29/1090] loss: 0.44331459105014803
train--43/100 [39/1090] loss: 0.43899224102497103
train--43/100 [49/1090] loss: 0.4476967006921768
train--43/100 [59/1090] loss: 0.4405811786651611
train--43/100 [69/1090] loss: 0.44374131560325625
train--43/100 [79/1090] loss: 0.4384451687335968
train--43/100 [89/1090] loss: 0.44473904371261597
train--43/100 [99/1090] loss: 0.4404781132936478
train--43/100 [109/1090] loss: 0.42467032074928285
train--43/100 [119/1090] loss: 0.42269709408283235
train--43/100 [129/1090] loss: 0.44978053867816925
train--43/100 [139/1090] loss: 0.4434669643640518
train--43/100 [149/1090] loss: 0.4517770230770111
train--43/100 [159/1090] loss: 0.43248975872993467
train--43/100 [169/1090] loss: 0.4472077935934067
train--43/100 [179/1090] loss: 0.4552613377571106
train--43/100 [189/1090] loss: 0.460397270321846
train--43/100 [199/1090] loss: 0.45950607061386106
train--43/100 [209/1090] loss: 0.4503632843494415
train--43/100 [219/1090] loss: 0.4335504323244095
train--43/100 [229/1090] loss: 0.43401203155517576
train--43/100 [239/1090] loss: 0.44746200144290926
train--43/100 [249/1090] loss: 0.4507373571395874
train--43/100 [259/1090] loss: 0.4312356859445572
train--43/100 [269/1090] loss: 0.4282699257135391
train--43/100 [279/1090] loss: 0.4312792539596558
train--43/100 [289/1090] loss: 0.44468770623207093
train--43/100 [299/1090] loss: 0.4599033951759338
train--43/100 [309/1090] loss: 0.4504408836364746
train--43/100 [319/1090] loss: 0.43400337994098664
train--43/100 [329/1090] loss: 0.4399935305118561
train--43/100 [339/1090] loss: 0.4731567412614822
train--43/100 [349/1090] loss: 0.44730031192302705
train--43/100 [359/1090] loss: 0.4265584409236908
train--43/100 [369/1090] loss: 0.44953500032424926
train--43/100 [379/1090] loss: 0.4276194840669632
train--43/100 [389/1090] loss: 0.4609431564807892
train--43/100 [399/1090] loss: 0.46467346251010894
train--43/100 [409/1090] loss: 0.4605373919010162
train--43/100 [419/1090] loss: 0.4479970633983612
train--43/100 [429/1090] loss: 0.43058440685272215
train--43/100 [439/1090] loss: 0.4365808516740799
train--43/100 [449/1090] loss: 0.45203188955783846
train--43/100 [459/1090] loss: 0.4477360606193542
train--43/100 [469/1090] loss: 0.44849165081977843
train--43/100 [479/1090] loss: 0.43101310133934023
train--43/100 [489/1090] loss: 0.4570048153400421
train--43/100 [499/1090] loss: 0.4399802088737488
train--43/100 [509/1090] loss: 0.4355219453573227
train--43/100 [519/1090] loss: 0.4539992243051529
train--43/100 [529/1090] loss: 0.43082315325737
train--43/100 [539/1090] loss: 0.46201362609863283
train--43/100 [549/1090] loss: 0.45167494416236875
train--43/100 [559/1090] loss: 0.46381320953369143
train--43/100 [569/1090] loss: 0.4537414699792862
train--43/100 [579/1090] loss: 0.43902082443237306
train--43/100 [589/1090] loss: 0.4562485605478287
train--43/100 [599/1090] loss: 0.4537948489189148
train--43/100 [609/1090] loss: 0.4499492973089218
train--43/100 [619/1090] loss: 0.44890877306461335
train--43/100 [629/1090] loss: 0.43626687228679656
train--43/100 [639/1090] loss: 0.4291662245988846
train--43/100 [649/1090] loss: 0.4356903344392776
train--43/100 [659/1090] loss: 0.4458418607711792
train--43/100 [669/1090] loss: 0.45370895266532896
train--43/100 [679/1090] loss: 0.43851629495620725
train--43/100 [689/1090] loss: 0.4578696936368942
train--43/100 [699/1090] loss: 0.470966774225235
train--43/100 [709/1090] loss: 0.4542557954788208
train--43/100 [719/1090] loss: 0.44625996351242064
train--43/100 [729/1090] loss: 0.4647564828395844
train--43/100 [739/1090] loss: 0.44564005434513093
train--43/100 [749/1090] loss: 0.4384250044822693
train--43/100 [759/1090] loss: 0.44241017997264864
train--43/100 [769/1090] loss: 0.45861257016658785
train--43/100 [779/1090] loss: 0.4610375642776489
train--43/100 [789/1090] loss: 0.42380922138690946
train--43/100 [799/1090] loss: 0.4530940055847168
train--43/100 [809/1090] loss: 0.4784113258123398
train--43/100 [819/1090] loss: 0.44184347689151765
train--43/100 [829/1090] loss: 0.4579811543226242
train--43/100 [839/1090] loss: 0.4297089666128159
train--43/100 [849/1090] loss: 0.4481004327535629
train--43/100 [859/1090] loss: 0.44114136397838594
train--43/100 [869/1090] loss: 0.437287038564682
train--43/100 [879/1090] loss: 0.4466386616230011
train--43/100 [889/1090] loss: 0.44769310057163236
train--43/100 [899/1090] loss: 0.43420192301273347
train--43/100 [909/1090] loss: 0.4570127695798874
train--43/100 [919/1090] loss: 0.4398153454065323
train--43/100 [929/1090] loss: 0.442577651143074
train--43/100 [939/1090] loss: 0.44638983607292176
train--43/100 [949/1090] loss: 0.4557637214660645
train--43/100 [959/1090] loss: 0.44891821444034574
train--43/100 [969/1090] loss: 0.45762312412261963
train--43/100 [979/1090] loss: 0.4458383321762085
train--43/100 [989/1090] loss: 0.44611639380455015
train--43/100 [999/1090] loss: 0.4277328699827194
train--43/100 [1009/1090] loss: 0.4595318794250488
train--43/100 [1019/1090] loss: 0.4330040246248245
train--43/100 [1029/1090] loss: 0.4688878059387207
train--43/100 [1039/1090] loss: 0.436329060792923
train--43/100 [1049/1090] loss: 0.46268164217472074
train--43/100 [1059/1090] loss: 0.44725890159606935
train--43/100 [1069/1090] loss: 0.4617650955915451
train--43/100 [1079/1090] loss: 0.4525084048509598
train--43/100 [1089/1090] loss: 0.44325228333473204
predicting model...
val--43/100 [10/1090] acc: 0.795703125
val--43/100 [20/1090] acc: 0.7955078125
val--43/100 [30/1090] acc: 0.7950520833333333
val--43/100 [40/1090] acc: 0.7947265625
val--43/100 [50/1090] acc: 0.794140625
val--43/100 [60/1090] acc: 0.7927734375
val--43/100 [70/1090] acc: 0.7934151785714286
val--43/100 [80/1090] acc: 0.79228515625
val--43/100 [90/1090] acc: 0.7924913194444444
val--43/100 [100/1090] acc: 0.7934765625
val--43/100 [110/1090] acc: 0.7938565340909091
val--43/100 [120/1090] acc: 0.7934244791666667
val--43/100 [130/1090] acc: 0.7943209134615384
val--43/100 [140/1090] acc: 0.7944754464285714
val--43/100 [150/1090] acc: 0.7945572916666667
val--43/100 [160/1090] acc: 0.7947998046875
val--43/100 [170/1090] acc: 0.7946920955882353
val--43/100 [180/1090] acc: 0.7942491319444445
val--43/100 [190/1090] acc: 0.7951274671052632
val--43/100 [200/1090] acc: 0.79533203125
val--43/100 [210/1090] acc: 0.7957217261904762
val--43/100 [220/1090] acc: 0.7948508522727272
val--43/100 [230/1090] acc: 0.7955672554347826
val--43/100 [240/1090] acc: 0.7953776041666667
val--43/100 [250/1090] acc: 0.79553125
val--43/100 [260/1090] acc: 0.7954927884615385
val--43/100 [270/1090] acc: 0.7957320601851852
val--43/100 [280/1090] acc: 0.7956473214285714
val--43/100 [290/1090] acc: 0.7954202586206897
val--43/100 [300/1090] acc: 0.7954947916666667
val--43/100 [310/1090] acc: 0.7952368951612904
val--43/100 [320/1090] acc: 0.7953857421875
val--43/100 [330/1090] acc: 0.7956439393939394
val--43/100 [340/1090] acc: 0.7957835477941176
val--43/100 [350/1090] acc: 0.7958705357142857
val--43/100 [360/1090] acc: 0.7958875868055556
val--43/100 [370/1090] acc: 0.7959459459459459
val--43/100 [380/1090] acc: 0.7960115131578948
val--43/100 [390/1090] acc: 0.795693108974359
val--43/100 [400/1090] acc: 0.795615234375
val--43/100 [410/1090] acc: 0.7958079268292683
val--43/100 [420/1090] acc: 0.7957589285714286
val--43/100 [430/1090] acc: 0.795639534883721
val--43/100 [440/1090] acc: 0.7956676136363636
val--43/100 [450/1090] acc: 0.7954861111111111
val--43/100 [460/1090] acc: 0.7953719429347826
val--43/100 [470/1090] acc: 0.7953041888297873
val--43/100 [480/1090] acc: 0.79541015625
val--43/100 [490/1090] acc: 0.7955357142857142
val--43/100 [500/1090] acc: 0.795734375
val--43/100 [510/1090] acc: 0.7955882352941176
val--43/100 [520/1090] acc: 0.79580078125
val--43/100 [530/1090] acc: 0.7957547169811321
val--43/100 [540/1090] acc: 0.7959346064814815
val--43/100 [550/1090] acc: 0.795859375
val--43/100 [560/1090] acc: 0.7956263950892857
val--43/100 [570/1090] acc: 0.7953536184210527
val--43/100 [580/1090] acc: 0.7953529094827586
val--43/100 [590/1090] acc: 0.7953853283898306
val--43/100 [600/1090] acc: 0.7954036458333333
val--43/100 [610/1090] acc: 0.7953060963114754
val--43/100 [620/1090] acc: 0.7951927923387097
val--43/100 [630/1090] acc: 0.7953993055555556
val--43/100 [640/1090] acc: 0.79559326171875
val--43/100 [650/1090] acc: 0.7955769230769231
val--43/100 [660/1090] acc: 0.7954308712121212
val--43/100 [670/1090] acc: 0.7951026119402985
val--43/100 [680/1090] acc: 0.7950425091911765
val--43/100 [690/1090] acc: 0.7952105978260869
val--43/100 [700/1090] acc: 0.7952399553571429
val--43/100 [710/1090] acc: 0.7950044014084507
val--43/100 [720/1090] acc: 0.7948350694444445
val--43/100 [730/1090] acc: 0.7948095034246575
val--43/100 [740/1090] acc: 0.7947265625
val--43/100 [750/1090] acc: 0.794796875
val--43/100 [760/1090] acc: 0.7948601973684211
val--43/100 [770/1090] acc: 0.794820413961039
val--43/100 [780/1090] acc: 0.7947866586538461
val--43/100 [790/1090] acc: 0.7948229825949367
val--43/100 [800/1090] acc: 0.7950732421875
val--43/100 [810/1090] acc: 0.7951630015432098
val--43/100 [820/1090] acc: 0.7952600990853659
val--43/100 [830/1090] acc: 0.7953642695783133
val--43/100 [840/1090] acc: 0.7953125
val--43/100 [850/1090] acc: 0.7953033088235294
val--43/100 [860/1090] acc: 0.7955259811046511
val--43/100 [870/1090] acc: 0.7953663793103448
val--43/100 [880/1090] acc: 0.7953391335227272
val--43/100 [890/1090] acc: 0.7954310042134831
val--43/100 [900/1090] acc: 0.7954036458333333
val--43/100 [910/1090] acc: 0.795415521978022
val--43/100 [920/1090] acc: 0.7954016644021739
val--43/100 [930/1090] acc: 0.7954847110215054
val--43/100 [940/1090] acc: 0.7955119680851064
val--43/100 [950/1090] acc: 0.7954029605263158
val--43/100 [960/1090] acc: 0.7953531901041667
val--43/100 [970/1090] acc: 0.7953286082474227
val--43/100 [980/1090] acc: 0.7953164859693878
val--43/100 [990/1090] acc: 0.795245422979798
val--43/100 [1000/1090] acc: 0.7951328125
val--43/100 [1010/1090] acc: 0.7949953589108911
val--43/100 [1020/1090] acc: 0.7950520833333333
val--43/100 [1030/1090] acc: 0.7950811589805825
val--43/100 [1040/1090] acc: 0.7950608473557692
val--43/100 [1050/1090] acc: 0.7951190476190476
val--43/100 [1060/1090] acc: 0.7950471698113207
val--43/100 [1070/1090] acc: 0.7950606016355141
val--43/100 [1080/1090] acc: 0.7950050636574074
val--43/100 [1090/1090] acc: 0.7948537844036697
epoch= 43, accuracy= 0.794854, rmse= 0.378135, auc= 0.854937
train--44/100 [9/1090] loss: 0.4088247776031494
train--44/100 [19/1090] loss: 0.43666632771492003
train--44/100 [29/1090] loss: 0.44959173202514646
train--44/100 [39/1090] loss: 0.4475040346384048
train--44/100 [49/1090] loss: 0.4251404911279678
train--44/100 [59/1090] loss: 0.43754864633083346
train--44/100 [69/1090] loss: 0.42898082435131074
train--44/100 [79/1090] loss: 0.44065621495246887
train--44/100 [89/1090] loss: 0.45620151460170744
train--44/100 [99/1090] loss: 0.435394087433815
train--44/100 [109/1090] loss: 0.4371426284313202
train--44/100 [119/1090] loss: 0.4470888376235962
train--44/100 [129/1090] loss: 0.45940716564655304
train--44/100 [139/1090] loss: 0.4425896733999252
train--44/100 [149/1090] loss: 0.45051631331443787
train--44/100 [159/1090] loss: 0.4386417090892792
train--44/100 [169/1090] loss: 0.4451653629541397
train--44/100 [179/1090] loss: 0.4456446558237076
train--44/100 [189/1090] loss: 0.43064128160476683
train--44/100 [199/1090] loss: 0.4283053815364838
train--44/100 [209/1090] loss: 0.45158656537532804
train--44/100 [219/1090] loss: 0.45024936497211454
train--44/100 [229/1090] loss: 0.45150302052497865
train--44/100 [239/1090] loss: 0.4340721666812897
train--44/100 [249/1090] loss: 0.4313108503818512
train--44/100 [259/1090] loss: 0.439643582701683
train--44/100 [269/1090] loss: 0.4295090824365616
train--44/100 [279/1090] loss: 0.44780504405498506
train--44/100 [289/1090] loss: 0.46008132994174955
train--44/100 [299/1090] loss: 0.45729797184467313
train--44/100 [309/1090] loss: 0.43055598735809325
train--44/100 [319/1090] loss: 0.4443951278924942
train--44/100 [329/1090] loss: 0.45481945276260377
train--44/100 [339/1090] loss: 0.4372165471315384
train--44/100 [349/1090] loss: 0.44617756009101867
train--44/100 [359/1090] loss: 0.44638932347297666
train--44/100 [369/1090] loss: 0.4599425494670868
train--44/100 [379/1090] loss: 0.42462614476680755
train--44/100 [389/1090] loss: 0.43991505205631254
train--44/100 [399/1090] loss: 0.44994312822818755
train--44/100 [409/1090] loss: 0.46372333765029905
train--44/100 [419/1090] loss: 0.4478319436311722
train--44/100 [429/1090] loss: 0.44441714584827424
train--44/100 [439/1090] loss: 0.43431169986724855
train--44/100 [449/1090] loss: 0.4420769542455673
train--44/100 [459/1090] loss: 0.4380617499351501
train--44/100 [469/1090] loss: 0.4380819469690323
train--44/100 [479/1090] loss: 0.4411604732275009
train--44/100 [489/1090] loss: 0.4617155879735947
train--44/100 [499/1090] loss: 0.42178835570812223
train--44/100 [509/1090] loss: 0.4344374507665634
train--44/100 [519/1090] loss: 0.45089247822761536
train--44/100 [529/1090] loss: 0.4387678146362305
train--44/100 [539/1090] loss: 0.4375513315200806
train--44/100 [549/1090] loss: 0.43754838705062865
train--44/100 [559/1090] loss: 0.43817376494407656
train--44/100 [569/1090] loss: 0.45590475797653196
train--44/100 [579/1090] loss: 0.46908722519874574
train--44/100 [589/1090] loss: 0.4672748774290085
train--44/100 [599/1090] loss: 0.4683659762144089
train--44/100 [609/1090] loss: 0.44280522763729097
train--44/100 [619/1090] loss: 0.45849878191947935
train--44/100 [629/1090] loss: 0.46359293162822723
train--44/100 [639/1090] loss: 0.4507298797369003
train--44/100 [649/1090] loss: 0.45125211775302887
train--44/100 [659/1090] loss: 0.4559877574443817
train--44/100 [669/1090] loss: 0.4404232829809189
train--44/100 [679/1090] loss: 0.46081731021404265
train--44/100 [689/1090] loss: 0.47080047726631163
train--44/100 [699/1090] loss: 0.4348894268274307
train--44/100 [709/1090] loss: 0.43701601922512057
train--44/100 [719/1090] loss: 0.4254036694765091
train--44/100 [729/1090] loss: 0.438854256272316
train--44/100 [739/1090] loss: 0.4480661988258362
train--44/100 [749/1090] loss: 0.45729054808616637
train--44/100 [759/1090] loss: 0.4458935558795929
train--44/100 [769/1090] loss: 0.4548594981431961
train--44/100 [779/1090] loss: 0.4478783875703812
train--44/100 [789/1090] loss: 0.44206498861312865
train--44/100 [799/1090] loss: 0.46323366165161134
train--44/100 [809/1090] loss: 0.45591903030872344
train--44/100 [819/1090] loss: 0.43779602348804475
train--44/100 [829/1090] loss: 0.45700128078460694
train--44/100 [839/1090] loss: 0.45694070160388944
train--44/100 [849/1090] loss: 0.45574849247932436
train--44/100 [859/1090] loss: 0.44519329369068145
train--44/100 [869/1090] loss: 0.44719679057598116
train--44/100 [879/1090] loss: 0.4533910691738129
train--44/100 [889/1090] loss: 0.447310546040535
train--44/100 [899/1090] loss: 0.4514871329069138
train--44/100 [909/1090] loss: 0.4575472861528397
train--44/100 [919/1090] loss: 0.4420056790113449
train--44/100 [929/1090] loss: 0.4495916306972504
train--44/100 [939/1090] loss: 0.4576676607131958
train--44/100 [949/1090] loss: 0.4338087558746338
train--44/100 [959/1090] loss: 0.42974231839179994
train--44/100 [969/1090] loss: 0.4554832369089127
train--44/100 [979/1090] loss: 0.4358378559350967
train--44/100 [989/1090] loss: 0.4479136556386948
train--44/100 [999/1090] loss: 0.44214261174201963
train--44/100 [1009/1090] loss: 0.4540001958608627
train--44/100 [1019/1090] loss: 0.4552820444107056
train--44/100 [1029/1090] loss: 0.4530228078365326
train--44/100 [1039/1090] loss: 0.42719746232032774
train--44/100 [1049/1090] loss: 0.45209856927394865
train--44/100 [1059/1090] loss: 0.460398867726326
train--44/100 [1069/1090] loss: 0.44613825976848603
train--44/100 [1079/1090] loss: 0.45038336515426636
train--44/100 [1089/1090] loss: 0.44346587657928466
predicting model...
val--44/100 [10/1090] acc: 0.794140625
val--44/100 [20/1090] acc: 0.7943359375
val--44/100 [30/1090] acc: 0.7936197916666666
val--44/100 [40/1090] acc: 0.79384765625
val--44/100 [50/1090] acc: 0.79265625
val--44/100 [60/1090] acc: 0.7918619791666667
val--44/100 [70/1090] acc: 0.7924107142857143
val--44/100 [80/1090] acc: 0.79130859375
val--44/100 [90/1090] acc: 0.7918836805555556
val--44/100 [100/1090] acc: 0.7932421875
val--44/100 [110/1090] acc: 0.7936789772727273
val--44/100 [120/1090] acc: 0.7931966145833333
val--44/100 [130/1090] acc: 0.7942908653846154
val--44/100 [140/1090] acc: 0.7943080357142858
val--44/100 [150/1090] acc: 0.79453125
val--44/100 [160/1090] acc: 0.794921875
val--44/100 [170/1090] acc: 0.7947150735294117
val--44/100 [180/1090] acc: 0.79453125
val--44/100 [190/1090] acc: 0.7953947368421053
val--44/100 [200/1090] acc: 0.7956640625
val--44/100 [210/1090] acc: 0.7960751488095238
val--44/100 [220/1090] acc: 0.7952059659090909
val--44/100 [230/1090] acc: 0.795805027173913
val--44/100 [240/1090] acc: 0.7957356770833334
val--44/100 [250/1090] acc: 0.79578125
val--44/100 [260/1090] acc: 0.7957932692307692
val--44/100 [270/1090] acc: 0.796021412037037
val--44/100 [280/1090] acc: 0.7958426339285715
val--44/100 [290/1090] acc: 0.7955818965517242
val--44/100 [300/1090] acc: 0.795546875
val--44/100 [310/1090] acc: 0.7952242943548387
val--44/100 [320/1090] acc: 0.7954345703125
val--44/100 [330/1090] acc: 0.7957149621212121
val--44/100 [340/1090] acc: 0.7957261029411765
val--44/100 [350/1090] acc: 0.7958147321428571
val--44/100 [360/1090] acc: 0.7956922743055556
val--44/100 [370/1090] acc: 0.7958403716216216
val--44/100 [380/1090] acc: 0.7958264802631579
val--44/100 [390/1090] acc: 0.7956129807692308
val--44/100 [400/1090] acc: 0.79560546875
val--44/100 [410/1090] acc: 0.7957983993902439
val--44/100 [420/1090] acc: 0.7957682291666667
val--44/100 [430/1090] acc: 0.7956486191860465
val--44/100 [440/1090] acc: 0.7956143465909091
val--44/100 [450/1090] acc: 0.7953472222222222
val--44/100 [460/1090] acc: 0.7952021059782609
val--44/100 [470/1090] acc: 0.795171210106383
val--44/100 [480/1090] acc: 0.795263671875
val--44/100 [490/1090] acc: 0.7954241071428572
val--44/100 [500/1090] acc: 0.795625
val--44/100 [510/1090] acc: 0.7955346200980392
val--44/100 [520/1090] acc: 0.7957106370192307
val--44/100 [530/1090] acc: 0.7957547169811321
val--44/100 [540/1090] acc: 0.7959056712962963
val--44/100 [550/1090] acc: 0.7957528409090909
val--44/100 [560/1090] acc: 0.795556640625
val--44/100 [570/1090] acc: 0.7953193530701754
val--44/100 [580/1090] acc: 0.7953125
val--44/100 [590/1090] acc: 0.795358845338983
val--44/100 [600/1090] acc: 0.7953841145833334
val--44/100 [610/1090] acc: 0.7952932889344262
val--44/100 [620/1090] acc: 0.7952305947580646
val--44/100 [630/1090] acc: 0.7954427083333333
val--44/100 [640/1090] acc: 0.795660400390625
val--44/100 [650/1090] acc: 0.7956490384615384
val--44/100 [660/1090] acc: 0.7955374053030303
val--44/100 [670/1090] acc: 0.7951784048507463
val--44/100 [680/1090] acc: 0.7950999540441176
val--44/100 [690/1090] acc: 0.7952389039855072
val--44/100 [700/1090] acc: 0.7952399553571429
val--44/100 [710/1090] acc: 0.7950429137323943
val--44/100 [720/1090] acc: 0.7949001736111111
val--44/100 [730/1090] acc: 0.7949004708904109
val--44/100 [740/1090] acc: 0.7948057432432433
val--44/100 [750/1090] acc: 0.7948697916666667
val--44/100 [760/1090] acc: 0.7949115953947369
val--44/100 [770/1090] acc: 0.7948762175324675
val--44/100 [780/1090] acc: 0.7948517628205128
val--44/100 [790/1090] acc: 0.7948872626582278
val--44/100 [800/1090] acc: 0.79509765625
val--44/100 [810/1090] acc: 0.7951630015432098
val--44/100 [820/1090] acc: 0.7952743902439025
val--44/100 [830/1090] acc: 0.7953454442771084
val--44/100 [840/1090] acc: 0.7953125
val--44/100 [850/1090] acc: 0.7954090073529412
val--44/100 [860/1090] acc: 0.795680414244186
val--44/100 [870/1090] acc: 0.7955774066091954
val--44/100 [880/1090] acc: 0.7955344460227273
val--44/100 [890/1090] acc: 0.7956899578651685
val--44/100 [900/1090] acc: 0.7956901041666666
val--44/100 [910/1090] acc: 0.7956773695054945
val--44/100 [920/1090] acc: 0.7956776494565218
val--44/100 [930/1090] acc: 0.7957661290322581
val--44/100 [940/1090] acc: 0.7957613031914894
val--44/100 [950/1090] acc: 0.7956620065789474
val--44/100 [960/1090] acc: 0.79556884765625
val--44/100 [970/1090] acc: 0.7955621778350516
val--44/100 [980/1090] acc: 0.7955516581632653
val--44/100 [990/1090] acc: 0.7954308712121212
val--44/100 [1000/1090] acc: 0.79530859375
val--44/100 [1010/1090] acc: 0.7951693997524752
val--44/100 [1020/1090] acc: 0.7952359068627451
val--44/100 [1030/1090] acc: 0.7952518203883495
val--44/100 [1040/1090] acc: 0.7952261117788462
val--44/100 [1050/1090] acc: 0.7952641369047619
val--44/100 [1060/1090] acc: 0.7952166863207547
val--44/100 [1070/1090] acc: 0.7952102803738318
val--44/100 [1080/1090] acc: 0.7951822916666667
val--44/100 [1090/1090] acc: 0.7950329701834863
epoch= 44, accuracy= 0.795033, rmse= 0.378064, auc= 0.855047
train--45/100 [9/1090] loss: 0.3905774265527725
train--45/100 [19/1090] loss: 0.41996176540851593
train--45/100 [29/1090] loss: 0.4416966617107391
train--45/100 [39/1090] loss: 0.44380012452602385
train--45/100 [49/1090] loss: 0.4500123172998428
train--45/100 [59/1090] loss: 0.42783263325691223
train--45/100 [69/1090] loss: 0.45080211758613586
train--45/100 [79/1090] loss: 0.4591577410697937
train--45/100 [89/1090] loss: 0.4327648788690567
train--45/100 [99/1090] loss: 0.45079525709152224
train--45/100 [109/1090] loss: 0.4300181299448013
train--45/100 [119/1090] loss: 0.4504091292619705
train--45/100 [129/1090] loss: 0.4166142076253891
train--45/100 [139/1090] loss: 0.4252768188714981
train--45/100 [149/1090] loss: 0.4545610725879669
train--45/100 [159/1090] loss: 0.44688802361488345
train--45/100 [169/1090] loss: 0.4410219699144363
train--45/100 [179/1090] loss: 0.4355924904346466
train--45/100 [189/1090] loss: 0.4502784788608551
train--45/100 [199/1090] loss: 0.44159595370292665
train--45/100 [209/1090] loss: 0.44410276114940644
train--45/100 [219/1090] loss: 0.4508627444505692
train--45/100 [229/1090] loss: 0.46085280179977417
train--45/100 [239/1090] loss: 0.43835440278053284
train--45/100 [249/1090] loss: 0.4432171434164047
train--45/100 [259/1090] loss: 0.44433326125144956
train--45/100 [269/1090] loss: 0.46064509749412536
train--45/100 [279/1090] loss: 0.4366221487522125
train--45/100 [289/1090] loss: 0.45929892659187316
train--45/100 [299/1090] loss: 0.44526016116142275
train--45/100 [309/1090] loss: 0.4674318194389343
train--45/100 [319/1090] loss: 0.44616149365901947
train--45/100 [329/1090] loss: 0.4375817120075226
train--45/100 [339/1090] loss: 0.458370167016983
train--45/100 [349/1090] loss: 0.4492953896522522
train--45/100 [359/1090] loss: 0.43510914146900176
train--45/100 [369/1090] loss: 0.456429061293602
train--45/100 [379/1090] loss: 0.4523268312215805
train--45/100 [389/1090] loss: 0.4318870663642883
train--45/100 [399/1090] loss: 0.42533917129039767
train--45/100 [409/1090] loss: 0.4318956196308136
train--45/100 [419/1090] loss: 0.4399932146072388
train--45/100 [429/1090] loss: 0.43996776938438414
train--45/100 [439/1090] loss: 0.4416233986616135
train--45/100 [449/1090] loss: 0.43907198309898376
train--45/100 [459/1090] loss: 0.4365358382463455
train--45/100 [469/1090] loss: 0.4592173844575882
train--45/100 [479/1090] loss: 0.4481011748313904
train--45/100 [489/1090] loss: 0.4456818997859955
train--45/100 [499/1090] loss: 0.4497904866933823
train--45/100 [509/1090] loss: 0.4413928955793381
train--45/100 [519/1090] loss: 0.435364705324173
train--45/100 [529/1090] loss: 0.46473619639873504
train--45/100 [539/1090] loss: 0.45581703186035155
train--45/100 [549/1090] loss: 0.44076320230960847
train--45/100 [559/1090] loss: 0.4549466758966446
train--45/100 [569/1090] loss: 0.4443655014038086
train--45/100 [579/1090] loss: 0.44151256382465365
train--45/100 [589/1090] loss: 0.45562012791633605
train--45/100 [599/1090] loss: 0.4286472171545029
train--45/100 [609/1090] loss: 0.44924031794071195
train--45/100 [619/1090] loss: 0.43594918251037595
train--45/100 [629/1090] loss: 0.45505860149860383
train--45/100 [639/1090] loss: 0.44755893647670747
train--45/100 [649/1090] loss: 0.45542346835136416
train--45/100 [659/1090] loss: 0.4495760589838028
train--45/100 [669/1090] loss: 0.44627601802349093
train--45/100 [679/1090] loss: 0.43381412923336027
train--45/100 [689/1090] loss: 0.44367324411869047
train--45/100 [699/1090] loss: 0.44726341068744657
train--45/100 [709/1090] loss: 0.4517325282096863
train--45/100 [719/1090] loss: 0.4450687050819397
train--45/100 [729/1090] loss: 0.4539612054824829
train--45/100 [739/1090] loss: 0.44897340834140775
train--45/100 [749/1090] loss: 0.4672719746828079
train--45/100 [759/1090] loss: 0.4524180591106415
train--45/100 [769/1090] loss: 0.4416812002658844
train--45/100 [779/1090] loss: 0.45089358389377593
train--45/100 [789/1090] loss: 0.4519234448671341
train--45/100 [799/1090] loss: 0.45750877559185027
train--45/100 [809/1090] loss: 0.44713903963565826
train--45/100 [819/1090] loss: 0.4333364963531494
train--45/100 [829/1090] loss: 0.44549846947193145
train--45/100 [839/1090] loss: 0.4467517524957657
train--45/100 [849/1090] loss: 0.45036334693431856
train--45/100 [859/1090] loss: 0.42874268293380735
train--45/100 [869/1090] loss: 0.450201553106308
train--45/100 [879/1090] loss: 0.4427604913711548
train--45/100 [889/1090] loss: 0.48178828358650205
train--45/100 [899/1090] loss: 0.4566417634487152
train--45/100 [909/1090] loss: 0.44425012469291686
train--45/100 [919/1090] loss: 0.45962344408035277
train--45/100 [929/1090] loss: 0.46173831820487976
train--45/100 [939/1090] loss: 0.4488160789012909
train--45/100 [949/1090] loss: 0.43722947537899015
train--45/100 [959/1090] loss: 0.43649932742118835
train--45/100 [969/1090] loss: 0.43493394553661346
train--45/100 [979/1090] loss: 0.4482619404792786
train--45/100 [989/1090] loss: 0.44586099684238434
train--45/100 [999/1090] loss: 0.4659367173910141
train--45/100 [1009/1090] loss: 0.4511678725481033
train--45/100 [1019/1090] loss: 0.4287142068147659
train--45/100 [1029/1090] loss: 0.43411619663238527
train--45/100 [1039/1090] loss: 0.4524476170539856
train--45/100 [1049/1090] loss: 0.44271627366542815
train--45/100 [1059/1090] loss: 0.4422727167606354
train--45/100 [1069/1090] loss: 0.4554917186498642
train--45/100 [1079/1090] loss: 0.449713933467865
train--45/100 [1089/1090] loss: 0.48262985944747927
predicting model...
val--45/100 [10/1090] acc: 0.794921875
val--45/100 [20/1090] acc: 0.7947265625
val--45/100 [30/1090] acc: 0.7940104166666667
val--45/100 [40/1090] acc: 0.7939453125
val--45/100 [50/1090] acc: 0.792890625
val--45/100 [60/1090] acc: 0.791796875
val--45/100 [70/1090] acc: 0.7920758928571429
val--45/100 [80/1090] acc: 0.791259765625
val--45/100 [90/1090] acc: 0.7921006944444444
val--45/100 [100/1090] acc: 0.7930859375
val--45/100 [110/1090] acc: 0.7932883522727273
val--45/100 [120/1090] acc: 0.7930338541666667
val--45/100 [130/1090] acc: 0.7942908653846154
val--45/100 [140/1090] acc: 0.79453125
val--45/100 [150/1090] acc: 0.794609375
val--45/100 [160/1090] acc: 0.79482421875
val--45/100 [170/1090] acc: 0.7946691176470588
val--45/100 [180/1090] acc: 0.7943576388888889
val--45/100 [190/1090] acc: 0.7951480263157895
val--45/100 [200/1090] acc: 0.795390625
val--45/100 [210/1090] acc: 0.7958705357142857
val--45/100 [220/1090] acc: 0.7949573863636363
val--45/100 [230/1090] acc: 0.7956351902173913
val--45/100 [240/1090] acc: 0.7955240885416667
val--45/100 [250/1090] acc: 0.795546875
val--45/100 [260/1090] acc: 0.7956280048076924
val--45/100 [270/1090] acc: 0.7957899305555556
val--45/100 [280/1090] acc: 0.7957310267857143
val--45/100 [290/1090] acc: 0.7954741379310345
val--45/100 [300/1090] acc: 0.7955208333333333
val--45/100 [310/1090] acc: 0.7951864919354839
val--45/100 [320/1090] acc: 0.795361328125
val--45/100 [330/1090] acc: 0.795596590909091
val--45/100 [340/1090] acc: 0.7956801470588235
val--45/100 [350/1090] acc: 0.7958147321428571
val--45/100 [360/1090] acc: 0.7957465277777778
val--45/100 [370/1090] acc: 0.7958931587837837
val--45/100 [380/1090] acc: 0.7958162006578947
val--45/100 [390/1090] acc: 0.7955729166666666
val--45/100 [400/1090] acc: 0.795478515625
val--45/100 [410/1090] acc: 0.795655487804878
val--45/100 [420/1090] acc: 0.7956194196428571
val--45/100 [430/1090] acc: 0.7954851017441861
val--45/100 [440/1090] acc: 0.7954989346590909
val--45/100 [450/1090] acc: 0.7953645833333334
val--45/100 [460/1090] acc: 0.7952021059782609
val--45/100 [470/1090] acc: 0.7950797872340426
val--45/100 [480/1090] acc: 0.7951416015625
val--45/100 [490/1090] acc: 0.795328443877551
val--45/100 [500/1090] acc: 0.79546875
val--45/100 [510/1090] acc: 0.7953507965686275
val--45/100 [520/1090] acc: 0.7954702524038462
val--45/100 [530/1090] acc: 0.7954304245283019
val--45/100 [540/1090] acc: 0.7955367476851852
val--45/100 [550/1090] acc: 0.7954545454545454
val--45/100 [560/1090] acc: 0.7952845982142858
val--45/100 [570/1090] acc: 0.7950520833333333
val--45/100 [580/1090] acc: 0.7950700431034483
val--45/100 [590/1090] acc: 0.7951271186440678
val--45/100 [600/1090] acc: 0.7951171875
val--45/100 [610/1090] acc: 0.7950371413934426
val--45/100 [620/1090] acc: 0.7949596774193548
val--45/100 [630/1090] acc: 0.7951884920634921
val--45/100 [640/1090] acc: 0.795343017578125
val--45/100 [650/1090] acc: 0.7953305288461539
val--45/100 [660/1090] acc: 0.7952000473484848
val--45/100 [670/1090] acc: 0.7949043843283582
val--45/100 [680/1090] acc: 0.7948299632352941
val--45/100 [690/1090] acc: 0.7950067934782609
val--45/100 [700/1090] acc: 0.7950613839285714
val--45/100 [710/1090] acc: 0.7948393485915493
val--45/100 [720/1090] acc: 0.794677734375
val--45/100 [730/1090] acc: 0.7946275684931506
val--45/100 [740/1090] acc: 0.7945259712837838
val--45/100 [750/1090] acc: 0.794578125
val--45/100 [760/1090] acc: 0.7946340460526315
val--45/100 [770/1090] acc: 0.7945819805194805
val--45/100 [780/1090] acc: 0.794541266025641
val--45/100 [790/1090] acc: 0.7945757515822784
val--45/100 [800/1090] acc: 0.7947802734375
val--45/100 [810/1090] acc: 0.7948447145061729
val--45/100 [820/1090] acc: 0.7949361661585366
val--45/100 [830/1090] acc: 0.7950065888554216
val--45/100 [840/1090] acc: 0.7949265252976191
val--45/100 [850/1090] acc: 0.7949586397058823
val--45/100 [860/1090] acc: 0.7951853197674419
val--45/100 [870/1090] acc: 0.7950610632183908
val--45/100 [880/1090] acc: 0.7950106534090909
val--45/100 [890/1090] acc: 0.7951676615168539
val--45/100 [900/1090] acc: 0.7951736111111111
val--45/100 [910/1090] acc: 0.7951923076923076
val--45/100 [920/1090] acc: 0.7952360733695653
val--45/100 [930/1090] acc: 0.7953251008064516
val--45/100 [940/1090] acc: 0.7953623670212766
val--45/100 [950/1090] acc: 0.7952220394736842
val--45/100 [960/1090] acc: 0.7951741536458333
val--45/100 [970/1090] acc: 0.7951675257731958
val--45/100 [980/1090] acc: 0.7951809630102041
val--45/100 [990/1090] acc: 0.795111268939394
val--45/100 [1000/1090] acc: 0.7950234375
val--45/100 [1010/1090] acc: 0.7948638613861386
val--45/100 [1020/1090] acc: 0.7949448529411764
val--45/100 [1030/1090] acc: 0.7949977245145631
val--45/100 [1040/1090] acc: 0.7949819711538462
val--45/100 [1050/1090] acc: 0.7950520833333333
val--45/100 [1060/1090] acc: 0.7949992629716981
val--45/100 [1070/1090] acc: 0.7950167932242991
val--45/100 [1080/1090] acc: 0.7949761284722222
val--45/100 [1090/1090] acc: 0.7948286983944954
epoch= 45, accuracy= 0.794829, rmse= 0.378038, auc= 0.855076
train--46/100 [9/1090] loss: 0.4152488440275192
train--46/100 [19/1090] loss: 0.44808781445026397
train--46/100 [29/1090] loss: 0.4578601211309433
train--46/100 [39/1090] loss: 0.406534218788147
train--46/100 [49/1090] loss: 0.45547311305999755
train--46/100 [59/1090] loss: 0.4673492670059204
train--46/100 [69/1090] loss: 0.4436193495988846
train--46/100 [79/1090] loss: 0.43263834416866304
train--46/100 [89/1090] loss: 0.4568234920501709
train--46/100 [99/1090] loss: 0.45208909511566164
train--46/100 [109/1090] loss: 0.4395630359649658
train--46/100 [119/1090] loss: 0.42318124771118165
train--46/100 [129/1090] loss: 0.4323505342006683
train--46/100 [139/1090] loss: 0.4475244104862213
train--46/100 [149/1090] loss: 0.4595485031604767
train--46/100 [159/1090] loss: 0.4480258941650391
train--46/100 [169/1090] loss: 0.46067609786987307
train--46/100 [179/1090] loss: 0.4423279821872711
train--46/100 [189/1090] loss: 0.43529644012451174
train--46/100 [199/1090] loss: 0.43399934470653534
train--46/100 [209/1090] loss: 0.4506330847740173
train--46/100 [219/1090] loss: 0.4563632071018219
train--46/100 [229/1090] loss: 0.45509652197360995
train--46/100 [239/1090] loss: 0.45714959502220154
train--46/100 [249/1090] loss: 0.43156838715076445
train--46/100 [259/1090] loss: 0.4390925824642181
train--46/100 [269/1090] loss: 0.4459419369697571
train--46/100 [279/1090] loss: 0.44496543109416964
train--46/100 [289/1090] loss: 0.4398800164461136
train--46/100 [299/1090] loss: 0.44564386904239656
train--46/100 [309/1090] loss: 0.44473797082901
train--46/100 [319/1090] loss: 0.4604277342557907
train--46/100 [329/1090] loss: 0.43903393745422364
train--46/100 [339/1090] loss: 0.4304155111312866
train--46/100 [349/1090] loss: 0.4347540318965912
train--46/100 [359/1090] loss: 0.4522378593683243
train--46/100 [369/1090] loss: 0.44407511949539186
train--46/100 [379/1090] loss: 0.4420960068702698
train--46/100 [389/1090] loss: 0.4532288581132889
train--46/100 [399/1090] loss: 0.44236452877521515
train--46/100 [409/1090] loss: 0.4378113359212875
train--46/100 [419/1090] loss: 0.44627974927425385
train--46/100 [429/1090] loss: 0.44939391911029813
train--46/100 [439/1090] loss: 0.4609046697616577
train--46/100 [449/1090] loss: 0.42683468461036683
train--46/100 [459/1090] loss: 0.4347758859395981
train--46/100 [469/1090] loss: 0.4526004731655121
train--46/100 [479/1090] loss: 0.4544133186340332
train--46/100 [489/1090] loss: 0.4481444865465164
train--46/100 [499/1090] loss: 0.4483150988817215
train--46/100 [509/1090] loss: 0.43854010105133057
train--46/100 [519/1090] loss: 0.4371741473674774
train--46/100 [529/1090] loss: 0.4362095832824707
train--46/100 [539/1090] loss: 0.4357312709093094
train--46/100 [549/1090] loss: 0.42622690498828886
train--46/100 [559/1090] loss: 0.45180716216564176
train--46/100 [569/1090] loss: 0.45285255908966066
train--46/100 [579/1090] loss: 0.44302894473075866
train--46/100 [589/1090] loss: 0.4274489164352417
train--46/100 [599/1090] loss: 0.43481927514076235
train--46/100 [609/1090] loss: 0.4480511963367462
train--46/100 [619/1090] loss: 0.44352840483188627
train--46/100 [629/1090] loss: 0.4403132289648056
train--46/100 [639/1090] loss: 0.44516001641750336
train--46/100 [649/1090] loss: 0.4506623178720474
train--46/100 [659/1090] loss: 0.4355916053056717
train--46/100 [669/1090] loss: 0.435141783952713
train--46/100 [679/1090] loss: 0.4538233935832977
train--46/100 [689/1090] loss: 0.4460311621427536
train--46/100 [699/1090] loss: 0.47221421003341674
train--46/100 [709/1090] loss: 0.44586842954158784
train--46/100 [719/1090] loss: 0.45148834884166716
train--46/100 [729/1090] loss: 0.46277485489845277
train--46/100 [739/1090] loss: 0.4473371595144272
train--46/100 [749/1090] loss: 0.4680908352136612
train--46/100 [759/1090] loss: 0.43946375250816344
train--46/100 [769/1090] loss: 0.43078297972679136
train--46/100 [779/1090] loss: 0.4385639488697052
train--46/100 [789/1090] loss: 0.4485141634941101
train--46/100 [799/1090] loss: 0.4457815259695053
train--46/100 [809/1090] loss: 0.44774769246578217
train--46/100 [819/1090] loss: 0.4484359920024872
train--46/100 [829/1090] loss: 0.46846057176589967
train--46/100 [839/1090] loss: 0.46565375924110414
train--46/100 [849/1090] loss: 0.43160822689533235
train--46/100 [859/1090] loss: 0.42603548169136046
train--46/100 [869/1090] loss: 0.43468318283557894
train--46/100 [879/1090] loss: 0.4696406424045563
train--46/100 [889/1090] loss: 0.4447216778993607
train--46/100 [899/1090] loss: 0.4507220029830933
train--46/100 [909/1090] loss: 0.44589694440364835
train--46/100 [919/1090] loss: 0.4509101390838623
train--46/100 [929/1090] loss: 0.4165641129016876
train--46/100 [939/1090] loss: 0.4529829680919647
train--46/100 [949/1090] loss: 0.4303410768508911
train--46/100 [959/1090] loss: 0.4437382251024246
train--46/100 [969/1090] loss: 0.44519805908203125
train--46/100 [979/1090] loss: 0.4467380255460739
train--46/100 [989/1090] loss: 0.46130905151367185
train--46/100 [999/1090] loss: 0.43930649757385254
train--46/100 [1009/1090] loss: 0.4454040914773941
train--46/100 [1019/1090] loss: 0.4592010498046875
train--46/100 [1029/1090] loss: 0.4606510490179062
train--46/100 [1039/1090] loss: 0.45994406938552856
train--46/100 [1049/1090] loss: 0.4588360905647278
train--46/100 [1059/1090] loss: 0.4471926808357239
train--46/100 [1069/1090] loss: 0.4508111923933029
train--46/100 [1079/1090] loss: 0.452901753783226
train--46/100 [1089/1090] loss: 0.45314267873764036
predicting model...
val--46/100 [10/1090] acc: 0.79296875
val--46/100 [20/1090] acc: 0.79375
val--46/100 [30/1090] acc: 0.794140625
val--46/100 [40/1090] acc: 0.79423828125
val--46/100 [50/1090] acc: 0.79375
val--46/100 [60/1090] acc: 0.7923828125
val--46/100 [70/1090] acc: 0.7928013392857143
val--46/100 [80/1090] acc: 0.791943359375
val--46/100 [90/1090] acc: 0.7927517361111112
val--46/100 [100/1090] acc: 0.7936328125
val--46/100 [110/1090] acc: 0.7940696022727273
val--46/100 [120/1090] acc: 0.7937825520833334
val--46/100 [130/1090] acc: 0.7945913461538462
val--46/100 [140/1090] acc: 0.7946986607142857
val--46/100 [150/1090] acc: 0.794765625
val--46/100 [160/1090] acc: 0.7950439453125
val--46/100 [170/1090] acc: 0.7948759191176471
val--46/100 [180/1090] acc: 0.7945963541666666
val--46/100 [190/1090] acc: 0.7954564144736842
val--46/100 [200/1090] acc: 0.795625
val--46/100 [210/1090] acc: 0.7961123511904762
val--46/100 [220/1090] acc: 0.7952769886363636
val--46/100 [230/1090] acc: 0.795991847826087
val--46/100 [240/1090] acc: 0.7958984375
val--46/100 [250/1090] acc: 0.796015625
val--46/100 [260/1090] acc: 0.7960186298076923
val--46/100 [270/1090] acc: 0.7962962962962963
val--46/100 [280/1090] acc: 0.7962332589285714
val--46/100 [290/1090] acc: 0.7960398706896552
val--46/100 [300/1090] acc: 0.7961067708333334
val--46/100 [310/1090] acc: 0.7958291330645161
val--46/100 [320/1090] acc: 0.79598388671875
val--46/100 [330/1090] acc: 0.7962239583333334
val--46/100 [340/1090] acc: 0.7963120404411764
val--46/100 [350/1090] acc: 0.7964955357142857
val--46/100 [360/1090] acc: 0.7963216145833333
val--46/100 [370/1090] acc: 0.7965266047297297
val--46/100 [380/1090] acc: 0.7964946546052631
val--46/100 [390/1090] acc: 0.7962940705128205
val--46/100 [400/1090] acc: 0.796240234375
val--46/100 [410/1090] acc: 0.7963891006097561
val--46/100 [420/1090] acc: 0.7963169642857143
val--46/100 [430/1090] acc: 0.7961845930232558
val--46/100 [440/1090] acc: 0.796200284090909
val--46/100 [450/1090] acc: 0.7960416666666666
val--46/100 [460/1090] acc: 0.7959663722826087
val--46/100 [470/1090] acc: 0.7958776595744681
val--46/100 [480/1090] acc: 0.7959228515625
val--46/100 [490/1090] acc: 0.7961336096938776
val--46/100 [500/1090] acc: 0.7963046875
val--46/100 [510/1090] acc: 0.7962162990196079
val--46/100 [520/1090] acc: 0.7964242788461539
val--46/100 [530/1090] acc: 0.7963443396226415
val--46/100 [540/1090] acc: 0.796412037037037
val--46/100 [550/1090] acc: 0.7962855113636363
val--46/100 [560/1090] acc: 0.7961077008928571
val--46/100 [570/1090] acc: 0.7958675986842105
val--46/100 [580/1090] acc: 0.7958714978448276
val--46/100 [590/1090] acc: 0.7958885063559322
val--46/100 [600/1090] acc: 0.7958723958333334
val--46/100 [610/1090] acc: 0.7956903176229508
val--46/100 [620/1090] acc: 0.7956464213709677
val--46/100 [630/1090] acc: 0.7958767361111111
val--46/100 [640/1090] acc: 0.796026611328125
val--46/100 [650/1090] acc: 0.7959975961538461
val--46/100 [660/1090] acc: 0.7958570075757576
val--46/100 [670/1090] acc: 0.7955690298507463
val--46/100 [680/1090] acc: 0.7954388786764706
val--46/100 [690/1090] acc: 0.795612545289855
val--46/100 [700/1090] acc: 0.7956361607142857
val--46/100 [710/1090] acc: 0.795428036971831
val--46/100 [720/1090] acc: 0.7952907986111111
val--46/100 [730/1090] acc: 0.7952482876712329
val--46/100 [740/1090] acc: 0.7951594172297297
val--46/100 [750/1090] acc: 0.7952291666666667
val--46/100 [760/1090] acc: 0.7952559621710527
val--46/100 [770/1090] acc: 0.7951653814935065
val--46/100 [780/1090] acc: 0.7951221955128205
val--46/100 [790/1090] acc: 0.7951592167721518
val--46/100 [800/1090] acc: 0.79537109375
val--46/100 [810/1090] acc: 0.7954427083333333
val--46/100 [820/1090] acc: 0.7955411585365854
val--46/100 [830/1090] acc: 0.7956137048192771
val--46/100 [840/1090] acc: 0.7955543154761905
val--46/100 [850/1090] acc: 0.795579044117647
val--46/100 [860/1090] acc: 0.795789425872093
val--46/100 [870/1090] acc: 0.7956761853448275
val--46/100 [880/1090] acc: 0.7956010298295455
val--46/100 [890/1090] acc: 0.7957382373595505
val--46/100 [900/1090] acc: 0.7957421875
val--46/100 [910/1090] acc: 0.7957117101648352
val--46/100 [920/1090] acc: 0.7956988790760869
val--46/100 [930/1090] acc: 0.7957829301075269
val--46/100 [940/1090] acc: 0.7957862367021277
val--46/100 [950/1090] acc: 0.7956661184210526
val--46/100 [960/1090] acc: 0.7956095377604167
val--46/100 [970/1090] acc: 0.7956105025773196
val--46/100 [980/1090] acc: 0.7956194196428571
val--46/100 [990/1090] acc: 0.7955334595959596
val--46/100 [1000/1090] acc: 0.79540625
val--46/100 [1010/1090] acc: 0.7952544863861386
val--46/100 [1020/1090] acc: 0.7953393075980392
val--46/100 [1030/1090] acc: 0.7953542172330097
val--46/100 [1040/1090] acc: 0.7953275240384615
val--46/100 [1050/1090] acc: 0.7953794642857143
val--46/100 [1060/1090] acc: 0.7953346108490567
val--46/100 [1070/1090] acc: 0.7953526577102804
val--46/100 [1080/1090] acc: 0.7953305844907408
val--46/100 [1090/1090] acc: 0.7951763188073394
epoch= 46, accuracy= 0.795176, rmse= 0.377945, auc= 0.855173
train--47/100 [9/1090] loss: 0.40021893978118894
train--47/100 [19/1090] loss: 0.4416716039180756
train--47/100 [29/1090] loss: 0.43814713060855864
train--47/100 [39/1090] loss: 0.4302043080329895
train--47/100 [49/1090] loss: 0.4424586117267609
train--47/100 [59/1090] loss: 0.43527872264385226
train--47/100 [69/1090] loss: 0.43636420369148254
train--47/100 [79/1090] loss: 0.40511121451854704
train--47/100 [89/1090] loss: 0.4563440352678299
train--47/100 [99/1090] loss: 0.4567487061023712
train--47/100 [109/1090] loss: 0.4387320399284363
train--47/100 [119/1090] loss: 0.4618400126695633
train--47/100 [129/1090] loss: 0.42520015239715575
train--47/100 [139/1090] loss: 0.4287232518196106
train--47/100 [149/1090] loss: 0.4492656260728836
train--47/100 [159/1090] loss: 0.45576417446136475
train--47/100 [169/1090] loss: 0.444536018371582
train--47/100 [179/1090] loss: 0.434213450551033
train--47/100 [189/1090] loss: 0.44548287987709045
train--47/100 [199/1090] loss: 0.444811949133873
train--47/100 [209/1090] loss: 0.44160489141941073
train--47/100 [219/1090] loss: 0.46570505797863004
train--47/100 [229/1090] loss: 0.4261462539434433
train--47/100 [239/1090] loss: 0.45027423799037936
train--47/100 [249/1090] loss: 0.4554379224777222
train--47/100 [259/1090] loss: 0.4572508126497269
train--47/100 [269/1090] loss: 0.4481506496667862
train--47/100 [279/1090] loss: 0.45211324095726013
train--47/100 [289/1090] loss: 0.4528310984373093
train--47/100 [299/1090] loss: 0.4379520833492279
train--47/100 [309/1090] loss: 0.4489913433790207
train--47/100 [319/1090] loss: 0.4373773604631424
train--47/100 [329/1090] loss: 0.4430563747882843
train--47/100 [339/1090] loss: 0.4431259840726852
train--47/100 [349/1090] loss: 0.4299096316099167
train--47/100 [359/1090] loss: 0.4319468230009079
train--47/100 [369/1090] loss: 0.45339183509349823
train--47/100 [379/1090] loss: 0.42809219360351564
train--47/100 [389/1090] loss: 0.4612339287996292
train--47/100 [399/1090] loss: 0.44468083679676057
train--47/100 [409/1090] loss: 0.4425737768411636
train--47/100 [419/1090] loss: 0.4529962480068207
train--47/100 [429/1090] loss: 0.4495591640472412
train--47/100 [439/1090] loss: 0.43525848388671873
train--47/100 [449/1090] loss: 0.4580481231212616
train--47/100 [459/1090] loss: 0.44830178916454316
train--47/100 [469/1090] loss: 0.4765928715467453
train--47/100 [479/1090] loss: 0.44487119615077975
train--47/100 [489/1090] loss: 0.4432073920965195
train--47/100 [499/1090] loss: 0.4289126843214035
train--47/100 [509/1090] loss: 0.4377229899168015
train--47/100 [519/1090] loss: 0.45687898993492126
train--47/100 [529/1090] loss: 0.44570826590061186
train--47/100 [539/1090] loss: 0.44321816563606264
train--47/100 [549/1090] loss: 0.44498003721237184
train--47/100 [559/1090] loss: 0.4505433112382889
train--47/100 [569/1090] loss: 0.448598313331604
train--47/100 [579/1090] loss: 0.44423354864120485
train--47/100 [589/1090] loss: 0.4431621551513672
train--47/100 [599/1090] loss: 0.43502727150917053
train--47/100 [609/1090] loss: 0.4356368839740753
train--47/100 [619/1090] loss: 0.43760994672775266
train--47/100 [629/1090] loss: 0.4506968021392822
train--47/100 [639/1090] loss: 0.4454049825668335
train--47/100 [649/1090] loss: 0.4769900619983673
train--47/100 [659/1090] loss: 0.4512725085020065
train--47/100 [669/1090] loss: 0.4378411889076233
train--47/100 [679/1090] loss: 0.43730978965759276
train--47/100 [689/1090] loss: 0.45198279023170473
train--47/100 [699/1090] loss: 0.43894830346107483
train--47/100 [709/1090] loss: 0.4230940878391266
train--47/100 [719/1090] loss: 0.4517881512641907
train--47/100 [729/1090] loss: 0.44721299707889556
train--47/100 [739/1090] loss: 0.43774033188819883
train--47/100 [749/1090] loss: 0.4597961395978928
train--47/100 [759/1090] loss: 0.4708449989557266
train--47/100 [769/1090] loss: 0.448443666100502
train--47/100 [779/1090] loss: 0.4406104326248169
train--47/100 [789/1090] loss: 0.44808539748191833
train--47/100 [799/1090] loss: 0.44261299073696136
train--47/100 [809/1090] loss: 0.4234853178262711
train--47/100 [819/1090] loss: 0.45141151547431946
train--47/100 [829/1090] loss: 0.4401474416255951
train--47/100 [839/1090] loss: 0.4532108515501022
train--47/100 [849/1090] loss: 0.4279840290546417
train--47/100 [859/1090] loss: 0.45427671670913694
train--47/100 [869/1090] loss: 0.4391106367111206
train--47/100 [879/1090] loss: 0.46081838607788084
train--47/100 [889/1090] loss: 0.4687943637371063
train--47/100 [899/1090] loss: 0.4591172605752945
train--47/100 [909/1090] loss: 0.4288066655397415
train--47/100 [919/1090] loss: 0.45570396780967715
train--47/100 [929/1090] loss: 0.4565264344215393
train--47/100 [939/1090] loss: 0.4397362232208252
train--47/100 [949/1090] loss: 0.45214801728725434
train--47/100 [959/1090] loss: 0.44760622382164
train--47/100 [969/1090] loss: 0.45307736992836
train--47/100 [979/1090] loss: 0.43471068143844604
train--47/100 [989/1090] loss: 0.44035136699676514
train--47/100 [999/1090] loss: 0.4544231444597244
train--47/100 [1009/1090] loss: 0.4576295644044876
train--47/100 [1019/1090] loss: 0.46736565232276917
train--47/100 [1029/1090] loss: 0.4519166320562363
train--47/100 [1039/1090] loss: 0.4544226676225662
train--47/100 [1049/1090] loss: 0.4584179788827896
train--47/100 [1059/1090] loss: 0.45800923705101015
train--47/100 [1069/1090] loss: 0.4224000334739685
train--47/100 [1079/1090] loss: 0.4533903956413269
train--47/100 [1089/1090] loss: 0.44959974884986875
predicting model...
val--47/100 [10/1090] acc: 0.7921875
val--47/100 [20/1090] acc: 0.793359375
val--47/100 [30/1090] acc: 0.794140625
val--47/100 [40/1090] acc: 0.79453125
val--47/100 [50/1090] acc: 0.793515625
val--47/100 [60/1090] acc: 0.792578125
val--47/100 [70/1090] acc: 0.7932477678571429
val--47/100 [80/1090] acc: 0.792431640625
val--47/100 [90/1090] acc: 0.7928819444444445
val--47/100 [100/1090] acc: 0.7937109375
val--47/100 [110/1090] acc: 0.7941761363636364
val--47/100 [120/1090] acc: 0.7936197916666666
val--47/100 [130/1090] acc: 0.7943810096153846
val--47/100 [140/1090] acc: 0.7943917410714286
val--47/100 [150/1090] acc: 0.794609375
val--47/100 [160/1090] acc: 0.794873046875
val--47/100 [170/1090] acc: 0.7947380514705882
val--47/100 [180/1090] acc: 0.7944444444444444
val--47/100 [190/1090] acc: 0.7953741776315789
val--47/100 [200/1090] acc: 0.795546875
val--47/100 [210/1090] acc: 0.7958519345238095
val--47/100 [220/1090] acc: 0.7950461647727273
val--47/100 [230/1090] acc: 0.795805027173913
val--47/100 [240/1090] acc: 0.7956380208333333
val--47/100 [250/1090] acc: 0.79575
val--47/100 [260/1090] acc: 0.7956881009615384
val--47/100 [270/1090] acc: 0.7959346064814815
val--47/100 [280/1090] acc: 0.7959681919642857
val--47/100 [290/1090] acc: 0.7958243534482758
val--47/100 [300/1090] acc: 0.7959114583333333
val--47/100 [310/1090] acc: 0.7954889112903226
val--47/100 [320/1090] acc: 0.7956787109375
val--47/100 [330/1090] acc: 0.795904356060606
val--47/100 [340/1090] acc: 0.7959788602941177
val--47/100 [350/1090] acc: 0.7961272321428572
val--47/100 [360/1090] acc: 0.7960503472222222
val--47/100 [370/1090] acc: 0.7962204391891892
val--47/100 [380/1090] acc: 0.796155427631579
val--47/100 [390/1090] acc: 0.7959535256410256
val--47/100 [400/1090] acc: 0.7958984375
val--47/100 [410/1090] acc: 0.7960651676829268
val--47/100 [420/1090] acc: 0.7960100446428572
val--47/100 [430/1090] acc: 0.7959302325581395
val--47/100 [440/1090] acc: 0.7959161931818182
val--47/100 [450/1090] acc: 0.7957552083333334
val--47/100 [460/1090] acc: 0.7956012228260869
val--47/100 [470/1090] acc: 0.7954953457446808
val--47/100 [480/1090] acc: 0.7955159505208333
val--47/100 [490/1090] acc: 0.7956792091836735
val--47/100 [500/1090] acc: 0.7958671875
val--47/100 [510/1090] acc: 0.7957873774509804
val--47/100 [520/1090] acc: 0.7959735576923077
val--47/100 [530/1090] acc: 0.7959389740566037
val--47/100 [540/1090] acc: 0.7960720486111111
val--47/100 [550/1090] acc: 0.7960014204545455
val--47/100 [560/1090] acc: 0.7958356584821429
val--47/100 [570/1090] acc: 0.7955729166666666
val--47/100 [580/1090] acc: 0.7955414870689655
val--47/100 [590/1090] acc: 0.7955971927966101
val--47/100 [600/1090] acc: 0.7955989583333334
val--47/100 [610/1090] acc: 0.7955430327868852
val--47/100 [620/1090] acc: 0.7954637096774193
val--47/100 [630/1090] acc: 0.795672123015873
val--47/100 [640/1090] acc: 0.7958740234375
val--47/100 [650/1090] acc: 0.7958353365384615
val--47/100 [660/1090] acc: 0.7957563920454546
val--47/100 [670/1090] acc: 0.7954524253731343
val--47/100 [680/1090] acc: 0.7953469669117647
val--47/100 [690/1090] acc: 0.7955276268115942
val--47/100 [700/1090] acc: 0.7955412946428572
val--47/100 [710/1090] acc: 0.7953620158450704
val--47/100 [720/1090] acc: 0.7952365451388889
val--47/100 [730/1090] acc: 0.7952482876712329
val--47/100 [740/1090] acc: 0.7951963682432432
val--47/100 [750/1090] acc: 0.7952708333333334
val--47/100 [760/1090] acc: 0.7953125
val--47/100 [770/1090] acc: 0.7952566964285714
val--47/100 [780/1090] acc: 0.7952173477564103
val--47/100 [790/1090] acc: 0.7952630537974683
val--47/100 [800/1090] acc: 0.7955224609375
val--47/100 [810/1090] acc: 0.7955970293209876
val--47/100 [820/1090] acc: 0.7956697789634146
val--47/100 [830/1090] acc: 0.795750188253012
val--47/100 [840/1090] acc: 0.795707775297619
val--47/100 [850/1090] acc: 0.7957536764705883
val--47/100 [860/1090] acc: 0.7959665697674418
val--47/100 [870/1090] acc: 0.795855783045977
val--47/100 [880/1090] acc: 0.7958096590909091
val--47/100 [890/1090] acc: 0.7959576896067416
val--47/100 [900/1090] acc: 0.7959505208333333
val--47/100 [910/1090] acc: 0.7959349244505495
val--47/100 [920/1090] acc: 0.7959366508152174
val--47/100 [930/1090] acc: 0.7960139448924731
val--47/100 [940/1090] acc: 0.7960231050531915
val--47/100 [950/1090] acc: 0.7958963815789474
val--47/100 [960/1090] acc: 0.79581298828125
val--47/100 [970/1090] acc: 0.7958078286082474
val--47/100 [980/1090] acc: 0.7958067602040816
val--47/100 [990/1090] acc: 0.7957386363636364
val--47/100 [1000/1090] acc: 0.79562890625
val--47/100 [1010/1090] acc: 0.7954865408415842
val--47/100 [1020/1090] acc: 0.7955499387254902
val--47/100 [1030/1090] acc: 0.7955893507281553
val--47/100 [1040/1090] acc: 0.7955942007211538
val--47/100 [1050/1090] acc: 0.7956510416666667
val--47/100 [1060/1090] acc: 0.795592570754717
val--47/100 [1070/1090] acc: 0.7955972546728972
val--47/100 [1080/1090] acc: 0.7955403645833333
val--47/100 [1090/1090] acc: 0.7953949254587156
epoch= 47, accuracy= 0.795395, rmse= 0.377903, auc= 0.855176
train--48/100 [9/1090] loss: 0.3977767050266266
train--48/100 [19/1090] loss: 0.44269046783447263
train--48/100 [29/1090] loss: 0.43113225400447847
train--48/100 [39/1090] loss: 0.4223325550556183
train--48/100 [49/1090] loss: 0.45465838015079496
train--48/100 [59/1090] loss: 0.436678546667099
train--48/100 [69/1090] loss: 0.43260085880756377
train--48/100 [79/1090] loss: 0.4564893990755081
train--48/100 [89/1090] loss: 0.4646158367395401
train--48/100 [99/1090] loss: 0.4425092875957489
train--48/100 [109/1090] loss: 0.4480798363685608
train--48/100 [119/1090] loss: 0.44425631165504453
train--48/100 [129/1090] loss: 0.4664949059486389
train--48/100 [139/1090] loss: 0.44472028613090514
train--48/100 [149/1090] loss: 0.45036448538303375
train--48/100 [159/1090] loss: 0.44089131355285643
train--48/100 [169/1090] loss: 0.44082202613353727
train--48/100 [179/1090] loss: 0.4420413881540298
train--48/100 [189/1090] loss: 0.43590386807918546
train--48/100 [199/1090] loss: 0.45960074067115786
train--48/100 [209/1090] loss: 0.45108835995197294
train--48/100 [219/1090] loss: 0.4339930474758148
train--48/100 [229/1090] loss: 0.42810467779636385
train--48/100 [239/1090] loss: 0.45471170246601106
train--48/100 [249/1090] loss: 0.4424451380968094
train--48/100 [259/1090] loss: 0.4507367193698883
train--48/100 [269/1090] loss: 0.4419751316308975
train--48/100 [279/1090] loss: 0.4580226629972458
train--48/100 [289/1090] loss: 0.4411807179450989
train--48/100 [299/1090] loss: 0.44801622331142427
train--48/100 [309/1090] loss: 0.4495529532432556
train--48/100 [319/1090] loss: 0.4543907016515732
train--48/100 [329/1090] loss: 0.4522790789604187
train--48/100 [339/1090] loss: 0.4263102859258652
train--48/100 [349/1090] loss: 0.42856707870960237
train--48/100 [359/1090] loss: 0.44796372950077057
train--48/100 [369/1090] loss: 0.4527373492717743
train--48/100 [379/1090] loss: 0.4466573089361191
train--48/100 [389/1090] loss: 0.42382632493972777
train--48/100 [399/1090] loss: 0.45628880262374877
train--48/100 [409/1090] loss: 0.4353854238986969
train--48/100 [419/1090] loss: 0.4299540549516678
train--48/100 [429/1090] loss: 0.4468146562576294
train--48/100 [439/1090] loss: 0.4299014985561371
train--48/100 [449/1090] loss: 0.4466027796268463
train--48/100 [459/1090] loss: 0.47257028222084047
train--48/100 [469/1090] loss: 0.43769730627536774
train--48/100 [479/1090] loss: 0.44042720794677737
train--48/100 [489/1090] loss: 0.43427440226078035
train--48/100 [499/1090] loss: 0.44130081236362456
train--48/100 [509/1090] loss: 0.44741111993789673
train--48/100 [519/1090] loss: 0.44496710896492003
train--48/100 [529/1090] loss: 0.46265978217124937
train--48/100 [539/1090] loss: 0.4526494085788727
train--48/100 [549/1090] loss: 0.4579581916332245
train--48/100 [559/1090] loss: 0.440075421333313
train--48/100 [569/1090] loss: 0.45184153616428374
train--48/100 [579/1090] loss: 0.4373466342687607
train--48/100 [589/1090] loss: 0.4242590665817261
train--48/100 [599/1090] loss: 0.4339927792549133
train--48/100 [609/1090] loss: 0.45518416464328765
train--48/100 [619/1090] loss: 0.4477809131145477
train--48/100 [629/1090] loss: 0.46088544428348543
train--48/100 [639/1090] loss: 0.47032361924648286
train--48/100 [649/1090] loss: 0.43236651420593264
train--48/100 [659/1090] loss: 0.4293275743722916
train--48/100 [669/1090] loss: 0.44703649282455443
train--48/100 [679/1090] loss: 0.4423081785440445
train--48/100 [689/1090] loss: 0.4429767996072769
train--48/100 [699/1090] loss: 0.43817279040813445
train--48/100 [709/1090] loss: 0.45236034989356994
train--48/100 [719/1090] loss: 0.4406163215637207
train--48/100 [729/1090] loss: 0.4409176707267761
train--48/100 [739/1090] loss: 0.4520025461912155
train--48/100 [749/1090] loss: 0.473092246055603
train--48/100 [759/1090] loss: 0.4504083156585693
train--48/100 [769/1090] loss: 0.4315603464841843
train--48/100 [779/1090] loss: 0.44681008756160734
train--48/100 [789/1090] loss: 0.43560430109500886
train--48/100 [799/1090] loss: 0.45884659588336946
train--48/100 [809/1090] loss: 0.4269113391637802
train--48/100 [819/1090] loss: 0.4516946107149124
train--48/100 [829/1090] loss: 0.46183146834373473
train--48/100 [839/1090] loss: 0.45794306993484496
train--48/100 [849/1090] loss: 0.4593412816524506
train--48/100 [859/1090] loss: 0.4334086537361145
train--48/100 [869/1090] loss: 0.4373992711305618
train--48/100 [879/1090] loss: 0.44586617946624757
train--48/100 [889/1090] loss: 0.43611503541469576
train--48/100 [899/1090] loss: 0.4326382726430893
train--48/100 [909/1090] loss: 0.45381630063056944
train--48/100 [919/1090] loss: 0.44024568498134614
train--48/100 [929/1090] loss: 0.4432611972093582
train--48/100 [939/1090] loss: 0.455322790145874
train--48/100 [949/1090] loss: 0.4618529111146927
train--48/100 [959/1090] loss: 0.4366620361804962
train--48/100 [969/1090] loss: 0.43350349068641664
train--48/100 [979/1090] loss: 0.45123193264007566
train--48/100 [989/1090] loss: 0.45244936645030975
train--48/100 [999/1090] loss: 0.4673208326101303
train--48/100 [1009/1090] loss: 0.4540854036808014
train--48/100 [1019/1090] loss: 0.45250874757766724
train--48/100 [1029/1090] loss: 0.4458482384681702
train--48/100 [1039/1090] loss: 0.4495091259479523
train--48/100 [1049/1090] loss: 0.4398883193731308
train--48/100 [1059/1090] loss: 0.4262828856706619
train--48/100 [1069/1090] loss: 0.43957599699497224
train--48/100 [1079/1090] loss: 0.4591751366853714
train--48/100 [1089/1090] loss: 0.4586780935525894
predicting model...
val--48/100 [10/1090] acc: 0.797265625
val--48/100 [20/1090] acc: 0.7982421875
val--48/100 [30/1090] acc: 0.7971354166666667
val--48/100 [40/1090] acc: 0.7966796875
val--48/100 [50/1090] acc: 0.795078125
val--48/100 [60/1090] acc: 0.79375
val--48/100 [70/1090] acc: 0.794140625
val--48/100 [80/1090] acc: 0.7931640625
val--48/100 [90/1090] acc: 0.7935763888888889
val--48/100 [100/1090] acc: 0.794609375
val--48/100 [110/1090] acc: 0.7951349431818182
val--48/100 [120/1090] acc: 0.7947591145833334
val--48/100 [130/1090] acc: 0.7959134615384615
val--48/100 [140/1090] acc: 0.7957310267857143
val--48/100 [150/1090] acc: 0.7956770833333333
val--48/100 [160/1090] acc: 0.7959228515625
val--48/100 [170/1090] acc: 0.7957950367647059
val--48/100 [180/1090] acc: 0.7954644097222222
val--48/100 [190/1090] acc: 0.7962582236842105
val--48/100 [200/1090] acc: 0.79640625
val--48/100 [210/1090] acc: 0.7967819940476191
val--48/100 [220/1090] acc: 0.7959872159090909
val--48/100 [230/1090] acc: 0.7964673913043478
val--48/100 [240/1090] acc: 0.7962565104166667
val--48/100 [250/1090] acc: 0.7963125
val--48/100 [260/1090] acc: 0.7964092548076923
val--48/100 [270/1090] acc: 0.7965133101851852
val--48/100 [280/1090] acc: 0.7964285714285714
val--48/100 [290/1090] acc: 0.796228448275862
val--48/100 [300/1090] acc: 0.7963020833333333
val--48/100 [310/1090] acc: 0.7959803427419355
val--48/100 [320/1090] acc: 0.79613037109375
val--48/100 [330/1090] acc: 0.7964370265151515
val--48/100 [340/1090] acc: 0.7965762867647059
val--48/100 [350/1090] acc: 0.7966629464285714
val--48/100 [360/1090] acc: 0.79658203125
val--48/100 [370/1090] acc: 0.7966955236486486
val--48/100 [380/1090] acc: 0.7966694078947368
val--48/100 [390/1090] acc: 0.7964042467948718
val--48/100 [400/1090] acc: 0.796357421875
val--48/100 [410/1090] acc: 0.7965320121951219
val--48/100 [420/1090] acc: 0.7965215773809524
val--48/100 [430/1090] acc: 0.7964117005813953
val--48/100 [440/1090] acc: 0.7964488636363637
val--48/100 [450/1090] acc: 0.796328125
val--48/100 [460/1090] acc: 0.7962041440217391
val--48/100 [470/1090] acc: 0.7961103723404256
val--48/100 [480/1090] acc: 0.7961344401041667
val--48/100 [490/1090] acc: 0.7962930484693878
val--48/100 [500/1090] acc: 0.7964375
val--48/100 [510/1090] acc: 0.7963311887254902
val--48/100 [520/1090] acc: 0.796484375
val--48/100 [530/1090] acc: 0.7964696344339622
val--48/100 [540/1090] acc: 0.7965856481481481
val--48/100 [550/1090] acc: 0.7964772727272728
val--48/100 [560/1090] acc: 0.7962193080357143
val--48/100 [570/1090] acc: 0.7959361293859649
val--48/100 [580/1090] acc: 0.7958782327586207
val--48/100 [590/1090] acc: 0.7959348516949153
val--48/100 [600/1090] acc: 0.7959700520833334
val--48/100 [610/1090] acc: 0.7958952356557377
val--48/100 [620/1090] acc: 0.7958228326612903
val--48/100 [630/1090] acc: 0.7960441468253968
val--48/100 [640/1090] acc: 0.79617919921875
val--48/100 [650/1090] acc: 0.7961598557692308
val--48/100 [660/1090] acc: 0.7960227272727273
val--48/100 [670/1090] acc: 0.7957264458955224
val--48/100 [680/1090] acc: 0.7956169577205883
val--48/100 [690/1090] acc: 0.7957597373188405
val--48/100 [700/1090] acc: 0.7957589285714286
val--48/100 [710/1090] acc: 0.7955215669014084
val--48/100 [720/1090] acc: 0.7954155815972223
val--48/100 [730/1090] acc: 0.7953767123287672
val--48/100 [740/1090] acc: 0.7953388935810811
val--48/100 [750/1090] acc: 0.79540625
val--48/100 [760/1090] acc: 0.7954769736842106
val--48/100 [770/1090] acc: 0.7954393262987013
val--48/100 [780/1090] acc: 0.7953876201923077
val--48/100 [790/1090] acc: 0.7954064477848102
val--48/100 [800/1090] acc: 0.795615234375
val--48/100 [810/1090] acc: 0.7956838348765433
val--48/100 [820/1090] acc: 0.7957888719512195
val--48/100 [830/1090] acc: 0.7958490210843373
val--48/100 [840/1090] acc: 0.7958193824404762
val--48/100 [850/1090] acc: 0.7958501838235295
val--48/100 [860/1090] acc: 0.79609375
val--48/100 [870/1090] acc: 0.7959949712643678
val--48/100 [880/1090] acc: 0.7959694602272728
val--48/100 [890/1090] acc: 0.7961156952247191
val--48/100 [900/1090] acc: 0.7961284722222223
val--48/100 [910/1090] acc: 0.7961280906593406
val--48/100 [920/1090] acc: 0.7961107336956522
val--48/100 [930/1090] acc: 0.7961945564516129
val--48/100 [940/1090] acc: 0.7961934840425532
val--48/100 [950/1090] acc: 0.7960649671052632
val--48/100 [960/1090] acc: 0.7960001627604166
val--48/100 [970/1090] acc: 0.7959809922680412
val--48/100 [980/1090] acc: 0.7959661989795919
val--48/100 [990/1090] acc: 0.7958767361111111
val--48/100 [1000/1090] acc: 0.79577734375
val--48/100 [1010/1090] acc: 0.7956141707920792
val--48/100 [1020/1090] acc: 0.7956533394607843
val--48/100 [1030/1090] acc: 0.7956841626213592
val--48/100 [1040/1090] acc: 0.7956693209134615
val--48/100 [1050/1090] acc: 0.7957142857142857
val--48/100 [1060/1090] acc: 0.795677329009434
val--48/100 [1070/1090] acc: 0.7956848714953271
val--48/100 [1080/1090] acc: 0.7956344039351851
val--48/100 [1090/1090] acc: 0.7954916857798165
epoch= 48, accuracy= 0.795492, rmse= 0.377823, auc= 0.855404
train--49/100 [9/1090] loss: 0.4085359275341034
train--49/100 [19/1090] loss: 0.42697606384754183
train--49/100 [29/1090] loss: 0.42665803134441377
train--49/100 [39/1090] loss: 0.4319121927022934
train--49/100 [49/1090] loss: 0.42888415455818174
train--49/100 [59/1090] loss: 0.4319002956151962
train--49/100 [69/1090] loss: 0.44314523339271544
train--49/100 [79/1090] loss: 0.45330549478530885
train--49/100 [89/1090] loss: 0.4420667141675949
train--49/100 [99/1090] loss: 0.44287826418876647
train--49/100 [109/1090] loss: 0.43231757581233976
train--49/100 [119/1090] loss: 0.44127883911132815
train--49/100 [129/1090] loss: 0.45773483216762545
train--49/100 [139/1090] loss: 0.4291535377502441
train--49/100 [149/1090] loss: 0.433121520280838
train--49/100 [159/1090] loss: 0.43785482048988345
train--49/100 [169/1090] loss: 0.426940506696701
train--49/100 [179/1090] loss: 0.43473324477672576
train--49/100 [189/1090] loss: 0.4397978276014328
train--49/100 [199/1090] loss: 0.44974881410598755
train--49/100 [209/1090] loss: 0.43487649261951444
train--49/100 [219/1090] loss: 0.4448728978633881
train--49/100 [229/1090] loss: 0.4388415694236755
train--49/100 [239/1090] loss: 0.4522067099809647
train--49/100 [249/1090] loss: 0.4412313669919968
train--49/100 [259/1090] loss: 0.4496060609817505
train--49/100 [269/1090] loss: 0.4140468567609787
train--49/100 [279/1090] loss: 0.42057653069496154
train--49/100 [289/1090] loss: 0.46675172448158264
train--49/100 [299/1090] loss: 0.4506076693534851
train--49/100 [309/1090] loss: 0.43608513474464417
train--49/100 [319/1090] loss: 0.4410964369773865
train--49/100 [329/1090] loss: 0.45445643961429594
train--49/100 [339/1090] loss: 0.44142021536827086
train--49/100 [349/1090] loss: 0.4541112154722214
train--49/100 [359/1090] loss: 0.4559404343366623
train--49/100 [369/1090] loss: 0.44443712532520296
train--49/100 [379/1090] loss: 0.43546212315559385
train--49/100 [389/1090] loss: 0.42687774896621705
train--49/100 [399/1090] loss: 0.45156663954257964
train--49/100 [409/1090] loss: 0.4420762300491333
train--49/100 [419/1090] loss: 0.43734212815761564
train--49/100 [429/1090] loss: 0.4406356245279312
train--49/100 [439/1090] loss: 0.45966229736804964
train--49/100 [449/1090] loss: 0.4420148879289627
train--49/100 [459/1090] loss: 0.45828472077846527
train--49/100 [469/1090] loss: 0.4280277669429779
train--49/100 [479/1090] loss: 0.45548442006111145
train--49/100 [489/1090] loss: 0.44767451882362364
train--49/100 [499/1090] loss: 0.4518645703792572
train--49/100 [509/1090] loss: 0.44408594965934756
train--49/100 [519/1090] loss: 0.4574980676174164
train--49/100 [529/1090] loss: 0.45729381442070005
train--49/100 [539/1090] loss: 0.42902683913707734
train--49/100 [549/1090] loss: 0.4239544004201889
train--49/100 [559/1090] loss: 0.45330785512924193
train--49/100 [569/1090] loss: 0.43139238357543946
train--49/100 [579/1090] loss: 0.43020429015159606
train--49/100 [589/1090] loss: 0.45922803282737734
train--49/100 [599/1090] loss: 0.44495564997196196
train--49/100 [609/1090] loss: 0.43296816647052766
train--49/100 [619/1090] loss: 0.4643306314945221
train--49/100 [629/1090] loss: 0.45039104521274564
train--49/100 [639/1090] loss: 0.4389252871274948
train--49/100 [649/1090] loss: 0.45697362422943116
train--49/100 [659/1090] loss: 0.44611178934574125
train--49/100 [669/1090] loss: 0.45808476209640503
train--49/100 [679/1090] loss: 0.4718289315700531
train--49/100 [689/1090] loss: 0.430830717086792
train--49/100 [699/1090] loss: 0.44598868787288665
train--49/100 [709/1090] loss: 0.4303701430559158
train--49/100 [719/1090] loss: 0.46115471720695494
train--49/100 [729/1090] loss: 0.4514929562807083
train--49/100 [739/1090] loss: 0.438498654961586
train--49/100 [749/1090] loss: 0.43383544981479644
train--49/100 [759/1090] loss: 0.4397817522287369
train--49/100 [769/1090] loss: 0.43712531924247744
train--49/100 [779/1090] loss: 0.4655961036682129
train--49/100 [789/1090] loss: 0.441682368516922
train--49/100 [799/1090] loss: 0.4408650517463684
train--49/100 [809/1090] loss: 0.4563082218170166
train--49/100 [819/1090] loss: 0.4679769456386566
train--49/100 [829/1090] loss: 0.4678472101688385
train--49/100 [839/1090] loss: 0.44278992116451266
train--49/100 [849/1090] loss: 0.4751510977745056
train--49/100 [859/1090] loss: 0.46256788074970245
train--49/100 [869/1090] loss: 0.432086655497551
train--49/100 [879/1090] loss: 0.4532780975103378
train--49/100 [889/1090] loss: 0.4469913601875305
train--49/100 [899/1090] loss: 0.4544401615858078
train--49/100 [909/1090] loss: 0.43012372255325315
train--49/100 [919/1090] loss: 0.43468417823314665
train--49/100 [929/1090] loss: 0.4528634637594223
train--49/100 [939/1090] loss: 0.4507340520620346
train--49/100 [949/1090] loss: 0.4234066098928452
train--49/100 [959/1090] loss: 0.453903004527092
train--49/100 [969/1090] loss: 0.44384042024612425
train--49/100 [979/1090] loss: 0.45570795238018036
train--49/100 [989/1090] loss: 0.4497611701488495
train--49/100 [999/1090] loss: 0.4533443748950958
train--49/100 [1009/1090] loss: 0.45279031693935395
train--49/100 [1019/1090] loss: 0.4743474990129471
train--49/100 [1029/1090] loss: 0.46351535320281984
train--49/100 [1039/1090] loss: 0.4556061774492264
train--49/100 [1049/1090] loss: 0.4453999936580658
train--49/100 [1059/1090] loss: 0.4447659611701965
train--49/100 [1069/1090] loss: 0.45130799114704134
train--49/100 [1079/1090] loss: 0.45226727426052094
train--49/100 [1089/1090] loss: 0.44641710817813873
predicting model...
val--49/100 [10/1090] acc: 0.793359375
val--49/100 [20/1090] acc: 0.794921875
val--49/100 [30/1090] acc: 0.7944010416666667
val--49/100 [40/1090] acc: 0.79423828125
val--49/100 [50/1090] acc: 0.79328125
val--49/100 [60/1090] acc: 0.792578125
val--49/100 [70/1090] acc: 0.7932477678571429
val--49/100 [80/1090] acc: 0.792431640625
val--49/100 [90/1090] acc: 0.7930989583333333
val--49/100 [100/1090] acc: 0.7940625
val--49/100 [110/1090] acc: 0.7946022727272727
val--49/100 [120/1090] acc: 0.7941731770833333
val--49/100 [130/1090] acc: 0.7954627403846154
val--49/100 [140/1090] acc: 0.7952566964285714
val--49/100 [150/1090] acc: 0.7952604166666667
val--49/100 [160/1090] acc: 0.795361328125
val--49/100 [170/1090] acc: 0.7952435661764706
val--49/100 [180/1090] acc: 0.7950303819444444
val--49/100 [190/1090] acc: 0.7960115131578948
val--49/100 [200/1090] acc: 0.796171875
val--49/100 [210/1090] acc: 0.7964471726190476
val--49/100 [220/1090] acc: 0.7955433238636364
val--49/100 [230/1090] acc: 0.7962635869565218
val--49/100 [240/1090] acc: 0.7960774739583333
val--49/100 [250/1090] acc: 0.796125
val--49/100 [260/1090] acc: 0.796063701923077
val--49/100 [270/1090] acc: 0.7964554398148148
val--49/100 [280/1090] acc: 0.7964006696428572
val--49/100 [290/1090] acc: 0.7961880387931034
val--49/100 [300/1090] acc: 0.7962760416666667
val--49/100 [310/1090] acc: 0.795929939516129
val--49/100 [320/1090] acc: 0.79609375
val--49/100 [330/1090] acc: 0.7963541666666667
val--49/100 [340/1090] acc: 0.7965533088235294
val--49/100 [350/1090] acc: 0.79671875
val--49/100 [360/1090] acc: 0.79658203125
val--49/100 [370/1090] acc: 0.7966955236486486
val--49/100 [380/1090] acc: 0.7966385690789474
val--49/100 [390/1090] acc: 0.796444310897436
val--49/100 [400/1090] acc: 0.796396484375
val--49/100 [410/1090] acc: 0.7966082317073171
val--49/100 [420/1090] acc: 0.796577380952381
val--49/100 [430/1090] acc: 0.7964389534883721
val--49/100 [440/1090] acc: 0.7964133522727272
val--49/100 [450/1090] acc: 0.7962934027777778
val--49/100 [460/1090] acc: 0.7961786684782609
val--49/100 [470/1090] acc: 0.796126994680851
val--49/100 [480/1090] acc: 0.7961018880208334
val--49/100 [490/1090] acc: 0.7962213010204081
val--49/100 [500/1090] acc: 0.796375
val--49/100 [510/1090] acc: 0.7962928921568627
val--49/100 [520/1090] acc: 0.796484375
val--49/100 [530/1090] acc: 0.7964622641509433
val--49/100 [540/1090] acc: 0.7966145833333333
val--49/100 [550/1090] acc: 0.7964914772727273
val--49/100 [560/1090] acc: 0.7963169642857143
val--49/100 [570/1090] acc: 0.7960731907894737
val--49/100 [580/1090] acc: 0.7960398706896552
val--49/100 [590/1090] acc: 0.7961136122881356
val--49/100 [600/1090] acc: 0.79611328125
val--49/100 [610/1090] acc: 0.7960040983606558
val--49/100 [620/1090] acc: 0.7959551411290322
val--49/100 [630/1090] acc: 0.7961743551587301
val--49/100 [640/1090] acc: 0.7963623046875
val--49/100 [650/1090] acc: 0.7963100961538462
val--49/100 [660/1090] acc: 0.7962062026515152
val--49/100 [670/1090] acc: 0.7958896921641792
val--49/100 [680/1090] acc: 0.7958065257352941
val--49/100 [690/1090] acc: 0.7959295742753624
val--49/100 [700/1090] acc: 0.7959821428571429
val--49/100 [710/1090] acc: 0.7957691461267605
val--49/100 [720/1090] acc: 0.7956488715277777
val--49/100 [730/1090] acc: 0.7956282106164384
val--49/100 [740/1090] acc: 0.795534206081081
val--49/100 [750/1090] acc: 0.7955989583333334
val--49/100 [760/1090] acc: 0.7956825657894737
val--49/100 [770/1090] acc: 0.7956219561688311
val--49/100 [780/1090] acc: 0.7955528846153846
val--49/100 [790/1090] acc: 0.7955696202531646
val--49/100 [800/1090] acc: 0.795771484375
val--49/100 [810/1090] acc: 0.7958333333333333
val--49/100 [820/1090] acc: 0.7959508384146341
val--49/100 [830/1090] acc: 0.7960231551204819
val--49/100 [840/1090] acc: 0.796000744047619
val--49/100 [850/1090] acc: 0.7960294117647059
val--49/100 [860/1090] acc: 0.7962618095930233
val--49/100 [870/1090] acc: 0.7961566091954023
val--49/100 [880/1090] acc: 0.7961248224431818
val--49/100 [890/1090] acc: 0.7962824789325843
val--49/100 [900/1090] acc: 0.7962803819444444
val--49/100 [910/1090] acc: 0.7962869162087912
val--49/100 [920/1090] acc: 0.7962678328804348
val--49/100 [930/1090] acc: 0.7963583669354839
val--49/100 [940/1090] acc: 0.7963597074468085
val--49/100 [950/1090] acc: 0.7962129934210527
val--49/100 [960/1090] acc: 0.7961263020833333
val--49/100 [970/1090] acc: 0.7961098582474226
val--49/100 [980/1090] acc: 0.7961455676020408
val--49/100 [990/1090] acc: 0.7960503472222222
val--49/100 [1000/1090] acc: 0.7959375
val--49/100 [1010/1090] acc: 0.7957843440594059
val--49/100 [1020/1090] acc: 0.7958486519607844
val--49/100 [1030/1090] acc: 0.7958548240291262
val--49/100 [1040/1090] acc: 0.7958759014423077
val--49/100 [1050/1090] acc: 0.7959561011904762
val--49/100 [1060/1090] acc: 0.7958726415094339
val--49/100 [1070/1090] acc: 0.7958929614485981
val--49/100 [1080/1090] acc: 0.7958333333333333
val--49/100 [1090/1090] acc: 0.7956744552752294
epoch= 49, accuracy= 0.795674, rmse= 0.377692, auc= 0.855417
train--50/100 [9/1090] loss: 0.4035136938095093
train--50/100 [19/1090] loss: 0.42464140951633456
train--50/100 [29/1090] loss: 0.44474258124828336
train--50/100 [39/1090] loss: 0.42588173747062685
train--50/100 [49/1090] loss: 0.41971824765205384
train--50/100 [59/1090] loss: 0.4405161261558533
train--50/100 [69/1090] loss: 0.43745030760765075
train--50/100 [79/1090] loss: 0.4326378405094147
train--50/100 [89/1090] loss: 0.45742300152778625
train--50/100 [99/1090] loss: 0.44057284891605375
train--50/100 [109/1090] loss: 0.4375734865665436
train--50/100 [119/1090] loss: 0.4577628314495087
train--50/100 [129/1090] loss: 0.4203463762998581
train--50/100 [139/1090] loss: 0.45692351162433625
train--50/100 [149/1090] loss: 0.4354579508304596
train--50/100 [159/1090] loss: 0.4422849535942078
train--50/100 [169/1090] loss: 0.4389301806688309
train--50/100 [179/1090] loss: 0.4363461911678314
train--50/100 [189/1090] loss: 0.45247367322444915
train--50/100 [199/1090] loss: 0.46512395739555357
train--50/100 [209/1090] loss: 0.443413519859314
train--50/100 [219/1090] loss: 0.4469925105571747
train--50/100 [229/1090] loss: 0.43865229189395905
train--50/100 [239/1090] loss: 0.43554435670375824
train--50/100 [249/1090] loss: 0.43894076645374297
train--50/100 [259/1090] loss: 0.4344473034143448
train--50/100 [269/1090] loss: 0.45919611155986784
train--50/100 [279/1090] loss: 0.4366362035274506
train--50/100 [289/1090] loss: 0.4528858929872513
train--50/100 [299/1090] loss: 0.46417767703533175
train--50/100 [309/1090] loss: 0.44667229652404783
train--50/100 [319/1090] loss: 0.4469389200210571
train--50/100 [329/1090] loss: 0.4494053602218628
train--50/100 [339/1090] loss: 0.45895837247371674
train--50/100 [349/1090] loss: 0.43809528946876525
train--50/100 [359/1090] loss: 0.45909627079963683
train--50/100 [369/1090] loss: 0.4393503785133362
train--50/100 [379/1090] loss: 0.4607537120580673
train--50/100 [389/1090] loss: 0.4399951100349426
train--50/100 [399/1090] loss: 0.4435575634241104
train--50/100 [409/1090] loss: 0.4537687450647354
train--50/100 [419/1090] loss: 0.4328200787305832
train--50/100 [429/1090] loss: 0.42382327020168303
train--50/100 [439/1090] loss: 0.463139271736145
train--50/100 [449/1090] loss: 0.4508110612630844
train--50/100 [459/1090] loss: 0.45346408188343046
train--50/100 [469/1090] loss: 0.45628259181976316
train--50/100 [479/1090] loss: 0.43469233214855196
train--50/100 [489/1090] loss: 0.433390936255455
train--50/100 [499/1090] loss: 0.4515692710876465
train--50/100 [509/1090] loss: 0.4334814578294754
train--50/100 [519/1090] loss: 0.44072976112365725
train--50/100 [529/1090] loss: 0.44393028020858766
train--50/100 [539/1090] loss: 0.45708869099617006
train--50/100 [549/1090] loss: 0.4405811309814453
train--50/100 [559/1090] loss: 0.44175044298171995
train--50/100 [569/1090] loss: 0.4474446028470993
train--50/100 [579/1090] loss: 0.4447237432003021
train--50/100 [589/1090] loss: 0.43591658771038055
train--50/100 [599/1090] loss: 0.43223151564598083
train--50/100 [609/1090] loss: 0.42542571723461153
train--50/100 [619/1090] loss: 0.46166500449180603
train--50/100 [629/1090] loss: 0.4373602867126465
train--50/100 [639/1090] loss: 0.4595067143440247
train--50/100 [649/1090] loss: 0.4382886916399002
train--50/100 [659/1090] loss: 0.4424663186073303
train--50/100 [669/1090] loss: 0.44501636624336244
train--50/100 [679/1090] loss: 0.46912614703178407
train--50/100 [689/1090] loss: 0.4665846139192581
train--50/100 [699/1090] loss: 0.45449556708335875
train--50/100 [709/1090] loss: 0.46560740768909453
train--50/100 [719/1090] loss: 0.43685696721076966
train--50/100 [729/1090] loss: 0.4415790617465973
train--50/100 [739/1090] loss: 0.4614925742149353
train--50/100 [749/1090] loss: 0.44395465552806856
train--50/100 [759/1090] loss: 0.453770250082016
train--50/100 [769/1090] loss: 0.448187854886055
train--50/100 [779/1090] loss: 0.4416922450065613
train--50/100 [789/1090] loss: 0.4442396104335785
train--50/100 [799/1090] loss: 0.45319457948207853
train--50/100 [809/1090] loss: 0.4378984451293945
train--50/100 [819/1090] loss: 0.4543438494205475
train--50/100 [829/1090] loss: 0.4404642790555954
train--50/100 [839/1090] loss: 0.4542704164981842
train--50/100 [849/1090] loss: 0.44173412322998046
train--50/100 [859/1090] loss: 0.45978576242923735
train--50/100 [869/1090] loss: 0.43549267053604124
train--50/100 [879/1090] loss: 0.45390047430992125
train--50/100 [889/1090] loss: 0.44066149890422823
train--50/100 [899/1090] loss: 0.4273478537797928
train--50/100 [909/1090] loss: 0.4518495500087738
train--50/100 [919/1090] loss: 0.4486947000026703
train--50/100 [929/1090] loss: 0.448453089594841
train--50/100 [939/1090] loss: 0.43806758522987366
train--50/100 [949/1090] loss: 0.42953420281410215
train--50/100 [959/1090] loss: 0.44874814450740813
train--50/100 [969/1090] loss: 0.43151419460773466
train--50/100 [979/1090] loss: 0.4475225806236267
train--50/100 [989/1090] loss: 0.44053917825222016
train--50/100 [999/1090] loss: 0.4475096106529236
train--50/100 [1009/1090] loss: 0.43257040083408355
train--50/100 [1019/1090] loss: 0.45145838856697085
train--50/100 [1029/1090] loss: 0.44677398204803465
train--50/100 [1039/1090] loss: 0.45990256071090696
train--50/100 [1049/1090] loss: 0.4550481975078583
train--50/100 [1059/1090] loss: 0.4325594365596771
train--50/100 [1069/1090] loss: 0.43540104329586027
train--50/100 [1079/1090] loss: 0.45035008490085604
train--50/100 [1089/1090] loss: 0.4612683683633804
predicting model...
val--50/100 [10/1090] acc: 0.796484375
val--50/100 [20/1090] acc: 0.796875
val--50/100 [30/1090] acc: 0.795703125
val--50/100 [40/1090] acc: 0.795703125
val--50/100 [50/1090] acc: 0.795078125
val--50/100 [60/1090] acc: 0.7930338541666667
val--50/100 [70/1090] acc: 0.7931919642857143
val--50/100 [80/1090] acc: 0.7919921875
val--50/100 [90/1090] acc: 0.7927517361111112
val--50/100 [100/1090] acc: 0.7940234375
val--50/100 [110/1090] acc: 0.7944602272727272
val--50/100 [120/1090] acc: 0.7940755208333333
val--50/100 [130/1090] acc: 0.7953425480769231
val--50/100 [140/1090] acc: 0.7953125
val--50/100 [150/1090] acc: 0.7953645833333334
val--50/100 [160/1090] acc: 0.795654296875
val--50/100 [170/1090] acc: 0.7954963235294118
val--50/100 [180/1090] acc: 0.7952907986111111
val--50/100 [190/1090] acc: 0.7961759868421052
val--50/100 [200/1090] acc: 0.79640625
val--50/100 [210/1090] acc: 0.7968191964285715
val--50/100 [220/1090] acc: 0.7960049715909091
val--50/100 [230/1090] acc: 0.7966881793478261
val--50/100 [240/1090] acc: 0.7964518229166667
val--50/100 [250/1090] acc: 0.7965
val--50/100 [260/1090] acc: 0.7965895432692308
val--50/100 [270/1090] acc: 0.7968315972222222
val--50/100 [280/1090] acc: 0.7967354910714286
val--50/100 [290/1090] acc: 0.7966594827586206
val--50/100 [300/1090] acc: 0.7966276041666667
val--50/100 [310/1090] acc: 0.7962701612903226
val--50/100 [320/1090] acc: 0.796484375
val--50/100 [330/1090] acc: 0.7967566287878788
val--50/100 [340/1090] acc: 0.7969669117647059
val--50/100 [350/1090] acc: 0.7970647321428571
val--50/100 [360/1090] acc: 0.7970052083333333
val--50/100 [370/1090] acc: 0.7972233952702703
val--50/100 [380/1090] acc: 0.7971525493421052
val--50/100 [390/1090] acc: 0.7969851762820512
val--50/100 [400/1090] acc: 0.796875
val--50/100 [410/1090] acc: 0.7970274390243902
val--50/100 [420/1090] acc: 0.7969401041666667
val--50/100 [430/1090] acc: 0.7967387354651163
val--50/100 [440/1090] acc: 0.7967063210227273
val--50/100 [450/1090] acc: 0.7965451388888889
val--50/100 [460/1090] acc: 0.7964079483695652
val--50/100 [470/1090] acc: 0.7963513962765958
val--50/100 [480/1090] acc: 0.7963704427083333
val--50/100 [490/1090] acc: 0.7965082908163266
val--50/100 [500/1090] acc: 0.79665625
val--50/100 [510/1090] acc: 0.796484375
val--50/100 [520/1090] acc: 0.7966496394230769
val--50/100 [530/1090] acc: 0.7965875589622642
val--50/100 [540/1090] acc: 0.7967230902777778
val--50/100 [550/1090] acc: 0.7965838068181819
val--50/100 [560/1090] acc: 0.7963588169642857
val--50/100 [570/1090] acc: 0.7961417214912281
val--50/100 [580/1090] acc: 0.7961476293103448
val--50/100 [590/1090] acc: 0.7961930614406779
val--50/100 [600/1090] acc: 0.7962369791666667
val--50/100 [610/1090] acc: 0.7961321721311475
val--50/100 [620/1090] acc: 0.7960811491935483
val--50/100 [630/1090] acc: 0.7962735615079365
val--50/100 [640/1090] acc: 0.79642333984375
val--50/100 [650/1090] acc: 0.7964002403846154
val--50/100 [660/1090] acc: 0.7963304924242425
val--50/100 [670/1090] acc: 0.7960121268656717
val--50/100 [680/1090] acc: 0.7959386488970588
val--50/100 [690/1090] acc: 0.7960654438405798
val--50/100 [700/1090] acc: 0.7960993303571429
val--50/100 [710/1090] acc: 0.7959286971830986
val--50/100 [720/1090] acc: 0.7958170572916666
val--50/100 [730/1090] acc: 0.7957619863013699
val--50/100 [740/1090] acc: 0.7956872888513513
val--50/100 [750/1090] acc: 0.7957291666666667
val--50/100 [760/1090] acc: 0.7957648026315789
val--50/100 [770/1090] acc: 0.7956828327922078
val--50/100 [780/1090] acc: 0.7956380208333333
val--50/100 [790/1090] acc: 0.7956339003164556
val--50/100 [800/1090] acc: 0.7958544921875
val--50/100 [810/1090] acc: 0.7959104938271605
val--50/100 [820/1090] acc: 0.796046112804878
val--50/100 [830/1090] acc: 0.7961031626506024
val--50/100 [840/1090] acc: 0.7960611979166666
val--50/100 [850/1090] acc: 0.7961259191176471
val--50/100 [860/1090] acc: 0.7963799055232558
val--50/100 [870/1090] acc: 0.7962508979885058
val--50/100 [880/1090] acc: 0.796200284090909
val--50/100 [890/1090] acc: 0.7963614817415731
val--50/100 [900/1090] acc: 0.7963628472222222
val--50/100 [910/1090] acc: 0.7963427197802198
val--50/100 [920/1090] acc: 0.7963187839673913
val--50/100 [930/1090] acc: 0.7964171706989247
val--50/100 [940/1090] acc: 0.7964261968085107
val--50/100 [950/1090] acc: 0.7962787828947369
val--50/100 [960/1090] acc: 0.7962117513020833
val--50/100 [970/1090] acc: 0.7962065077319588
val--50/100 [980/1090] acc: 0.7962053571428571
val--50/100 [990/1090] acc: 0.7960898042929293
val--50/100 [1000/1090] acc: 0.7959609375
val--50/100 [1010/1090] acc: 0.7957959467821782
val--50/100 [1020/1090] acc: 0.7958984375
val--50/100 [1030/1090] acc: 0.7958889563106796
val--50/100 [1040/1090] acc: 0.7958871694711539
val--50/100 [1050/1090] acc: 0.795952380952381
val--50/100 [1060/1090] acc: 0.7958763266509434
val--50/100 [1070/1090] acc: 0.7958893107476636
val--50/100 [1080/1090] acc: 0.7958188657407408
val--50/100 [1090/1090] acc: 0.7956887901376147
epoch= 50, accuracy= 0.795689, rmse= 0.377491, auc= 0.855682
train--51/100 [9/1090] loss: 0.39769158959388734
train--51/100 [19/1090] loss: 0.4292712926864624
train--51/100 [29/1090] loss: 0.44994066655635834
train--51/100 [39/1090] loss: 0.42576214373111726
train--51/100 [49/1090] loss: 0.42009258568286895
train--51/100 [59/1090] loss: 0.42540740966796875
train--51/100 [69/1090] loss: 0.447869610786438
train--51/100 [79/1090] loss: 0.44827072620391845
train--51/100 [89/1090] loss: 0.4413095980882645
train--51/100 [99/1090] loss: 0.4216959238052368
train--51/100 [109/1090] loss: 0.4416817486286163
train--51/100 [119/1090] loss: 0.4485630184412003
train--51/100 [129/1090] loss: 0.45377775132656095
train--51/100 [139/1090] loss: 0.44828322529792786
train--51/100 [149/1090] loss: 0.4547958254814148
train--51/100 [159/1090] loss: 0.42890576720237733
train--51/100 [169/1090] loss: 0.451449790596962
train--51/100 [179/1090] loss: 0.43450210690498353
train--51/100 [189/1090] loss: 0.4628248780965805
train--51/100 [199/1090] loss: 0.45234466195106504
train--51/100 [209/1090] loss: 0.43299467861652374
train--51/100 [219/1090] loss: 0.432538166642189
train--51/100 [229/1090] loss: 0.44147553443908694
train--51/100 [239/1090] loss: 0.42924987971782685
train--51/100 [249/1090] loss: 0.44868957102298734
train--51/100 [259/1090] loss: 0.4287460774183273
train--51/100 [269/1090] loss: 0.4240878731012344
train--51/100 [279/1090] loss: 0.4434945583343506
train--51/100 [289/1090] loss: 0.4669007420539856
train--51/100 [299/1090] loss: 0.4495019823312759
train--51/100 [309/1090] loss: 0.44029746353626253
train--51/100 [319/1090] loss: 0.4621411144733429
train--51/100 [329/1090] loss: 0.4443846642971039
train--51/100 [339/1090] loss: 0.44598169922828673
train--51/100 [349/1090] loss: 0.44240838289260864
train--51/100 [359/1090] loss: 0.4396596610546112
train--51/100 [369/1090] loss: 0.432096591591835
train--51/100 [379/1090] loss: 0.43412875533103945
train--51/100 [389/1090] loss: 0.4494276702404022
train--51/100 [399/1090] loss: 0.44656167924404144
train--51/100 [409/1090] loss: 0.4443196028470993
train--51/100 [419/1090] loss: 0.44508726596832277
train--51/100 [429/1090] loss: 0.43118092119693757
train--51/100 [439/1090] loss: 0.42698114216327665
train--51/100 [449/1090] loss: 0.4628641605377197
train--51/100 [459/1090] loss: 0.45046992003917696
train--51/100 [469/1090] loss: 0.4389166206121445
train--51/100 [479/1090] loss: 0.4343002200126648
train--51/100 [489/1090] loss: 0.4563447445631027
train--51/100 [499/1090] loss: 0.4612133353948593
train--51/100 [509/1090] loss: 0.43835642337799074
train--51/100 [519/1090] loss: 0.4448158949613571
train--51/100 [529/1090] loss: 0.43987360000610354
train--51/100 [539/1090] loss: 0.44850424528121946
train--51/100 [549/1090] loss: 0.4430780529975891
train--51/100 [559/1090] loss: 0.4280332297086716
train--51/100 [569/1090] loss: 0.4241496562957764
train--51/100 [579/1090] loss: 0.4297382444143295
train--51/100 [589/1090] loss: 0.4426537752151489
train--51/100 [599/1090] loss: 0.426728692650795
train--51/100 [609/1090] loss: 0.4430342882871628
train--51/100 [619/1090] loss: 0.4289907932281494
train--51/100 [629/1090] loss: 0.4604144811630249
train--51/100 [639/1090] loss: 0.4447498172521591
train--51/100 [649/1090] loss: 0.4534171372652054
train--51/100 [659/1090] loss: 0.44515352249145507
train--51/100 [669/1090] loss: 0.4569076180458069
train--51/100 [679/1090] loss: 0.44732699990272523
train--51/100 [689/1090] loss: 0.42839842438697817
train--51/100 [699/1090] loss: 0.4502594888210297
train--51/100 [709/1090] loss: 0.451421445608139
train--51/100 [719/1090] loss: 0.4243441164493561
train--51/100 [729/1090] loss: 0.4507952332496643
train--51/100 [739/1090] loss: 0.4470317602157593
train--51/100 [749/1090] loss: 0.4616015821695328
train--51/100 [759/1090] loss: 0.4532532572746277
train--51/100 [769/1090] loss: 0.45215781331062316
train--51/100 [779/1090] loss: 0.44194933474063874
train--51/100 [789/1090] loss: 0.4380340039730072
train--51/100 [799/1090] loss: 0.4420055359601974
train--51/100 [809/1090] loss: 0.4478971928358078
train--51/100 [819/1090] loss: 0.43688754439353944
train--51/100 [829/1090] loss: 0.4538211762905121
train--51/100 [839/1090] loss: 0.46474031507968905
train--51/100 [849/1090] loss: 0.454762464761734
train--51/100 [859/1090] loss: 0.4389800429344177
train--51/100 [869/1090] loss: 0.44167469441890717
train--51/100 [879/1090] loss: 0.4500490427017212
train--51/100 [889/1090] loss: 0.4639388173818588
train--51/100 [899/1090] loss: 0.4490229696035385
train--51/100 [909/1090] loss: 0.46106401085853577
train--51/100 [919/1090] loss: 0.44147769212722776
train--51/100 [929/1090] loss: 0.4287443578243256
train--51/100 [939/1090] loss: 0.4506762266159058
train--51/100 [949/1090] loss: 0.4531379997730255
train--51/100 [959/1090] loss: 0.470040825009346
train--51/100 [969/1090] loss: 0.4382557302713394
train--51/100 [979/1090] loss: 0.43988655507564545
train--51/100 [989/1090] loss: 0.4377191036939621
train--51/100 [999/1090] loss: 0.4642006903886795
train--51/100 [1009/1090] loss: 0.4507636219263077
train--51/100 [1019/1090] loss: 0.4686387687921524
train--51/100 [1029/1090] loss: 0.46498788297176363
train--51/100 [1039/1090] loss: 0.46019707918167113
train--51/100 [1049/1090] loss: 0.47003779411315916
train--51/100 [1059/1090] loss: 0.43819926083087923
train--51/100 [1069/1090] loss: 0.45747950077056887
train--51/100 [1079/1090] loss: 0.4444896697998047
train--51/100 [1089/1090] loss: 0.44220819473266604
predicting model...
val--51/100 [10/1090] acc: 0.796875
val--51/100 [20/1090] acc: 0.7966796875
val--51/100 [30/1090] acc: 0.7959635416666667
val--51/100 [40/1090] acc: 0.7953125
val--51/100 [50/1090] acc: 0.794140625
val--51/100 [60/1090] acc: 0.7929036458333333
val--51/100 [70/1090] acc: 0.7933035714285714
val--51/100 [80/1090] acc: 0.792724609375
val--51/100 [90/1090] acc: 0.7934461805555556
val--51/100 [100/1090] acc: 0.794375
val--51/100 [110/1090] acc: 0.7947798295454546
val--51/100 [120/1090] acc: 0.79423828125
val--51/100 [130/1090] acc: 0.7954326923076923
val--51/100 [140/1090] acc: 0.7953962053571428
val--51/100 [150/1090] acc: 0.795390625
val--51/100 [160/1090] acc: 0.79541015625
val--51/100 [170/1090] acc: 0.7953125
val--51/100 [180/1090] acc: 0.7951822916666667
val--51/100 [190/1090] acc: 0.7961143092105263
val--51/100 [200/1090] acc: 0.796328125
val--51/100 [210/1090] acc: 0.7967447916666667
val--51/100 [220/1090] acc: 0.7959872159090909
val--51/100 [230/1090] acc: 0.7966032608695652
val--51/100 [240/1090] acc: 0.79638671875
val--51/100 [250/1090] acc: 0.796515625
val--51/100 [260/1090] acc: 0.7965745192307693
val--51/100 [270/1090] acc: 0.7969473379629629
val--51/100 [280/1090] acc: 0.7969168526785714
val--51/100 [290/1090] acc: 0.7967537715517241
val--51/100 [300/1090] acc: 0.7967447916666667
val--51/100 [310/1090] acc: 0.7964591733870968
val--51/100 [320/1090] acc: 0.79671630859375
val--51/100 [330/1090] acc: 0.7969460227272728
val--51/100 [340/1090] acc: 0.7970703125
val--51/100 [350/1090] acc: 0.7971763392857143
val--51/100 [360/1090] acc: 0.7970377604166666
val--51/100 [370/1090] acc: 0.7971600506756756
val--51/100 [380/1090] acc: 0.7971114309210526
val--51/100 [390/1090] acc: 0.7969050480769231
val--51/100 [400/1090] acc: 0.796865234375
val--51/100 [410/1090] acc: 0.7970179115853658
val--51/100 [420/1090] acc: 0.7969494047619048
val--51/100 [430/1090] acc: 0.7968204941860465
val--51/100 [440/1090] acc: 0.7967329545454546
val--51/100 [450/1090] acc: 0.7966232638888889
val--51/100 [460/1090] acc: 0.7964673913043478
val--51/100 [470/1090] acc: 0.796376329787234
val--51/100 [480/1090] acc: 0.7963541666666667
val--51/100 [490/1090] acc: 0.7965401785714286
val--51/100 [500/1090] acc: 0.7967421875
val--51/100 [510/1090] acc: 0.7965916053921569
val--51/100 [520/1090] acc: 0.7967848557692307
val--51/100 [530/1090] acc: 0.7966907429245284
val--51/100 [540/1090] acc: 0.7968822337962963
val--51/100 [550/1090] acc: 0.7967400568181818
val--51/100 [560/1090] acc: 0.7965192522321428
val--51/100 [570/1090] acc: 0.7962787828947369
val--51/100 [580/1090] acc: 0.796356411637931
val--51/100 [590/1090] acc: 0.796385063559322
val--51/100 [600/1090] acc: 0.7964127604166666
val--51/100 [610/1090] acc: 0.7963627049180327
val--51/100 [620/1090] acc: 0.7962953629032258
val--51/100 [630/1090] acc: 0.796546378968254
val--51/100 [640/1090] acc: 0.796728515625
val--51/100 [650/1090] acc: 0.7966766826923077
val--51/100 [660/1090] acc: 0.7965376420454545
val--51/100 [670/1090] acc: 0.7961986940298508
val--51/100 [680/1090] acc: 0.7960822610294118
val--51/100 [690/1090] acc: 0.7962352807971015
val--51/100 [700/1090] acc: 0.7962779017857143
val--51/100 [710/1090] acc: 0.79609375
val--51/100 [720/1090] acc: 0.7959689670138889
val--51/100 [730/1090] acc: 0.7959332191780822
val--51/100 [740/1090] acc: 0.7958509290540541
val--51/100 [750/1090] acc: 0.7959322916666667
val--51/100 [760/1090] acc: 0.7959806743421053
val--51/100 [770/1090] acc: 0.795900974025974
val--51/100 [780/1090] acc: 0.7958283253205128
val--51/100 [790/1090] acc: 0.7958712420886076
val--51/100 [800/1090] acc: 0.796083984375
val--51/100 [810/1090] acc: 0.7961323302469135
val--51/100 [820/1090] acc: 0.7962271341463415
val--51/100 [830/1090] acc: 0.7963149472891566
val--51/100 [840/1090] acc: 0.7962704613095238
val--51/100 [850/1090] acc: 0.7963097426470588
val--51/100 [860/1090] acc: 0.7965843023255814
val--51/100 [870/1090] acc: 0.7964574353448276
val--51/100 [880/1090] acc: 0.7964044744318182
val--51/100 [890/1090] acc: 0.796532654494382
val--51/100 [900/1090] acc: 0.7965147569444444
val--51/100 [910/1090] acc: 0.7964972527472527
val--51/100 [920/1090] acc: 0.7964971127717392
val--51/100 [930/1090] acc: 0.7966103830645161
val--51/100 [940/1090] acc: 0.7966090425531915
val--51/100 [950/1090] acc: 0.7964597039473684
val--51/100 [960/1090] acc: 0.7963907877604167
val--51/100 [970/1090] acc: 0.7963836984536082
val--51/100 [980/1090] acc: 0.7963807397959184
val--51/100 [990/1090] acc: 0.7963068181818181
val--51/100 [1000/1090] acc: 0.79622265625
val--51/100 [1010/1090] acc: 0.7960550742574257
val--51/100 [1020/1090] acc: 0.7961320465686275
val--51/100 [1030/1090] acc: 0.7961354672330098
val--51/100 [1040/1090] acc: 0.7961576021634615
val--51/100 [1050/1090] acc: 0.7962127976190476
val--51/100 [1060/1090] acc: 0.7961269162735849
val--51/100 [1070/1090] acc: 0.7961302570093458
val--51/100 [1080/1090] acc: 0.7960720486111111
val--51/100 [1090/1090] acc: 0.7959217316513761
epoch= 51, accuracy= 0.795922, rmse= 0.377412, auc= 0.855770
train--52/100 [9/1090] loss: 0.3954692453145981
train--52/100 [19/1090] loss: 0.4176712781190872
train--52/100 [29/1090] loss: 0.4386239737272263
train--52/100 [39/1090] loss: 0.4430696487426758
train--52/100 [49/1090] loss: 0.45650416910648345
train--52/100 [59/1090] loss: 0.4425597310066223
train--52/100 [69/1090] loss: 0.4396697491407394
train--52/100 [79/1090] loss: 0.4289541095495224
train--52/100 [89/1090] loss: 0.43456933200359343
train--52/100 [99/1090] loss: 0.43626642823219297
train--52/100 [109/1090] loss: 0.43711569607257844
train--52/100 [119/1090] loss: 0.44721072912216187
train--52/100 [129/1090] loss: 0.43823747634887694
train--52/100 [139/1090] loss: 0.43398933708667753
train--52/100 [149/1090] loss: 0.4530364364385605
train--52/100 [159/1090] loss: 0.4421222895383835
train--52/100 [169/1090] loss: 0.4399808406829834
train--52/100 [179/1090] loss: 0.4317741334438324
train--52/100 [189/1090] loss: 0.45161058008670807
train--52/100 [199/1090] loss: 0.4520768016576767
train--52/100 [209/1090] loss: 0.4587680011987686
train--52/100 [219/1090] loss: 0.45386290550231934
train--52/100 [229/1090] loss: 0.4228995680809021
train--52/100 [239/1090] loss: 0.429093262553215
train--52/100 [249/1090] loss: 0.4298970878124237
train--52/100 [259/1090] loss: 0.4406012505292892
train--52/100 [269/1090] loss: 0.42679654955863955
train--52/100 [279/1090] loss: 0.4397479623556137
train--52/100 [289/1090] loss: 0.44155184626579286
train--52/100 [299/1090] loss: 0.4550320625305176
train--52/100 [309/1090] loss: 0.4461801558732986
train--52/100 [319/1090] loss: 0.44505069553852084
train--52/100 [329/1090] loss: 0.437150838971138
train--52/100 [339/1090] loss: 0.43600958287715913
train--52/100 [349/1090] loss: 0.4636514335870743
train--52/100 [359/1090] loss: 0.43434021472930906
train--52/100 [369/1090] loss: 0.4552788406610489
train--52/100 [379/1090] loss: 0.45562497079372405
train--52/100 [389/1090] loss: 0.45030022263526914
train--52/100 [399/1090] loss: 0.448196092247963
train--52/100 [409/1090] loss: 0.46735660433769227
train--52/100 [419/1090] loss: 0.44714873731136323
train--52/100 [429/1090] loss: 0.44328832626342773
train--52/100 [439/1090] loss: 0.4329319030046463
train--52/100 [449/1090] loss: 0.4345721244812012
train--52/100 [459/1090] loss: 0.45005083084106445
train--52/100 [469/1090] loss: 0.44426563680171965
train--52/100 [479/1090] loss: 0.44868687689304354
train--52/100 [489/1090] loss: 0.43832802176475527
train--52/100 [499/1090] loss: 0.44103352427482606
train--52/100 [509/1090] loss: 0.4351386159658432
train--52/100 [519/1090] loss: 0.42871294021606443
train--52/100 [529/1090] loss: 0.4611181914806366
train--52/100 [539/1090] loss: 0.45535517632961275
train--52/100 [549/1090] loss: 0.44474156498908995
train--52/100 [559/1090] loss: 0.4476537466049194
train--52/100 [569/1090] loss: 0.46017696261405944
train--52/100 [579/1090] loss: 0.44486347734928133
train--52/100 [589/1090] loss: 0.4478737711906433
train--52/100 [599/1090] loss: 0.4362588137388229
train--52/100 [609/1090] loss: 0.46854266822338103
train--52/100 [619/1090] loss: 0.4427353531122208
train--52/100 [629/1090] loss: 0.4576928079128265
train--52/100 [639/1090] loss: 0.4394730269908905
train--52/100 [649/1090] loss: 0.4223970800638199
train--52/100 [659/1090] loss: 0.4445980072021484
train--52/100 [669/1090] loss: 0.4604999601840973
train--52/100 [679/1090] loss: 0.4650650918483734
train--52/100 [689/1090] loss: 0.4515346080064774
train--52/100 [699/1090] loss: 0.43736691772937775
train--52/100 [709/1090] loss: 0.4517451971769333
train--52/100 [719/1090] loss: 0.4331695228815079
train--52/100 [729/1090] loss: 0.43536652624607086
train--52/100 [739/1090] loss: 0.42399377524852755
train--52/100 [749/1090] loss: 0.41918104887008667
train--52/100 [759/1090] loss: 0.4486237406730652
train--52/100 [769/1090] loss: 0.45303418338298795
train--52/100 [779/1090] loss: 0.43717133402824404
train--52/100 [789/1090] loss: 0.4463284194469452
train--52/100 [799/1090] loss: 0.4527584820985794
train--52/100 [809/1090] loss: 0.43096075356006625
train--52/100 [819/1090] loss: 0.44777497947216033
train--52/100 [829/1090] loss: 0.4524871945381165
train--52/100 [839/1090] loss: 0.43767387568950655
train--52/100 [849/1090] loss: 0.45746157467365267
train--52/100 [859/1090] loss: 0.44371682703495025
train--52/100 [869/1090] loss: 0.4403688877820969
train--52/100 [879/1090] loss: 0.45640056431293485
train--52/100 [889/1090] loss: 0.4597616642713547
train--52/100 [899/1090] loss: 0.4512524873018265
train--52/100 [909/1090] loss: 0.45214776396751405
train--52/100 [919/1090] loss: 0.4379416942596436
train--52/100 [929/1090] loss: 0.4483033776283264
train--52/100 [939/1090] loss: 0.437564542889595
train--52/100 [949/1090] loss: 0.46919613480567934
train--52/100 [959/1090] loss: 0.4645299881696701
train--52/100 [969/1090] loss: 0.4423411458730698
train--52/100 [979/1090] loss: 0.44651956856250763
train--52/100 [989/1090] loss: 0.44027612209320066
train--52/100 [999/1090] loss: 0.4545731574296951
train--52/100 [1009/1090] loss: 0.44547879695892334
train--52/100 [1019/1090] loss: 0.4408390522003174
train--52/100 [1029/1090] loss: 0.443799564242363
train--52/100 [1039/1090] loss: 0.440309140086174
train--52/100 [1049/1090] loss: 0.44897669851779937
train--52/100 [1059/1090] loss: 0.4431604862213135
train--52/100 [1069/1090] loss: 0.4474395662546158
train--52/100 [1079/1090] loss: 0.4342090427875519
train--52/100 [1089/1090] loss: 0.4582638323307037
predicting model...
val--52/100 [10/1090] acc: 0.796484375
val--52/100 [20/1090] acc: 0.7951171875
val--52/100 [30/1090] acc: 0.7936197916666666
val--52/100 [40/1090] acc: 0.79384765625
val--52/100 [50/1090] acc: 0.792578125
val--52/100 [60/1090] acc: 0.7916666666666666
val--52/100 [70/1090] acc: 0.7928013392857143
val--52/100 [80/1090] acc: 0.79208984375
val--52/100 [90/1090] acc: 0.7928819444444445
val--52/100 [100/1090] acc: 0.7941015625
val--52/100 [110/1090] acc: 0.7943536931818181
val--52/100 [120/1090] acc: 0.79384765625
val--52/100 [130/1090] acc: 0.794921875
val--52/100 [140/1090] acc: 0.7948381696428571
val--52/100 [150/1090] acc: 0.7947916666666667
val--52/100 [160/1090] acc: 0.7949951171875
val--52/100 [170/1090] acc: 0.7950137867647059
val--52/100 [180/1090] acc: 0.7949001736111111
val--52/100 [190/1090] acc: 0.7958059210526316
val--52/100 [200/1090] acc: 0.79607421875
val--52/100 [210/1090] acc: 0.7964099702380952
val--52/100 [220/1090] acc: 0.7954190340909091
val--52/100 [230/1090] acc: 0.7960767663043479
val--52/100 [240/1090] acc: 0.7958658854166667
val--52/100 [250/1090] acc: 0.795921875
val--52/100 [260/1090] acc: 0.7959585336538462
val--52/100 [270/1090] acc: 0.7963107638888889
val--52/100 [280/1090] acc: 0.7963309151785715
val--52/100 [290/1090] acc: 0.7962553879310345
val--52/100 [300/1090] acc: 0.796328125
val--52/100 [310/1090] acc: 0.7960181451612903
val--52/100 [320/1090] acc: 0.79619140625
val--52/100 [330/1090] acc: 0.7964015151515151
val--52/100 [340/1090] acc: 0.7965418198529411
val--52/100 [350/1090] acc: 0.7966741071428571
val--52/100 [360/1090] acc: 0.7965928819444444
val--52/100 [370/1090] acc: 0.796727195945946
val--52/100 [380/1090] acc: 0.7967619243421052
val--52/100 [390/1090] acc: 0.7965745192307693
val--52/100 [400/1090] acc: 0.79654296875
val--52/100 [410/1090] acc: 0.7966844512195121
val--52/100 [420/1090] acc: 0.7966424851190477
val--52/100 [430/1090] acc: 0.7964752906976744
val--52/100 [440/1090] acc: 0.7965021306818182
val--52/100 [450/1090] acc: 0.7963454861111111
val--52/100 [460/1090] acc: 0.7961786684782609
val--52/100 [470/1090] acc: 0.7961103723404256
val--52/100 [480/1090] acc: 0.7961507161458333
val--52/100 [490/1090] acc: 0.7962771045918368
val--52/100 [500/1090] acc: 0.796390625
val--52/100 [510/1090] acc: 0.7963694852941177
val--52/100 [520/1090] acc: 0.7965895432692308
val--52/100 [530/1090] acc: 0.7965875589622642
val--52/100 [540/1090] acc: 0.7967737268518519
val--52/100 [550/1090] acc: 0.7966477272727273
val--52/100 [560/1090] acc: 0.7964494977678571
val--52/100 [570/1090] acc: 0.7961896929824561
val--52/100 [580/1090] acc: 0.7962217133620689
val--52/100 [590/1090] acc: 0.796285752118644
val--52/100 [600/1090] acc: 0.7962760416666667
val--52/100 [610/1090] acc: 0.7961834016393443
val--52/100 [620/1090] acc: 0.7960370463709677
val--52/100 [630/1090] acc: 0.7962797619047619
val--52/100 [640/1090] acc: 0.79644775390625
val--52/100 [650/1090] acc: 0.7964423076923077
val--52/100 [660/1090] acc: 0.7963660037878788
val--52/100 [670/1090] acc: 0.7960529384328359
val--52/100 [680/1090] acc: 0.7959329044117647
val--52/100 [690/1090] acc: 0.796088088768116
val--52/100 [700/1090] acc: 0.7961104910714286
val--52/100 [710/1090] acc: 0.795934198943662
val--52/100 [720/1090] acc: 0.7957736545138889
val--52/100 [730/1090] acc: 0.7957405821917808
val--52/100 [740/1090] acc: 0.7956503378378378
val--52/100 [750/1090] acc: 0.7957395833333333
val--52/100 [760/1090] acc: 0.7958213404605263
val--52/100 [770/1090] acc: 0.7957538555194805
val--52/100 [780/1090] acc: 0.7957131410256411
val--52/100 [790/1090] acc: 0.7957377373417721
val--52/100 [800/1090] acc: 0.795966796875
val--52/100 [810/1090] acc: 0.7960551697530864
val--52/100 [820/1090] acc: 0.7961652057926829
val--52/100 [830/1090] acc: 0.7962396460843374
val--52/100 [840/1090] acc: 0.7962007068452381
val--52/100 [850/1090] acc: 0.7962408088235294
val--52/100 [860/1090] acc: 0.7964707485465117
val--52/100 [870/1090] acc: 0.7963811063218391
val--52/100 [880/1090] acc: 0.7963556463068182
val--52/100 [890/1090] acc: 0.7964887640449438
val--52/100 [900/1090] acc: 0.7964453125
val--52/100 [910/1090] acc: 0.7964414491758242
val--52/100 [920/1090] acc: 0.7964206861413043
val--52/100 [930/1090] acc: 0.7965431787634408
val--52/100 [940/1090] acc: 0.7965550199468086
val--52/100 [950/1090] acc: 0.7964350328947368
val--52/100 [960/1090] acc: 0.7963623046875
val--52/100 [970/1090] acc: 0.7963434278350515
val--52/100 [980/1090] acc: 0.7963448660714286
val--52/100 [990/1090] acc: 0.7962397411616161
val--52/100 [1000/1090] acc: 0.79614453125
val--52/100 [1010/1090] acc: 0.7959699876237624
val--52/100 [1020/1090] acc: 0.796063112745098
val--52/100 [1030/1090] acc: 0.7960596177184466
val--52/100 [1040/1090] acc: 0.796063701923077
val--52/100 [1050/1090] acc: 0.7961086309523809
val--52/100 [1060/1090] acc: 0.7960384728773585
val--52/100 [1070/1090] acc: 0.7960207359813084
val--52/100 [1080/1090] acc: 0.7959526909722222
val--52/100 [1090/1090] acc: 0.7957963016055046
epoch= 52, accuracy= 0.795796, rmse= 0.377295, auc= 0.855918
train--53/100 [9/1090] loss: 0.38791858553886416
train--53/100 [19/1090] loss: 0.43926297426223754
train--53/100 [29/1090] loss: 0.4423545956611633
train--53/100 [39/1090] loss: 0.45463926792144777
train--53/100 [49/1090] loss: 0.45127941071987154
train--53/100 [59/1090] loss: 0.4257933974266052
train--53/100 [69/1090] loss: 0.4328243523836136
train--53/100 [79/1090] loss: 0.42887088358402253
train--53/100 [89/1090] loss: 0.4470210701227188
train--53/100 [99/1090] loss: 0.45249211192131045
train--53/100 [109/1090] loss: 0.4318352252244949
train--53/100 [119/1090] loss: 0.41619025468826293
train--53/100 [129/1090] loss: 0.45339410901069643
train--53/100 [139/1090] loss: 0.43201973736286164
train--53/100 [149/1090] loss: 0.4386262774467468
train--53/100 [159/1090] loss: 0.4464248836040497
train--53/100 [169/1090] loss: 0.4337657421827316
train--53/100 [179/1090] loss: 0.43720479905605314
train--53/100 [189/1090] loss: 0.44740951657295225
train--53/100 [199/1090] loss: 0.4306353032588959
train--53/100 [209/1090] loss: 0.4418014734983444
train--53/100 [219/1090] loss: 0.4359388828277588
train--53/100 [229/1090] loss: 0.43011753261089325
train--53/100 [239/1090] loss: 0.4446159899234772
train--53/100 [249/1090] loss: 0.44185354709625246
train--53/100 [259/1090] loss: 0.4407251328229904
train--53/100 [269/1090] loss: 0.4464676737785339
train--53/100 [279/1090] loss: 0.4255386620759964
train--53/100 [289/1090] loss: 0.4599142611026764
train--53/100 [299/1090] loss: 0.44245573580265046
train--53/100 [309/1090] loss: 0.4460408896207809
train--53/100 [319/1090] loss: 0.42981193363666537
train--53/100 [329/1090] loss: 0.44168512225151063
train--53/100 [339/1090] loss: 0.4409252256155014
train--53/100 [349/1090] loss: 0.4554200232028961
train--53/100 [359/1090] loss: 0.4460802435874939
train--53/100 [369/1090] loss: 0.4407694011926651
train--53/100 [379/1090] loss: 0.44938736259937284
train--53/100 [389/1090] loss: 0.4531576156616211
train--53/100 [399/1090] loss: 0.43890333771705625
train--53/100 [409/1090] loss: 0.4545984208583832
train--53/100 [419/1090] loss: 0.45148618519306183
train--53/100 [429/1090] loss: 0.43790461122989655
train--53/100 [439/1090] loss: 0.44758658707141874
train--53/100 [449/1090] loss: 0.44225096702575684
train--53/100 [459/1090] loss: 0.4435316026210785
train--53/100 [469/1090] loss: 0.42073585093021393
train--53/100 [479/1090] loss: 0.4485796183347702
train--53/100 [489/1090] loss: 0.45127842128276824
train--53/100 [499/1090] loss: 0.4420024186372757
train--53/100 [509/1090] loss: 0.44903539419174193
train--53/100 [519/1090] loss: 0.4574697345495224
train--53/100 [529/1090] loss: 0.45571975111961366
train--53/100 [539/1090] loss: 0.4533346891403198
train--53/100 [549/1090] loss: 0.4509564727544785
train--53/100 [559/1090] loss: 0.4479594171047211
train--53/100 [569/1090] loss: 0.44330150783061983
train--53/100 [579/1090] loss: 0.4443397790193558
train--53/100 [589/1090] loss: 0.4374513357877731
train--53/100 [599/1090] loss: 0.4417529046535492
train--53/100 [609/1090] loss: 0.439988973736763
train--53/100 [619/1090] loss: 0.4421082079410553
train--53/100 [629/1090] loss: 0.44182267785072327
train--53/100 [639/1090] loss: 0.4133511871099472
train--53/100 [649/1090] loss: 0.45704306066036227
train--53/100 [659/1090] loss: 0.43903741240501404
train--53/100 [669/1090] loss: 0.42705565094947817
train--53/100 [679/1090] loss: 0.4447558969259262
train--53/100 [689/1090] loss: 0.45483503937721254
train--53/100 [699/1090] loss: 0.4452478617429733
train--53/100 [709/1090] loss: 0.4557375133037567
train--53/100 [719/1090] loss: 0.457695284485817
train--53/100 [729/1090] loss: 0.4240374356508255
train--53/100 [739/1090] loss: 0.4351422041654587
train--53/100 [749/1090] loss: 0.4463951587677002
train--53/100 [759/1090] loss: 0.4533801257610321
train--53/100 [769/1090] loss: 0.42949322760105135
train--53/100 [779/1090] loss: 0.43782094717025755
train--53/100 [789/1090] loss: 0.4527948975563049
train--53/100 [799/1090] loss: 0.46750906109809875
train--53/100 [809/1090] loss: 0.4457273334264755
train--53/100 [819/1090] loss: 0.4609519809484482
train--53/100 [829/1090] loss: 0.4572185635566711
train--53/100 [839/1090] loss: 0.45175538063049314
train--53/100 [849/1090] loss: 0.45110786259174346
train--53/100 [859/1090] loss: 0.41793431639671325
train--53/100 [869/1090] loss: 0.4260822534561157
train--53/100 [879/1090] loss: 0.4664984613656998
train--53/100 [889/1090] loss: 0.44412216544151306
train--53/100 [899/1090] loss: 0.4484925776720047
train--53/100 [909/1090] loss: 0.44248190224170686
train--53/100 [919/1090] loss: 0.4591019958257675
train--53/100 [929/1090] loss: 0.4637200564146042
train--53/100 [939/1090] loss: 0.44983114004135133
train--53/100 [949/1090] loss: 0.43678379356861113
train--53/100 [959/1090] loss: 0.45121290981769563
train--53/100 [969/1090] loss: 0.4372348517179489
train--53/100 [979/1090] loss: 0.4712465345859528
train--53/100 [989/1090] loss: 0.4530932277441025
train--53/100 [999/1090] loss: 0.43410525619983675
train--53/100 [1009/1090] loss: 0.4445393025875092
train--53/100 [1019/1090] loss: 0.45989453196525576
train--53/100 [1029/1090] loss: 0.44562398493289945
train--53/100 [1039/1090] loss: 0.4564035445451736
train--53/100 [1049/1090] loss: 0.452150484919548
train--53/100 [1059/1090] loss: 0.44143844544887545
train--53/100 [1069/1090] loss: 0.42979379296302794
train--53/100 [1079/1090] loss: 0.44825827777385713
train--53/100 [1089/1090] loss: 0.45660710632801055
predicting model...
val--53/100 [10/1090] acc: 0.794921875
val--53/100 [20/1090] acc: 0.7953125
val--53/100 [30/1090] acc: 0.7940104166666667
val--53/100 [40/1090] acc: 0.794921875
val--53/100 [50/1090] acc: 0.793515625
val--53/100 [60/1090] acc: 0.793359375
val--53/100 [70/1090] acc: 0.7938058035714286
val--53/100 [80/1090] acc: 0.792724609375
val--53/100 [90/1090] acc: 0.7934461805555556
val--53/100 [100/1090] acc: 0.794453125
val--53/100 [110/1090] acc: 0.7949928977272728
val--53/100 [120/1090] acc: 0.7944986979166667
val--53/100 [130/1090] acc: 0.7958533653846154
val--53/100 [140/1090] acc: 0.7957868303571428
val--53/100 [150/1090] acc: 0.7955989583333334
val--53/100 [160/1090] acc: 0.7959228515625
val--53/100 [170/1090] acc: 0.7957950367647059
val--53/100 [180/1090] acc: 0.795703125
val--53/100 [190/1090] acc: 0.7964432565789473
val--53/100 [200/1090] acc: 0.7966015625
val--53/100 [210/1090] acc: 0.7969308035714285
val--53/100 [220/1090] acc: 0.7959339488636363
val--53/100 [230/1090] acc: 0.7965353260869565
val--53/100 [240/1090] acc: 0.7964029947916667
val--53/100 [250/1090] acc: 0.796484375
val--53/100 [260/1090] acc: 0.7966045673076924
val--53/100 [270/1090] acc: 0.7969039351851852
val--53/100 [280/1090] acc: 0.7967912946428571
val--53/100 [290/1090] acc: 0.7965651939655173
val--53/100 [300/1090] acc: 0.7965364583333333
val--53/100 [310/1090] acc: 0.7963079637096774
val--53/100 [320/1090] acc: 0.79649658203125
val--53/100 [330/1090] acc: 0.7967921401515151
val--53/100 [340/1090] acc: 0.7968979779411764
val--53/100 [350/1090] acc: 0.7970758928571429
val--53/100 [360/1090] acc: 0.7969509548611111
val--53/100 [370/1090] acc: 0.7970755912162162
val--53/100 [380/1090] acc: 0.7971422697368421
val--53/100 [390/1090] acc: 0.7969150641025641
val--53/100 [400/1090] acc: 0.796875
val--53/100 [410/1090] acc: 0.7970369664634146
val--53/100 [420/1090] acc: 0.7969959077380953
val--53/100 [430/1090] acc: 0.7968568313953488
val--53/100 [440/1090] acc: 0.7969016335227272
val--53/100 [450/1090] acc: 0.7966927083333334
val--53/100 [460/1090] acc: 0.7965268342391304
val--53/100 [470/1090] acc: 0.7965009973404256
val--53/100 [480/1090] acc: 0.7965576171875
val--53/100 [490/1090] acc: 0.7967155612244898
val--53/100 [500/1090] acc: 0.7968125
val--53/100 [510/1090] acc: 0.7966988357843138
val--53/100 [520/1090] acc: 0.7968449519230769
val--53/100 [530/1090] acc: 0.796875
val--53/100 [540/1090] acc: 0.7970052083333333
val--53/100 [550/1090] acc: 0.7968963068181818
val--53/100 [560/1090] acc: 0.7967075892857143
val--53/100 [570/1090] acc: 0.7964432565789473
val--53/100 [580/1090] acc: 0.7964304956896552
val--53/100 [590/1090] acc: 0.7964512711864407
val--53/100 [600/1090] acc: 0.7964713541666667
val--53/100 [610/1090] acc: 0.7963563012295082
val--53/100 [620/1090] acc: 0.7962953629032258
val--53/100 [630/1090] acc: 0.7965029761904762
val--53/100 [640/1090] acc: 0.796697998046875
val--53/100 [650/1090] acc: 0.796688701923077
val--53/100 [660/1090] acc: 0.7966086647727273
val--53/100 [670/1090] acc: 0.7962744869402985
val--53/100 [680/1090] acc: 0.7961856617647058
val--53/100 [690/1090] acc: 0.7962749094202899
val--53/100 [700/1090] acc: 0.7962946428571429
val--53/100 [710/1090] acc: 0.7961432658450704
val--53/100 [720/1090] acc: 0.7959906684027778
val--53/100 [730/1090] acc: 0.7959439212328767
val--53/100 [740/1090] acc: 0.7958403716216216
val--53/100 [750/1090] acc: 0.7959010416666666
val--53/100 [760/1090] acc: 0.7959755345394737
val--53/100 [770/1090] acc: 0.7958908279220779
val--53/100 [780/1090] acc: 0.7958333333333333
val--53/100 [790/1090] acc: 0.7958712420886076
val--53/100 [800/1090] acc: 0.79607421875
val--53/100 [810/1090] acc: 0.796141975308642
val--53/100 [820/1090] acc: 0.7962795350609756
val--53/100 [830/1090] acc: 0.796324359939759
val--53/100 [840/1090] acc: 0.7963169642857143
val--53/100 [850/1090] acc: 0.7963694852941177
val--53/100 [860/1090] acc: 0.7966388081395349
val--53/100 [870/1090] acc: 0.7965607040229885
val--53/100 [880/1090] acc: 0.7965065696022727
val--53/100 [890/1090] acc: 0.7966643258426966
val--53/100 [900/1090] acc: 0.796640625
val--53/100 [910/1090] acc: 0.7966517857142857
val--53/100 [920/1090] acc: 0.7966414741847826
val--53/100 [930/1090] acc: 0.7967615927419355
val--53/100 [940/1090] acc: 0.7967586436170213
val--53/100 [950/1090] acc: 0.796624177631579
val--53/100 [960/1090] acc: 0.796533203125
val--53/100 [970/1090] acc: 0.7964884020618557
val--53/100 [980/1090] acc: 0.7964963329081632
val--53/100 [990/1090] acc: 0.7963936237373738
val--53/100 [1000/1090] acc: 0.79628125
val--53/100 [1010/1090] acc: 0.7961014851485149
val--53/100 [1020/1090] acc: 0.7961358762254902
val--53/100 [1030/1090] acc: 0.7961354672330098
val--53/100 [1040/1090] acc: 0.7961050180288461
val--53/100 [1050/1090] acc: 0.7961495535714286
val--53/100 [1060/1090] acc: 0.79609375
val--53/100 [1070/1090] acc: 0.796075496495327
val--53/100 [1080/1090] acc: 0.7960358796296296
val--53/100 [1090/1090] acc: 0.7958751433486239
epoch= 53, accuracy= 0.795875, rmse= 0.377179, auc= 0.856185
train--54/100 [9/1090] loss: 0.39500136375427247
train--54/100 [19/1090] loss: 0.45314486026763917
train--54/100 [29/1090] loss: 0.4545149296522141
train--54/100 [39/1090] loss: 0.43392558097839357
train--54/100 [49/1090] loss: 0.43561230301856996
train--54/100 [59/1090] loss: 0.4294795483350754
train--54/100 [69/1090] loss: 0.44447202086448667
train--54/100 [79/1090] loss: 0.4508740335702896
train--54/100 [89/1090] loss: 0.4260775506496429
train--54/100 [99/1090] loss: 0.4366356641054153
train--54/100 [109/1090] loss: 0.4467280685901642
train--54/100 [119/1090] loss: 0.4461070835590363
train--54/100 [129/1090] loss: 0.43250887393951415
train--54/100 [139/1090] loss: 0.4407779693603516
train--54/100 [149/1090] loss: 0.4408966928720474
train--54/100 [159/1090] loss: 0.42241708040237425
train--54/100 [169/1090] loss: 0.4474914014339447
train--54/100 [179/1090] loss: 0.4568266898393631
train--54/100 [189/1090] loss: 0.45041548907756807
train--54/100 [199/1090] loss: 0.4269639074802399
train--54/100 [209/1090] loss: 0.45995605885982516
train--54/100 [219/1090] loss: 0.441143399477005
train--54/100 [229/1090] loss: 0.4364519059658051
train--54/100 [239/1090] loss: 0.44127838909626005
train--54/100 [249/1090] loss: 0.4397114336490631
train--54/100 [259/1090] loss: 0.4405830353498459
train--54/100 [269/1090] loss: 0.44162143766880035
train--54/100 [279/1090] loss: 0.44725187718868253
train--54/100 [289/1090] loss: 0.45407806932926176
train--54/100 [299/1090] loss: 0.43943721055984497
train--54/100 [309/1090] loss: 0.44037812650203706
train--54/100 [319/1090] loss: 0.44213090240955355
train--54/100 [329/1090] loss: 0.45886094868183136
train--54/100 [339/1090] loss: 0.44917117059230804
train--54/100 [349/1090] loss: 0.4641159921884537
train--54/100 [359/1090] loss: 0.43699593245983126
train--54/100 [369/1090] loss: 0.44997466802597047
train--54/100 [379/1090] loss: 0.44156402349472046
train--54/100 [389/1090] loss: 0.4290741980075836
train--54/100 [399/1090] loss: 0.43983870148658755
train--54/100 [409/1090] loss: 0.4277294635772705
train--54/100 [419/1090] loss: 0.43983088731765746
train--54/100 [429/1090] loss: 0.43496128022670744
train--54/100 [439/1090] loss: 0.4299922436475754
train--54/100 [449/1090] loss: 0.4437521457672119
train--54/100 [459/1090] loss: 0.4297660768032074
train--54/100 [469/1090] loss: 0.4602862745523453
train--54/100 [479/1090] loss: 0.4476243257522583
train--54/100 [489/1090] loss: 0.4421428442001343
train--54/100 [499/1090] loss: 0.43129792511463166
train--54/100 [509/1090] loss: 0.4397952139377594
train--54/100 [519/1090] loss: 0.43051465749740603
train--54/100 [529/1090] loss: 0.4574605107307434
train--54/100 [539/1090] loss: 0.4418253839015961
train--54/100 [549/1090] loss: 0.4419896900653839
train--54/100 [559/1090] loss: 0.43547105193138125
train--54/100 [569/1090] loss: 0.44508072435855867
train--54/100 [579/1090] loss: 0.44768368601799013
train--54/100 [589/1090] loss: 0.4456845045089722
train--54/100 [599/1090] loss: 0.4360969990491867
train--54/100 [609/1090] loss: 0.42932429909706116
train--54/100 [619/1090] loss: 0.4510687828063965
train--54/100 [629/1090] loss: 0.44795825481414797
train--54/100 [639/1090] loss: 0.4409989446401596
train--54/100 [649/1090] loss: 0.460586753487587
train--54/100 [659/1090] loss: 0.4345540255308151
train--54/100 [669/1090] loss: 0.4301225751638412
train--54/100 [679/1090] loss: 0.437855476140976
train--54/100 [689/1090] loss: 0.4418230623006821
train--54/100 [699/1090] loss: 0.435738742351532
train--54/100 [709/1090] loss: 0.4380433887243271
train--54/100 [719/1090] loss: 0.454420280456543
train--54/100 [729/1090] loss: 0.45496203005313873
train--54/100 [739/1090] loss: 0.44086838364601133
train--54/100 [749/1090] loss: 0.46844556331634524
train--54/100 [759/1090] loss: 0.45540907680988313
train--54/100 [769/1090] loss: 0.44043691754341124
train--54/100 [779/1090] loss: 0.43783788084983827
train--54/100 [789/1090] loss: 0.4499116659164429
train--54/100 [799/1090] loss: 0.4516246110200882
train--54/100 [809/1090] loss: 0.4439014196395874
train--54/100 [819/1090] loss: 0.46319853365421293
train--54/100 [829/1090] loss: 0.4315341740846634
train--54/100 [839/1090] loss: 0.47592002153396606
train--54/100 [849/1090] loss: 0.4230067998170853
train--54/100 [859/1090] loss: 0.4415002703666687
train--54/100 [869/1090] loss: 0.4636601090431213
train--54/100 [879/1090] loss: 0.42940654456615446
train--54/100 [889/1090] loss: 0.4512167662382126
train--54/100 [899/1090] loss: 0.44223435819149015
train--54/100 [909/1090] loss: 0.4500573217868805
train--54/100 [919/1090] loss: 0.43022115528583527
train--54/100 [929/1090] loss: 0.4663512587547302
train--54/100 [939/1090] loss: 0.43621599674224854
train--54/100 [949/1090] loss: 0.45099412798881533
train--54/100 [959/1090] loss: 0.4347971975803375
train--54/100 [969/1090] loss: 0.4355917125940323
train--54/100 [979/1090] loss: 0.445202961564064
train--54/100 [989/1090] loss: 0.445197194814682
train--54/100 [999/1090] loss: 0.4383749634027481
train--54/100 [1009/1090] loss: 0.42959846258163453
train--54/100 [1019/1090] loss: 0.45697909593582153
train--54/100 [1029/1090] loss: 0.4385834217071533
train--54/100 [1039/1090] loss: 0.44750224649906156
train--54/100 [1049/1090] loss: 0.45301519632339476
train--54/100 [1059/1090] loss: 0.4706561595201492
train--54/100 [1069/1090] loss: 0.4397579491138458
train--54/100 [1079/1090] loss: 0.47778389155864714
train--54/100 [1089/1090] loss: 0.45214945673942564
predicting model...
val--54/100 [10/1090] acc: 0.798046875
val--54/100 [20/1090] acc: 0.797265625
val--54/100 [30/1090] acc: 0.7958333333333333
val--54/100 [40/1090] acc: 0.79677734375
val--54/100 [50/1090] acc: 0.795078125
val--54/100 [60/1090] acc: 0.79375
val--54/100 [70/1090] acc: 0.79453125
val--54/100 [80/1090] acc: 0.79365234375
val--54/100 [90/1090] acc: 0.7941840277777777
val--54/100 [100/1090] acc: 0.7951953125
val--54/100 [110/1090] acc: 0.7955255681818182
val--54/100 [120/1090] acc: 0.7950520833333333
val--54/100 [130/1090] acc: 0.7962439903846154
val--54/100 [140/1090] acc: 0.7962890625
val--54/100 [150/1090] acc: 0.7961458333333333
val--54/100 [160/1090] acc: 0.7963134765625
val--54/100 [170/1090] acc: 0.7961397058823529
val--54/100 [180/1090] acc: 0.7960503472222222
val--54/100 [190/1090] acc: 0.7968133223684211
val--54/100 [200/1090] acc: 0.7969921875
val--54/100 [210/1090] acc: 0.7973214285714286
val--54/100 [220/1090] acc: 0.7964133522727272
val--54/100 [230/1090] acc: 0.7969089673913043
val--54/100 [240/1090] acc: 0.79658203125
val--54/100 [250/1090] acc: 0.796515625
val--54/100 [260/1090] acc: 0.7966195913461539
val--54/100 [270/1090] acc: 0.7969762731481481
val--54/100 [280/1090] acc: 0.7968191964285715
val--54/100 [290/1090] acc: 0.7966460129310344
val--54/100 [300/1090] acc: 0.796640625
val--54/100 [310/1090] acc: 0.7963331653225807
val--54/100 [320/1090] acc: 0.796533203125
val--54/100 [330/1090] acc: 0.7968158143939394
val--54/100 [340/1090] acc: 0.7970128676470588
val--54/100 [350/1090] acc: 0.7971763392857143
val--54/100 [360/1090] acc: 0.7971137152777777
val--54/100 [370/1090] acc: 0.7972550675675676
val--54/100 [380/1090] acc: 0.7972861842105263
val--54/100 [390/1090] acc: 0.7971354166666667
val--54/100 [400/1090] acc: 0.797080078125
val--54/100 [410/1090] acc: 0.7972179878048781
val--54/100 [420/1090] acc: 0.797172619047619
val--54/100 [430/1090] acc: 0.7970385174418605
val--54/100 [440/1090] acc: 0.797061434659091
val--54/100 [450/1090] acc: 0.7968923611111111
val--54/100 [460/1090] acc: 0.7967561141304348
val--54/100 [470/1090] acc: 0.7966921542553191
val--54/100 [480/1090] acc: 0.7967610677083333
val--54/100 [490/1090] acc: 0.796875
val--54/100 [500/1090] acc: 0.7970078125
val--54/100 [510/1090] acc: 0.7969132965686274
val--54/100 [520/1090] acc: 0.7971228966346153
val--54/100 [530/1090] acc: 0.7970224056603774
val--54/100 [540/1090] acc: 0.7971498842592593
val--54/100 [550/1090] acc: 0.7969957386363636
val--54/100 [560/1090] acc: 0.7968052455357143
val--54/100 [570/1090] acc: 0.7965391995614035
val--54/100 [580/1090] acc: 0.7965180495689655
val--54/100 [590/1090] acc: 0.7965638241525423
val--54/100 [600/1090] acc: 0.7966145833333333
val--54/100 [610/1090] acc: 0.7964779713114755
val--54/100 [620/1090] acc: 0.7964276713709677
val--54/100 [630/1090] acc: 0.7966021825396825
val--54/100 [640/1090] acc: 0.796783447265625
val--54/100 [650/1090] acc: 0.796796875
val--54/100 [660/1090] acc: 0.7967270359848485
val--54/100 [670/1090] acc: 0.7964202425373135
val--54/100 [680/1090] acc: 0.7962890625
val--54/100 [690/1090] acc: 0.7963937952898551
val--54/100 [700/1090] acc: 0.7964285714285714
val--54/100 [710/1090] acc: 0.7962643045774648
val--54/100 [720/1090] acc: 0.7961208767361111
val--54/100 [730/1090] acc: 0.79609375
val--54/100 [740/1090] acc: 0.7960304054054054
val--54/100 [750/1090] acc: 0.7960729166666667
val--54/100 [760/1090] acc: 0.7961708470394737
val--54/100 [770/1090] acc: 0.7960734577922078
val--54/100 [780/1090] acc: 0.7959835737179487
val--54/100 [790/1090] acc: 0.7960146360759494
val--54/100 [800/1090] acc: 0.796240234375
val--54/100 [810/1090] acc: 0.7963011188271605
val--54/100 [820/1090] acc: 0.7964415015243902
val--54/100 [830/1090] acc: 0.7965408509036145
val--54/100 [840/1090] acc: 0.7965355282738096
val--54/100 [850/1090] acc: 0.7965716911764706
val--54/100 [860/1090] acc: 0.7968159520348838
val--54/100 [870/1090] acc: 0.7967268318965517
val--54/100 [880/1090] acc: 0.7966930042613637
val--54/100 [890/1090] acc: 0.7968354985955056
val--54/100 [900/1090] acc: 0.7968055555555555
val--54/100 [910/1090] acc: 0.796802026098901
val--54/100 [920/1090] acc: 0.7968155570652173
val--54/100 [930/1090] acc: 0.7969212029569892
val--54/100 [940/1090] acc: 0.7969040890957447
val--54/100 [950/1090] acc: 0.7968009868421052
val--54/100 [960/1090] acc: 0.7967203776041667
val--54/100 [970/1090] acc: 0.7966897551546391
val--54/100 [980/1090] acc: 0.7967155612244898
val--54/100 [990/1090] acc: 0.7966422032828283
val--54/100 [1000/1090] acc: 0.7965390625
val--54/100 [1010/1090] acc: 0.7963644801980198
val--54/100 [1020/1090] acc: 0.796423100490196
val--54/100 [1030/1090] acc: 0.7964236953883496
val--54/100 [1040/1090] acc: 0.7963979867788461
val--54/100 [1050/1090] acc: 0.7964471726190476
val--54/100 [1060/1090] acc: 0.7964069870283019
val--54/100 [1070/1090] acc: 0.79639675817757
val--54/100 [1080/1090] acc: 0.7963396990740741
val--54/100 [1090/1090] acc: 0.7961546731651377
epoch= 54, accuracy= 0.796155, rmse= 0.376986, auc= 0.856297
train--55/100 [9/1090] loss: 0.4011989116668701
train--55/100 [19/1090] loss: 0.450698533654213
train--55/100 [29/1090] loss: 0.43970254361629485
train--55/100 [39/1090] loss: 0.45931633114814757
train--55/100 [49/1090] loss: 0.44460746347904206
train--55/100 [59/1090] loss: 0.45374335050582887
train--55/100 [69/1090] loss: 0.45397387742996215
train--55/100 [79/1090] loss: 0.43632274866104126
train--55/100 [89/1090] loss: 0.4453790128231049
train--55/100 [99/1090] loss: 0.4390082716941833
train--55/100 [109/1090] loss: 0.43974089324474336
train--55/100 [119/1090] loss: 0.4194695234298706
train--55/100 [129/1090] loss: 0.4422844499349594
train--55/100 [139/1090] loss: 0.4387016534805298
train--55/100 [149/1090] loss: 0.4309983283281326
train--55/100 [159/1090] loss: 0.4520815074443817
train--55/100 [169/1090] loss: 0.4470833629369736
train--55/100 [179/1090] loss: 0.44397246837615967
train--55/100 [189/1090] loss: 0.44421627521514895
train--55/100 [199/1090] loss: 0.4499738484621048
train--55/100 [209/1090] loss: 0.4397399127483368
train--55/100 [219/1090] loss: 0.4343536525964737
train--55/100 [229/1090] loss: 0.4447887271642685
train--55/100 [239/1090] loss: 0.4348334759473801
train--55/100 [249/1090] loss: 0.43535726368427274
train--55/100 [259/1090] loss: 0.43252667784690857
train--55/100 [269/1090] loss: 0.44346338212490083
train--55/100 [279/1090] loss: 0.43204334676265715
train--55/100 [289/1090] loss: 0.4336914151906967
train--55/100 [299/1090] loss: 0.45544970631599424
train--55/100 [309/1090] loss: 0.4399771988391876
train--55/100 [319/1090] loss: 0.44877837896347045
train--55/100 [329/1090] loss: 0.4422531396150589
train--55/100 [339/1090] loss: 0.45181558430194857
train--55/100 [349/1090] loss: 0.4539519906044006
train--55/100 [359/1090] loss: 0.4370705813169479
train--55/100 [369/1090] loss: 0.4360324114561081
train--55/100 [379/1090] loss: 0.44453679621219633
train--55/100 [389/1090] loss: 0.4608811289072037
train--55/100 [399/1090] loss: 0.4419462263584137
train--55/100 [409/1090] loss: 0.4422428458929062
train--55/100 [419/1090] loss: 0.44460299909114837
train--55/100 [429/1090] loss: 0.44115700423717497
train--55/100 [439/1090] loss: 0.44704214334487913
train--55/100 [449/1090] loss: 0.45740763545036317
train--55/100 [459/1090] loss: 0.4370731681585312
train--55/100 [469/1090] loss: 0.4384814739227295
train--55/100 [479/1090] loss: 0.43836461901664736
train--55/100 [489/1090] loss: 0.45696949660778047
train--55/100 [499/1090] loss: 0.4361725807189941
train--55/100 [509/1090] loss: 0.4211808294057846
train--55/100 [519/1090] loss: 0.42605121433734894
train--55/100 [529/1090] loss: 0.45278188586235046
train--55/100 [539/1090] loss: 0.4375524789094925
train--55/100 [549/1090] loss: 0.44117119908332825
train--55/100 [559/1090] loss: 0.4407801032066345
train--55/100 [569/1090] loss: 0.45763701796531675
train--55/100 [579/1090] loss: 0.44982624650001524
train--55/100 [589/1090] loss: 0.4523084431886673
train--55/100 [599/1090] loss: 0.4468251943588257
train--55/100 [609/1090] loss: 0.4363450050354004
train--55/100 [619/1090] loss: 0.4377086400985718
train--55/100 [629/1090] loss: 0.429317444562912
train--55/100 [639/1090] loss: 0.44592739045619967
train--55/100 [649/1090] loss: 0.45573841631412504
train--55/100 [659/1090] loss: 0.4427876681089401
train--55/100 [669/1090] loss: 0.43239579200744627
train--55/100 [679/1090] loss: 0.43481352031230924
train--55/100 [689/1090] loss: 0.4537464827299118
train--55/100 [699/1090] loss: 0.4102015793323517
train--55/100 [709/1090] loss: 0.43290367126464846
train--55/100 [719/1090] loss: 0.47158838510513307
train--55/100 [729/1090] loss: 0.4537764132022858
train--55/100 [739/1090] loss: 0.4252005249261856
train--55/100 [749/1090] loss: 0.4462629109621048
train--55/100 [759/1090] loss: 0.43605221509933473
train--55/100 [769/1090] loss: 0.45145165026187895
train--55/100 [779/1090] loss: 0.4590598285198212
train--55/100 [789/1090] loss: 0.4669143110513687
train--55/100 [799/1090] loss: 0.4394910544157028
train--55/100 [809/1090] loss: 0.4564743846654892
train--55/100 [819/1090] loss: 0.4476590156555176
train--55/100 [829/1090] loss: 0.45244530737400057
train--55/100 [839/1090] loss: 0.4408596843481064
train--55/100 [849/1090] loss: 0.46001123189926146
train--55/100 [859/1090] loss: 0.4397359311580658
train--55/100 [869/1090] loss: 0.44194415509700774
train--55/100 [879/1090] loss: 0.4424305409193039
train--55/100 [889/1090] loss: 0.4369684547185898
train--55/100 [899/1090] loss: 0.44367656111717224
train--55/100 [909/1090] loss: 0.4327841430902481
train--55/100 [919/1090] loss: 0.4485297381877899
train--55/100 [929/1090] loss: 0.430648273229599
train--55/100 [939/1090] loss: 0.4494544506072998
train--55/100 [949/1090] loss: 0.4368209272623062
train--55/100 [959/1090] loss: 0.44872682392597196
train--55/100 [969/1090] loss: 0.4375118017196655
train--55/100 [979/1090] loss: 0.43896367847919465
train--55/100 [989/1090] loss: 0.4605957746505737
train--55/100 [999/1090] loss: 0.4390043646097183
train--55/100 [1009/1090] loss: 0.4516836881637573
train--55/100 [1019/1090] loss: 0.44326351284980775
train--55/100 [1029/1090] loss: 0.44546839594841003
train--55/100 [1039/1090] loss: 0.44376852810382844
train--55/100 [1049/1090] loss: 0.44546795189380645
train--55/100 [1059/1090] loss: 0.4663663238286972
train--55/100 [1069/1090] loss: 0.4533356189727783
train--55/100 [1079/1090] loss: 0.4431394457817078
train--55/100 [1089/1090] loss: 0.43545018434524535
predicting model...
val--55/100 [10/1090] acc: 0.797265625
val--55/100 [20/1090] acc: 0.7962890625
val--55/100 [30/1090] acc: 0.7950520833333333
val--55/100 [40/1090] acc: 0.7955078125
val--55/100 [50/1090] acc: 0.794140625
val--55/100 [60/1090] acc: 0.7932291666666667
val--55/100 [70/1090] acc: 0.7939174107142857
val--55/100 [80/1090] acc: 0.79306640625
val--55/100 [90/1090] acc: 0.7936631944444444
val--55/100 [100/1090] acc: 0.7946875
val--55/100 [110/1090] acc: 0.7952414772727273
val--55/100 [120/1090] acc: 0.794921875
val--55/100 [130/1090] acc: 0.7961237980769231
val--55/100 [140/1090] acc: 0.79609375
val--55/100 [150/1090] acc: 0.7959635416666667
val--55/100 [160/1090] acc: 0.7960205078125
val--55/100 [170/1090] acc: 0.7958409926470589
val--55/100 [180/1090] acc: 0.7957248263888889
val--55/100 [190/1090] acc: 0.7963610197368421
val--55/100 [200/1090] acc: 0.7965234375
val--55/100 [210/1090] acc: 0.7968191964285715
val--55/100 [220/1090] acc: 0.7957563920454546
val--55/100 [230/1090] acc: 0.7962975543478261
val--55/100 [240/1090] acc: 0.79619140625
val--55/100 [250/1090] acc: 0.79621875
val--55/100 [260/1090] acc: 0.7961989182692307
val--55/100 [270/1090] acc: 0.7964699074074074
val--55/100 [280/1090] acc: 0.7963030133928571
val--55/100 [290/1090] acc: 0.7961206896551725
val--55/100 [300/1090] acc: 0.7961067708333334
val--55/100 [310/1090] acc: 0.7959551411290322
val--55/100 [320/1090] acc: 0.79615478515625
val--55/100 [330/1090] acc: 0.7964607007575758
val--55/100 [340/1090] acc: 0.7966681985294117
val--55/100 [350/1090] acc: 0.7968861607142858
val--55/100 [360/1090] acc: 0.7968098958333333
val--55/100 [370/1090] acc: 0.7969383445945946
val--55/100 [380/1090] acc: 0.7968852796052631
val--55/100 [390/1090] acc: 0.7966746794871795
val--55/100 [400/1090] acc: 0.7966796875
val--55/100 [410/1090] acc: 0.7968178353658537
val--55/100 [420/1090] acc: 0.7967912946428571
val--55/100 [430/1090] acc: 0.7966297238372093
val--55/100 [440/1090] acc: 0.796688565340909
val--55/100 [450/1090] acc: 0.7965625
val--55/100 [460/1090] acc: 0.7964419157608695
val--55/100 [470/1090] acc: 0.7964511303191489
val--55/100 [480/1090] acc: 0.7964762369791667
val--55/100 [490/1090] acc: 0.7965880102040817
val--55/100 [500/1090] acc: 0.7967265625
val--55/100 [510/1090] acc: 0.7966299019607843
val--55/100 [520/1090] acc: 0.7968224158653846
val--55/100 [530/1090] acc: 0.7968381485849056
val--55/100 [540/1090] acc: 0.7970052083333333
val--55/100 [550/1090] acc: 0.7969247159090909
val--55/100 [560/1090] acc: 0.79677734375
val--55/100 [570/1090] acc: 0.7965529057017544
val--55/100 [580/1090] acc: 0.796544989224138
val--55/100 [590/1090] acc: 0.796583686440678
val--55/100 [600/1090] acc: 0.7966471354166667
val--55/100 [610/1090] acc: 0.7965227971311475
val--55/100 [620/1090] acc: 0.7964780745967742
val--55/100 [630/1090] acc: 0.7966827876984127
val--55/100 [640/1090] acc: 0.796856689453125
val--55/100 [650/1090] acc: 0.7968449519230769
val--55/100 [660/1090] acc: 0.7967566287878788
val--55/100 [670/1090] acc: 0.7964085820895522
val--55/100 [680/1090] acc: 0.7962775735294118
val--55/100 [690/1090] acc: 0.796382472826087
val--55/100 [700/1090] acc: 0.7964341517857143
val--55/100 [710/1090] acc: 0.796280809859155
val--55/100 [720/1090] acc: 0.7961263020833333
val--55/100 [730/1090] acc: 0.7960616438356164
val--55/100 [740/1090] acc: 0.7959459459459459
val--55/100 [750/1090] acc: 0.7959895833333334
val--55/100 [760/1090] acc: 0.7960320723684211
val--55/100 [770/1090] acc: 0.7959466314935065
val--55/100 [780/1090] acc: 0.7958733974358975
val--55/100 [790/1090] acc: 0.7959206882911393
val--55/100 [800/1090] acc: 0.796123046875
val--55/100 [810/1090] acc: 0.7962094907407408
val--55/100 [820/1090] acc: 0.7963224085365853
val--55/100 [830/1090] acc: 0.7963902484939759
val--55/100 [840/1090] acc: 0.7963541666666667
val--55/100 [850/1090] acc: 0.7964016544117647
val--55/100 [860/1090] acc: 0.796656976744186
val--55/100 [870/1090] acc: 0.796569683908046
val--55/100 [880/1090] acc: 0.7965465198863636
val--55/100 [890/1090] acc: 0.796655547752809
val--55/100 [900/1090] acc: 0.7966493055555556
val--55/100 [910/1090] acc: 0.7966346153846153
val--55/100 [920/1090] acc: 0.7966627038043478
val--55/100 [930/1090] acc: 0.7967615927419355
val--55/100 [940/1090] acc: 0.7967461768617021
val--55/100 [950/1090] acc: 0.7966447368421052
val--55/100 [960/1090] acc: 0.7965372721354167
val--55/100 [970/1090] acc: 0.796496456185567
val--55/100 [980/1090] acc: 0.7965043048469388
val--55/100 [990/1090] acc: 0.7964212436868687
val--55/100 [1000/1090] acc: 0.79633984375
val--55/100 [1010/1090] acc: 0.7961827042079208
val--55/100 [1020/1090] acc: 0.7962469362745098
val--55/100 [1030/1090] acc: 0.7962606189320388
val--55/100 [1040/1090] acc: 0.796240234375
val--55/100 [1050/1090] acc: 0.7962909226190477
val--55/100 [1060/1090] acc: 0.7962411556603773
val--55/100 [1070/1090] acc: 0.796232476635514
val--55/100 [1080/1090] acc: 0.7961877893518519
val--55/100 [1090/1090] acc: 0.7960256594036698
epoch= 55, accuracy= 0.796026, rmse= 0.376961, auc= 0.856336
train--56/100 [9/1090] loss: 0.402759975194931
train--56/100 [19/1090] loss: 0.4411832720041275
train--56/100 [29/1090] loss: 0.43085590898990633
train--56/100 [39/1090] loss: 0.43558585047721865
train--56/100 [49/1090] loss: 0.44097681641578673
train--56/100 [59/1090] loss: 0.43602060079574584
train--56/100 [69/1090] loss: 0.4526891797780991
train--56/100 [79/1090] loss: 0.4425608962774277
train--56/100 [89/1090] loss: 0.4285045087337494
train--56/100 [99/1090] loss: 0.43029800057411194
train--56/100 [109/1090] loss: 0.4435523867607117
train--56/100 [119/1090] loss: 0.43936824798583984
train--56/100 [129/1090] loss: 0.4457441449165344
train--56/100 [139/1090] loss: 0.4403198003768921
train--56/100 [149/1090] loss: 0.43227205872535707
train--56/100 [159/1090] loss: 0.4573054641485214
train--56/100 [169/1090] loss: 0.45262246429920194
train--56/100 [179/1090] loss: 0.425678551197052
train--56/100 [189/1090] loss: 0.43573244512081144
train--56/100 [199/1090] loss: 0.4172120988368988
train--56/100 [209/1090] loss: 0.44974892139434813
train--56/100 [219/1090] loss: 0.4392255753278732
train--56/100 [229/1090] loss: 0.4467912703752518
train--56/100 [239/1090] loss: 0.4347623407840729
train--56/100 [249/1090] loss: 0.4174822002649307
train--56/100 [259/1090] loss: 0.4441557347774506
train--56/100 [269/1090] loss: 0.4416538953781128
train--56/100 [279/1090] loss: 0.44675173163414
train--56/100 [289/1090] loss: 0.4300283432006836
train--56/100 [299/1090] loss: 0.4440793007612228
train--56/100 [309/1090] loss: 0.4507569283246994
train--56/100 [319/1090] loss: 0.4381508857011795
train--56/100 [329/1090] loss: 0.4508715808391571
train--56/100 [339/1090] loss: 0.43514150381088257
train--56/100 [349/1090] loss: 0.4296385496854782
train--56/100 [359/1090] loss: 0.4608860194683075
train--56/100 [369/1090] loss: 0.45672555565834044
train--56/100 [379/1090] loss: 0.4229979872703552
train--56/100 [389/1090] loss: 0.45414956510066984
train--56/100 [399/1090] loss: 0.4649646908044815
train--56/100 [409/1090] loss: 0.4488340765237808
train--56/100 [419/1090] loss: 0.44795066118240356
train--56/100 [429/1090] loss: 0.44084447622299194
train--56/100 [439/1090] loss: 0.44851738810539243
train--56/100 [449/1090] loss: 0.42244124710559844
train--56/100 [459/1090] loss: 0.43486094772815703
train--56/100 [469/1090] loss: 0.43550425171852114
train--56/100 [479/1090] loss: 0.43739842176437377
train--56/100 [489/1090] loss: 0.4442423671483994
train--56/100 [499/1090] loss: 0.4510051548480988
train--56/100 [509/1090] loss: 0.42431513369083407
train--56/100 [519/1090] loss: 0.4345028430223465
train--56/100 [529/1090] loss: 0.4645911753177643
train--56/100 [539/1090] loss: 0.446272075176239
train--56/100 [549/1090] loss: 0.438495010137558
train--56/100 [559/1090] loss: 0.44263469278812406
train--56/100 [569/1090] loss: 0.43659011721611024
train--56/100 [579/1090] loss: 0.42520667612552643
train--56/100 [589/1090] loss: 0.4386434078216553
train--56/100 [599/1090] loss: 0.43673578798770907
train--56/100 [609/1090] loss: 0.4296451598405838
train--56/100 [619/1090] loss: 0.44684062600135804
train--56/100 [629/1090] loss: 0.45815773904323576
train--56/100 [639/1090] loss: 0.43269400894641874
train--56/100 [649/1090] loss: 0.4498758465051651
train--56/100 [659/1090] loss: 0.43895902633666994
train--56/100 [669/1090] loss: 0.44895640313625335
train--56/100 [679/1090] loss: 0.4365938395261765
train--56/100 [689/1090] loss: 0.44024832248687745
train--56/100 [699/1090] loss: 0.43283643424510954
train--56/100 [709/1090] loss: 0.44302985072135925
train--56/100 [719/1090] loss: 0.43871191143989563
train--56/100 [729/1090] loss: 0.4419918119907379
train--56/100 [739/1090] loss: 0.4334334522485733
train--56/100 [749/1090] loss: 0.45666438341140747
train--56/100 [759/1090] loss: 0.4498275190591812
train--56/100 [769/1090] loss: 0.4377763122320175
train--56/100 [779/1090] loss: 0.44905342161655426
train--56/100 [789/1090] loss: 0.45147235989570617
train--56/100 [799/1090] loss: 0.46174144446849824
train--56/100 [809/1090] loss: 0.474343341588974
train--56/100 [819/1090] loss: 0.44720374047756195
train--56/100 [829/1090] loss: 0.45598978400230405
train--56/100 [839/1090] loss: 0.4595597416162491
train--56/100 [849/1090] loss: 0.44759387373924253
train--56/100 [859/1090] loss: 0.4647186487913132
train--56/100 [869/1090] loss: 0.441805562376976
train--56/100 [879/1090] loss: 0.42640152871608733
train--56/100 [889/1090] loss: 0.4419425517320633
train--56/100 [899/1090] loss: 0.46895939111709595
train--56/100 [909/1090] loss: 0.4292451947927475
train--56/100 [919/1090] loss: 0.43518554866313935
train--56/100 [929/1090] loss: 0.4226296991109848
train--56/100 [939/1090] loss: 0.4506560117006302
train--56/100 [949/1090] loss: 0.4375140368938446
train--56/100 [959/1090] loss: 0.46401559114456176
train--56/100 [969/1090] loss: 0.4440581887960434
train--56/100 [979/1090] loss: 0.43963274657726287
train--56/100 [989/1090] loss: 0.4596708118915558
train--56/100 [999/1090] loss: 0.46816742420196533
train--56/100 [1009/1090] loss: 0.4484026044607162
train--56/100 [1019/1090] loss: 0.45057350397109985
train--56/100 [1029/1090] loss: 0.45572725832462313
train--56/100 [1039/1090] loss: 0.4362581580877304
train--56/100 [1049/1090] loss: 0.4601925551891327
train--56/100 [1059/1090] loss: 0.4554480880498886
train--56/100 [1069/1090] loss: 0.44895271956920624
train--56/100 [1079/1090] loss: 0.4418894350528717
train--56/100 [1089/1090] loss: 0.44263386726379395
predicting model...
val--56/100 [10/1090] acc: 0.79765625
val--56/100 [20/1090] acc: 0.7978515625
val--56/100 [30/1090] acc: 0.7962239583333334
val--56/100 [40/1090] acc: 0.7966796875
val--56/100 [50/1090] acc: 0.795
val--56/100 [60/1090] acc: 0.7938802083333333
val--56/100 [70/1090] acc: 0.7946986607142857
val--56/100 [80/1090] acc: 0.79365234375
val--56/100 [90/1090] acc: 0.7943576388888889
val--56/100 [100/1090] acc: 0.7954296875
val--56/100 [110/1090] acc: 0.795703125
val--56/100 [120/1090] acc: 0.7954752604166667
val--56/100 [130/1090] acc: 0.7967548076923077
val--56/100 [140/1090] acc: 0.7965122767857142
val--56/100 [150/1090] acc: 0.7964583333333334
val--56/100 [160/1090] acc: 0.79658203125
val--56/100 [170/1090] acc: 0.7963694852941177
val--56/100 [180/1090] acc: 0.7961588541666667
val--56/100 [190/1090] acc: 0.7968338815789474
val--56/100 [200/1090] acc: 0.79705078125
val--56/100 [210/1090] acc: 0.797451636904762
val--56/100 [220/1090] acc: 0.7965021306818182
val--56/100 [230/1090] acc: 0.7969429347826087
val--56/100 [240/1090] acc: 0.7967610677083333
val--56/100 [250/1090] acc: 0.796796875
val--56/100 [260/1090] acc: 0.7968900240384615
val--56/100 [270/1090] acc: 0.7971932870370371
val--56/100 [280/1090] acc: 0.7971400669642857
val--56/100 [290/1090] acc: 0.7970096982758621
val--56/100 [300/1090] acc: 0.7970182291666666
val--56/100 [310/1090] acc: 0.796875
val--56/100 [320/1090] acc: 0.7970947265625
val--56/100 [330/1090] acc: 0.7973248106060606
val--56/100 [340/1090] acc: 0.7974954044117647
val--56/100 [350/1090] acc: 0.79765625
val--56/100 [360/1090] acc: 0.79755859375
val--56/100 [370/1090] acc: 0.7976456925675676
val--56/100 [380/1090] acc: 0.7976665296052632
val--56/100 [390/1090] acc: 0.7974859775641026
val--56/100 [400/1090] acc: 0.79748046875
val--56/100 [410/1090] acc: 0.7975895579268293
val--56/100 [420/1090] acc: 0.7975446428571429
val--56/100 [430/1090] acc: 0.797374636627907
val--56/100 [440/1090] acc: 0.7973544034090909
val--56/100 [450/1090] acc: 0.7972916666666666
val--56/100 [460/1090] acc: 0.7971382472826087
val--56/100 [470/1090] acc: 0.7970578457446809
val--56/100 [480/1090] acc: 0.7971110026041667
val--56/100 [490/1090] acc: 0.7972417091836734
val--56/100 [500/1090] acc: 0.7973671875
val--56/100 [510/1090] acc: 0.7972886029411764
val--56/100 [520/1090] acc: 0.7974909855769231
val--56/100 [530/1090] acc: 0.797435141509434
val--56/100 [540/1090] acc: 0.7975694444444444
val--56/100 [550/1090] acc: 0.7974715909090909
val--56/100 [560/1090] acc: 0.7973005022321429
val--56/100 [570/1090] acc: 0.7970257675438597
val--56/100 [580/1090] acc: 0.7970703125
val--56/100 [590/1090] acc: 0.7970802436440678
val--56/100 [600/1090] acc: 0.7970572916666666
val--56/100 [610/1090] acc: 0.7969390368852459
val--56/100 [620/1090] acc: 0.7968939012096774
val--56/100 [630/1090] acc: 0.7971106150793651
val--56/100 [640/1090] acc: 0.79725341796875
val--56/100 [650/1090] acc: 0.7972536057692308
val--56/100 [660/1090] acc: 0.797170928030303
val--56/100 [670/1090] acc: 0.7968341884328358
val--56/100 [680/1090] acc: 0.7966969209558824
val--56/100 [690/1090] acc: 0.7968183876811594
val--56/100 [700/1090] acc: 0.7968861607142858
val--56/100 [710/1090] acc: 0.7967539612676057
val--56/100 [720/1090] acc: 0.7965983072916667
val--56/100 [730/1090] acc: 0.7965378852739726
val--56/100 [740/1090] acc: 0.7964527027027027
val--56/100 [750/1090] acc: 0.7965104166666667
val--56/100 [760/1090] acc: 0.7965871710526315
val--56/100 [770/1090] acc: 0.7964945211038961
val--56/100 [780/1090] acc: 0.796444310897436
val--56/100 [790/1090] acc: 0.7965189873417722
val--56/100 [800/1090] acc: 0.796748046875
val--56/100 [810/1090] acc: 0.7967978395061729
val--56/100 [820/1090] acc: 0.796898818597561
val--56/100 [830/1090] acc: 0.7969691265060241
val--56/100 [840/1090] acc: 0.7969261532738096
val--56/100 [850/1090] acc: 0.7969577205882353
val--56/100 [860/1090] acc: 0.7972247456395349
val--56/100 [870/1090] acc: 0.7971219468390804
val--56/100 [880/1090] acc: 0.7970836292613637
val--56/100 [890/1090] acc: 0.7971954002808989
val--56/100 [900/1090] acc: 0.7971875
val--56/100 [910/1090] acc: 0.7971668956043956
val--56/100 [920/1090] acc: 0.7971891983695653
val--56/100 [930/1090] acc: 0.797286626344086
val--56/100 [940/1090] acc: 0.7972988696808511
val--56/100 [950/1090] acc: 0.7971957236842105
val--56/100 [960/1090] acc: 0.79708251953125
val--56/100 [970/1090] acc: 0.7970401095360825
val--56/100 [980/1090] acc: 0.7970942283163265
val--56/100 [990/1090] acc: 0.7970249368686869
val--56/100 [1000/1090] acc: 0.79696875
val--56/100 [1010/1090] acc: 0.7967860457920792
val--56/100 [1020/1090] acc: 0.7968481924019608
val--56/100 [1030/1090] acc: 0.7968712075242719
val--56/100 [1040/1090] acc: 0.7968825120192308
val--56/100 [1050/1090] acc: 0.7969308035714285
val--56/100 [1060/1090] acc: 0.7968528891509434
val--56/100 [1070/1090] acc: 0.796831191588785
val--56/100 [1080/1090] acc: 0.796752025462963
val--56/100 [1090/1090] acc: 0.7965668004587156
epoch= 56, accuracy= 0.796567, rmse= 0.376835, auc= 0.856521
train--57/100 [9/1090] loss: 0.40216792821884156
train--57/100 [19/1090] loss: 0.4492719143629074
train--57/100 [29/1090] loss: 0.44770273864269255
train--57/100 [39/1090] loss: 0.4320437967777252
train--57/100 [49/1090] loss: 0.4237196534872055
train--57/100 [59/1090] loss: 0.44799970984458926
train--57/100 [69/1090] loss: 0.4412273198366165
train--57/100 [79/1090] loss: 0.43894352316856383
train--57/100 [89/1090] loss: 0.45390906035900114
train--57/100 [99/1090] loss: 0.4362160176038742
train--57/100 [109/1090] loss: 0.43753196597099303
train--57/100 [119/1090] loss: 0.43631735146045686
train--57/100 [129/1090] loss: 0.4298382341861725
train--57/100 [139/1090] loss: 0.4556415557861328
train--57/100 [149/1090] loss: 0.441097217798233
train--57/100 [159/1090] loss: 0.44991467893123627
train--57/100 [169/1090] loss: 0.4637418657541275
train--57/100 [179/1090] loss: 0.44297959804534914
train--57/100 [189/1090] loss: 0.44728323817253113
train--57/100 [199/1090] loss: 0.4447185307741165
train--57/100 [209/1090] loss: 0.4368318676948547
train--57/100 [219/1090] loss: 0.44666182100772855
train--57/100 [229/1090] loss: 0.4475879281759262
train--57/100 [239/1090] loss: 0.445805624127388
train--57/100 [249/1090] loss: 0.43881364464759826
train--57/100 [259/1090] loss: 0.41920275390148165
train--57/100 [269/1090] loss: 0.4434174448251724
train--57/100 [279/1090] loss: 0.4228202998638153
train--57/100 [289/1090] loss: 0.435264852643013
train--57/100 [299/1090] loss: 0.44036966264247895
train--57/100 [309/1090] loss: 0.4371741831302643
train--57/100 [319/1090] loss: 0.4342304885387421
train--57/100 [329/1090] loss: 0.4396911174058914
train--57/100 [339/1090] loss: 0.4388167828321457
train--57/100 [349/1090] loss: 0.4617417573928833
train--57/100 [359/1090] loss: 0.4323508232831955
train--57/100 [369/1090] loss: 0.4467287749052048
train--57/100 [379/1090] loss: 0.46222559809684755
train--57/100 [389/1090] loss: 0.46147648990154266
train--57/100 [399/1090] loss: 0.4522862136363983
train--57/100 [409/1090] loss: 0.4432000607252121
train--57/100 [419/1090] loss: 0.4254093438386917
train--57/100 [429/1090] loss: 0.4431471794843674
train--57/100 [439/1090] loss: 0.42118302881717684
train--57/100 [449/1090] loss: 0.4539384424686432
train--57/100 [459/1090] loss: 0.4614153027534485
train--57/100 [469/1090] loss: 0.4596020579338074
train--57/100 [479/1090] loss: 0.42778473496437075
train--57/100 [489/1090] loss: 0.43425842225551603
train--57/100 [499/1090] loss: 0.45612666606903074
train--57/100 [509/1090] loss: 0.4465115189552307
train--57/100 [519/1090] loss: 0.4402801632881165
train--57/100 [529/1090] loss: 0.44749237298965455
train--57/100 [539/1090] loss: 0.4388860583305359
train--57/100 [549/1090] loss: 0.43616258502006533
train--57/100 [559/1090] loss: 0.4376837909221649
train--57/100 [569/1090] loss: 0.46416663825511933
train--57/100 [579/1090] loss: 0.44392336905002594
train--57/100 [589/1090] loss: 0.434231835603714
train--57/100 [599/1090] loss: 0.44767439365386963
train--57/100 [609/1090] loss: 0.4435483396053314
train--57/100 [619/1090] loss: 0.4355482429265976
train--57/100 [629/1090] loss: 0.43672170042991637
train--57/100 [639/1090] loss: 0.4434280455112457
train--57/100 [649/1090] loss: 0.4327534168958664
train--57/100 [659/1090] loss: 0.44827198684215547
train--57/100 [669/1090] loss: 0.44526183009147646
train--57/100 [679/1090] loss: 0.4331184387207031
train--57/100 [689/1090] loss: 0.4448330342769623
train--57/100 [699/1090] loss: 0.4386394202709198
train--57/100 [709/1090] loss: 0.44295393824577334
train--57/100 [719/1090] loss: 0.4350818574428558
train--57/100 [729/1090] loss: 0.42953717708587646
train--57/100 [739/1090] loss: 0.44326415061950686
train--57/100 [749/1090] loss: 0.4473381370306015
train--57/100 [759/1090] loss: 0.466137507557869
train--57/100 [769/1090] loss: 0.4459368109703064
train--57/100 [779/1090] loss: 0.442557755112648
train--57/100 [789/1090] loss: 0.46634910702705384
train--57/100 [799/1090] loss: 0.4522353708744049
train--57/100 [809/1090] loss: 0.42562724351882936
train--57/100 [819/1090] loss: 0.43392297625541687
train--57/100 [829/1090] loss: 0.42228061854839327
train--57/100 [839/1090] loss: 0.45426905155181885
train--57/100 [849/1090] loss: 0.4433407157659531
train--57/100 [859/1090] loss: 0.45427059531211855
train--57/100 [869/1090] loss: 0.43872417509555817
train--57/100 [879/1090] loss: 0.436399906873703
train--57/100 [889/1090] loss: 0.45259600281715395
train--57/100 [899/1090] loss: 0.44766835272312167
train--57/100 [909/1090] loss: 0.4555313766002655
train--57/100 [919/1090] loss: 0.4377501368522644
train--57/100 [929/1090] loss: 0.43828374743461607
train--57/100 [939/1090] loss: 0.43565859496593473
train--57/100 [949/1090] loss: 0.4401997536420822
train--57/100 [959/1090] loss: 0.4412120461463928
train--57/100 [969/1090] loss: 0.45564334392547606
train--57/100 [979/1090] loss: 0.4357443511486053
train--57/100 [989/1090] loss: 0.4641826659440994
train--57/100 [999/1090] loss: 0.4252039670944214
train--57/100 [1009/1090] loss: 0.43412732183933256
train--57/100 [1019/1090] loss: 0.44212505519390105
train--57/100 [1029/1090] loss: 0.46666709184646604
train--57/100 [1039/1090] loss: 0.4458882063627243
train--57/100 [1049/1090] loss: 0.44059852957725526
train--57/100 [1059/1090] loss: 0.46181854605674744
train--57/100 [1069/1090] loss: 0.43461163341999054
train--57/100 [1079/1090] loss: 0.44787377715110777
train--57/100 [1089/1090] loss: 0.4483072072267532
predicting model...
val--57/100 [10/1090] acc: 0.796875
val--57/100 [20/1090] acc: 0.7970703125
val--57/100 [30/1090] acc: 0.7959635416666667
val--57/100 [40/1090] acc: 0.79609375
val--57/100 [50/1090] acc: 0.794921875
val--57/100 [60/1090] acc: 0.7939453125
val--57/100 [70/1090] acc: 0.7948102678571428
val--57/100 [80/1090] acc: 0.79404296875
val--57/100 [90/1090] acc: 0.7944878472222222
val--57/100 [100/1090] acc: 0.795546875
val--57/100 [110/1090] acc: 0.7958096590909091
val--57/100 [120/1090] acc: 0.7953776041666667
val--57/100 [130/1090] acc: 0.7963641826923077
val--57/100 [140/1090] acc: 0.7964564732142857
val--57/100 [150/1090] acc: 0.79640625
val--57/100 [160/1090] acc: 0.7965087890625
val--57/100 [170/1090] acc: 0.7961856617647058
val--57/100 [180/1090] acc: 0.7961588541666667
val--57/100 [190/1090] acc: 0.7968338815789474
val--57/100 [200/1090] acc: 0.79693359375
val--57/100 [210/1090] acc: 0.7973772321428572
val--57/100 [220/1090] acc: 0.7966264204545455
val--57/100 [230/1090] acc: 0.7970788043478261
val--57/100 [240/1090] acc: 0.7968912760416667
val--57/100 [250/1090] acc: 0.79684375
val--57/100 [260/1090] acc: 0.7969501201923077
val--57/100 [270/1090] acc: 0.7972511574074074
val--57/100 [280/1090] acc: 0.7971400669642857
val--57/100 [290/1090] acc: 0.7969558189655173
val--57/100 [300/1090] acc: 0.7970442708333333
val--57/100 [310/1090] acc: 0.796875
val--57/100 [320/1090] acc: 0.79715576171875
val--57/100 [330/1090] acc: 0.797265625
val--57/100 [340/1090] acc: 0.7974379595588236
val--57/100 [350/1090] acc: 0.7976004464285714
val--57/100 [360/1090] acc: 0.7974826388888889
val--57/100 [370/1090] acc: 0.797582347972973
val--57/100 [380/1090] acc: 0.7975842927631579
val--57/100 [390/1090] acc: 0.7974459134615385
val--57/100 [400/1090] acc: 0.797470703125
val--57/100 [410/1090] acc: 0.7975705030487805
val--57/100 [420/1090] acc: 0.797553943452381
val--57/100 [430/1090] acc: 0.7973928052325582
val--57/100 [440/1090] acc: 0.79736328125
val--57/100 [450/1090] acc: 0.7971961805555555
val--57/100 [460/1090] acc: 0.796968410326087
val--57/100 [470/1090] acc: 0.7968916223404255
val--57/100 [480/1090] acc: 0.7968587239583333
val--57/100 [490/1090] acc: 0.7970025510204082
val--57/100 [500/1090] acc: 0.7971640625
val--57/100 [510/1090] acc: 0.7971354166666667
val--57/100 [520/1090] acc: 0.7973858173076923
val--57/100 [530/1090] acc: 0.7973982900943396
val--57/100 [540/1090] acc: 0.7975043402777777
val--57/100 [550/1090] acc: 0.7973508522727273
val--57/100 [560/1090] acc: 0.7971749441964285
val--57/100 [570/1090] acc: 0.7969024122807018
val--57/100 [580/1090] acc: 0.7969894935344828
val--57/100 [590/1090] acc: 0.7970537605932203
val--57/100 [600/1090] acc: 0.7970703125
val--57/100 [610/1090] acc: 0.7969774590163935
val--57/100 [620/1090] acc: 0.7969128024193548
val--57/100 [630/1090] acc: 0.7971168154761905
val--57/100 [640/1090] acc: 0.79725341796875
val--57/100 [650/1090] acc: 0.7972415865384616
val--57/100 [660/1090] acc: 0.797176846590909
val--57/100 [670/1090] acc: 0.7968633395522388
val--57/100 [680/1090] acc: 0.7967371323529412
val--57/100 [690/1090] acc: 0.7968919836956522
val--57/100 [700/1090] acc: 0.7969363839285715
val--57/100 [710/1090] acc: 0.7967979753521127
val--57/100 [720/1090] acc: 0.796630859375
val--57/100 [730/1090] acc: 0.7965699914383562
val--57/100 [740/1090] acc: 0.7964738175675675
val--57/100 [750/1090] acc: 0.796546875
val--57/100 [760/1090] acc: 0.7965974506578948
val--57/100 [770/1090] acc: 0.7965046672077922
val--57/100 [780/1090] acc: 0.7964393028846154
val--57/100 [790/1090] acc: 0.7964942642405063
val--57/100 [800/1090] acc: 0.796689453125
val--57/100 [810/1090] acc: 0.7967351466049383
val--57/100 [820/1090] acc: 0.7968654725609756
val--57/100 [830/1090] acc: 0.7969314759036145
val--57/100 [840/1090] acc: 0.7969029017857143
val--57/100 [850/1090] acc: 0.7969301470588235
val--57/100 [860/1090] acc: 0.7971611555232558
val--57/100 [870/1090] acc: 0.7970860272988506
val--57/100 [880/1090] acc: 0.7970703125
val--57/100 [890/1090] acc: 0.7972217345505618
val--57/100 [900/1090] acc: 0.7972048611111111
val--57/100 [910/1090] acc: 0.7972312843406594
val--57/100 [920/1090] acc: 0.7972528872282608
val--57/100 [930/1090] acc: 0.7973496303763441
val--57/100 [940/1090] acc: 0.7973653590425532
val--57/100 [950/1090] acc: 0.7972615131578947
val--57/100 [960/1090] acc: 0.7971394856770834
val--57/100 [970/1090] acc: 0.7971085695876289
val--57/100 [980/1090] acc: 0.7971659757653061
val--57/100 [990/1090] acc: 0.7970801767676767
val--57/100 [1000/1090] acc: 0.7969921875
val--57/100 [1010/1090] acc: 0.7968092512376238
val--57/100 [1020/1090] acc: 0.7968864889705882
val--57/100 [1030/1090] acc: 0.7969091322815534
val--57/100 [1040/1090] acc: 0.7969088040865384
val--57/100 [1050/1090] acc: 0.7969494047619048
val--57/100 [1060/1090] acc: 0.796875
val--57/100 [1070/1090] acc: 0.7968494450934579
val--57/100 [1080/1090] acc: 0.7967918113425926
val--57/100 [1090/1090] acc: 0.7966241399082569
epoch= 57, accuracy= 0.796624, rmse= 0.376733, auc= 0.856578
train--58/100 [9/1090] loss: 0.395812514424324
train--58/100 [19/1090] loss: 0.45659880340099335
train--58/100 [29/1090] loss: 0.44896926879882815
train--58/100 [39/1090] loss: 0.457795512676239
train--58/100 [49/1090] loss: 0.42497558891773224
train--58/100 [59/1090] loss: 0.4373707741498947
train--58/100 [69/1090] loss: 0.44294517338275907
train--58/100 [79/1090] loss: 0.42772771418094635
train--58/100 [89/1090] loss: 0.4250104457139969
train--58/100 [99/1090] loss: 0.44379324913024903
train--58/100 [109/1090] loss: 0.43725583255290984
train--58/100 [119/1090] loss: 0.4427645057439804
train--58/100 [129/1090] loss: 0.4328369379043579
train--58/100 [139/1090] loss: 0.4421550273895264
train--58/100 [149/1090] loss: 0.4415020912885666
train--58/100 [159/1090] loss: 0.4321914792060852
train--58/100 [169/1090] loss: 0.4433995753526688
train--58/100 [179/1090] loss: 0.45569036304950716
train--58/100 [189/1090] loss: 0.4326659470796585
train--58/100 [199/1090] loss: 0.4376624971628189
train--58/100 [209/1090] loss: 0.4443142145872116
train--58/100 [219/1090] loss: 0.44133571684360506
train--58/100 [229/1090] loss: 0.4452409207820892
train--58/100 [239/1090] loss: 0.43564368784427643
train--58/100 [249/1090] loss: 0.46486364901065824
train--58/100 [259/1090] loss: 0.4415645331144333
train--58/100 [269/1090] loss: 0.4405764490365982
train--58/100 [279/1090] loss: 0.45097469389438627
train--58/100 [289/1090] loss: 0.42812809348106384
train--58/100 [299/1090] loss: 0.4382037967443466
train--58/100 [309/1090] loss: 0.43503434360027315
train--58/100 [319/1090] loss: 0.4379834920167923
train--58/100 [329/1090] loss: 0.4344567656517029
train--58/100 [339/1090] loss: 0.4612201899290085
train--58/100 [349/1090] loss: 0.41193366050720215
train--58/100 [359/1090] loss: 0.4489647477865219
train--58/100 [369/1090] loss: 0.42909348011016846
train--58/100 [379/1090] loss: 0.4310294210910797
train--58/100 [389/1090] loss: 0.42621256709098815
train--58/100 [399/1090] loss: 0.4493145078420639
train--58/100 [409/1090] loss: 0.4425480902194977
train--58/100 [419/1090] loss: 0.43239628672599795
train--58/100 [429/1090] loss: 0.46953544914722445
train--58/100 [439/1090] loss: 0.4321157217025757
train--58/100 [449/1090] loss: 0.4466012388467789
train--58/100 [459/1090] loss: 0.4527525454759598
train--58/100 [469/1090] loss: 0.4634579747915268
train--58/100 [479/1090] loss: 0.44286392331123353
train--58/100 [489/1090] loss: 0.4277417778968811
train--58/100 [499/1090] loss: 0.46917175948619844
train--58/100 [509/1090] loss: 0.445769402384758
train--58/100 [519/1090] loss: 0.418626070022583
train--58/100 [529/1090] loss: 0.4506735414266586
train--58/100 [539/1090] loss: 0.4374535918235779
train--58/100 [549/1090] loss: 0.4439020574092865
train--58/100 [559/1090] loss: 0.43793978691101076
train--58/100 [569/1090] loss: 0.4371509045362473
train--58/100 [579/1090] loss: 0.43574694395065305
train--58/100 [589/1090] loss: 0.44370672702789304
train--58/100 [599/1090] loss: 0.4452293276786804
train--58/100 [609/1090] loss: 0.4511573940515518
train--58/100 [619/1090] loss: 0.4463776767253876
train--58/100 [629/1090] loss: 0.44374153316020964
train--58/100 [639/1090] loss: 0.4460967153310776
train--58/100 [649/1090] loss: 0.4479927450418472
train--58/100 [659/1090] loss: 0.4530986398458481
train--58/100 [669/1090] loss: 0.42944490909576416
train--58/100 [679/1090] loss: 0.4634582310914993
train--58/100 [689/1090] loss: 0.4369554877281189
train--58/100 [699/1090] loss: 0.4340706288814545
train--58/100 [709/1090] loss: 0.4307581901550293
train--58/100 [719/1090] loss: 0.4494675248861313
train--58/100 [729/1090] loss: 0.44710926711559296
train--58/100 [739/1090] loss: 0.437466761469841
train--58/100 [749/1090] loss: 0.46470717489719393
train--58/100 [759/1090] loss: 0.4392689973115921
train--58/100 [769/1090] loss: 0.4419422894716263
train--58/100 [779/1090] loss: 0.44379119873046874
train--58/100 [789/1090] loss: 0.4558533489704132
train--58/100 [799/1090] loss: 0.4315812557935715
train--58/100 [809/1090] loss: 0.4465155601501465
train--58/100 [819/1090] loss: 0.44341281354427337
train--58/100 [829/1090] loss: 0.45933727324008944
train--58/100 [839/1090] loss: 0.4532857656478882
train--58/100 [849/1090] loss: 0.4372828871011734
train--58/100 [859/1090] loss: 0.4441609442234039
train--58/100 [869/1090] loss: 0.4439305514097214
train--58/100 [879/1090] loss: 0.45597304999828336
train--58/100 [889/1090] loss: 0.4499020427465439
train--58/100 [899/1090] loss: 0.4440027058124542
train--58/100 [909/1090] loss: 0.45817403197288514
train--58/100 [919/1090] loss: 0.4482808232307434
train--58/100 [929/1090] loss: 0.4390678137540817
train--58/100 [939/1090] loss: 0.4564954936504364
train--58/100 [949/1090] loss: 0.4454323172569275
train--58/100 [959/1090] loss: 0.4561715841293335
train--58/100 [969/1090] loss: 0.43299527168273927
train--58/100 [979/1090] loss: 0.45963358879089355
train--58/100 [989/1090] loss: 0.4422332465648651
train--58/100 [999/1090] loss: 0.4400420546531677
train--58/100 [1009/1090] loss: 0.4160779803991318
train--58/100 [1019/1090] loss: 0.4358309358358383
train--58/100 [1029/1090] loss: 0.4417318969964981
train--58/100 [1039/1090] loss: 0.44217008650302886
train--58/100 [1049/1090] loss: 0.4498710185289383
train--58/100 [1059/1090] loss: 0.43258011639118193
train--58/100 [1069/1090] loss: 0.43771480619907377
train--58/100 [1079/1090] loss: 0.45601082742214205
train--58/100 [1089/1090] loss: 0.44826106131076815
predicting model...
val--58/100 [10/1090] acc: 0.794921875
val--58/100 [20/1090] acc: 0.7970703125
val--58/100 [30/1090] acc: 0.7963541666666667
val--58/100 [40/1090] acc: 0.79716796875
val--58/100 [50/1090] acc: 0.79609375
val--58/100 [60/1090] acc: 0.7947916666666667
val--58/100 [70/1090] acc: 0.7950892857142857
val--58/100 [80/1090] acc: 0.793798828125
val--58/100 [90/1090] acc: 0.7938802083333333
val--58/100 [100/1090] acc: 0.7950390625
val--58/100 [110/1090] acc: 0.7956676136363636
val--58/100 [120/1090] acc: 0.79521484375
val--58/100 [130/1090] acc: 0.7965144230769231
val--58/100 [140/1090] acc: 0.7962890625
val--58/100 [150/1090] acc: 0.7962239583333334
val--58/100 [160/1090] acc: 0.796337890625
val--58/100 [170/1090] acc: 0.7963005514705882
val--58/100 [180/1090] acc: 0.79609375
val--58/100 [190/1090] acc: 0.7968544407894737
val--58/100 [200/1090] acc: 0.7970703125
val--58/100 [210/1090] acc: 0.7972842261904762
val--58/100 [220/1090] acc: 0.796484375
val--58/100 [230/1090] acc: 0.7971807065217391
val--58/100 [240/1090] acc: 0.796875
val--58/100 [250/1090] acc: 0.796984375
val--58/100 [260/1090] acc: 0.7971454326923076
val--58/100 [270/1090] acc: 0.7972945601851852
val--58/100 [280/1090] acc: 0.7971819196428571
val--58/100 [290/1090] acc: 0.7970231681034483
val--58/100 [300/1090] acc: 0.79703125
val--58/100 [310/1090] acc: 0.7968245967741936
val--58/100 [320/1090] acc: 0.79710693359375
val--58/100 [330/1090] acc: 0.7973248106060606
val--58/100 [340/1090] acc: 0.7975298713235294
val--58/100 [350/1090] acc: 0.79765625
val--58/100 [360/1090] acc: 0.7975477430555555
val--58/100 [370/1090] acc: 0.79765625
val--58/100 [380/1090] acc: 0.7975637335526315
val--58/100 [390/1090] acc: 0.7974559294871795
val--58/100 [400/1090] acc: 0.797431640625
val--58/100 [410/1090] acc: 0.7975705030487805
val--58/100 [420/1090] acc: 0.7975260416666666
val--58/100 [430/1090] acc: 0.7973382994186047
val--58/100 [440/1090] acc: 0.7973987926136363
val--58/100 [450/1090] acc: 0.7972829861111111
val--58/100 [460/1090] acc: 0.7971891983695653
val--58/100 [470/1090] acc: 0.7971160239361702
val--58/100 [480/1090] acc: 0.797119140625
val--58/100 [490/1090] acc: 0.797233737244898
val--58/100 [500/1090] acc: 0.797359375
val--58/100 [510/1090] acc: 0.7971890318627451
val--58/100 [520/1090] acc: 0.7974609375
val--58/100 [530/1090] acc: 0.7974498820754717
val--58/100 [540/1090] acc: 0.7975622106481481
val--58/100 [550/1090] acc: 0.7974502840909091
val--58/100 [560/1090] acc: 0.797265625
val--58/100 [570/1090] acc: 0.7970531798245614
val--58/100 [580/1090] acc: 0.7970231681034483
val--58/100 [590/1090] acc: 0.7971001059322034
val--58/100 [600/1090] acc: 0.7971744791666666
val--58/100 [610/1090] acc: 0.7970543032786885
val--58/100 [620/1090] acc: 0.7970262096774193
val--58/100 [630/1090] acc: 0.7972470238095238
val--58/100 [640/1090] acc: 0.7974609375
val--58/100 [650/1090] acc: 0.7974879807692308
val--58/100 [660/1090] acc: 0.7974076704545454
val--58/100 [670/1090] acc: 0.7971082089552238
val--58/100 [680/1090] acc: 0.7970071231617647
val--58/100 [690/1090] acc: 0.7971127717391304
val--58/100 [700/1090] acc: 0.7971595982142857
val--58/100 [710/1090] acc: 0.7969960387323943
val--58/100 [720/1090] acc: 0.7968315972222222
val--58/100 [730/1090] acc: 0.7967786815068493
val--58/100 [740/1090] acc: 0.7967113597972973
val--58/100 [750/1090] acc: 0.7967552083333334
val--58/100 [760/1090] acc: 0.7968184621710527
val--58/100 [770/1090] acc: 0.7967989042207793
val--58/100 [780/1090] acc: 0.7966796875
val--58/100 [790/1090] acc: 0.7966623813291139
val--58/100 [800/1090] acc: 0.7968798828125
val--58/100 [810/1090] acc: 0.7969376929012346
val--58/100 [820/1090] acc: 0.7970607850609757
val--58/100 [830/1090] acc: 0.797129141566265
val--58/100 [840/1090] acc: 0.7970935639880953
val--58/100 [850/1090] acc: 0.7971737132352941
val--58/100 [860/1090] acc: 0.7974109738372093
val--58/100 [870/1090] acc: 0.7972880747126436
val--58/100 [880/1090] acc: 0.7972922585227272
val--58/100 [890/1090] acc: 0.7974499648876404
val--58/100 [900/1090] acc: 0.7974565972222222
val--58/100 [910/1090] acc: 0.7974416208791208
val--58/100 [920/1090] acc: 0.7974524456521739
val--58/100 [930/1090] acc: 0.7975470430107527
val--58/100 [940/1090] acc: 0.7975440492021276
val--58/100 [950/1090] acc: 0.7974547697368422
val--58/100 [960/1090] acc: 0.7973714192708333
val--58/100 [970/1090] acc: 0.7973340850515463
val--58/100 [980/1090] acc: 0.7973533163265306
val--58/100 [990/1090] acc: 0.797238005050505
val--58/100 [1000/1090] acc: 0.79713671875
val--58/100 [1010/1090] acc: 0.7969678217821782
val--58/100 [1020/1090] acc: 0.7970128676470588
val--58/100 [1030/1090] acc: 0.7970001516990292
val--58/100 [1040/1090] acc: 0.7970027043269231
val--58/100 [1050/1090] acc: 0.7970014880952381
val--58/100 [1060/1090] acc: 0.7969855542452831
val--58/100 [1070/1090] acc: 0.7969845210280374
val--58/100 [1080/1090] acc: 0.7969437210648148
val--58/100 [1090/1090] acc: 0.7967854071100917
epoch= 58, accuracy= 0.796785, rmse= 0.376622, auc= 0.856666
train--59/100 [9/1090] loss: 0.38848757147789004
train--59/100 [19/1090] loss: 0.444034019112587
train--59/100 [29/1090] loss: 0.4405790358781815
train--59/100 [39/1090] loss: 0.4440699279308319
train--59/100 [49/1090] loss: 0.440576633810997
train--59/100 [59/1090] loss: 0.45095003843307496
train--59/100 [69/1090] loss: 0.4502697676420212
train--59/100 [79/1090] loss: 0.4201406478881836
train--59/100 [89/1090] loss: 0.4508542358875275
train--59/100 [99/1090] loss: 0.41292132139205934
train--59/100 [109/1090] loss: 0.42317443788051606
train--59/100 [119/1090] loss: 0.43262702226638794
train--59/100 [129/1090] loss: 0.4178155094385147
train--59/100 [139/1090] loss: 0.4392849326133728
train--59/100 [149/1090] loss: 0.42467206418514253
train--59/100 [159/1090] loss: 0.4148176282644272
train--59/100 [169/1090] loss: 0.45446673035621643
train--59/100 [179/1090] loss: 0.4474588006734848
train--59/100 [189/1090] loss: 0.4421568691730499
train--59/100 [199/1090] loss: 0.4413107126951218
train--59/100 [209/1090] loss: 0.4371545612812042
train--59/100 [219/1090] loss: 0.4445882886648178
train--59/100 [229/1090] loss: 0.47097470462322233
train--59/100 [239/1090] loss: 0.44260959029197694
train--59/100 [249/1090] loss: 0.4397147983312607
train--59/100 [259/1090] loss: 0.4486899197101593
train--59/100 [269/1090] loss: 0.44047110080718993
train--59/100 [279/1090] loss: 0.45456814765930176
train--59/100 [289/1090] loss: 0.4253609746694565
train--59/100 [299/1090] loss: 0.456197127699852
train--59/100 [309/1090] loss: 0.4469560980796814
train--59/100 [319/1090] loss: 0.4563161313533783
train--59/100 [329/1090] loss: 0.4397246718406677
train--59/100 [339/1090] loss: 0.4273844212293625
train--59/100 [349/1090] loss: 0.4556919068098068
train--59/100 [359/1090] loss: 0.45230581164360045
train--59/100 [369/1090] loss: 0.4189219087362289
train--59/100 [379/1090] loss: 0.4418244242668152
train--59/100 [389/1090] loss: 0.43474813401699064
train--59/100 [399/1090] loss: 0.44377208948135377
train--59/100 [409/1090] loss: 0.44345684349536896
train--59/100 [419/1090] loss: 0.43871475756168365
train--59/100 [429/1090] loss: 0.43519395887851714
train--59/100 [439/1090] loss: 0.42825218439102175
train--59/100 [449/1090] loss: 0.45131032466888427
train--59/100 [459/1090] loss: 0.44125382602214813
train--59/100 [469/1090] loss: 0.4490794658660889
train--59/100 [479/1090] loss: 0.43005274832248686
train--59/100 [489/1090] loss: 0.4378624826669693
train--59/100 [499/1090] loss: 0.44399382174015045
train--59/100 [509/1090] loss: 0.44633824229240415
train--59/100 [519/1090] loss: 0.4394965797662735
train--59/100 [529/1090] loss: 0.4472513943910599
train--59/100 [539/1090] loss: 0.4473192781209946
train--59/100 [549/1090] loss: 0.4378502607345581
train--59/100 [559/1090] loss: 0.4209186673164368
train--59/100 [569/1090] loss: 0.4597303241491318
train--59/100 [579/1090] loss: 0.431458055973053
train--59/100 [589/1090] loss: 0.43933863937854767
train--59/100 [599/1090] loss: 0.4524421125650406
train--59/100 [609/1090] loss: 0.4190224468708038
train--59/100 [619/1090] loss: 0.4372302919626236
train--59/100 [629/1090] loss: 0.4420462787151337
train--59/100 [639/1090] loss: 0.45827527344226837
train--59/100 [649/1090] loss: 0.4494705945253372
train--59/100 [659/1090] loss: 0.4457582116127014
train--59/100 [669/1090] loss: 0.4540000379085541
train--59/100 [679/1090] loss: 0.4401103645563126
train--59/100 [689/1090] loss: 0.45868948101997375
train--59/100 [699/1090] loss: 0.4616952985525131
train--59/100 [709/1090] loss: 0.44405790567398074
train--59/100 [719/1090] loss: 0.4290222853422165
train--59/100 [729/1090] loss: 0.4305638462305069
train--59/100 [739/1090] loss: 0.4366310328245163
train--59/100 [749/1090] loss: 0.4400907278060913
train--59/100 [759/1090] loss: 0.44814868867397306
train--59/100 [769/1090] loss: 0.4375550806522369
train--59/100 [779/1090] loss: 0.45232572257518766
train--59/100 [789/1090] loss: 0.4542714625597
train--59/100 [799/1090] loss: 0.45154304802417755
train--59/100 [809/1090] loss: 0.44070363938808443
train--59/100 [819/1090] loss: 0.4494433283805847
train--59/100 [829/1090] loss: 0.4414048075675964
train--59/100 [839/1090] loss: 0.44271954894065857
train--59/100 [849/1090] loss: 0.45961669981479647
train--59/100 [859/1090] loss: 0.4455998867750168
train--59/100 [869/1090] loss: 0.4409269064664841
train--59/100 [879/1090] loss: 0.4458214282989502
train--59/100 [889/1090] loss: 0.43925821483135224
train--59/100 [899/1090] loss: 0.4547954171895981
train--59/100 [909/1090] loss: 0.4576563864946365
train--59/100 [919/1090] loss: 0.4440030694007874
train--59/100 [929/1090] loss: 0.4552016586065292
train--59/100 [939/1090] loss: 0.4294837564229965
train--59/100 [949/1090] loss: 0.43819411396980285
train--59/100 [959/1090] loss: 0.4395322144031525
train--59/100 [969/1090] loss: 0.43261014521121977
train--59/100 [979/1090] loss: 0.47500584125518797
train--59/100 [989/1090] loss: 0.43814387917518616
train--59/100 [999/1090] loss: 0.4341290593147278
train--59/100 [1009/1090] loss: 0.43203552067279816
train--59/100 [1019/1090] loss: 0.4527275025844574
train--59/100 [1029/1090] loss: 0.45799056589603426
train--59/100 [1039/1090] loss: 0.438799124956131
train--59/100 [1049/1090] loss: 0.45584059357643125
train--59/100 [1059/1090] loss: 0.44266612231731417
train--59/100 [1069/1090] loss: 0.4482175290584564
train--59/100 [1079/1090] loss: 0.46802369952201844
train--59/100 [1089/1090] loss: 0.4626269549131393
predicting model...
val--59/100 [10/1090] acc: 0.79921875
val--59/100 [20/1090] acc: 0.798046875
val--59/100 [30/1090] acc: 0.796875
val--59/100 [40/1090] acc: 0.79775390625
val--59/100 [50/1090] acc: 0.79640625
val--59/100 [60/1090] acc: 0.7952473958333334
val--59/100 [70/1090] acc: 0.7954241071428572
val--59/100 [80/1090] acc: 0.794140625
val--59/100 [90/1090] acc: 0.7942708333333334
val--59/100 [100/1090] acc: 0.795390625
val--59/100 [110/1090] acc: 0.7958806818181818
val--59/100 [120/1090] acc: 0.7954752604166667
val--59/100 [130/1090] acc: 0.7967247596153846
val--59/100 [140/1090] acc: 0.7967354910714286
val--59/100 [150/1090] acc: 0.796796875
val--59/100 [160/1090] acc: 0.796923828125
val--59/100 [170/1090] acc: 0.7966681985294117
val--59/100 [180/1090] acc: 0.7964409722222222
val--59/100 [190/1090] acc: 0.7971628289473685
val--59/100 [200/1090] acc: 0.79734375
val--59/100 [210/1090] acc: 0.7977120535714286
val--59/100 [220/1090] acc: 0.7970170454545454
val--59/100 [230/1090] acc: 0.7974184782608695
val--59/100 [240/1090] acc: 0.7971354166666667
val--59/100 [250/1090] acc: 0.797171875
val--59/100 [260/1090] acc: 0.7972355769230769
val--59/100 [270/1090] acc: 0.7975983796296297
val--59/100 [280/1090] acc: 0.7975027901785714
val--59/100 [290/1090] acc: 0.7974272629310345
val--59/100 [300/1090] acc: 0.7975260416666666
val--59/100 [310/1090] acc: 0.7973538306451613
val--59/100 [320/1090] acc: 0.79754638671875
val--59/100 [330/1090] acc: 0.7977746212121212
val--59/100 [340/1090] acc: 0.7978400735294118
val--59/100 [350/1090] acc: 0.7979129464285715
val--59/100 [360/1090] acc: 0.7978624131944444
val--59/100 [370/1090] acc: 0.7979096283783784
val--59/100 [380/1090] acc: 0.7978926809210526
val--59/100 [390/1090] acc: 0.7977964743589744
val--59/100 [400/1090] acc: 0.7978125
val--59/100 [410/1090] acc: 0.7979801829268293
val--59/100 [420/1090] acc: 0.7979445684523809
val--59/100 [430/1090] acc: 0.7977107558139535
val--59/100 [440/1090] acc: 0.7977183948863636
val--59/100 [450/1090] acc: 0.7976215277777777
val--59/100 [460/1090] acc: 0.7975033967391304
val--59/100 [470/1090] acc: 0.7973902925531915
val--59/100 [480/1090] acc: 0.7973795572916667
val--59/100 [490/1090] acc: 0.7975207270408163
val--59/100 [500/1090] acc: 0.7976328125
val--59/100 [510/1090] acc: 0.7975643382352942
val--59/100 [520/1090] acc: 0.7978140024038461
val--59/100 [530/1090] acc: 0.7977078419811321
val--59/100 [540/1090] acc: 0.7978298611111111
val--59/100 [550/1090] acc: 0.7976988636363637
val--59/100 [560/1090] acc: 0.797509765625
val--59/100 [570/1090] acc: 0.7972450657894737
val--59/100 [580/1090] acc: 0.7972252155172413
val--59/100 [590/1090] acc: 0.7972854872881356
val--59/100 [600/1090] acc: 0.7973502604166667
val--59/100 [610/1090] acc: 0.7972592213114754
val--59/100 [620/1090] acc: 0.7972089213709678
val--59/100 [630/1090] acc: 0.7974330357142857
val--59/100 [640/1090] acc: 0.797607421875
val--59/100 [650/1090] acc: 0.7976021634615384
val--59/100 [660/1090] acc: 0.7974905303030303
val--59/100 [670/1090] acc: 0.7972539645522388
val--59/100 [680/1090] acc: 0.7971047794117647
val--59/100 [690/1090] acc: 0.7972033514492753
val--59/100 [700/1090] acc: 0.7972823660714285
val--59/100 [710/1090] acc: 0.7971170774647888
val--59/100 [720/1090] acc: 0.79697265625
val--59/100 [730/1090] acc: 0.7969124571917808
val--59/100 [740/1090] acc: 0.7968591638513514
val--59/100 [750/1090] acc: 0.7969427083333334
val--59/100 [760/1090] acc: 0.7970137746710526
val--59/100 [770/1090] acc: 0.7969308035714285
val--59/100 [780/1090] acc: 0.7968599759615385
val--59/100 [790/1090] acc: 0.7968700553797469
val--59/100 [800/1090] acc: 0.7970947265625
val--59/100 [810/1090] acc: 0.797145061728395
val--59/100 [820/1090] acc: 0.7972370426829268
val--59/100 [830/1090] acc: 0.7972797439759036
val--59/100 [840/1090] acc: 0.7972470238095238
val--59/100 [850/1090] acc: 0.7972931985294117
val--59/100 [860/1090] acc: 0.797592659883721
val--59/100 [870/1090] acc: 0.7974721623563218
val--59/100 [880/1090] acc: 0.7974476207386364
val--59/100 [890/1090] acc: 0.7975948033707865
val--59/100 [900/1090] acc: 0.7975998263888889
val--59/100 [910/1090] acc: 0.7975832760989011
val--59/100 [920/1090] acc: 0.7976265285326087
val--59/100 [930/1090] acc: 0.7977360551075269
val--59/100 [940/1090] acc: 0.7977642952127659
val--59/100 [950/1090] acc: 0.7976685855263158
val--59/100 [960/1090] acc: 0.7975504557291667
val--59/100 [970/1090] acc: 0.7975032216494845
val--59/100 [980/1090] acc: 0.7975526147959183
val--59/100 [990/1090] acc: 0.7974668560606061
val--59/100 [1000/1090] acc: 0.797390625
val--59/100 [1010/1090] acc: 0.7971998762376238
val--59/100 [1020/1090] acc: 0.7972388174019608
val--59/100 [1030/1090] acc: 0.7972239077669903
val--59/100 [1040/1090] acc: 0.7972092848557693
val--59/100 [1050/1090] acc: 0.7972470238095238
val--59/100 [1060/1090] acc: 0.7971882370283019
val--59/100 [1070/1090] acc: 0.7971670560747663
val--59/100 [1080/1090] acc: 0.7971137152777777
val--59/100 [1090/1090] acc: 0.7969430905963303
epoch= 59, accuracy= 0.796943, rmse= 0.376551, auc= 0.856800
train--60/100 [9/1090] loss: 0.40583357214927673
train--60/100 [19/1090] loss: 0.43870499432086946
train--60/100 [29/1090] loss: 0.4325256168842316
train--60/100 [39/1090] loss: 0.4422293394804001
train--60/100 [49/1090] loss: 0.45896124839782715
train--60/100 [59/1090] loss: 0.4344883143901825
train--60/100 [69/1090] loss: 0.42990395724773406
train--60/100 [79/1090] loss: 0.44612585604190824
train--60/100 [89/1090] loss: 0.4240214079618454
train--60/100 [99/1090] loss: 0.4388315349817276
train--60/100 [109/1090] loss: 0.4421732097864151
train--60/100 [119/1090] loss: 0.4553197294473648
train--60/100 [129/1090] loss: 0.44467059671878817
train--60/100 [139/1090] loss: 0.4480085551738739
train--60/100 [149/1090] loss: 0.4277463674545288
train--60/100 [159/1090] loss: 0.41964068412780764
train--60/100 [169/1090] loss: 0.4243551790714264
train--60/100 [179/1090] loss: 0.44038287103176116
train--60/100 [189/1090] loss: 0.44419058263301847
train--60/100 [199/1090] loss: 0.4396858960390091
train--60/100 [209/1090] loss: 0.43310558795928955
train--60/100 [219/1090] loss: 0.4372782528400421
train--60/100 [229/1090] loss: 0.43923541307449343
train--60/100 [239/1090] loss: 0.4220211744308472
train--60/100 [249/1090] loss: 0.44280197024345397
train--60/100 [259/1090] loss: 0.4415390521287918
train--60/100 [269/1090] loss: 0.4406665235757828
train--60/100 [279/1090] loss: 0.4390700846910477
train--60/100 [289/1090] loss: 0.43932859897613524
train--60/100 [299/1090] loss: 0.43614567816257477
train--60/100 [309/1090] loss: 0.4322450399398804
train--60/100 [319/1090] loss: 0.42705747187137605
train--60/100 [329/1090] loss: 0.4342857778072357
train--60/100 [339/1090] loss: 0.43693157434463503
train--60/100 [349/1090] loss: 0.43442944884300233
train--60/100 [359/1090] loss: 0.4202280670404434
train--60/100 [369/1090] loss: 0.42221956253051757
train--60/100 [379/1090] loss: 0.4511783093214035
train--60/100 [389/1090] loss: 0.4474512606859207
train--60/100 [399/1090] loss: 0.4570463627576828
train--60/100 [409/1090] loss: 0.4300582349300385
train--60/100 [419/1090] loss: 0.4359644949436188
train--60/100 [429/1090] loss: 0.4522949308156967
train--60/100 [439/1090] loss: 0.4554094344377518
train--60/100 [449/1090] loss: 0.436020290851593
train--60/100 [459/1090] loss: 0.43572171628475187
train--60/100 [469/1090] loss: 0.4563770920038223
train--60/100 [479/1090] loss: 0.4514216661453247
train--60/100 [489/1090] loss: 0.44225246012210845
train--60/100 [499/1090] loss: 0.45601692199707033
train--60/100 [509/1090] loss: 0.45360271632671356
train--60/100 [519/1090] loss: 0.4501491546630859
train--60/100 [529/1090] loss: 0.4456507176160812
train--60/100 [539/1090] loss: 0.4433795571327209
train--60/100 [549/1090] loss: 0.4412018060684204
train--60/100 [559/1090] loss: 0.45274138152599336
train--60/100 [569/1090] loss: 0.4587411195039749
train--60/100 [579/1090] loss: 0.4556967169046402
train--60/100 [589/1090] loss: 0.4541304260492325
train--60/100 [599/1090] loss: 0.44834176301956175
train--60/100 [609/1090] loss: 0.44052977561950685
train--60/100 [619/1090] loss: 0.44397286176681516
train--60/100 [629/1090] loss: 0.43895999789237977
train--60/100 [639/1090] loss: 0.4495897710323334
train--60/100 [649/1090] loss: 0.46033958792686464
train--60/100 [659/1090] loss: 0.4195821315050125
train--60/100 [669/1090] loss: 0.4277491420507431
train--60/100 [679/1090] loss: 0.42861065566539763
train--60/100 [689/1090] loss: 0.45431760549545286
train--60/100 [699/1090] loss: 0.43805802166461943
train--60/100 [709/1090] loss: 0.44868893921375275
train--60/100 [719/1090] loss: 0.4356251239776611
train--60/100 [729/1090] loss: 0.4486579805612564
train--60/100 [739/1090] loss: 0.43300824165344237
train--60/100 [749/1090] loss: 0.4271728128194809
train--60/100 [759/1090] loss: 0.4416224420070648
train--60/100 [769/1090] loss: 0.4630561798810959
train--60/100 [779/1090] loss: 0.4400070160627365
train--60/100 [789/1090] loss: 0.42605639100074766
train--60/100 [799/1090] loss: 0.44850740730762484
train--60/100 [809/1090] loss: 0.4553057849407196
train--60/100 [819/1090] loss: 0.44717738032341003
train--60/100 [829/1090] loss: 0.4487133204936981
train--60/100 [839/1090] loss: 0.43732908070087434
train--60/100 [849/1090] loss: 0.4582828551530838
train--60/100 [859/1090] loss: 0.42946437895298006
train--60/100 [869/1090] loss: 0.44835483729839326
train--60/100 [879/1090] loss: 0.44020808935165406
train--60/100 [889/1090] loss: 0.4505320131778717
train--60/100 [899/1090] loss: 0.43455676436424256
train--60/100 [909/1090] loss: 0.43980041742324827
train--60/100 [919/1090] loss: 0.44263474345207215
train--60/100 [929/1090] loss: 0.4314757317304611
train--60/100 [939/1090] loss: 0.45088785886764526
train--60/100 [949/1090] loss: 0.4332372397184372
train--60/100 [959/1090] loss: 0.44898570477962496
train--60/100 [969/1090] loss: 0.42895447909832
train--60/100 [979/1090] loss: 0.4605367541313171
train--60/100 [989/1090] loss: 0.46278500854969024
train--60/100 [999/1090] loss: 0.44964366853237153
train--60/100 [1009/1090] loss: 0.44894370436668396
train--60/100 [1019/1090] loss: 0.4556449711322784
train--60/100 [1029/1090] loss: 0.44596617221832274
train--60/100 [1039/1090] loss: 0.4522024571895599
train--60/100 [1049/1090] loss: 0.4486304849386215
train--60/100 [1059/1090] loss: 0.45068480670452116
train--60/100 [1069/1090] loss: 0.4542692393064499
train--60/100 [1079/1090] loss: 0.4529556125402451
train--60/100 [1089/1090] loss: 0.45109965801239016
predicting model...
val--60/100 [10/1090] acc: 0.79765625
val--60/100 [20/1090] acc: 0.7978515625
val--60/100 [30/1090] acc: 0.7966145833333333
val--60/100 [40/1090] acc: 0.796875
val--60/100 [50/1090] acc: 0.7953125
val--60/100 [60/1090] acc: 0.7943359375
val--60/100 [70/1090] acc: 0.7946428571428571
val--60/100 [80/1090] acc: 0.793896484375
val--60/100 [90/1090] acc: 0.7938802083333333
val--60/100 [100/1090] acc: 0.7950390625
val--60/100 [110/1090] acc: 0.7956676136363636
val--60/100 [120/1090] acc: 0.79541015625
val--60/100 [130/1090] acc: 0.7966947115384615
val--60/100 [140/1090] acc: 0.7967075892857143
val--60/100 [150/1090] acc: 0.7967447916666667
val--60/100 [160/1090] acc: 0.796923828125
val--60/100 [170/1090] acc: 0.7966681985294117
val--60/100 [180/1090] acc: 0.7964626736111111
val--60/100 [190/1090] acc: 0.7971011513157895
val--60/100 [200/1090] acc: 0.7973828125
val--60/100 [210/1090] acc: 0.797749255952381
val--60/100 [220/1090] acc: 0.7968927556818182
val--60/100 [230/1090] acc: 0.7974354619565217
val--60/100 [240/1090] acc: 0.7972005208333334
val--60/100 [250/1090] acc: 0.797296875
val--60/100 [260/1090] acc: 0.7972956730769231
val--60/100 [270/1090] acc: 0.7975983796296297
val--60/100 [280/1090] acc: 0.7974609375
val--60/100 [290/1090] acc: 0.7974407327586207
val--60/100 [300/1090] acc: 0.7975651041666667
val--60/100 [310/1090] acc: 0.797429435483871
val--60/100 [320/1090] acc: 0.79757080078125
val--60/100 [330/1090] acc: 0.7977391098484848
val--60/100 [340/1090] acc: 0.7978975183823529
val--60/100 [350/1090] acc: 0.7980245535714285
val--60/100 [360/1090] acc: 0.7979383680555555
val--60/100 [370/1090] acc: 0.798046875
val--60/100 [380/1090] acc: 0.7979543585526315
val--60/100 [390/1090] acc: 0.7978465544871794
val--60/100 [400/1090] acc: 0.797802734375
val--60/100 [410/1090] acc: 0.7979611280487805
val--60/100 [420/1090] acc: 0.7978701636904761
val--60/100 [430/1090] acc: 0.7976744186046512
val--60/100 [440/1090] acc: 0.7977627840909091
val--60/100 [450/1090] acc: 0.7975868055555555
val--60/100 [460/1090] acc: 0.7974864130434782
val--60/100 [470/1090] acc: 0.797373670212766
val--60/100 [480/1090] acc: 0.797412109375
val--60/100 [490/1090] acc: 0.7975366709183673
val--60/100 [500/1090] acc: 0.7976015625
val--60/100 [510/1090] acc: 0.7974264705882353
val--60/100 [520/1090] acc: 0.7977088341346154
val--60/100 [530/1090] acc: 0.7976415094339623
val--60/100 [540/1090] acc: 0.7977358217592593
val--60/100 [550/1090] acc: 0.7976207386363636
val--60/100 [560/1090] acc: 0.7974469866071429
val--60/100 [570/1090] acc: 0.7972245065789474
val--60/100 [580/1090] acc: 0.7972386853448276
val--60/100 [590/1090] acc: 0.7972788665254237
val--60/100 [600/1090] acc: 0.7973567708333333
val--60/100 [610/1090] acc: 0.7972912397540983
val--60/100 [620/1090] acc: 0.7972089213709678
val--60/100 [630/1090] acc: 0.7974702380952381
val--60/100 [640/1090] acc: 0.797650146484375
val--60/100 [650/1090] acc: 0.7976802884615385
val--60/100 [660/1090] acc: 0.7976029829545455
val--60/100 [670/1090] acc: 0.7973414179104478
val--60/100 [680/1090] acc: 0.7972541360294118
val--60/100 [690/1090] acc: 0.7974071557971014
val--60/100 [700/1090] acc: 0.7974497767857143
val--60/100 [710/1090] acc: 0.7973481514084507
val--60/100 [720/1090] acc: 0.7972005208333334
val--60/100 [730/1090] acc: 0.7971211472602739
val--60/100 [740/1090] acc: 0.7970597550675675
val--60/100 [750/1090] acc: 0.7970885416666667
val--60/100 [760/1090] acc: 0.7971833881578947
val--60/100 [770/1090] acc: 0.7971235795454545
val--60/100 [780/1090] acc: 0.797090344551282
val--60/100 [790/1090] acc: 0.7971222310126582
val--60/100 [800/1090] acc: 0.7973583984375
val--60/100 [810/1090] acc: 0.7974344135802469
val--60/100 [820/1090] acc: 0.7975466844512196
val--60/100 [830/1090] acc: 0.797609186746988
val--60/100 [840/1090] acc: 0.7975818452380953
val--60/100 [850/1090] acc: 0.7976056985294118
val--60/100 [860/1090] acc: 0.7978833575581395
val--60/100 [870/1090] acc: 0.7977640086206896
val--60/100 [880/1090] acc: 0.7977761008522727
val--60/100 [890/1090] acc: 0.7979283707865169
val--60/100 [900/1090] acc: 0.7979210069444445
val--60/100 [910/1090] acc: 0.7979138049450549
val--60/100 [920/1090] acc: 0.7979110054347827
val--60/100 [930/1090] acc: 0.7979964717741935
val--60/100 [940/1090] acc: 0.7980094747340426
val--60/100 [950/1090] acc: 0.7979111842105263
val--60/100 [960/1090] acc: 0.79781494140625
val--60/100 [970/1090] acc: 0.7977770618556701
val--60/100 [980/1090] acc: 0.7977997448979591
val--60/100 [990/1090] acc: 0.797695707070707
val--60/100 [1000/1090] acc: 0.79759765625
val--60/100 [1010/1090] acc: 0.7974241955445545
val--60/100 [1020/1090] acc: 0.7975183823529411
val--60/100 [1030/1090] acc: 0.7975235133495145
val--60/100 [1040/1090] acc: 0.797528545673077
val--60/100 [1050/1090] acc: 0.7975818452380953
val--60/100 [1060/1090] acc: 0.7975420106132075
val--60/100 [1070/1090] acc: 0.7975321261682243
val--60/100 [1080/1090] acc: 0.797511574074074
val--60/100 [1090/1090] acc: 0.7973480504587156
epoch= 60, accuracy= 0.797348, rmse= 0.376544, auc= 0.856909
train--61/100 [9/1090] loss: 0.39008053839206697
train--61/100 [19/1090] loss: 0.44199334979057314
train--61/100 [29/1090] loss: 0.43298623859882357
train--61/100 [39/1090] loss: 0.43369066417217256
train--61/100 [49/1090] loss: 0.4454998254776001
train--61/100 [59/1090] loss: 0.4351334273815155
train--61/100 [69/1090] loss: 0.44381132125854494
train--61/100 [79/1090] loss: 0.43595688343048095
train--61/100 [89/1090] loss: 0.4221153289079666
train--61/100 [99/1090] loss: 0.4484690070152283
train--61/100 [109/1090] loss: 0.4332108795642853
train--61/100 [119/1090] loss: 0.4435757786035538
train--61/100 [129/1090] loss: 0.4323499798774719
train--61/100 [139/1090] loss: 0.4453552454710007
train--61/100 [149/1090] loss: 0.438289201259613
train--61/100 [159/1090] loss: 0.440425318479538
train--61/100 [169/1090] loss: 0.4468336313962936
train--61/100 [179/1090] loss: 0.4335166960954666
train--61/100 [189/1090] loss: 0.4341630071401596
train--61/100 [199/1090] loss: 0.4452997803688049
train--61/100 [209/1090] loss: 0.4507569521665573
train--61/100 [219/1090] loss: 0.4540843665599823
train--61/100 [229/1090] loss: 0.4513222336769104
train--61/100 [239/1090] loss: 0.42603872120380404
train--61/100 [249/1090] loss: 0.4423642992973328
train--61/100 [259/1090] loss: 0.43492157459259034
train--61/100 [269/1090] loss: 0.4483516365289688
train--61/100 [279/1090] loss: 0.43586359918117523
train--61/100 [289/1090] loss: 0.4336833477020264
train--61/100 [299/1090] loss: 0.4418812096118927
train--61/100 [309/1090] loss: 0.4325474888086319
train--61/100 [319/1090] loss: 0.44681339859962466
train--61/100 [329/1090] loss: 0.4380578577518463
train--61/100 [339/1090] loss: 0.43483811616897583
train--61/100 [349/1090] loss: 0.44521743953228
train--61/100 [359/1090] loss: 0.4364029854536057
train--61/100 [369/1090] loss: 0.44368568658828733
train--61/100 [379/1090] loss: 0.4233388781547546
train--61/100 [389/1090] loss: 0.4687323808670044
train--61/100 [399/1090] loss: 0.4358206748962402
train--61/100 [409/1090] loss: 0.4444903552532196
train--61/100 [419/1090] loss: 0.45571786165237427
train--61/100 [429/1090] loss: 0.4326528936624527
train--61/100 [439/1090] loss: 0.4519211620092392
train--61/100 [449/1090] loss: 0.43251295387744904
train--61/100 [459/1090] loss: 0.4371896296739578
train--61/100 [469/1090] loss: 0.4417932599782944
train--61/100 [479/1090] loss: 0.45473356544971466
train--61/100 [489/1090] loss: 0.4363206446170807
train--61/100 [499/1090] loss: 0.4426329553127289
train--61/100 [509/1090] loss: 0.4502765715122223
train--61/100 [519/1090] loss: 0.4368554174900055
train--61/100 [529/1090] loss: 0.4454303324222565
train--61/100 [539/1090] loss: 0.43577572107315066
train--61/100 [549/1090] loss: 0.4358276426792145
train--61/100 [559/1090] loss: 0.4380043148994446
train--61/100 [569/1090] loss: 0.4472171276807785
train--61/100 [579/1090] loss: 0.43224802017211916
train--61/100 [589/1090] loss: 0.4541772693395615
train--61/100 [599/1090] loss: 0.4161789000034332
train--61/100 [609/1090] loss: 0.44876236021518706
train--61/100 [619/1090] loss: 0.4608813226222992
train--61/100 [629/1090] loss: 0.4464453011751175
train--61/100 [639/1090] loss: 0.4358188986778259
train--61/100 [649/1090] loss: 0.4513328015804291
train--61/100 [659/1090] loss: 0.44508196413517
train--61/100 [669/1090] loss: 0.44092174172401427
train--61/100 [679/1090] loss: 0.43960308134555814
train--61/100 [689/1090] loss: 0.42319234013557433
train--61/100 [699/1090] loss: 0.45451645851135253
train--61/100 [709/1090] loss: 0.4477889597415924
train--61/100 [719/1090] loss: 0.4425778776407242
train--61/100 [729/1090] loss: 0.43556753396987913
train--61/100 [739/1090] loss: 0.45539061427116395
train--61/100 [749/1090] loss: 0.45273619294166567
train--61/100 [759/1090] loss: 0.4447938174009323
train--61/100 [769/1090] loss: 0.4513875424861908
train--61/100 [779/1090] loss: 0.43369846045970917
train--61/100 [789/1090] loss: 0.46007299721240996
train--61/100 [799/1090] loss: 0.4342916578054428
train--61/100 [809/1090] loss: 0.46471400260925294
train--61/100 [819/1090] loss: 0.44162437617778777
train--61/100 [829/1090] loss: 0.4436453700065613
train--61/100 [839/1090] loss: 0.4485520660877228
train--61/100 [849/1090] loss: 0.4520833700895309
train--61/100 [859/1090] loss: 0.4340897262096405
train--61/100 [869/1090] loss: 0.4255580633878708
train--61/100 [879/1090] loss: 0.44058787226676943
train--61/100 [889/1090] loss: 0.43621848821640014
train--61/100 [899/1090] loss: 0.44792607724666594
train--61/100 [909/1090] loss: 0.4529013246297836
train--61/100 [919/1090] loss: 0.4432741284370422
train--61/100 [929/1090] loss: 0.4381412923336029
train--61/100 [939/1090] loss: 0.4611679196357727
train--61/100 [949/1090] loss: 0.45073032677173613
train--61/100 [959/1090] loss: 0.4394123286008835
train--61/100 [969/1090] loss: 0.4401512682437897
train--61/100 [979/1090] loss: 0.45598456263542175
train--61/100 [989/1090] loss: 0.4265607923269272
train--61/100 [999/1090] loss: 0.455596050620079
train--61/100 [1009/1090] loss: 0.44155292510986327
train--61/100 [1019/1090] loss: 0.4489646524190903
train--61/100 [1029/1090] loss: 0.45582098960876466
train--61/100 [1039/1090] loss: 0.45460085570812225
train--61/100 [1049/1090] loss: 0.4299772590398788
train--61/100 [1059/1090] loss: 0.4304970890283585
train--61/100 [1069/1090] loss: 0.4432180732488632
train--61/100 [1079/1090] loss: 0.45126386284828185
train--61/100 [1089/1090] loss: 0.4570830136537552
predicting model...
val--61/100 [10/1090] acc: 0.797265625
val--61/100 [20/1090] acc: 0.7966796875
val--61/100 [30/1090] acc: 0.796484375
val--61/100 [40/1090] acc: 0.79677734375
val--61/100 [50/1090] acc: 0.795625
val--61/100 [60/1090] acc: 0.7947916666666667
val--61/100 [70/1090] acc: 0.7952566964285714
val--61/100 [80/1090] acc: 0.7943359375
val--61/100 [90/1090] acc: 0.7949652777777778
val--61/100 [100/1090] acc: 0.796015625
val--61/100 [110/1090] acc: 0.7965553977272727
val--61/100 [120/1090] acc: 0.79609375
val--61/100 [130/1090] acc: 0.7973557692307692
val--61/100 [140/1090] acc: 0.7972377232142858
val--61/100 [150/1090] acc: 0.797109375
val--61/100 [160/1090] acc: 0.797265625
val--61/100 [170/1090] acc: 0.7970358455882353
val--61/100 [180/1090] acc: 0.7967447916666667
val--61/100 [190/1090] acc: 0.7974917763157895
val--61/100 [200/1090] acc: 0.7976953125
val--61/100 [210/1090] acc: 0.798046875
val--61/100 [220/1090] acc: 0.7971413352272727
val--61/100 [230/1090] acc: 0.7975883152173913
val--61/100 [240/1090] acc: 0.7972330729166667
val--61/100 [250/1090] acc: 0.79728125
val--61/100 [260/1090] acc: 0.7973557692307692
val--61/100 [270/1090] acc: 0.7976996527777778
val--61/100 [280/1090] acc: 0.7974469866071429
val--61/100 [290/1090] acc: 0.7974137931034483
val--61/100 [300/1090] acc: 0.7975520833333334
val--61/100 [310/1090] acc: 0.7973790322580645
val--61/100 [320/1090] acc: 0.797509765625
val--61/100 [330/1090] acc: 0.79765625
val--61/100 [340/1090] acc: 0.7977711397058823
val--61/100 [350/1090] acc: 0.7979017857142857
val--61/100 [360/1090] acc: 0.7977756076388889
val--61/100 [370/1090] acc: 0.7978462837837837
val--61/100 [380/1090] acc: 0.7977384868421052
val--61/100 [390/1090] acc: 0.797676282051282
val--61/100 [400/1090] acc: 0.797626953125
val--61/100 [410/1090] acc: 0.7978086890243903
val--61/100 [420/1090] acc: 0.7977585565476191
val--61/100 [430/1090] acc: 0.7975654069767442
val--61/100 [440/1090] acc: 0.7976296164772727
val--61/100 [450/1090] acc: 0.7975173611111112
val--61/100 [460/1090] acc: 0.7973845108695652
val--61/100 [470/1090] acc: 0.7972905585106383
val--61/100 [480/1090] acc: 0.7973307291666667
val--61/100 [490/1090] acc: 0.7974968112244898
val--61/100 [500/1090] acc: 0.7975859375
val--61/100 [510/1090] acc: 0.7974494485294118
val--61/100 [520/1090] acc: 0.7976712740384615
val--61/100 [530/1090] acc: 0.7976857311320755
val--61/100 [540/1090] acc: 0.7978226273148148
val--61/100 [550/1090] acc: 0.7977272727272727
val--61/100 [560/1090] acc: 0.7975306919642857
val--61/100 [570/1090] acc: 0.7972793311403509
val--61/100 [580/1090] acc: 0.7972858297413793
val--61/100 [590/1090] acc: 0.7973252118644067
val--61/100 [600/1090] acc: 0.7973502604166667
val--61/100 [610/1090] acc: 0.7972528176229509
val--61/100 [620/1090] acc: 0.7971711189516129
val--61/100 [630/1090] acc: 0.7974454365079365
val--61/100 [640/1090] acc: 0.7976318359375
val--61/100 [650/1090] acc: 0.7975961538461539
val--61/100 [660/1090] acc: 0.7975437973484848
val--61/100 [670/1090] acc: 0.7972481343283582
val--61/100 [680/1090] acc: 0.7971335018382353
val--61/100 [690/1090] acc: 0.7972826086956522
val--61/100 [700/1090] acc: 0.7973716517857142
val--61/100 [710/1090] acc: 0.7972326144366197
val--61/100 [720/1090] acc: 0.7970648871527778
val--61/100 [730/1090] acc: 0.7969820205479452
val--61/100 [740/1090] acc: 0.7969647381756757
val--61/100 [750/1090] acc: 0.797
val--61/100 [760/1090] acc: 0.7970960115131579
val--61/100 [770/1090] acc: 0.7970373376623376
val--61/100 [780/1090] acc: 0.7969551282051283
val--61/100 [790/1090] acc: 0.796993670886076
val--61/100 [800/1090] acc: 0.7972216796875
val--61/100 [810/1090] acc: 0.7972849151234568
val--61/100 [820/1090] acc: 0.7973799542682927
val--61/100 [830/1090] acc: 0.7974115210843373
val--61/100 [840/1090] acc: 0.7973958333333333
val--61/100 [850/1090] acc: 0.7974172794117647
val--61/100 [860/1090] acc: 0.7976789607558139
val--61/100 [870/1090] acc: 0.7975844109195402
val--61/100 [880/1090] acc: 0.797549715909091
val--61/100 [890/1090] acc: 0.7976738061797752
val--61/100 [900/1090] acc: 0.7976822916666667
val--61/100 [910/1090] acc: 0.7976820054945055
val--61/100 [920/1090] acc: 0.7977072010869565
val--61/100 [930/1090] acc: 0.797799059139785
val--61/100 [940/1090] acc: 0.7978100066489362
val--61/100 [950/1090] acc: 0.7977384868421052
val--61/100 [960/1090] acc: 0.79764404296875
val--61/100 [970/1090] acc: 0.7976240335051547
val--61/100 [980/1090] acc: 0.7976442920918367
val--61/100 [990/1090] acc: 0.7975418244949495
val--61/100 [1000/1090] acc: 0.7974921875
val--61/100 [1010/1090] acc: 0.7973120358910891
val--61/100 [1020/1090] acc: 0.7973728553921569
val--61/100 [1030/1090] acc: 0.7973756067961165
val--61/100 [1040/1090] acc: 0.7973557692307692
val--61/100 [1050/1090] acc: 0.797406994047619
val--61/100 [1060/1090] acc: 0.7973135318396226
val--61/100 [1070/1090] acc: 0.7972765771028038
val--61/100 [1080/1090] acc: 0.7972005208333334
val--61/100 [1090/1090] acc: 0.7970255160550459
epoch= 61, accuracy= 0.797026, rmse= 0.376409, auc= 0.856945
train--62/100 [9/1090] loss: 0.40401429533958433
train--62/100 [19/1090] loss: 0.427142408490181
train--62/100 [29/1090] loss: 0.4459459811449051
train--62/100 [39/1090] loss: 0.4371580809354782
train--62/100 [49/1090] loss: 0.4378733724355698
train--62/100 [59/1090] loss: 0.4374276429414749
train--62/100 [69/1090] loss: 0.4326099932193756
train--62/100 [79/1090] loss: 0.42346811294555664
train--62/100 [89/1090] loss: 0.43729087710380554
train--62/100 [99/1090] loss: 0.4374218285083771
train--62/100 [109/1090] loss: 0.4469451576471329
train--62/100 [119/1090] loss: 0.4511470556259155
train--62/100 [129/1090] loss: 0.4319699615240097
train--62/100 [139/1090] loss: 0.421051949262619
train--62/100 [149/1090] loss: 0.425717881321907
train--62/100 [159/1090] loss: 0.4361725658178329
train--62/100 [169/1090] loss: 0.43063772916793824
train--62/100 [179/1090] loss: 0.45280310809612273
train--62/100 [189/1090] loss: 0.45870246887207033
train--62/100 [199/1090] loss: 0.43332802653312685
train--62/100 [209/1090] loss: 0.43892612755298616
train--62/100 [219/1090] loss: 0.4329299420118332
train--62/100 [229/1090] loss: 0.43047202527523043
train--62/100 [239/1090] loss: 0.44058768451213837
train--62/100 [249/1090] loss: 0.4597784340381622
train--62/100 [259/1090] loss: 0.4388602524995804
train--62/100 [269/1090] loss: 0.4387817203998566
train--62/100 [279/1090] loss: 0.44847807884216306
train--62/100 [289/1090] loss: 0.45389901995658877
train--62/100 [299/1090] loss: 0.4447971612215042
train--62/100 [309/1090] loss: 0.44117167592048645
train--62/100 [319/1090] loss: 0.4506982654333115
train--62/100 [329/1090] loss: 0.43338688313961027
train--62/100 [339/1090] loss: 0.424063441157341
train--62/100 [349/1090] loss: 0.4611110478639603
train--62/100 [359/1090] loss: 0.4412903398275375
train--62/100 [369/1090] loss: 0.441342231631279
train--62/100 [379/1090] loss: 0.451322203874588
train--62/100 [389/1090] loss: 0.44062419831752775
train--62/100 [399/1090] loss: 0.44677613377571107
train--62/100 [409/1090] loss: 0.4460017055273056
train--62/100 [419/1090] loss: 0.4386244624853134
train--62/100 [429/1090] loss: 0.4523175060749054
train--62/100 [439/1090] loss: 0.43345536589622496
train--62/100 [449/1090] loss: 0.4536498636007309
train--62/100 [459/1090] loss: 0.4171094924211502
train--62/100 [469/1090] loss: 0.44839936792850493
train--62/100 [479/1090] loss: 0.4474319666624069
train--62/100 [489/1090] loss: 0.43357554376125335
train--62/100 [499/1090] loss: 0.4333508133888245
train--62/100 [509/1090] loss: 0.4347589075565338
train--62/100 [519/1090] loss: 0.4618314027786255
train--62/100 [529/1090] loss: 0.4553129345178604
train--62/100 [539/1090] loss: 0.43775772750377656
train--62/100 [549/1090] loss: 0.448177433013916
train--62/100 [559/1090] loss: 0.44993202686309813
train--62/100 [569/1090] loss: 0.45861314833164213
train--62/100 [579/1090] loss: 0.4406804829835892
train--62/100 [589/1090] loss: 0.43463416695594786
train--62/100 [599/1090] loss: 0.45115169882774353
train--62/100 [609/1090] loss: 0.44374326467514036
train--62/100 [619/1090] loss: 0.4520698457956314
train--62/100 [629/1090] loss: 0.4509695738554001
train--62/100 [639/1090] loss: 0.44046675860881807
train--62/100 [649/1090] loss: 0.4476264029741287
train--62/100 [659/1090] loss: 0.4440140277147293
train--62/100 [669/1090] loss: 0.45658227801322937
train--62/100 [679/1090] loss: 0.4404280722141266
train--62/100 [689/1090] loss: 0.4322540253400803
train--62/100 [699/1090] loss: 0.4309334307909012
train--62/100 [709/1090] loss: 0.441447114944458
train--62/100 [719/1090] loss: 0.4559360772371292
train--62/100 [729/1090] loss: 0.442959126830101
train--62/100 [739/1090] loss: 0.45855228006839754
train--62/100 [749/1090] loss: 0.45401560366153715
train--62/100 [759/1090] loss: 0.45897010564804075
train--62/100 [769/1090] loss: 0.4403482437133789
train--62/100 [779/1090] loss: 0.43939110934734343
train--62/100 [789/1090] loss: 0.44127787053585055
train--62/100 [799/1090] loss: 0.4311388909816742
train--62/100 [809/1090] loss: 0.4443816989660263
train--62/100 [819/1090] loss: 0.44094434976577757
train--62/100 [829/1090] loss: 0.43896790146827697
train--62/100 [839/1090] loss: 0.43201584815979005
train--62/100 [849/1090] loss: 0.45490930080413816
train--62/100 [859/1090] loss: 0.43554448783397676
train--62/100 [869/1090] loss: 0.4574567824602127
train--62/100 [879/1090] loss: 0.43790789544582365
train--62/100 [889/1090] loss: 0.4315041869878769
train--62/100 [899/1090] loss: 0.442498978972435
train--62/100 [909/1090] loss: 0.45418956577777864
train--62/100 [919/1090] loss: 0.44309906363487245
train--62/100 [929/1090] loss: 0.4697175592184067
train--62/100 [939/1090] loss: 0.44370541274547576
train--62/100 [949/1090] loss: 0.4483476191759109
train--62/100 [959/1090] loss: 0.43409016728401184
train--62/100 [969/1090] loss: 0.42535712718963625
train--62/100 [979/1090] loss: 0.44432648420333865
train--62/100 [989/1090] loss: 0.43302290737628935
train--62/100 [999/1090] loss: 0.4234734088182449
train--62/100 [1009/1090] loss: 0.45215703547000885
train--62/100 [1019/1090] loss: 0.4502717614173889
train--62/100 [1029/1090] loss: 0.4426221698522568
train--62/100 [1039/1090] loss: 0.4535591840744019
train--62/100 [1049/1090] loss: 0.44138869643211365
train--62/100 [1059/1090] loss: 0.420117461681366
train--62/100 [1069/1090] loss: 0.44534366130828856
train--62/100 [1079/1090] loss: 0.4570321351289749
train--62/100 [1089/1090] loss: 0.41423792243003843
predicting model...
val--62/100 [10/1090] acc: 0.798828125
val--62/100 [20/1090] acc: 0.798828125
val--62/100 [30/1090] acc: 0.79765625
val--62/100 [40/1090] acc: 0.79716796875
val--62/100 [50/1090] acc: 0.79609375
val--62/100 [60/1090] acc: 0.7953776041666667
val--62/100 [70/1090] acc: 0.7958147321428571
val--62/100 [80/1090] acc: 0.7951171875
val--62/100 [90/1090] acc: 0.7954427083333333
val--62/100 [100/1090] acc: 0.7964453125
val--62/100 [110/1090] acc: 0.7969460227272728
val--62/100 [120/1090] acc: 0.7964518229166667
val--62/100 [130/1090] acc: 0.7975961538461539
val--62/100 [140/1090] acc: 0.7976283482142857
val--62/100 [150/1090] acc: 0.7976302083333333
val--62/100 [160/1090] acc: 0.7976318359375
val--62/100 [170/1090] acc: 0.7972196691176471
val--62/100 [180/1090] acc: 0.7968967013888889
val--62/100 [190/1090] acc: 0.7975534539473684
val--62/100 [200/1090] acc: 0.79775390625
val--62/100 [210/1090] acc: 0.798139880952381
val--62/100 [220/1090] acc: 0.7971946022727273
val--62/100 [230/1090] acc: 0.7977072010869565
val--62/100 [240/1090] acc: 0.7974772135416667
val--62/100 [250/1090] acc: 0.797484375
val--62/100 [260/1090] acc: 0.7974909855769231
val--62/100 [270/1090] acc: 0.7978443287037037
val--62/100 [280/1090] acc: 0.7976981026785714
val--62/100 [290/1090] acc: 0.7975754310344828
val--62/100 [300/1090] acc: 0.7976953125
val--62/100 [310/1090] acc: 0.7975554435483871
val--62/100 [320/1090] acc: 0.79764404296875
val--62/100 [330/1090] acc: 0.7978811553030303
val--62/100 [340/1090] acc: 0.798000919117647
val--62/100 [350/1090] acc: 0.7981138392857143
val--62/100 [360/1090] acc: 0.7980577256944444
val--62/100 [370/1090] acc: 0.7981524493243243
val--62/100 [380/1090] acc: 0.7980777138157895
val--62/100 [390/1090] acc: 0.7979567307692308
val--62/100 [400/1090] acc: 0.79794921875
val--62/100 [410/1090] acc: 0.7980659298780488
val--62/100 [420/1090] acc: 0.7980096726190476
val--62/100 [430/1090] acc: 0.7977743459302326
val--62/100 [440/1090] acc: 0.7978338068181818
val--62/100 [450/1090] acc: 0.7976996527777778
val--62/100 [460/1090] acc: 0.7975373641304347
val--62/100 [470/1090] acc: 0.7974567819148937
val--62/100 [480/1090] acc: 0.7974853515625
val--62/100 [490/1090] acc: 0.79765625
val--62/100 [500/1090] acc: 0.7978203125
val--62/100 [510/1090] acc: 0.7977098651960784
val--62/100 [520/1090] acc: 0.7979642427884616
val--62/100 [530/1090] acc: 0.7979215801886792
val--62/100 [540/1090] acc: 0.7980396412037037
val--62/100 [550/1090] acc: 0.7979474431818182
val--62/100 [560/1090] acc: 0.7977818080357143
val--62/100 [570/1090] acc: 0.7975191885964912
val--62/100 [580/1090] acc: 0.7975282866379311
val--62/100 [590/1090] acc: 0.7975238347457627
val--62/100 [600/1090] acc: 0.7975325520833333
val--62/100 [610/1090] acc: 0.7974129098360656
val--62/100 [620/1090] acc: 0.7973412298387097
val--62/100 [630/1090] acc: 0.7975756448412699
val--62/100 [640/1090] acc: 0.797735595703125
val--62/100 [650/1090] acc: 0.797686298076923
val--62/100 [660/1090] acc: 0.7976325757575757
val--62/100 [670/1090] acc: 0.7973355876865672
val--62/100 [680/1090] acc: 0.7972369025735294
val--62/100 [690/1090] acc: 0.7974014945652174
val--62/100 [700/1090] acc: 0.7974609375
val--62/100 [710/1090] acc: 0.7973481514084507
val--62/100 [720/1090] acc: 0.7971896701388889
val--62/100 [730/1090] acc: 0.7971318493150685
val--62/100 [740/1090] acc: 0.7971019847972973
val--62/100 [750/1090] acc: 0.79715625
val--62/100 [760/1090] acc: 0.7972399259868421
val--62/100 [770/1090] acc: 0.797169237012987
val--62/100 [780/1090] acc: 0.7971254006410257
val--62/100 [790/1090] acc: 0.7971518987341772
val--62/100 [800/1090] acc: 0.7973583984375
val--62/100 [810/1090] acc: 0.7974344135802469
val--62/100 [820/1090] acc: 0.7975276295731707
val--62/100 [830/1090] acc: 0.7975762424698796
val--62/100 [840/1090] acc: 0.7975074404761905
val--62/100 [850/1090] acc: 0.7975183823529411
val--62/100 [860/1090] acc: 0.7977834302325582
val--62/100 [870/1090] acc: 0.7976607399425287
val--62/100 [880/1090] acc: 0.7976429332386363
val--62/100 [890/1090] acc: 0.797752808988764
val--62/100 [900/1090] acc: 0.7977560763888889
val--62/100 [910/1090] acc: 0.7977421016483517
val--62/100 [920/1090] acc: 0.7977751358695652
val--62/100 [930/1090] acc: 0.7978536626344086
val--62/100 [940/1090] acc: 0.7978474069148936
val--62/100 [950/1090] acc: 0.7977713815789473
val--62/100 [960/1090] acc: 0.7977010091145833
val--62/100 [970/1090] acc: 0.7976884664948454
val--62/100 [980/1090] acc: 0.7977319834183674
val--62/100 [990/1090] acc: 0.7976207386363636
val--62/100 [1000/1090] acc: 0.79755078125
val--62/100 [1010/1090] acc: 0.7973429764851485
val--62/100 [1020/1090] acc: 0.7974303002450981
val--62/100 [1030/1090] acc: 0.797459041262136
val--62/100 [1040/1090] acc: 0.7974534254807693
val--62/100 [1050/1090] acc: 0.7975223214285714
val--62/100 [1060/1090] acc: 0.7974535672169811
val--62/100 [1070/1090] acc: 0.797429906542056
val--62/100 [1080/1090] acc: 0.7973668981481481
val--62/100 [1090/1090] acc: 0.797211869266055
epoch= 62, accuracy= 0.797212, rmse= 0.376372, auc= 0.856951
train--63/100 [9/1090] loss: 0.4079963803291321
train--63/100 [19/1090] loss: 0.44658786058425903
train--63/100 [29/1090] loss: 0.43869829177856445
train--63/100 [39/1090] loss: 0.43827158212661743
train--63/100 [49/1090] loss: 0.43439216911792755
train--63/100 [59/1090] loss: 0.4323585867881775
train--63/100 [69/1090] loss: 0.4307535469532013
train--63/100 [79/1090] loss: 0.42880387604236603
train--63/100 [89/1090] loss: 0.43428235352039335
train--63/100 [99/1090] loss: 0.43588080406188967
train--63/100 [109/1090] loss: 0.431795135140419
train--63/100 [119/1090] loss: 0.4566175192594528
train--63/100 [129/1090] loss: 0.43620434403419495
train--63/100 [139/1090] loss: 0.45963061451911924
train--63/100 [149/1090] loss: 0.4286715447902679
train--63/100 [159/1090] loss: 0.43332668840885163
train--63/100 [169/1090] loss: 0.4352395713329315
train--63/100 [179/1090] loss: 0.4385825484991074
train--63/100 [189/1090] loss: 0.42829746305942534
train--63/100 [199/1090] loss: 0.4416532039642334
train--63/100 [209/1090] loss: 0.44085895717144014
train--63/100 [219/1090] loss: 0.4398182094097137
train--63/100 [229/1090] loss: 0.4383218288421631
train--63/100 [239/1090] loss: 0.4391886293888092
train--63/100 [249/1090] loss: 0.43602360785007477
train--63/100 [259/1090] loss: 0.4535399407148361
train--63/100 [269/1090] loss: 0.4434693932533264
train--63/100 [279/1090] loss: 0.43191213309764864
train--63/100 [289/1090] loss: 0.44133598208427427
train--63/100 [299/1090] loss: 0.41699840426445006
train--63/100 [309/1090] loss: 0.4437711089849472
train--63/100 [319/1090] loss: 0.4485498696565628
train--63/100 [329/1090] loss: 0.4404276520013809
train--63/100 [339/1090] loss: 0.4537355452775955
train--63/100 [349/1090] loss: 0.44470744729042055
train--63/100 [359/1090] loss: 0.423716202378273
train--63/100 [369/1090] loss: 0.4425021320581436
train--63/100 [379/1090] loss: 0.44881580770015717
train--63/100 [389/1090] loss: 0.4394479900598526
train--63/100 [399/1090] loss: 0.4439890503883362
train--63/100 [409/1090] loss: 0.43546136617660525
train--63/100 [419/1090] loss: 0.4405123651027679
train--63/100 [429/1090] loss: 0.44874840080738065
train--63/100 [439/1090] loss: 0.43382943272590635
train--63/100 [449/1090] loss: 0.4278337389230728
train--63/100 [459/1090] loss: 0.4485770583152771
train--63/100 [469/1090] loss: 0.4313331961631775
train--63/100 [479/1090] loss: 0.43345488607883453
train--63/100 [489/1090] loss: 0.43364260494709017
train--63/100 [499/1090] loss: 0.4419221758842468
train--63/100 [509/1090] loss: 0.4332428365945816
train--63/100 [519/1090] loss: 0.445984223484993
train--63/100 [529/1090] loss: 0.4568718045949936
train--63/100 [539/1090] loss: 0.4286823749542236
train--63/100 [549/1090] loss: 0.4519059956073761
train--63/100 [559/1090] loss: 0.4463540494441986
train--63/100 [569/1090] loss: 0.43663862645626067
train--63/100 [579/1090] loss: 0.4582107484340668
train--63/100 [589/1090] loss: 0.4388579219579697
train--63/100 [599/1090] loss: 0.45703394412994386
train--63/100 [609/1090] loss: 0.4364274710416794
train--63/100 [619/1090] loss: 0.44847613871097564
train--63/100 [629/1090] loss: 0.45814881324768064
train--63/100 [639/1090] loss: 0.45031159818172456
train--63/100 [649/1090] loss: 0.4439927935600281
train--63/100 [659/1090] loss: 0.4481074303388596
train--63/100 [669/1090] loss: 0.44086785018444063
train--63/100 [679/1090] loss: 0.4472759187221527
train--63/100 [689/1090] loss: 0.4464790016412735
train--63/100 [699/1090] loss: 0.466805100440979
train--63/100 [709/1090] loss: 0.431982958316803
train--63/100 [719/1090] loss: 0.4160066217184067
train--63/100 [729/1090] loss: 0.45068864822387694
train--63/100 [739/1090] loss: 0.45049221217632296
train--63/100 [749/1090] loss: 0.4448437958955765
train--63/100 [759/1090] loss: 0.4444100022315979
train--63/100 [769/1090] loss: 0.45416305363178255
train--63/100 [779/1090] loss: 0.4597393870353699
train--63/100 [789/1090] loss: 0.438840314745903
train--63/100 [799/1090] loss: 0.4363124191761017
train--63/100 [809/1090] loss: 0.44611249268054964
train--63/100 [819/1090] loss: 0.44486771523952484
train--63/100 [829/1090] loss: 0.44138403236866
train--63/100 [839/1090] loss: 0.425300657749176
train--63/100 [849/1090] loss: 0.4259132593870163
train--63/100 [859/1090] loss: 0.42223305702209474
train--63/100 [869/1090] loss: 0.44306611716747285
train--63/100 [879/1090] loss: 0.44966364204883574
train--63/100 [889/1090] loss: 0.4476977318525314
train--63/100 [899/1090] loss: 0.45963620841503144
train--63/100 [909/1090] loss: 0.4340922713279724
train--63/100 [919/1090] loss: 0.4617083579301834
train--63/100 [929/1090] loss: 0.4462797999382019
train--63/100 [939/1090] loss: 0.451317635178566
train--63/100 [949/1090] loss: 0.4486513793468475
train--63/100 [959/1090] loss: 0.41406636238098143
train--63/100 [969/1090] loss: 0.46083172857761384
train--63/100 [979/1090] loss: 0.4393758445978165
train--63/100 [989/1090] loss: 0.45395328104496
train--63/100 [999/1090] loss: 0.4512964874505997
train--63/100 [1009/1090] loss: 0.43073972761631013
train--63/100 [1019/1090] loss: 0.4529753863811493
train--63/100 [1029/1090] loss: 0.43589845299720764
train--63/100 [1039/1090] loss: 0.44085060954093935
train--63/100 [1049/1090] loss: 0.4602733254432678
train--63/100 [1059/1090] loss: 0.43783959448337556
train--63/100 [1069/1090] loss: 0.45837621092796327
train--63/100 [1079/1090] loss: 0.438737154006958
train--63/100 [1089/1090] loss: 0.4486180245876312
predicting model...
val--63/100 [10/1090] acc: 0.796484375
val--63/100 [20/1090] acc: 0.7953125
val--63/100 [30/1090] acc: 0.7950520833333333
val--63/100 [40/1090] acc: 0.79599609375
val--63/100 [50/1090] acc: 0.795703125
val--63/100 [60/1090] acc: 0.7950520833333333
val--63/100 [70/1090] acc: 0.7955915178571429
val--63/100 [80/1090] acc: 0.79462890625
val--63/100 [90/1090] acc: 0.7947916666666667
val--63/100 [100/1090] acc: 0.7958984375
val--63/100 [110/1090] acc: 0.7964488636363637
val--63/100 [120/1090] acc: 0.7958984375
val--63/100 [130/1090] acc: 0.7969350961538462
val--63/100 [140/1090] acc: 0.7969029017857143
val--63/100 [150/1090] acc: 0.7969270833333333
val--63/100 [160/1090] acc: 0.797119140625
val--63/100 [170/1090] acc: 0.7969669117647059
val--63/100 [180/1090] acc: 0.7968315972222222
val--63/100 [190/1090] acc: 0.7975123355263158
val--63/100 [200/1090] acc: 0.79759765625
val--63/100 [210/1090] acc: 0.7980282738095238
val--63/100 [220/1090] acc: 0.7972301136363636
val--63/100 [230/1090] acc: 0.797758152173913
val--63/100 [240/1090] acc: 0.7974934895833333
val--63/100 [250/1090] acc: 0.797546875
val--63/100 [260/1090] acc: 0.7976111778846153
val--63/100 [270/1090] acc: 0.7978877314814815
val--63/100 [280/1090] acc: 0.7977678571428571
val--63/100 [290/1090] acc: 0.7976293103448275
val--63/100 [300/1090] acc: 0.7977864583333333
val--63/100 [310/1090] acc: 0.7977066532258065
val--63/100 [320/1090] acc: 0.7979736328125
val--63/100 [330/1090] acc: 0.7981770833333334
val--63/100 [340/1090] acc: 0.7982651654411764
val--63/100 [350/1090] acc: 0.7983816964285714
val--63/100 [360/1090] acc: 0.7982855902777778
val--63/100 [370/1090] acc: 0.7983952702702702
val--63/100 [380/1090] acc: 0.7983963815789473
val--63/100 [390/1090] acc: 0.7983072916666667
val--63/100 [400/1090] acc: 0.798271484375
val--63/100 [410/1090] acc: 0.7983517530487805
val--63/100 [420/1090] acc: 0.7982700892857143
val--63/100 [430/1090] acc: 0.7980377906976744
val--63/100 [440/1090] acc: 0.7981267755681818
val--63/100 [450/1090] acc: 0.7979947916666666
val--63/100 [460/1090] acc: 0.7978260869565217
val--63/100 [470/1090] acc: 0.7977559840425532
val--63/100 [480/1090] acc: 0.7977620442708333
val--63/100 [490/1090] acc: 0.7978874362244898
val--63/100 [500/1090] acc: 0.79796875
val--63/100 [510/1090] acc: 0.7978094362745098
val--63/100 [520/1090] acc: 0.7980543870192308
val--63/100 [530/1090] acc: 0.7979658018867924
val--63/100 [540/1090] acc: 0.798046875
val--63/100 [550/1090] acc: 0.7979332386363637
val--63/100 [560/1090] acc: 0.7977608816964286
val--63/100 [570/1090] acc: 0.7974986293859649
val--63/100 [580/1090] acc: 0.7974744073275862
val--63/100 [590/1090] acc: 0.7975039724576272
val--63/100 [600/1090] acc: 0.7975390625
val--63/100 [610/1090] acc: 0.7974513319672131
val--63/100 [620/1090] acc: 0.7974105342741935
val--63/100 [630/1090] acc: 0.7976314484126984
val--63/100 [640/1090] acc: 0.79781494140625
val--63/100 [650/1090] acc: 0.7978545673076923
val--63/100 [660/1090] acc: 0.7978101325757576
val--63/100 [670/1090] acc: 0.797568796641791
val--63/100 [680/1090] acc: 0.7974551930147059
val--63/100 [690/1090] acc: 0.7975769927536231
val--63/100 [700/1090] acc: 0.7976283482142857
val--63/100 [710/1090] acc: 0.7974856954225352
val--63/100 [720/1090] acc: 0.7973524305555556
val--63/100 [730/1090] acc: 0.7972923801369863
val--63/100 [740/1090] acc: 0.7972603462837838
val--63/100 [750/1090] acc: 0.7972864583333333
val--63/100 [760/1090] acc: 0.7973941200657895
val--63/100 [770/1090] acc: 0.7973518668831169
val--63/100 [780/1090] acc: 0.797255608974359
val--63/100 [790/1090] acc: 0.7973002373417721
val--63/100 [800/1090] acc: 0.7975146484375
val--63/100 [810/1090] acc: 0.7975646219135802
val--63/100 [820/1090] acc: 0.79765625
val--63/100 [830/1090] acc: 0.7977080195783133
val--63/100 [840/1090] acc: 0.7976981026785714
val--63/100 [850/1090] acc: 0.7977068014705883
val--63/100 [860/1090] acc: 0.7979514898255814
val--63/100 [870/1090] acc: 0.7978762571839081
val--63/100 [880/1090] acc: 0.7978915127840909
val--63/100 [890/1090] acc: 0.7980380969101124
val--63/100 [900/1090] acc: 0.7980555555555555
val--63/100 [910/1090] acc: 0.7980511675824176
val--63/100 [920/1090] acc: 0.7980511209239131
val--63/100 [930/1090] acc: 0.7981350806451613
val--63/100 [940/1090] acc: 0.7981673869680851
val--63/100 [950/1090] acc: 0.7981126644736842
val--63/100 [960/1090] acc: 0.79801025390625
val--63/100 [970/1090] acc: 0.7979582796391752
val--63/100 [980/1090] acc: 0.7979751275510204
val--63/100 [990/1090] acc: 0.7978890467171718
val--63/100 [1000/1090] acc: 0.7978046875
val--63/100 [1010/1090] acc: 0.7976523824257425
val--63/100 [1020/1090] acc: 0.7977175245098039
val--63/100 [1030/1090] acc: 0.7977245145631068
val--63/100 [1040/1090] acc: 0.7977163461538461
val--63/100 [1050/1090] acc: 0.797749255952381
val--63/100 [1060/1090] acc: 0.7977078419811321
val--63/100 [1070/1090] acc: 0.7976854556074766
val--63/100 [1080/1090] acc: 0.7976453993055556
val--63/100 [1090/1090] acc: 0.7974734805045871
epoch= 63, accuracy= 0.797473, rmse= 0.376191, auc= 0.857144
train--64/100 [9/1090] loss: 0.4057608425617218
train--64/100 [19/1090] loss: 0.4298876166343689
train--64/100 [29/1090] loss: 0.44653989374637604
train--64/100 [39/1090] loss: 0.4442009925842285
train--64/100 [49/1090] loss: 0.4376719444990158
train--64/100 [59/1090] loss: 0.44010922610759734
train--64/100 [69/1090] loss: 0.442131969332695
train--64/100 [79/1090] loss: 0.44394448697566985
train--64/100 [89/1090] loss: 0.4211639970541
train--64/100 [99/1090] loss: 0.447170227766037
train--64/100 [109/1090] loss: 0.4475142270326614
train--64/100 [119/1090] loss: 0.4577053487300873
train--64/100 [129/1090] loss: 0.44488799571990967
train--64/100 [139/1090] loss: 0.44149153530597685
train--64/100 [149/1090] loss: 0.4433046877384186
train--64/100 [159/1090] loss: 0.4507061630487442
train--64/100 [169/1090] loss: 0.44392854869365694
train--64/100 [179/1090] loss: 0.4261649936437607
train--64/100 [189/1090] loss: 0.4250581353902817
train--64/100 [199/1090] loss: 0.4398169696331024
train--64/100 [209/1090] loss: 0.440110781788826
train--64/100 [219/1090] loss: 0.4545559972524643
train--64/100 [229/1090] loss: 0.4554388254880905
train--64/100 [239/1090] loss: 0.4365034818649292
train--64/100 [249/1090] loss: 0.42147035002708433
train--64/100 [259/1090] loss: 0.4310024678707123
train--64/100 [269/1090] loss: 0.44055311381816864
train--64/100 [279/1090] loss: 0.4343250244855881
train--64/100 [289/1090] loss: 0.449047189950943
train--64/100 [299/1090] loss: 0.4285273849964142
train--64/100 [309/1090] loss: 0.4418567717075348
train--64/100 [319/1090] loss: 0.44693720936775205
train--64/100 [329/1090] loss: 0.4422547906637192
train--64/100 [339/1090] loss: 0.43864592611789704
train--64/100 [349/1090] loss: 0.443056645989418
train--64/100 [359/1090] loss: 0.4624536454677582
train--64/100 [369/1090] loss: 0.44665523767471316
train--64/100 [379/1090] loss: 0.4374498248100281
train--64/100 [389/1090] loss: 0.43689065277576444
train--64/100 [399/1090] loss: 0.441116201877594
train--64/100 [409/1090] loss: 0.45533314645290374
train--64/100 [419/1090] loss: 0.44070881605148315
train--64/100 [429/1090] loss: 0.4384716033935547
train--64/100 [439/1090] loss: 0.44363090991973875
train--64/100 [449/1090] loss: 0.43722262382507326
train--64/100 [459/1090] loss: 0.4240274965763092
train--64/100 [469/1090] loss: 0.4355316996574402
train--64/100 [479/1090] loss: 0.4628575176000595
train--64/100 [489/1090] loss: 0.4755051493644714
train--64/100 [499/1090] loss: 0.4336110055446625
train--64/100 [509/1090] loss: 0.43267427682876586
train--64/100 [519/1090] loss: 0.43688707053661346
train--64/100 [529/1090] loss: 0.44097112119197845
train--64/100 [539/1090] loss: 0.45003667175769807
train--64/100 [549/1090] loss: 0.44210211336612704
train--64/100 [559/1090] loss: 0.43818519115447996
train--64/100 [569/1090] loss: 0.43479501605033877
train--64/100 [579/1090] loss: 0.44551346600055697
train--64/100 [589/1090] loss: 0.4365920901298523
train--64/100 [599/1090] loss: 0.43827643394470217
train--64/100 [609/1090] loss: 0.4144058346748352
train--64/100 [619/1090] loss: 0.4299271732568741
train--64/100 [629/1090] loss: 0.45476928651332854
train--64/100 [639/1090] loss: 0.4196431487798691
train--64/100 [649/1090] loss: 0.4299126625061035
train--64/100 [659/1090] loss: 0.4500549852848053
train--64/100 [669/1090] loss: 0.439534467458725
train--64/100 [679/1090] loss: 0.4451588034629822
train--64/100 [689/1090] loss: 0.44708151519298556
train--64/100 [699/1090] loss: 0.43528697490692136
train--64/100 [709/1090] loss: 0.44852674305438994
train--64/100 [719/1090] loss: 0.4442355424165726
train--64/100 [729/1090] loss: 0.4287785440683365
train--64/100 [739/1090] loss: 0.4307066351175308
train--64/100 [749/1090] loss: 0.44333224296569823
train--64/100 [759/1090] loss: 0.44083011746406553
train--64/100 [769/1090] loss: 0.45349137783050536
train--64/100 [779/1090] loss: 0.4427075177431107
train--64/100 [789/1090] loss: 0.4510258823633194
train--64/100 [799/1090] loss: 0.42809746861457826
train--64/100 [809/1090] loss: 0.44095236659049986
train--64/100 [819/1090] loss: 0.43029464185237887
train--64/100 [829/1090] loss: 0.42887201607227327
train--64/100 [839/1090] loss: 0.4424203664064407
train--64/100 [849/1090] loss: 0.45028161704540254
train--64/100 [859/1090] loss: 0.44000530540943145
train--64/100 [869/1090] loss: 0.43469935059547427
train--64/100 [879/1090] loss: 0.44182067811489106
train--64/100 [889/1090] loss: 0.46370882987976075
train--64/100 [899/1090] loss: 0.4420132875442505
train--64/100 [909/1090] loss: 0.43626061677932737
train--64/100 [919/1090] loss: 0.4550656884908676
train--64/100 [929/1090] loss: 0.4633743971586227
train--64/100 [939/1090] loss: 0.43343918919563296
train--64/100 [949/1090] loss: 0.4423357963562012
train--64/100 [959/1090] loss: 0.4446690112352371
train--64/100 [969/1090] loss: 0.4461368978023529
train--64/100 [979/1090] loss: 0.4487931847572327
train--64/100 [989/1090] loss: 0.44866869747638705
train--64/100 [999/1090] loss: 0.44599067270755766
train--64/100 [1009/1090] loss: 0.4470573961734772
train--64/100 [1019/1090] loss: 0.44760963022708894
train--64/100 [1029/1090] loss: 0.4396596014499664
train--64/100 [1039/1090] loss: 0.4403385132551193
train--64/100 [1049/1090] loss: 0.45597332417964936
train--64/100 [1059/1090] loss: 0.4501682698726654
train--64/100 [1069/1090] loss: 0.44601968824863436
train--64/100 [1079/1090] loss: 0.4508968561887741
train--64/100 [1089/1090] loss: 0.44305860102176664
predicting model...
val--64/100 [10/1090] acc: 0.80078125
val--64/100 [20/1090] acc: 0.7990234375
val--64/100 [30/1090] acc: 0.7979166666666667
val--64/100 [40/1090] acc: 0.798046875
val--64/100 [50/1090] acc: 0.796875
val--64/100 [60/1090] acc: 0.7966145833333333
val--64/100 [70/1090] acc: 0.7967075892857143
val--64/100 [80/1090] acc: 0.79580078125
val--64/100 [90/1090] acc: 0.7962673611111111
val--64/100 [100/1090] acc: 0.797109375
val--64/100 [110/1090] acc: 0.7976207386363636
val--64/100 [120/1090] acc: 0.7972330729166667
val--64/100 [130/1090] acc: 0.7981971153846154
val--64/100 [140/1090] acc: 0.7981026785714286
val--64/100 [150/1090] acc: 0.7980989583333333
val--64/100 [160/1090] acc: 0.798291015625
val--64/100 [170/1090] acc: 0.798000919117647
val--64/100 [180/1090] acc: 0.7977430555555556
val--64/100 [190/1090] acc: 0.7983347039473684
val--64/100 [200/1090] acc: 0.7984375
val--64/100 [210/1090] acc: 0.7987723214285715
val--64/100 [220/1090] acc: 0.7978515625
val--64/100 [230/1090] acc: 0.7981997282608696
val--64/100 [240/1090] acc: 0.7979166666666667
val--64/100 [250/1090] acc: 0.7980625
val--64/100 [260/1090] acc: 0.798016826923077
val--64/100 [270/1090] acc: 0.7982204861111111
val--64/100 [280/1090] acc: 0.7981026785714286
val--64/100 [290/1090] acc: 0.7979391163793104
val--64/100 [300/1090] acc: 0.7980078125
val--64/100 [310/1090] acc: 0.7979208669354839
val--64/100 [320/1090] acc: 0.798095703125
val--64/100 [330/1090] acc: 0.7982954545454546
val--64/100 [340/1090] acc: 0.7984145220588236
val--64/100 [350/1090] acc: 0.798515625
val--64/100 [360/1090] acc: 0.7983723958333333
val--64/100 [370/1090] acc: 0.7984375
val--64/100 [380/1090] acc: 0.7984888980263158
val--64/100 [390/1090] acc: 0.798397435897436
val--64/100 [400/1090] acc: 0.798349609375
val--64/100 [410/1090] acc: 0.7984660823170732
val--64/100 [420/1090] acc: 0.7984188988095238
val--64/100 [430/1090] acc: 0.7982103924418604
val--64/100 [440/1090] acc: 0.7982066761363636
val--64/100 [450/1090] acc: 0.7980989583333333
val--64/100 [460/1090] acc: 0.797953464673913
val--64/100 [470/1090] acc: 0.7978474069148936
val--64/100 [480/1090] acc: 0.7978434244791667
val--64/100 [490/1090] acc: 0.797983099489796
val--64/100 [500/1090] acc: 0.7981171875
val--64/100 [510/1090] acc: 0.7980238970588235
val--64/100 [520/1090] acc: 0.7983173076923077
val--64/100 [530/1090] acc: 0.7982385023584906
val--64/100 [540/1090] acc: 0.7983796296296296
val--64/100 [550/1090] acc: 0.79828125
val--64/100 [560/1090] acc: 0.7981026785714286
val--64/100 [570/1090] acc: 0.7978412828947369
val--64/100 [580/1090] acc: 0.7978111530172414
val--64/100 [590/1090] acc: 0.7978416313559322
val--64/100 [600/1090] acc: 0.7978385416666667
val--64/100 [610/1090] acc: 0.7977715163934426
val--64/100 [620/1090] acc: 0.7977066532258065
val--64/100 [630/1090] acc: 0.7979724702380953
val--64/100 [640/1090] acc: 0.798150634765625
val--64/100 [650/1090] acc: 0.7981370192307692
val--64/100 [660/1090] acc: 0.7980527935606061
val--64/100 [670/1090] acc: 0.797802005597015
val--64/100 [680/1090] acc: 0.7976390165441176
val--64/100 [690/1090] acc: 0.7977411684782608
val--64/100 [700/1090] acc: 0.7978069196428571
val--64/100 [710/1090] acc: 0.7976617517605634
val--64/100 [720/1090] acc: 0.7975260416666666
val--64/100 [730/1090] acc: 0.7974529109589041
val--64/100 [740/1090] acc: 0.797387035472973
val--64/100 [750/1090] acc: 0.7974322916666666
val--64/100 [760/1090] acc: 0.7975277549342106
val--64/100 [770/1090] acc: 0.7974533279220779
val--64/100 [780/1090] acc: 0.7973858173076923
val--64/100 [790/1090] acc: 0.7973941851265823
val--64/100 [800/1090] acc: 0.7976025390625
val--64/100 [810/1090] acc: 0.7976417824074075
val--64/100 [820/1090] acc: 0.7977467606707317
val--64/100 [830/1090] acc: 0.7978021460843373
val--64/100 [840/1090] acc: 0.7977725074404762
val--64/100 [850/1090] acc: 0.7977941176470589
val--64/100 [860/1090] acc: 0.798069585755814
val--64/100 [870/1090] acc: 0.7980199353448276
val--64/100 [880/1090] acc: 0.7980202414772727
val--64/100 [890/1090] acc: 0.7981566011235955
val--64/100 [900/1090] acc: 0.7981814236111111
val--64/100 [910/1090] acc: 0.7982314560439561
val--64/100 [920/1090] acc: 0.7982676630434783
val--64/100 [930/1090] acc: 0.7983744959677419
val--64/100 [940/1090] acc: 0.798383477393617
val--64/100 [950/1090] acc: 0.7982935855263158
val--64/100 [960/1090] acc: 0.79820556640625
val--64/100 [970/1090] acc: 0.7981636597938144
val--64/100 [980/1090] acc: 0.7981863839285714
val--64/100 [990/1090] acc: 0.7980981691919192
val--64/100 [1000/1090] acc: 0.7980234375
val--64/100 [1010/1090] acc: 0.7978457611386138
val--64/100 [1020/1090] acc: 0.7979013480392156
val--64/100 [1030/1090] acc: 0.7979141383495145
val--64/100 [1040/1090] acc: 0.7979154146634615
val--64/100 [1050/1090] acc: 0.7979501488095239
val--64/100 [1060/1090] acc: 0.7978810436320755
val--64/100 [1070/1090] acc: 0.797838785046729
val--64/100 [1080/1090] acc: 0.7977683738425926
val--64/100 [1090/1090] acc: 0.7975953268348623
epoch= 64, accuracy= 0.797595, rmse= 0.376178, auc= 0.857261
train--65/100 [9/1090] loss: 0.39176301956176757
train--65/100 [19/1090] loss: 0.43567905724048617
train--65/100 [29/1090] loss: 0.45032224953174593
train--65/100 [39/1090] loss: 0.4442019760608673
train--65/100 [49/1090] loss: 0.4461571931838989
train--65/100 [59/1090] loss: 0.4226685851812363
train--65/100 [69/1090] loss: 0.43113312125205994
train--65/100 [79/1090] loss: 0.44039337038993837
train--65/100 [89/1090] loss: 0.4301920384168625
train--65/100 [99/1090] loss: 0.45081025660037993
train--65/100 [109/1090] loss: 0.4201258301734924
train--65/100 [119/1090] loss: 0.44583257138729093
train--65/100 [129/1090] loss: 0.432983922958374
train--65/100 [139/1090] loss: 0.44632663428783415
train--65/100 [149/1090] loss: 0.4666377604007721
train--65/100 [159/1090] loss: 0.43265477418899534
train--65/100 [169/1090] loss: 0.4293008863925934
train--65/100 [179/1090] loss: 0.4459233611822128
train--65/100 [189/1090] loss: 0.43389307260513305
train--65/100 [199/1090] loss: 0.43635326623916626
train--65/100 [209/1090] loss: 0.44747803211212156
train--65/100 [219/1090] loss: 0.42545146942138673
train--65/100 [229/1090] loss: 0.4403170168399811
train--65/100 [239/1090] loss: 0.4369458228349686
train--65/100 [249/1090] loss: 0.4366223216056824
train--65/100 [259/1090] loss: 0.43878885805606843
train--65/100 [269/1090] loss: 0.45301482975482943
train--65/100 [279/1090] loss: 0.46470033228397367
train--65/100 [289/1090] loss: 0.4452325254678726
train--65/100 [299/1090] loss: 0.4347078502178192
train--65/100 [309/1090] loss: 0.43379407525062563
train--65/100 [319/1090] loss: 0.43472842276096346
train--65/100 [329/1090] loss: 0.4354292958974838
train--65/100 [339/1090] loss: 0.4395368665456772
train--65/100 [349/1090] loss: 0.4432044714689255
train--65/100 [359/1090] loss: 0.43947658836841585
train--65/100 [369/1090] loss: 0.44859901666641233
train--65/100 [379/1090] loss: 0.4285008579492569
train--65/100 [389/1090] loss: 0.44353920221328735
train--65/100 [399/1090] loss: 0.44966189563274384
train--65/100 [409/1090] loss: 0.4384398251771927
train--65/100 [419/1090] loss: 0.4262477308511734
train--65/100 [429/1090] loss: 0.43080583214759827
train--65/100 [439/1090] loss: 0.4379228204488754
train--65/100 [449/1090] loss: 0.44684831500053407
train--65/100 [459/1090] loss: 0.4433726668357849
train--65/100 [469/1090] loss: 0.4433232039213181
train--65/100 [479/1090] loss: 0.43786309063434603
train--65/100 [489/1090] loss: 0.43655295073986056
train--65/100 [499/1090] loss: 0.4332769691944122
train--65/100 [509/1090] loss: 0.4453137218952179
train--65/100 [519/1090] loss: 0.4242313474416733
train--65/100 [529/1090] loss: 0.4334998160600662
train--65/100 [539/1090] loss: 0.4351325124502182
train--65/100 [549/1090] loss: 0.45025542974472044
train--65/100 [559/1090] loss: 0.4523420840501785
train--65/100 [569/1090] loss: 0.4407491534948349
train--65/100 [579/1090] loss: 0.44524958431720735
train--65/100 [589/1090] loss: 0.4376266777515411
train--65/100 [599/1090] loss: 0.45391733646392823
train--65/100 [609/1090] loss: 0.43087011873722075
train--65/100 [619/1090] loss: 0.43998037874698637
train--65/100 [629/1090] loss: 0.4508625239133835
train--65/100 [639/1090] loss: 0.44986645579338075
train--65/100 [649/1090] loss: 0.433811166882515
train--65/100 [659/1090] loss: 0.4622168898582458
train--65/100 [669/1090] loss: 0.4150071293115616
train--65/100 [679/1090] loss: 0.43856524527072904
train--65/100 [689/1090] loss: 0.4298412263393402
train--65/100 [699/1090] loss: 0.43546040952205656
train--65/100 [709/1090] loss: 0.44232766330242157
train--65/100 [719/1090] loss: 0.45415234863758086
train--65/100 [729/1090] loss: 0.4351538419723511
train--65/100 [739/1090] loss: 0.42057790160179137
train--65/100 [749/1090] loss: 0.4482579708099365
train--65/100 [759/1090] loss: 0.44318646788597105
train--65/100 [769/1090] loss: 0.4404265910387039
train--65/100 [779/1090] loss: 0.44649858176708224
train--65/100 [789/1090] loss: 0.44210433661937715
train--65/100 [799/1090] loss: 0.44969092309474945
train--65/100 [809/1090] loss: 0.43235665261745454
train--65/100 [819/1090] loss: 0.4556389719247818
train--65/100 [829/1090] loss: 0.4535942077636719
train--65/100 [839/1090] loss: 0.4466152101755142
train--65/100 [849/1090] loss: 0.4593114942312241
train--65/100 [859/1090] loss: 0.4260975539684296
train--65/100 [869/1090] loss: 0.4686767429113388
train--65/100 [879/1090] loss: 0.44764612019062044
train--65/100 [889/1090] loss: 0.44117497503757475
train--65/100 [899/1090] loss: 0.45604259967803956
train--65/100 [909/1090] loss: 0.44836053252220154
train--65/100 [919/1090] loss: 0.4429373800754547
train--65/100 [929/1090] loss: 0.4505867600440979
train--65/100 [939/1090] loss: 0.4356133878231049
train--65/100 [949/1090] loss: 0.4388674348592758
train--65/100 [959/1090] loss: 0.4506575673818588
train--65/100 [969/1090] loss: 0.46765202283859253
train--65/100 [979/1090] loss: 0.4486359715461731
train--65/100 [989/1090] loss: 0.4326263278722763
train--65/100 [999/1090] loss: 0.4413912922143936
train--65/100 [1009/1090] loss: 0.44042464196681974
train--65/100 [1019/1090] loss: 0.44284721910953523
train--65/100 [1029/1090] loss: 0.4711367666721344
train--65/100 [1039/1090] loss: 0.4333066701889038
train--65/100 [1049/1090] loss: 0.453038701415062
train--65/100 [1059/1090] loss: 0.44607665836811067
train--65/100 [1069/1090] loss: 0.4509219706058502
train--65/100 [1079/1090] loss: 0.43899425864219666
train--65/100 [1089/1090] loss: 0.4326569825410843
predicting model...
val--65/100 [10/1090] acc: 0.798828125
val--65/100 [20/1090] acc: 0.796484375
val--65/100 [30/1090] acc: 0.7953125
val--65/100 [40/1090] acc: 0.79609375
val--65/100 [50/1090] acc: 0.795234375
val--65/100 [60/1090] acc: 0.7946614583333333
val--65/100 [70/1090] acc: 0.7955357142857142
val--65/100 [80/1090] acc: 0.79541015625
val--65/100 [90/1090] acc: 0.7957899305555556
val--65/100 [100/1090] acc: 0.7967578125
val--65/100 [110/1090] acc: 0.7970170454545454
val--65/100 [120/1090] acc: 0.7966145833333333
val--65/100 [130/1090] acc: 0.7978064903846154
val--65/100 [140/1090] acc: 0.7977957589285715
val--65/100 [150/1090] acc: 0.797734375
val--65/100 [160/1090] acc: 0.7977294921875
val--65/100 [170/1090] acc: 0.7974954044117647
val--65/100 [180/1090] acc: 0.7971788194444445
val--65/100 [190/1090] acc: 0.7978618421052631
val--65/100 [200/1090] acc: 0.7980859375
val--65/100 [210/1090] acc: 0.7984002976190476
val--65/100 [220/1090] acc: 0.7975852272727273
val--65/100 [230/1090] acc: 0.797944972826087
val--65/100 [240/1090] acc: 0.7976236979166667
val--65/100 [250/1090] acc: 0.797703125
val--65/100 [260/1090] acc: 0.797686298076923
val--65/100 [270/1090] acc: 0.7980613425925925
val--65/100 [280/1090] acc: 0.7980329241071429
val--65/100 [290/1090] acc: 0.7978448275862069
val--65/100 [300/1090] acc: 0.7979427083333334
val--65/100 [310/1090] acc: 0.7978326612903226
val--65/100 [320/1090] acc: 0.7979736328125
val--65/100 [330/1090] acc: 0.7981770833333334
val--65/100 [340/1090] acc: 0.7981962316176471
val--65/100 [350/1090] acc: 0.7983370535714286
val--65/100 [360/1090] acc: 0.7982530381944445
val--65/100 [370/1090] acc: 0.7983530405405406
val--65/100 [380/1090] acc: 0.7983347039473684
val--65/100 [390/1090] acc: 0.7982772435897436
val--65/100 [400/1090] acc: 0.798310546875
val--65/100 [410/1090] acc: 0.7984565548780488
val--65/100 [420/1090] acc: 0.7983165922619048
val--65/100 [430/1090] acc: 0.798046875
val--65/100 [440/1090] acc: 0.7980113636363636
val--65/100 [450/1090] acc: 0.7979253472222222
val--65/100 [460/1090] acc: 0.7977751358695652
val--65/100 [470/1090] acc: 0.7977227393617021
val--65/100 [480/1090] acc: 0.7976888020833334
val--65/100 [490/1090] acc: 0.7978236607142857
val--65/100 [500/1090] acc: 0.797984375
val--65/100 [510/1090] acc: 0.7978936887254902
val--65/100 [520/1090] acc: 0.798174579326923
val--65/100 [530/1090] acc: 0.7981353183962264
val--65/100 [540/1090] acc: 0.7982711226851852
val--65/100 [550/1090] acc: 0.798153409090909
val--65/100 [560/1090] acc: 0.7979422433035714
val--65/100 [570/1090] acc: 0.79765625
val--65/100 [580/1090] acc: 0.7976697198275862
val--65/100 [590/1090] acc: 0.7976959745762712
val--65/100 [600/1090] acc: 0.79767578125
val--65/100 [610/1090] acc: 0.7976114241803278
val--65/100 [620/1090] acc: 0.797523941532258
val--65/100 [630/1090] acc: 0.7978174603174604
val--65/100 [640/1090] acc: 0.79801025390625
val--65/100 [650/1090] acc: 0.7979747596153847
val--65/100 [660/1090] acc: 0.7978929924242424
val--65/100 [670/1090] acc: 0.7976387593283583
val--65/100 [680/1090] acc: 0.7974724264705882
val--65/100 [690/1090] acc: 0.7976279438405797
val--65/100 [700/1090] acc: 0.7976618303571429
val--65/100 [710/1090] acc: 0.7975297095070423
val--65/100 [720/1090] acc: 0.7973578559027777
val--65/100 [730/1090] acc: 0.7973137842465754
val--65/100 [740/1090] acc: 0.7972761824324325
val--65/100 [750/1090] acc: 0.7973333333333333
val--65/100 [760/1090] acc: 0.7974352384868421
val--65/100 [770/1090] acc: 0.7973823051948052
val--65/100 [780/1090] acc: 0.7973207131410256
val--65/100 [790/1090] acc: 0.7973645174050633
val--65/100 [800/1090] acc: 0.7975732421875
val--65/100 [810/1090] acc: 0.7976176697530865
val--65/100 [820/1090] acc: 0.7976943597560976
val--65/100 [830/1090] acc: 0.7977362575301205
val--65/100 [840/1090] acc: 0.7977027529761904
val--65/100 [850/1090] acc: 0.7977481617647059
val--65/100 [860/1090] acc: 0.7979969113372093
val--65/100 [870/1090] acc: 0.7979525862068966
val--65/100 [880/1090] acc: 0.7979314630681819
val--65/100 [890/1090] acc: 0.7980161516853933
val--65/100 [900/1090] acc: 0.7980295138888889
val--65/100 [910/1090] acc: 0.798016826923077
val--65/100 [920/1090] acc: 0.7980596127717391
val--65/100 [930/1090] acc: 0.7981602822580646
val--65/100 [940/1090] acc: 0.7981798537234043
val--65/100 [950/1090] acc: 0.798125
val--65/100 [960/1090] acc: 0.7980550130208334
val--65/100 [970/1090] acc: 0.7980066043814433
val--65/100 [980/1090] acc: 0.7980588329081633
val--65/100 [990/1090] acc: 0.7979600694444444
val--65/100 [1000/1090] acc: 0.79788671875
val--65/100 [1010/1090] acc: 0.7976678527227723
val--65/100 [1020/1090] acc: 0.7977251838235294
val--65/100 [1030/1090] acc: 0.7977510618932039
val--65/100 [1040/1090] acc: 0.7977351262019231
val--65/100 [1050/1090] acc: 0.797797619047619
val--65/100 [1060/1090] acc: 0.7977225825471698
val--65/100 [1070/1090] acc: 0.7976379964953271
val--65/100 [1080/1090] acc: 0.7975802951388888
val--65/100 [1090/1090] acc: 0.7974233084862385
epoch= 65, accuracy= 0.797423, rmse= 0.376198, auc= 0.857159
train--66/100 [9/1090] loss: 0.3854834020137787
train--66/100 [19/1090] loss: 0.44958077669143676
train--66/100 [29/1090] loss: 0.4546584039926529
train--66/100 [39/1090] loss: 0.4356114476919174
train--66/100 [49/1090] loss: 0.45994404554367063
train--66/100 [59/1090] loss: 0.41854522824287416
train--66/100 [69/1090] loss: 0.44227608740329744
train--66/100 [79/1090] loss: 0.4499849140644073
train--66/100 [89/1090] loss: 0.4236329734325409
train--66/100 [99/1090] loss: 0.45446824133396146
train--66/100 [109/1090] loss: 0.43790627717971803
train--66/100 [119/1090] loss: 0.43878344893455506
train--66/100 [129/1090] loss: 0.428183251619339
train--66/100 [139/1090] loss: 0.4364109605550766
train--66/100 [149/1090] loss: 0.4375121742486954
train--66/100 [159/1090] loss: 0.435748353600502
train--66/100 [169/1090] loss: 0.4392598748207092
train--66/100 [179/1090] loss: 0.44332670271396635
train--66/100 [189/1090] loss: 0.4578686773777008
train--66/100 [199/1090] loss: 0.43944262266159057
train--66/100 [209/1090] loss: 0.42240228652954104
train--66/100 [219/1090] loss: 0.4350191742181778
train--66/100 [229/1090] loss: 0.43510104417800904
train--66/100 [239/1090] loss: 0.4430390954017639
train--66/100 [249/1090] loss: 0.4366645455360413
train--66/100 [259/1090] loss: 0.44424183666706085
train--66/100 [269/1090] loss: 0.40922085344791415
train--66/100 [279/1090] loss: 0.43542519211769104
train--66/100 [289/1090] loss: 0.4282277524471283
train--66/100 [299/1090] loss: 0.43461055159568784
train--66/100 [309/1090] loss: 0.4111480116844177
train--66/100 [319/1090] loss: 0.4468065857887268
train--66/100 [329/1090] loss: 0.43822877705097196
train--66/100 [339/1090] loss: 0.44445751905441283
train--66/100 [349/1090] loss: 0.4391329616308212
train--66/100 [359/1090] loss: 0.42414213716983795
train--66/100 [369/1090] loss: 0.4341017156839371
train--66/100 [379/1090] loss: 0.45118175745010375
train--66/100 [389/1090] loss: 0.4494831711053848
train--66/100 [399/1090] loss: 0.4552854269742966
train--66/100 [409/1090] loss: 0.4283118337392807
train--66/100 [419/1090] loss: 0.43587019145488737
train--66/100 [429/1090] loss: 0.43674648106098174
train--66/100 [439/1090] loss: 0.4518432080745697
train--66/100 [449/1090] loss: 0.4450109124183655
train--66/100 [459/1090] loss: 0.45262359380722045
train--66/100 [469/1090] loss: 0.441751292347908
train--66/100 [479/1090] loss: 0.43256724178791045
train--66/100 [489/1090] loss: 0.44147320091724396
train--66/100 [499/1090] loss: 0.4330914318561554
train--66/100 [509/1090] loss: 0.4350683897733688
train--66/100 [519/1090] loss: 0.44297953248023986
train--66/100 [529/1090] loss: 0.4308308720588684
train--66/100 [539/1090] loss: 0.44792805016040804
train--66/100 [549/1090] loss: 0.42573622763156893
train--66/100 [559/1090] loss: 0.4470208376646042
train--66/100 [569/1090] loss: 0.43483091294765475
train--66/100 [579/1090] loss: 0.4607587456703186
train--66/100 [589/1090] loss: 0.43688407838344573
train--66/100 [599/1090] loss: 0.44838316440582277
train--66/100 [609/1090] loss: 0.4335074007511139
train--66/100 [619/1090] loss: 0.4498002052307129
train--66/100 [629/1090] loss: 0.4458811849355698
train--66/100 [639/1090] loss: 0.45284850597381593
train--66/100 [649/1090] loss: 0.45213705599308013
train--66/100 [659/1090] loss: 0.42525356113910673
train--66/100 [669/1090] loss: 0.45434179306030276
train--66/100 [679/1090] loss: 0.4433145821094513
train--66/100 [689/1090] loss: 0.42952045798301697
train--66/100 [699/1090] loss: 0.453738334774971
train--66/100 [709/1090] loss: 0.4359907329082489
train--66/100 [719/1090] loss: 0.4264204680919647
train--66/100 [729/1090] loss: 0.4374226421117783
train--66/100 [739/1090] loss: 0.46176123321056367
train--66/100 [749/1090] loss: 0.47131372690200807
train--66/100 [759/1090] loss: 0.4391100645065308
train--66/100 [769/1090] loss: 0.44567975103855134
train--66/100 [779/1090] loss: 0.43431096971035005
train--66/100 [789/1090] loss: 0.45776119232177737
train--66/100 [799/1090] loss: 0.4443081170320511
train--66/100 [809/1090] loss: 0.44658597409725187
train--66/100 [819/1090] loss: 0.43565560281276705
train--66/100 [829/1090] loss: 0.4497785925865173
train--66/100 [839/1090] loss: 0.4471680223941803
train--66/100 [849/1090] loss: 0.4411365151405334
train--66/100 [859/1090] loss: 0.45478602051734923
train--66/100 [869/1090] loss: 0.45318119823932645
train--66/100 [879/1090] loss: 0.42717274725437165
train--66/100 [889/1090] loss: 0.45285158455371854
train--66/100 [899/1090] loss: 0.45299941301345825
train--66/100 [909/1090] loss: 0.44346498548984525
train--66/100 [919/1090] loss: 0.44672723710536955
train--66/100 [929/1090] loss: 0.42976378500461576
train--66/100 [939/1090] loss: 0.45416044592857363
train--66/100 [949/1090] loss: 0.4404104948043823
train--66/100 [959/1090] loss: 0.4511824667453766
train--66/100 [969/1090] loss: 0.4316374272108078
train--66/100 [979/1090] loss: 0.4424328565597534
train--66/100 [989/1090] loss: 0.44382140040397644
train--66/100 [999/1090] loss: 0.4517554551362991
train--66/100 [1009/1090] loss: 0.43422827422618865
train--66/100 [1019/1090] loss: 0.4266857266426086
train--66/100 [1029/1090] loss: 0.4398177832365036
train--66/100 [1039/1090] loss: 0.449013876914978
train--66/100 [1049/1090] loss: 0.44712142646312714
train--66/100 [1059/1090] loss: 0.46034595668315886
train--66/100 [1069/1090] loss: 0.4466142177581787
train--66/100 [1079/1090] loss: 0.4440715789794922
train--66/100 [1089/1090] loss: 0.44950557947158815
predicting model...
val--66/100 [10/1090] acc: 0.798046875
val--66/100 [20/1090] acc: 0.796875
val--66/100 [30/1090] acc: 0.7963541666666667
val--66/100 [40/1090] acc: 0.79658203125
val--66/100 [50/1090] acc: 0.795703125
val--66/100 [60/1090] acc: 0.7951822916666667
val--66/100 [70/1090] acc: 0.7959263392857143
val--66/100 [80/1090] acc: 0.794921875
val--66/100 [90/1090] acc: 0.7954861111111111
val--66/100 [100/1090] acc: 0.7968359375
val--66/100 [110/1090] acc: 0.7973011363636363
val--66/100 [120/1090] acc: 0.7969401041666667
val--66/100 [130/1090] acc: 0.7979266826923077
val--66/100 [140/1090] acc: 0.7979352678571429
val--66/100 [150/1090] acc: 0.7978645833333333
val--66/100 [160/1090] acc: 0.7980712890625
val--66/100 [170/1090] acc: 0.7979090073529411
val--66/100 [180/1090] acc: 0.7977647569444445
val--66/100 [190/1090] acc: 0.7984580592105263
val--66/100 [200/1090] acc: 0.79853515625
val--66/100 [210/1090] acc: 0.7988839285714285
val--66/100 [220/1090] acc: 0.7980113636363636
val--66/100 [230/1090] acc: 0.7984884510869565
val--66/100 [240/1090] acc: 0.7982096354166667
val--66/100 [250/1090] acc: 0.798375
val--66/100 [260/1090] acc: 0.7983924278846154
val--66/100 [270/1090] acc: 0.7986979166666667
val--66/100 [280/1090] acc: 0.7985212053571429
val--66/100 [290/1090] acc: 0.7984509698275862
val--66/100 [300/1090] acc: 0.7985416666666667
val--66/100 [310/1090] acc: 0.7984375
val--66/100 [320/1090] acc: 0.7985595703125
val--66/100 [330/1090] acc: 0.7987097537878788
val--66/100 [340/1090] acc: 0.7988166360294118
val--66/100 [350/1090] acc: 0.7988839285714285
val--66/100 [360/1090] acc: 0.798828125
val--66/100 [370/1090] acc: 0.7988597972972973
val--66/100 [380/1090] acc: 0.7988178453947369
val--66/100 [390/1090] acc: 0.7987279647435898
val--66/100 [400/1090] acc: 0.79869140625
val--66/100 [410/1090] acc: 0.7987995426829269
val--66/100 [420/1090] acc: 0.7987444196428571
val--66/100 [430/1090] acc: 0.7985192587209302
val--66/100 [440/1090] acc: 0.7985174005681818
val--66/100 [450/1090] acc: 0.7983680555555556
val--66/100 [460/1090] acc: 0.7981997282608696
val--66/100 [470/1090] acc: 0.7981050531914894
val--66/100 [480/1090] acc: 0.7980712890625
val--66/100 [490/1090] acc: 0.7982222576530612
val--66/100 [500/1090] acc: 0.7983125
val--66/100 [510/1090] acc: 0.7981311274509804
val--66/100 [520/1090] acc: 0.7984074519230769
val--66/100 [530/1090] acc: 0.7983859080188679
val--66/100 [540/1090] acc: 0.7984953703703703
val--66/100 [550/1090] acc: 0.798409090909091
val--66/100 [560/1090] acc: 0.7982282366071428
val--66/100 [570/1090] acc: 0.7979235197368421
val--66/100 [580/1090] acc: 0.7978785021551724
val--66/100 [590/1090] acc: 0.7978614936440678
val--66/100 [600/1090] acc: 0.7978841145833333
val--66/100 [610/1090] acc: 0.797797131147541
val--66/100 [620/1090] acc: 0.7977129536290323
val--66/100 [630/1090] acc: 0.7979910714285714
val--66/100 [640/1090] acc: 0.79813232421875
val--66/100 [650/1090] acc: 0.7981310096153846
val--66/100 [660/1090] acc: 0.7980705492424243
val--66/100 [670/1090] acc: 0.7978194962686567
val--66/100 [680/1090] acc: 0.7976619944852941
val--66/100 [690/1090] acc: 0.7978260869565217
val--66/100 [700/1090] acc: 0.7978571428571428
val--66/100 [710/1090] acc: 0.7977332746478873
val--66/100 [720/1090] acc: 0.7975857204861111
val--66/100 [730/1090] acc: 0.7975438784246576
val--66/100 [740/1090] acc: 0.7975031672297297
val--66/100 [750/1090] acc: 0.7975572916666667
val--66/100 [760/1090] acc: 0.7976768092105263
val--66/100 [770/1090] acc: 0.7976359577922078
val--66/100 [780/1090] acc: 0.7975610977564103
val--66/100 [790/1090] acc: 0.7976117484177215
val--66/100 [800/1090] acc: 0.797841796875
val--66/100 [810/1090] acc: 0.7978780864197531
val--66/100 [820/1090] acc: 0.7979706554878049
val--66/100 [830/1090] acc: 0.798023343373494
val--66/100 [840/1090] acc: 0.7980096726190476
val--66/100 [850/1090] acc: 0.7980330882352941
val--66/100 [860/1090] acc: 0.798328488372093
val--66/100 [870/1090] acc: 0.7982444324712644
val--66/100 [880/1090] acc: 0.7982421875
val--66/100 [890/1090] acc: 0.7983672752808989
val--66/100 [900/1090] acc: 0.7983637152777778
val--66/100 [910/1090] acc: 0.7983731112637362
val--66/100 [920/1090] acc: 0.7983992866847827
val--66/100 [930/1090] acc: 0.7985047043010752
val--66/100 [940/1090] acc: 0.7985372340425532
val--66/100 [950/1090] acc: 0.7984827302631579
val--66/100 [960/1090] acc: 0.7984049479166667
val--66/100 [970/1090] acc: 0.7983730670103093
val--66/100 [980/1090] acc: 0.7984175701530613
val--66/100 [990/1090] acc: 0.798342803030303
val--66/100 [1000/1090] acc: 0.79827734375
val--66/100 [1010/1090] acc: 0.7980932858910891
val--66/100 [1020/1090] acc: 0.7981579350490197
val--66/100 [1030/1090] acc: 0.7981985740291262
val--66/100 [1040/1090] acc: 0.7981858473557693
val--66/100 [1050/1090] acc: 0.7982068452380953
val--66/100 [1060/1090] acc: 0.7981426886792453
val--66/100 [1070/1090] acc: 0.7981052862149532
val--66/100 [1080/1090] acc: 0.7980504918981481
val--66/100 [1090/1090] acc: 0.7978676892201835
epoch= 66, accuracy= 0.797868, rmse= 0.375996, auc= 0.857482
train--67/100 [9/1090] loss: 0.40368905663490295
train--67/100 [19/1090] loss: 0.4345691859722137
train--67/100 [29/1090] loss: 0.426530721783638
train--67/100 [39/1090] loss: 0.42735415101051333
train--67/100 [49/1090] loss: 0.4366298645734787
train--67/100 [59/1090] loss: 0.44083990454673766
train--67/100 [69/1090] loss: 0.4450776487588882
train--67/100 [79/1090] loss: 0.4318441033363342
train--67/100 [89/1090] loss: 0.43857745826244354
train--67/100 [99/1090] loss: 0.4599586188793182
train--67/100 [109/1090] loss: 0.41644963920116423
train--67/100 [119/1090] loss: 0.4355571806430817
train--67/100 [129/1090] loss: 0.44983033239841463
train--67/100 [139/1090] loss: 0.43709033727645874
train--67/100 [149/1090] loss: 0.4509310156106949
train--67/100 [159/1090] loss: 0.4463952422142029
train--67/100 [169/1090] loss: 0.43873883187770846
train--67/100 [179/1090] loss: 0.43995297253131865
train--67/100 [189/1090] loss: 0.4474959343671799
train--67/100 [199/1090] loss: 0.4349755227565765
train--67/100 [209/1090] loss: 0.45783690810203553
train--67/100 [219/1090] loss: 0.4554972261190414
train--67/100 [229/1090] loss: 0.43785987198352816
train--67/100 [239/1090] loss: 0.42680902779102325
train--67/100 [249/1090] loss: 0.4350473195314407
train--67/100 [259/1090] loss: 0.42268777191638945
train--67/100 [269/1090] loss: 0.44280106127262114
train--67/100 [279/1090] loss: 0.4587857037782669
train--67/100 [289/1090] loss: 0.4411689579486847
train--67/100 [299/1090] loss: 0.42395787835121157
train--67/100 [309/1090] loss: 0.4515227645635605
train--67/100 [319/1090] loss: 0.4349755227565765
train--67/100 [329/1090] loss: 0.4417576938867569
train--67/100 [339/1090] loss: 0.44714856445789336
train--67/100 [349/1090] loss: 0.4351265847682953
train--67/100 [359/1090] loss: 0.4512329071760178
train--67/100 [369/1090] loss: 0.44346073269844055
train--67/100 [379/1090] loss: 0.44144768118858335
train--67/100 [389/1090] loss: 0.4414017766714096
train--67/100 [399/1090] loss: 0.4221253961324692
train--67/100 [409/1090] loss: 0.44177266061306
train--67/100 [419/1090] loss: 0.42893737852573394
train--67/100 [429/1090] loss: 0.44594199359416964
train--67/100 [439/1090] loss: 0.44949193596839904
train--67/100 [449/1090] loss: 0.4544372111558914
train--67/100 [459/1090] loss: 0.43419493436813356
train--67/100 [469/1090] loss: 0.43737753033638
train--67/100 [479/1090] loss: 0.4404414087533951
train--67/100 [489/1090] loss: 0.448304682970047
train--67/100 [499/1090] loss: 0.4686277866363525
train--67/100 [509/1090] loss: 0.4170221656560898
train--67/100 [519/1090] loss: 0.43948169350624083
train--67/100 [529/1090] loss: 0.4260342448949814
train--67/100 [539/1090] loss: 0.4415643185377121
train--67/100 [549/1090] loss: 0.4494019627571106
train--67/100 [559/1090] loss: 0.4407908469438553
train--67/100 [569/1090] loss: 0.44146873354911803
train--67/100 [579/1090] loss: 0.4333040237426758
train--67/100 [589/1090] loss: 0.43512428998947145
train--67/100 [599/1090] loss: 0.4547364503145218
train--67/100 [609/1090] loss: 0.4328447788953781
train--67/100 [619/1090] loss: 0.4535621017217636
train--67/100 [629/1090] loss: 0.4530382513999939
train--67/100 [639/1090] loss: 0.42464181780815125
train--67/100 [649/1090] loss: 0.4421060264110565
train--67/100 [659/1090] loss: 0.4418216377496719
train--67/100 [669/1090] loss: 0.43246992230415343
train--67/100 [679/1090] loss: 0.44800146520137785
train--67/100 [689/1090] loss: 0.44260129928588865
train--67/100 [699/1090] loss: 0.432352152466774
train--67/100 [709/1090] loss: 0.4546031951904297
train--67/100 [719/1090] loss: 0.4472733348608017
train--67/100 [729/1090] loss: 0.42593662440776825
train--67/100 [739/1090] loss: 0.4464735597372055
train--67/100 [749/1090] loss: 0.42867525219917296
train--67/100 [759/1090] loss: 0.4444118231534958
train--67/100 [769/1090] loss: 0.44775456488132476
train--67/100 [779/1090] loss: 0.43589860796928404
train--67/100 [789/1090] loss: 0.4610771954059601
train--67/100 [799/1090] loss: 0.450530469417572
train--67/100 [809/1090] loss: 0.4564781069755554
train--67/100 [819/1090] loss: 0.45699790120124817
train--67/100 [829/1090] loss: 0.43875917196273806
train--67/100 [839/1090] loss: 0.42800308763980865
train--67/100 [849/1090] loss: 0.4413780301809311
train--67/100 [859/1090] loss: 0.45103720426559446
train--67/100 [869/1090] loss: 0.4516815274953842
train--67/100 [879/1090] loss: 0.4501096934080124
train--67/100 [889/1090] loss: 0.4419586509466171
train--67/100 [899/1090] loss: 0.44758789241313934
train--67/100 [909/1090] loss: 0.4191439688205719
train--67/100 [919/1090] loss: 0.44343605637550354
train--67/100 [929/1090] loss: 0.44553062617778777
train--67/100 [939/1090] loss: 0.4252230614423752
train--67/100 [949/1090] loss: 0.45437478125095365
train--67/100 [959/1090] loss: 0.44347700476646423
train--67/100 [969/1090] loss: 0.44489213526248933
train--67/100 [979/1090] loss: 0.44412354826927186
train--67/100 [989/1090] loss: 0.44825642108917235
train--67/100 [999/1090] loss: 0.46157568097114565
train--67/100 [1009/1090] loss: 0.4375153422355652
train--67/100 [1019/1090] loss: 0.4440093576908112
train--67/100 [1029/1090] loss: 0.4225739598274231
train--67/100 [1039/1090] loss: 0.44191332161426544
train--67/100 [1049/1090] loss: 0.43288923501968385
train--67/100 [1059/1090] loss: 0.437040713429451
train--67/100 [1069/1090] loss: 0.4315683811903
train--67/100 [1079/1090] loss: 0.4471845656633377
train--67/100 [1089/1090] loss: 0.44864230453968046
predicting model...
val--67/100 [10/1090] acc: 0.79921875
val--67/100 [20/1090] acc: 0.7986328125
val--67/100 [30/1090] acc: 0.797265625
val--67/100 [40/1090] acc: 0.79736328125
val--67/100 [50/1090] acc: 0.796796875
val--67/100 [60/1090] acc: 0.7962239583333334
val--67/100 [70/1090] acc: 0.7965401785714286
val--67/100 [80/1090] acc: 0.795556640625
val--67/100 [90/1090] acc: 0.7957465277777778
val--67/100 [100/1090] acc: 0.7969140625
val--67/100 [110/1090] acc: 0.7971946022727273
val--67/100 [120/1090] acc: 0.796875
val--67/100 [130/1090] acc: 0.7979867788461539
val--67/100 [140/1090] acc: 0.7979352678571429
val--67/100 [150/1090] acc: 0.7979427083333334
val--67/100 [160/1090] acc: 0.7979736328125
val--67/100 [170/1090] acc: 0.7978630514705882
val--67/100 [180/1090] acc: 0.7978732638888889
val--67/100 [190/1090] acc: 0.7986225328947368
val--67/100 [200/1090] acc: 0.79884765625
val--67/100 [210/1090] acc: 0.7991815476190476
val--67/100 [220/1090] acc: 0.7981711647727273
val--67/100 [230/1090] acc: 0.7987771739130435
val--67/100 [240/1090] acc: 0.7984375
val--67/100 [250/1090] acc: 0.7986875
val--67/100 [260/1090] acc: 0.7986478365384615
val--67/100 [270/1090] acc: 0.7989149305555555
val--67/100 [280/1090] acc: 0.7986607142857143
val--67/100 [290/1090] acc: 0.7986395474137931
val--67/100 [300/1090] acc: 0.7987369791666666
val--67/100 [310/1090] acc: 0.798500504032258
val--67/100 [320/1090] acc: 0.7987060546875
val--67/100 [330/1090] acc: 0.7988399621212121
val--67/100 [340/1090] acc: 0.798977481617647
val--67/100 [350/1090] acc: 0.7991071428571429
val--67/100 [360/1090] acc: 0.7990559895833333
val--67/100 [370/1090] acc: 0.7991026182432432
val--67/100 [380/1090] acc: 0.7990645559210526
val--67/100 [390/1090] acc: 0.7989583333333333
val--67/100 [400/1090] acc: 0.798994140625
val--67/100 [410/1090] acc: 0.799123475609756
val--67/100 [420/1090] acc: 0.7990048363095238
val--67/100 [430/1090] acc: 0.7987554505813953
val--67/100 [440/1090] acc: 0.7987127130681818
val--67/100 [450/1090] acc: 0.7985243055555555
val--67/100 [460/1090] acc: 0.7984375
val--67/100 [470/1090] acc: 0.7983045212765958
val--67/100 [480/1090] acc: 0.798291015625
val--67/100 [490/1090] acc: 0.7984056122448979
val--67/100 [500/1090] acc: 0.7984921875
val--67/100 [510/1090] acc: 0.7983379289215686
val--67/100 [520/1090] acc: 0.7986478365384615
val--67/100 [530/1090] acc: 0.7986143867924528
val--67/100 [540/1090] acc: 0.7987413194444445
val--67/100 [550/1090] acc: 0.7986150568181818
val--67/100 [560/1090] acc: 0.7983816964285714
val--67/100 [570/1090] acc: 0.7981291118421052
val--67/100 [580/1090] acc: 0.798114224137931
val--67/100 [590/1090] acc: 0.7981461864406779
val--67/100 [600/1090] acc: 0.79818359375
val--67/100 [610/1090] acc: 0.798155737704918
val--67/100 [620/1090] acc: 0.7980405745967742
val--67/100 [630/1090] acc: 0.7983072916666667
val--67/100 [640/1090] acc: 0.7984619140625
val--67/100 [650/1090] acc: 0.7984975961538462
val--67/100 [660/1090] acc: 0.7984138257575758
val--67/100 [670/1090] acc: 0.7981459888059701
val--67/100 [680/1090] acc: 0.798000919117647
val--67/100 [690/1090] acc: 0.7981261322463769
val--67/100 [700/1090] acc: 0.7981640625
val--67/100 [710/1090] acc: 0.7980138644366197
val--67/100 [720/1090] acc: 0.7978895399305556
val--67/100 [730/1090] acc: 0.7978328339041096
val--67/100 [740/1090] acc: 0.7977723817567568
val--67/100 [750/1090] acc: 0.797828125
val--67/100 [760/1090] acc: 0.7979235197368421
val--67/100 [770/1090] acc: 0.7978388798701299
val--67/100 [780/1090] acc: 0.7977664262820513
val--67/100 [790/1090] acc: 0.7977600870253164
val--67/100 [800/1090] acc: 0.7979833984375
val--67/100 [810/1090] acc: 0.7980324074074074
val--67/100 [820/1090] acc: 0.7981088033536585
val--67/100 [830/1090] acc: 0.7981504141566265
val--67/100 [840/1090] acc: 0.7981119791666667
val--67/100 [850/1090] acc: 0.7981341911764706
val--67/100 [860/1090] acc: 0.7983920784883721
val--67/100 [870/1090] acc: 0.7983117816091954
val--67/100 [880/1090] acc: 0.7983354048295455
val--67/100 [890/1090] acc: 0.7984770014044944
val--67/100 [900/1090] acc: 0.7984548611111111
val--67/100 [910/1090] acc: 0.7984246222527472
val--67/100 [920/1090] acc: 0.7984672214673914
val--67/100 [930/1090] acc: 0.798538306451613
val--67/100 [940/1090] acc: 0.7985413896276595
val--67/100 [950/1090] acc: 0.7984621710526316
val--67/100 [960/1090] acc: 0.79840087890625
val--67/100 [970/1090] acc: 0.7983650128865979
val--67/100 [980/1090] acc: 0.7983498086734694
val--67/100 [990/1090] acc: 0.7982599431818181
val--67/100 [1000/1090] acc: 0.7981640625
val--67/100 [1010/1090] acc: 0.7979772586633663
val--67/100 [1020/1090] acc: 0.7980430453431373
val--67/100 [1030/1090] acc: 0.798046875
val--67/100 [1040/1090] acc: 0.7980506310096154
val--67/100 [1050/1090] acc: 0.7980840773809523
val--67/100 [1060/1090] acc: 0.7980321344339623
val--67/100 [1070/1090] acc: 0.7980030665887851
val--67/100 [1080/1090] acc: 0.7979528356481481
val--67/100 [1090/1090] acc: 0.7977709288990825
epoch= 67, accuracy= 0.797771, rmse= 0.375935, auc= 0.857503
train--68/100 [9/1090] loss: 0.38248156309127807
train--68/100 [19/1090] loss: 0.4192343682050705
train--68/100 [29/1090] loss: 0.4499668747186661
train--68/100 [39/1090] loss: 0.4406188040971756
train--68/100 [49/1090] loss: 0.43047537803649905
train--68/100 [59/1090] loss: 0.4504328280687332
train--68/100 [69/1090] loss: 0.4395345687866211
train--68/100 [79/1090] loss: 0.4384372740983963
train--68/100 [89/1090] loss: 0.42820669412612916
train--68/100 [99/1090] loss: 0.4377128005027771
train--68/100 [109/1090] loss: 0.45499311089515687
train--68/100 [119/1090] loss: 0.4487369507551193
train--68/100 [129/1090] loss: 0.42405484318733216
train--68/100 [139/1090] loss: 0.43547338247299194
train--68/100 [149/1090] loss: 0.4344933062791824
train--68/100 [159/1090] loss: 0.4311739832162857
train--68/100 [169/1090] loss: 0.44837540090084077
train--68/100 [179/1090] loss: 0.4232234388589859
train--68/100 [189/1090] loss: 0.4395597010850906
train--68/100 [199/1090] loss: 0.44230799973011015
train--68/100 [209/1090] loss: 0.4416629523038864
train--68/100 [219/1090] loss: 0.4418869405984879
train--68/100 [229/1090] loss: 0.44721519351005556
train--68/100 [239/1090] loss: 0.4545042634010315
train--68/100 [249/1090] loss: 0.4378168374300003
train--68/100 [259/1090] loss: 0.42112760841846464
train--68/100 [269/1090] loss: 0.43532817661762235
train--68/100 [279/1090] loss: 0.4361784338951111
train--68/100 [289/1090] loss: 0.43353419899940493
train--68/100 [299/1090] loss: 0.43905269503593447
train--68/100 [309/1090] loss: 0.45382115840911863
train--68/100 [319/1090] loss: 0.45218563377857207
train--68/100 [329/1090] loss: 0.42767761647701263
train--68/100 [339/1090] loss: 0.4473953664302826
train--68/100 [349/1090] loss: 0.434187525510788
train--68/100 [359/1090] loss: 0.4504996448755264
train--68/100 [369/1090] loss: 0.43508895933628083
train--68/100 [379/1090] loss: 0.44962131381034853
train--68/100 [389/1090] loss: 0.4539975643157959
train--68/100 [399/1090] loss: 0.4399978339672089
train--68/100 [409/1090] loss: 0.41658635437488556
train--68/100 [419/1090] loss: 0.44862607419490813
train--68/100 [429/1090] loss: 0.45754762887954714
train--68/100 [439/1090] loss: 0.4467725455760956
train--68/100 [449/1090] loss: 0.42654580175876616
train--68/100 [459/1090] loss: 0.4359937936067581
train--68/100 [469/1090] loss: 0.44734533727169035
train--68/100 [479/1090] loss: 0.43812417387962344
train--68/100 [489/1090] loss: 0.4325784891843796
train--68/100 [499/1090] loss: 0.4459552258253098
train--68/100 [509/1090] loss: 0.43507052958011627
train--68/100 [519/1090] loss: 0.4350379556417465
train--68/100 [529/1090] loss: 0.44161329567432406
train--68/100 [539/1090] loss: 0.4297706961631775
train--68/100 [549/1090] loss: 0.436734801530838
train--68/100 [559/1090] loss: 0.42726404368877413
train--68/100 [569/1090] loss: 0.44951472282409666
train--68/100 [579/1090] loss: 0.44449823200702665
train--68/100 [589/1090] loss: 0.43454883694648744
train--68/100 [599/1090] loss: 0.4281548738479614
train--68/100 [609/1090] loss: 0.45388744175434115
train--68/100 [619/1090] loss: 0.43521691858768463
train--68/100 [629/1090] loss: 0.4477624624967575
train--68/100 [639/1090] loss: 0.44281773269176483
train--68/100 [649/1090] loss: 0.4566429525613785
train--68/100 [659/1090] loss: 0.4490785539150238
train--68/100 [669/1090] loss: 0.43826608657836913
train--68/100 [679/1090] loss: 0.4296699970960617
train--68/100 [689/1090] loss: 0.454810106754303
train--68/100 [699/1090] loss: 0.4368857115507126
train--68/100 [709/1090] loss: 0.4262331336736679
train--68/100 [719/1090] loss: 0.43938670456409457
train--68/100 [729/1090] loss: 0.44506341516971587
train--68/100 [739/1090] loss: 0.42674743831157685
train--68/100 [749/1090] loss: 0.45211062431335447
train--68/100 [759/1090] loss: 0.458922079205513
train--68/100 [769/1090] loss: 0.4244175493717194
train--68/100 [779/1090] loss: 0.43187000751495364
train--68/100 [789/1090] loss: 0.44945901036262514
train--68/100 [799/1090] loss: 0.4562988609075546
train--68/100 [809/1090] loss: 0.4412020444869995
train--68/100 [819/1090] loss: 0.4276999145746231
train--68/100 [829/1090] loss: 0.4430488467216492
train--68/100 [839/1090] loss: 0.4436634689569473
train--68/100 [849/1090] loss: 0.4464871257543564
train--68/100 [859/1090] loss: 0.44521365463733675
train--68/100 [869/1090] loss: 0.440616250038147
train--68/100 [879/1090] loss: 0.4596073776483536
train--68/100 [889/1090] loss: 0.42047645449638366
train--68/100 [899/1090] loss: 0.43785504102706907
train--68/100 [909/1090] loss: 0.43429283499717714
train--68/100 [919/1090] loss: 0.4523714154958725
train--68/100 [929/1090] loss: 0.4398386687040329
train--68/100 [939/1090] loss: 0.44920721650123596
train--68/100 [949/1090] loss: 0.4609722465276718
train--68/100 [959/1090] loss: 0.4408746600151062
train--68/100 [969/1090] loss: 0.43955389559268954
train--68/100 [979/1090] loss: 0.4462792009115219
train--68/100 [989/1090] loss: 0.45517504811286924
train--68/100 [999/1090] loss: 0.4360960066318512
train--68/100 [1009/1090] loss: 0.45276002287864686
train--68/100 [1019/1090] loss: 0.4482632905244827
train--68/100 [1029/1090] loss: 0.4490634649991989
train--68/100 [1039/1090] loss: 0.44631246030330657
train--68/100 [1049/1090] loss: 0.4531111031770706
train--68/100 [1059/1090] loss: 0.4403799682855606
train--68/100 [1069/1090] loss: 0.44779808521270753
train--68/100 [1079/1090] loss: 0.4518527925014496
train--68/100 [1089/1090] loss: 0.45482640266418456
predicting model...
val--68/100 [10/1090] acc: 0.7984375
val--68/100 [20/1090] acc: 0.798046875
val--68/100 [30/1090] acc: 0.7971354166666667
val--68/100 [40/1090] acc: 0.7970703125
val--68/100 [50/1090] acc: 0.796640625
val--68/100 [60/1090] acc: 0.7957682291666667
val--68/100 [70/1090] acc: 0.7959263392857143
val--68/100 [80/1090] acc: 0.79501953125
val--68/100 [90/1090] acc: 0.7956163194444444
val--68/100 [100/1090] acc: 0.7968359375
val--68/100 [110/1090] acc: 0.7972301136363636
val--68/100 [120/1090] acc: 0.7970377604166666
val--68/100 [130/1090] acc: 0.7981069711538461
val--68/100 [140/1090] acc: 0.7981026785714286
val--68/100 [150/1090] acc: 0.798203125
val--68/100 [160/1090] acc: 0.79833984375
val--68/100 [170/1090] acc: 0.7981158088235294
val--68/100 [180/1090] acc: 0.7978732638888889
val--68/100 [190/1090] acc: 0.7986430921052632
val--68/100 [200/1090] acc: 0.79884765625
val--68/100 [210/1090] acc: 0.7990885416666667
val--68/100 [220/1090] acc: 0.798153409090909
val--68/100 [230/1090] acc: 0.7987092391304348
val--68/100 [240/1090] acc: 0.7983561197916667
val--68/100 [250/1090] acc: 0.79846875
val--68/100 [260/1090] acc: 0.7984224759615385
val--68/100 [270/1090] acc: 0.7987413194444445
val--68/100 [280/1090] acc: 0.7986607142857143
val--68/100 [290/1090] acc: 0.7986530172413793
val--68/100 [300/1090] acc: 0.7987630208333333
val--68/100 [310/1090] acc: 0.7985635080645161
val--68/100 [320/1090] acc: 0.79873046875
val--68/100 [330/1090] acc: 0.7988991477272728
val--68/100 [340/1090] acc: 0.7989545036764706
val--68/100 [350/1090] acc: 0.7990736607142858
val--68/100 [360/1090] acc: 0.7989691840277777
val--68/100 [370/1090] acc: 0.7990287162162162
val--68/100 [380/1090] acc: 0.7989720394736842
val--68/100 [390/1090] acc: 0.7988882211538462
val--68/100 [400/1090] acc: 0.79884765625
val--68/100 [410/1090] acc: 0.7990186737804879
val--68/100 [420/1090] acc: 0.7989397321428572
val--68/100 [430/1090] acc: 0.7986191860465116
val--68/100 [440/1090] acc: 0.7986150568181818
val--68/100 [450/1090] acc: 0.7984722222222222
val--68/100 [460/1090] acc: 0.7983525815217392
val--68/100 [470/1090] acc: 0.7982297207446809
val--68/100 [480/1090] acc: 0.7982177734375
val--68/100 [490/1090] acc: 0.7983577806122449
val--68/100 [500/1090] acc: 0.798453125
val--68/100 [510/1090] acc: 0.7982919730392157
val--68/100 [520/1090] acc: 0.79853515625
val--68/100 [530/1090] acc: 0.7984743514150944
val--68/100 [540/1090] acc: 0.7985677083333333
val--68/100 [550/1090] acc: 0.7984943181818182
val--68/100 [560/1090] acc: 0.798291015625
val--68/100 [570/1090] acc: 0.7980331688596491
val--68/100 [580/1090] acc: 0.7980064655172414
val--68/100 [590/1090] acc: 0.7980534957627119
val--68/100 [600/1090] acc: 0.798046875
val--68/100 [610/1090] acc: 0.7980020491803279
val--68/100 [620/1090] acc: 0.7979208669354839
val--68/100 [630/1090] acc: 0.7981336805555556
val--68/100 [640/1090] acc: 0.7982666015625
val--68/100 [650/1090] acc: 0.7982872596153846
val--68/100 [660/1090] acc: 0.7982421875
val--68/100 [670/1090] acc: 0.7980118936567164
val--68/100 [680/1090] acc: 0.7978745404411764
val--68/100 [690/1090] acc: 0.7980242300724638
val--68/100 [700/1090] acc: 0.7980245535714285
val--68/100 [710/1090] acc: 0.7978708186619718
val--68/100 [720/1090] acc: 0.7976942274305555
val--68/100 [730/1090] acc: 0.7976241438356164
val--68/100 [740/1090] acc: 0.7975717905405405
val--68/100 [750/1090] acc: 0.797609375
val--68/100 [760/1090] acc: 0.7976870888157894
val--68/100 [770/1090] acc: 0.7976207386363636
val--68/100 [780/1090] acc: 0.7975210336538462
val--68/100 [790/1090] acc: 0.7975474683544304
val--68/100 [800/1090] acc: 0.7977783203125
val--68/100 [810/1090] acc: 0.7978395061728395
val--68/100 [820/1090] acc: 0.7979373094512195
val--68/100 [830/1090] acc: 0.7979621611445783
val--68/100 [840/1090] acc: 0.797939918154762
val--68/100 [850/1090] acc: 0.7979779411764706
val--68/100 [860/1090] acc: 0.7982421875
val--68/100 [870/1090] acc: 0.7981546336206896
val--68/100 [880/1090] acc: 0.7981356534090909
val--68/100 [890/1090] acc: 0.7982751053370787
val--68/100 [900/1090] acc: 0.7982725694444445
val--68/100 [910/1090] acc: 0.7982700892857143
val--68/100 [920/1090] acc: 0.7983058763586957
val--68/100 [930/1090] acc: 0.7983660954301075
val--68/100 [940/1090] acc: 0.798383477393617
val--68/100 [950/1090] acc: 0.7983223684210526
val--68/100 [960/1090] acc: 0.7982584635416666
val--68/100 [970/1090] acc: 0.7981918492268041
val--68/100 [980/1090] acc: 0.7982222576530612
val--68/100 [990/1090] acc: 0.7981297348484848
val--68/100 [1000/1090] acc: 0.7980390625
val--68/100 [1010/1090] acc: 0.7978573638613862
val--68/100 [1020/1090] acc: 0.7979396446078432
val--68/100 [1030/1090] acc: 0.7979634405339806
val--68/100 [1040/1090] acc: 0.7979679987980769
val--68/100 [1050/1090] acc: 0.7980096726190476
val--68/100 [1060/1090] acc: 0.7979584316037736
val--68/100 [1070/1090] acc: 0.7979044976635514
val--68/100 [1080/1090] acc: 0.7978479456018519
val--68/100 [1090/1090] acc: 0.7976634174311926
epoch= 68, accuracy= 0.797663, rmse= 0.375931, auc= 0.857569
train--69/100 [9/1090] loss: 0.3935402661561966
train--69/100 [19/1090] loss: 0.4345168828964233
train--69/100 [29/1090] loss: 0.4426340013742447
train--69/100 [39/1090] loss: 0.4737866699695587
train--69/100 [49/1090] loss: 0.44942833483219147
train--69/100 [59/1090] loss: 0.43361225724220276
train--69/100 [69/1090] loss: 0.45820480287075044
train--69/100 [79/1090] loss: 0.4423472762107849
train--69/100 [89/1090] loss: 0.42930765450000763
train--69/100 [99/1090] loss: 0.43610926270484923
train--69/100 [109/1090] loss: 0.42310830652713777
train--69/100 [119/1090] loss: 0.4299389958381653
train--69/100 [129/1090] loss: 0.43467044830322266
train--69/100 [139/1090] loss: 0.44120278358459475
train--69/100 [149/1090] loss: 0.43313204050064086
train--69/100 [159/1090] loss: 0.43504858314990996
train--69/100 [169/1090] loss: 0.445867657661438
train--69/100 [179/1090] loss: 0.4435523867607117
train--69/100 [189/1090] loss: 0.443777534365654
train--69/100 [199/1090] loss: 0.4432121396064758
train--69/100 [209/1090] loss: 0.4441984981298447
train--69/100 [219/1090] loss: 0.43824570775032046
train--69/100 [229/1090] loss: 0.44100656509399416
train--69/100 [239/1090] loss: 0.44685713946819305
train--69/100 [249/1090] loss: 0.4501527577638626
train--69/100 [259/1090] loss: 0.43381487727165224
train--69/100 [269/1090] loss: 0.4381132960319519
train--69/100 [279/1090] loss: 0.429966539144516
train--69/100 [289/1090] loss: 0.4311652183532715
train--69/100 [299/1090] loss: 0.43616931736469267
train--69/100 [309/1090] loss: 0.4355542063713074
train--69/100 [319/1090] loss: 0.44668281376361846
train--69/100 [329/1090] loss: 0.43178983628749845
train--69/100 [339/1090] loss: 0.44307324290275574
train--69/100 [349/1090] loss: 0.43358211815357206
train--69/100 [359/1090] loss: 0.4377249270677567
train--69/100 [369/1090] loss: 0.4442775309085846
train--69/100 [379/1090] loss: 0.453590327501297
train--69/100 [389/1090] loss: 0.4318642675876617
train--69/100 [399/1090] loss: 0.4558890163898468
train--69/100 [409/1090] loss: 0.4538817167282104
train--69/100 [419/1090] loss: 0.44847261607646943
train--69/100 [429/1090] loss: 0.45052096247673035
train--69/100 [439/1090] loss: 0.45331424474716187
train--69/100 [449/1090] loss: 0.44106117486953733
train--69/100 [459/1090] loss: 0.4299400895833969
train--69/100 [469/1090] loss: 0.4404798686504364
train--69/100 [479/1090] loss: 0.43394839465618135
train--69/100 [489/1090] loss: 0.439641872048378
train--69/100 [499/1090] loss: 0.44079025089740753
train--69/100 [509/1090] loss: 0.45983744561672213
train--69/100 [519/1090] loss: 0.4279071420431137
train--69/100 [529/1090] loss: 0.4321323335170746
train--69/100 [539/1090] loss: 0.44151028990745544
train--69/100 [549/1090] loss: 0.43819320499897
train--69/100 [559/1090] loss: 0.4546044796705246
train--69/100 [569/1090] loss: 0.4520396739244461
train--69/100 [579/1090] loss: 0.4431694090366364
train--69/100 [589/1090] loss: 0.4485070466995239
train--69/100 [599/1090] loss: 0.44929792582988737
train--69/100 [609/1090] loss: 0.45747982561588285
train--69/100 [619/1090] loss: 0.4515195280313492
train--69/100 [629/1090] loss: 0.44419646859169004
train--69/100 [639/1090] loss: 0.44241645038127897
train--69/100 [649/1090] loss: 0.4485423147678375
train--69/100 [659/1090] loss: 0.4534875750541687
train--69/100 [669/1090] loss: 0.4411534547805786
train--69/100 [679/1090] loss: 0.43365672826766966
train--69/100 [689/1090] loss: 0.4537994980812073
train--69/100 [699/1090] loss: 0.4374863415956497
train--69/100 [709/1090] loss: 0.42673954367637634
train--69/100 [719/1090] loss: 0.4263020187616348
train--69/100 [729/1090] loss: 0.43971065878868104
train--69/100 [739/1090] loss: 0.45102732479572294
train--69/100 [749/1090] loss: 0.45388777256011964
train--69/100 [759/1090] loss: 0.4656509578227997
train--69/100 [769/1090] loss: 0.43606491982936857
train--69/100 [779/1090] loss: 0.4249361753463745
train--69/100 [789/1090] loss: 0.4417057275772095
train--69/100 [799/1090] loss: 0.43394929766654966
train--69/100 [809/1090] loss: 0.43558776676654815
train--69/100 [819/1090] loss: 0.4320836365222931
train--69/100 [829/1090] loss: 0.4392763763666153
train--69/100 [839/1090] loss: 0.43026299178600313
train--69/100 [849/1090] loss: 0.42014701962471007
train--69/100 [859/1090] loss: 0.45524588525295256
train--69/100 [869/1090] loss: 0.45418301820755
train--69/100 [879/1090] loss: 0.44851204454898835
train--69/100 [889/1090] loss: 0.43066151440143585
train--69/100 [899/1090] loss: 0.43784070014953613
train--69/100 [909/1090] loss: 0.4192760646343231
train--69/100 [919/1090] loss: 0.4208748996257782
train--69/100 [929/1090] loss: 0.451316824555397
train--69/100 [939/1090] loss: 0.42618978321552276
train--69/100 [949/1090] loss: 0.442835932970047
train--69/100 [959/1090] loss: 0.44833036661148074
train--69/100 [969/1090] loss: 0.4428732544183731
train--69/100 [979/1090] loss: 0.4547384947538376
train--69/100 [989/1090] loss: 0.45168725252151487
train--69/100 [999/1090] loss: 0.4309979796409607
train--69/100 [1009/1090] loss: 0.42890592515468595
train--69/100 [1019/1090] loss: 0.4278764069080353
train--69/100 [1029/1090] loss: 0.43922348916530607
train--69/100 [1039/1090] loss: 0.4409546822309494
train--69/100 [1049/1090] loss: 0.43899070024490355
train--69/100 [1059/1090] loss: 0.44598334431648257
train--69/100 [1069/1090] loss: 0.4394802778959274
train--69/100 [1079/1090] loss: 0.447077476978302
train--69/100 [1089/1090] loss: 0.43470528721809387
predicting model...
val--69/100 [10/1090] acc: 0.797265625
val--69/100 [20/1090] acc: 0.7953125
val--69/100 [30/1090] acc: 0.7951822916666667
val--69/100 [40/1090] acc: 0.79580078125
val--69/100 [50/1090] acc: 0.7953125
val--69/100 [60/1090] acc: 0.7951171875
val--69/100 [70/1090] acc: 0.7957589285714286
val--69/100 [80/1090] acc: 0.795458984375
val--69/100 [90/1090] acc: 0.7961805555555556
val--69/100 [100/1090] acc: 0.797109375
val--69/100 [110/1090] acc: 0.7976207386363636
val--69/100 [120/1090] acc: 0.7972005208333334
val--69/100 [130/1090] acc: 0.7983173076923077
val--69/100 [140/1090] acc: 0.7983816964285714
val--69/100 [150/1090] acc: 0.7984375
val--69/100 [160/1090] acc: 0.7986083984375
val--69/100 [170/1090] acc: 0.7985294117647059
val--69/100 [180/1090] acc: 0.7983940972222222
val--69/100 [190/1090] acc: 0.7990131578947368
val--69/100 [200/1090] acc: 0.79919921875
val--69/100 [210/1090] acc: 0.799516369047619
val--69/100 [220/1090] acc: 0.798526278409091
val--69/100 [230/1090] acc: 0.7989639945652174
val--69/100 [240/1090] acc: 0.7986979166666667
val--69/100 [250/1090] acc: 0.79878125
val--69/100 [260/1090] acc: 0.7987680288461538
val--69/100 [270/1090] acc: 0.7989149305555555
val--69/100 [280/1090] acc: 0.7986746651785714
val--69/100 [290/1090] acc: 0.7985317887931035
val--69/100 [300/1090] acc: 0.7986328125
val--69/100 [310/1090] acc: 0.7984501008064516
val--69/100 [320/1090] acc: 0.79866943359375
val--69/100 [330/1090] acc: 0.7988636363636363
val--69/100 [340/1090] acc: 0.7989889705882353
val--69/100 [350/1090] acc: 0.7991183035714285
val--69/100 [360/1090] acc: 0.7989691840277777
val--69/100 [370/1090] acc: 0.7990603885135135
val--69/100 [380/1090] acc: 0.799085115131579
val--69/100 [390/1090] acc: 0.7989683493589743
val--69/100 [400/1090] acc: 0.798994140625
val--69/100 [410/1090] acc: 0.7990948932926829
val--69/100 [420/1090] acc: 0.7989955357142857
val--69/100 [430/1090] acc: 0.7987645348837209
val--69/100 [440/1090] acc: 0.7987571022727272
val--69/100 [450/1090] acc: 0.7985590277777778
val--69/100 [460/1090] acc: 0.7983950407608695
val--69/100 [470/1090] acc: 0.7983128324468085
val--69/100 [480/1090] acc: 0.7982991536458334
val--69/100 [490/1090] acc: 0.7983896683673469
val--69/100 [500/1090] acc: 0.7984921875
val--69/100 [510/1090] acc: 0.7983532475490196
val--69/100 [520/1090] acc: 0.7986328125
val--69/100 [530/1090] acc: 0.7985849056603773
val--69/100 [540/1090] acc: 0.7987123842592593
val--69/100 [550/1090] acc: 0.7986576704545455
val--69/100 [560/1090] acc: 0.7984723772321428
val--69/100 [570/1090] acc: 0.7982113486842105
val--69/100 [580/1090] acc: 0.7981748383620689
val--69/100 [590/1090] acc: 0.7981859110169491
val--69/100 [600/1090] acc: 0.7981510416666666
val--69/100 [610/1090] acc: 0.7980917008196722
val--69/100 [620/1090] acc: 0.7980594758064516
val--69/100 [630/1090] acc: 0.7983134920634921
val--69/100 [640/1090] acc: 0.7984619140625
val--69/100 [650/1090] acc: 0.7984074519230769
val--69/100 [660/1090] acc: 0.7983250473484849
val--69/100 [670/1090] acc: 0.798046875
val--69/100 [680/1090] acc: 0.7978745404411764
val--69/100 [690/1090] acc: 0.797939311594203
val--69/100 [700/1090] acc: 0.7979743303571428
val--69/100 [710/1090] acc: 0.797815801056338
val--69/100 [720/1090] acc: 0.7976671006944445
val--69/100 [730/1090] acc: 0.7976187928082191
val--69/100 [740/1090] acc: 0.7976140202702703
val--69/100 [750/1090] acc: 0.797609375
val--69/100 [760/1090] acc: 0.7977384868421052
val--69/100 [770/1090] acc: 0.7977171266233766
val--69/100 [780/1090] acc: 0.7976211939102564
val--69/100 [790/1090] acc: 0.7976315268987342
val--69/100 [800/1090] acc: 0.797841796875
val--69/100 [810/1090] acc: 0.7978973765432099
val--69/100 [820/1090] acc: 0.798023056402439
val--69/100 [830/1090] acc: 0.7980515813253012
val--69/100 [840/1090] acc: 0.7980236235119048
val--69/100 [850/1090] acc: 0.7980514705882353
val--69/100 [860/1090] acc: 0.7983375726744186
val--69/100 [870/1090] acc: 0.7982848419540229
val--69/100 [880/1090] acc: 0.7982998934659091
val--69/100 [890/1090] acc: 0.7984067766853933
val--69/100 [900/1090] acc: 0.7984071180555555
val--69/100 [910/1090] acc: 0.7983945741758242
val--69/100 [920/1090] acc: 0.7984247622282609
val--69/100 [930/1090] acc: 0.798538306451613
val--69/100 [940/1090] acc: 0.7985580119680851
val--69/100 [950/1090] acc: 0.7985279605263158
val--69/100 [960/1090] acc: 0.7984293619791667
val--69/100 [970/1090] acc: 0.7983650128865979
val--69/100 [980/1090] acc: 0.7983577806122449
val--69/100 [990/1090] acc: 0.7982520517676768
val--69/100 [1000/1090] acc: 0.7981484375
val--69/100 [1010/1090] acc: 0.7979424504950495
val--69/100 [1020/1090] acc: 0.7980047487745098
val--69/100 [1030/1090] acc: 0.7979899878640777
val--69/100 [1040/1090] acc: 0.7980130709134615
val--69/100 [1050/1090] acc: 0.7980766369047619
val--69/100 [1060/1090] acc: 0.7980247641509434
val--69/100 [1070/1090] acc: 0.7979811623831776
val--69/100 [1080/1090] acc: 0.7979166666666667
val--69/100 [1090/1090] acc: 0.7977315080275229
epoch= 69, accuracy= 0.797732, rmse= 0.375811, auc= 0.857611
train--70/100 [9/1090] loss: 0.4108668893575668
train--70/100 [19/1090] loss: 0.45793223977088926
train--70/100 [29/1090] loss: 0.44015015959739684
train--70/100 [39/1090] loss: 0.42393624782562256
train--70/100 [49/1090] loss: 0.4389590352773666
train--70/100 [59/1090] loss: 0.44111583530902865
train--70/100 [69/1090] loss: 0.44542845487594607
train--70/100 [79/1090] loss: 0.45505971908569337
train--70/100 [89/1090] loss: 0.43268272578716277
train--70/100 [99/1090] loss: 0.43057813346385954
train--70/100 [109/1090] loss: 0.44368269145488737
train--70/100 [119/1090] loss: 0.4427944034337997
train--70/100 [129/1090] loss: 0.4356870949268341
train--70/100 [139/1090] loss: 0.4350355237722397
train--70/100 [149/1090] loss: 0.4353510946035385
train--70/100 [159/1090] loss: 0.4352022886276245
train--70/100 [169/1090] loss: 0.4357228308916092
train--70/100 [179/1090] loss: 0.4361251503229141
train--70/100 [189/1090] loss: 0.4279881328344345
train--70/100 [199/1090] loss: 0.4336513340473175
train--70/100 [209/1090] loss: 0.42862220108509064
train--70/100 [219/1090] loss: 0.4287707835435867
train--70/100 [229/1090] loss: 0.44531711339950564
train--70/100 [239/1090] loss: 0.45003076195716857
train--70/100 [249/1090] loss: 0.42888429164886477
train--70/100 [259/1090] loss: 0.4301385134458542
train--70/100 [269/1090] loss: 0.44103444218635557
train--70/100 [279/1090] loss: 0.43311250805854795
train--70/100 [289/1090] loss: 0.43680734038352964
train--70/100 [299/1090] loss: 0.4349226176738739
train--70/100 [309/1090] loss: 0.4555904269218445
train--70/100 [319/1090] loss: 0.422909215092659
train--70/100 [329/1090] loss: 0.4474669724702835
train--70/100 [339/1090] loss: 0.44280197024345397
train--70/100 [349/1090] loss: 0.44580093026161194
train--70/100 [359/1090] loss: 0.4524743467569351
train--70/100 [369/1090] loss: 0.4310348600149155
train--70/100 [379/1090] loss: 0.43130206167697904
train--70/100 [389/1090] loss: 0.4430455207824707
train--70/100 [399/1090] loss: 0.4209087401628494
train--70/100 [409/1090] loss: 0.442546072602272
train--70/100 [419/1090] loss: 0.45955163836479185
train--70/100 [429/1090] loss: 0.4390119701623917
train--70/100 [439/1090] loss: 0.43641671538352966
train--70/100 [449/1090] loss: 0.46102372705936434
train--70/100 [459/1090] loss: 0.42846072614192965
train--70/100 [469/1090] loss: 0.4193409353494644
train--70/100 [479/1090] loss: 0.435246005654335
train--70/100 [489/1090] loss: 0.4404319792985916
train--70/100 [499/1090] loss: 0.4289538413286209
train--70/100 [509/1090] loss: 0.4408364981412888
train--70/100 [519/1090] loss: 0.4447455108165741
train--70/100 [529/1090] loss: 0.4363884925842285
train--70/100 [539/1090] loss: 0.442792746424675
train--70/100 [549/1090] loss: 0.4357154041528702
train--70/100 [559/1090] loss: 0.42809638381004333
train--70/100 [569/1090] loss: 0.4619618684053421
train--70/100 [579/1090] loss: 0.4516092300415039
train--70/100 [589/1090] loss: 0.4436911791563034
train--70/100 [599/1090] loss: 0.4409511864185333
train--70/100 [609/1090] loss: 0.4532347619533539
train--70/100 [619/1090] loss: 0.42775129079818724
train--70/100 [629/1090] loss: 0.4408354341983795
train--70/100 [639/1090] loss: 0.4354920476675034
train--70/100 [649/1090] loss: 0.4307625502347946
train--70/100 [659/1090] loss: 0.44021628201007845
train--70/100 [669/1090] loss: 0.44663926362991335
train--70/100 [679/1090] loss: 0.4663733810186386
train--70/100 [689/1090] loss: 0.44313318431377413
train--70/100 [699/1090] loss: 0.44515647292137145
train--70/100 [709/1090] loss: 0.43621433079242705
train--70/100 [719/1090] loss: 0.46567842066287995
train--70/100 [729/1090] loss: 0.44701607525348663
train--70/100 [739/1090] loss: 0.4460100710391998
train--70/100 [749/1090] loss: 0.43915853798389437
train--70/100 [759/1090] loss: 0.43253732323646543
train--70/100 [769/1090] loss: 0.4335994631052017
train--70/100 [779/1090] loss: 0.4530652672052383
train--70/100 [789/1090] loss: 0.4517581403255463
train--70/100 [799/1090] loss: 0.4165128141641617
train--70/100 [809/1090] loss: 0.42002734541893005
train--70/100 [819/1090] loss: 0.4343772858381271
train--70/100 [829/1090] loss: 0.4474344730377197
train--70/100 [839/1090] loss: 0.4429557263851166
train--70/100 [849/1090] loss: 0.47398883402347564
train--70/100 [859/1090] loss: 0.4458608001470566
train--70/100 [869/1090] loss: 0.45890572369098664
train--70/100 [879/1090] loss: 0.4578441858291626
train--70/100 [889/1090] loss: 0.4410781770944595
train--70/100 [899/1090] loss: 0.43630395233631136
train--70/100 [909/1090] loss: 0.4360670268535614
train--70/100 [919/1090] loss: 0.43135531842708585
train--70/100 [929/1090] loss: 0.4460283190011978
train--70/100 [939/1090] loss: 0.43580347299575806
train--70/100 [949/1090] loss: 0.4263613849878311
train--70/100 [959/1090] loss: 0.4247360199689865
train--70/100 [969/1090] loss: 0.4387600600719452
train--70/100 [979/1090] loss: 0.45033290684223176
train--70/100 [989/1090] loss: 0.42514444291591647
train--70/100 [999/1090] loss: 0.46160736083984377
train--70/100 [1009/1090] loss: 0.4727675288915634
train--70/100 [1019/1090] loss: 0.4394194930791855
train--70/100 [1029/1090] loss: 0.43581392168998717
train--70/100 [1039/1090] loss: 0.43313585221767426
train--70/100 [1049/1090] loss: 0.43911018669605256
train--70/100 [1059/1090] loss: 0.4491776764392853
train--70/100 [1069/1090] loss: 0.4470376282930374
train--70/100 [1079/1090] loss: 0.44696164727210996
train--70/100 [1089/1090] loss: 0.4577445834875107
predicting model...
val--70/100 [10/1090] acc: 0.797265625
val--70/100 [20/1090] acc: 0.798046875
val--70/100 [30/1090] acc: 0.7971354166666667
val--70/100 [40/1090] acc: 0.79716796875
val--70/100 [50/1090] acc: 0.796640625
val--70/100 [60/1090] acc: 0.7958984375
val--70/100 [70/1090] acc: 0.7964285714285714
val--70/100 [80/1090] acc: 0.79580078125
val--70/100 [90/1090] acc: 0.7964409722222222
val--70/100 [100/1090] acc: 0.7973828125
val--70/100 [110/1090] acc: 0.7977982954545455
val--70/100 [120/1090] acc: 0.79736328125
val--70/100 [130/1090] acc: 0.7982872596153846
val--70/100 [140/1090] acc: 0.7982421875
val--70/100 [150/1090] acc: 0.798203125
val--70/100 [160/1090] acc: 0.7983154296875
val--70/100 [170/1090] acc: 0.7981847426470589
val--70/100 [180/1090] acc: 0.7981119791666667
val--70/100 [190/1090] acc: 0.7987253289473685
val--70/100 [200/1090] acc: 0.798984375
val--70/100 [210/1090] acc: 0.7993489583333333
val--70/100 [220/1090] acc: 0.7984730113636364
val--70/100 [230/1090] acc: 0.7989130434782609
val--70/100 [240/1090] acc: 0.7986328125
val--70/100 [250/1090] acc: 0.798765625
val--70/100 [260/1090] acc: 0.7988131009615385
val--70/100 [270/1090] acc: 0.7990596064814814
val--70/100 [280/1090] acc: 0.79892578125
val--70/100 [290/1090] acc: 0.798828125
val--70/100 [300/1090] acc: 0.7990364583333334
val--70/100 [310/1090] acc: 0.7988659274193548
val--70/100 [320/1090] acc: 0.79912109375
val--70/100 [330/1090] acc: 0.79921875
val--70/100 [340/1090] acc: 0.7992991727941177
val--70/100 [350/1090] acc: 0.7994642857142857
val--70/100 [360/1090] acc: 0.7993272569444444
val--70/100 [370/1090] acc: 0.7994193412162162
val--70/100 [380/1090] acc: 0.7994346217105263
val--70/100 [390/1090] acc: 0.7993489583333333
val--70/100 [400/1090] acc: 0.79939453125
val--70/100 [410/1090] acc: 0.7994950457317073
val--70/100 [420/1090] acc: 0.7993768601190476
val--70/100 [430/1090] acc: 0.7991006540697675
val--70/100 [440/1090] acc: 0.79912109375
val--70/100 [450/1090] acc: 0.7990104166666666
val--70/100 [460/1090] acc: 0.7988196331521739
val--70/100 [470/1090] acc: 0.7987533244680851
val--70/100 [480/1090] acc: 0.7986897786458333
val--70/100 [490/1090] acc: 0.7987802933673469
val--70/100 [500/1090] acc: 0.7989140625
val--70/100 [510/1090] acc: 0.798843443627451
val--70/100 [520/1090] acc: 0.79912109375
val--70/100 [530/1090] acc: 0.799049233490566
val--70/100 [540/1090] acc: 0.7991174768518519
val--70/100 [550/1090] acc: 0.7989914772727272
val--70/100 [560/1090] acc: 0.7988071986607143
val--70/100 [570/1090] acc: 0.7985814144736842
val--70/100 [580/1090] acc: 0.7985317887931035
val--70/100 [590/1090] acc: 0.7985500529661017
val--70/100 [600/1090] acc: 0.79849609375
val--70/100 [610/1090] acc: 0.7984182889344262
val--70/100 [620/1090] acc: 0.7983744959677419
val--70/100 [630/1090] acc: 0.7985987103174603
val--70/100 [640/1090] acc: 0.79874267578125
val--70/100 [650/1090] acc: 0.7987379807692307
val--70/100 [660/1090] acc: 0.7986624053030303
val--70/100 [670/1090] acc: 0.798408348880597
val--70/100 [680/1090] acc: 0.7982421875
val--70/100 [690/1090] acc: 0.7983808876811594
val--70/100 [700/1090] acc: 0.7983816964285714
val--70/100 [710/1090] acc: 0.7982394366197183
val--70/100 [720/1090] acc: 0.7980577256944444
val--70/100 [730/1090] acc: 0.7980147688356164
val--70/100 [740/1090] acc: 0.7979835304054054
val--70/100 [750/1090] acc: 0.798
val--70/100 [760/1090] acc: 0.79814453125
val--70/100 [770/1090] acc: 0.7981381899350649
val--70/100 [780/1090] acc: 0.798046875
val--70/100 [790/1090] acc: 0.7980320411392405
val--70/100 [800/1090] acc: 0.798291015625
val--70/100 [810/1090] acc: 0.798341049382716
val--70/100 [820/1090] acc: 0.7984375
val--70/100 [830/1090] acc: 0.7984892695783132
val--70/100 [840/1090] acc: 0.7984840029761905
val--70/100 [850/1090] acc: 0.7984972426470588
val--70/100 [860/1090] acc: 0.7987963299418605
val--70/100 [870/1090] acc: 0.7987383261494253
val--70/100 [880/1090] acc: 0.7987437855113636
val--70/100 [890/1090] acc: 0.7988237359550562
val--70/100 [900/1090] acc: 0.7988324652777777
val--70/100 [910/1090] acc: 0.7988452953296703
val--70/100 [920/1090] acc: 0.7989003057065217
val--70/100 [930/1090] acc: 0.7989877352150537
val--70/100 [940/1090] acc: 0.7989818816489361
val--70/100 [950/1090] acc: 0.7988898026315789
val--70/100 [960/1090] acc: 0.7988199869791667
val--70/100 [970/1090] acc: 0.7987395296391753
val--70/100 [980/1090] acc: 0.7987643494897959
val--70/100 [990/1090] acc: 0.798666351010101
val--70/100 [1000/1090] acc: 0.79852734375
val--70/100 [1010/1090] acc: 0.7983060024752475
val--70/100 [1020/1090] acc: 0.7983877144607843
val--70/100 [1030/1090] acc: 0.7983995752427184
val--70/100 [1040/1090] acc: 0.7984112079326923
val--70/100 [1050/1090] acc: 0.7984709821428572
val--70/100 [1060/1090] acc: 0.7984006485849057
val--70/100 [1070/1090] acc: 0.7983717873831776
val--70/100 [1080/1090] acc: 0.7983109085648148
val--70/100 [1090/1090] acc: 0.7981042144495413
epoch= 70, accuracy= 0.798104, rmse= 0.375709, auc= 0.857768
train--71/100 [9/1090] loss: 0.3929435282945633
train--71/100 [19/1090] loss: 0.4569523811340332
train--71/100 [29/1090] loss: 0.44229927361011506
train--71/100 [39/1090] loss: 0.42004695236682893
train--71/100 [49/1090] loss: 0.42462837100028994
train--71/100 [59/1090] loss: 0.4356871873140335
train--71/100 [69/1090] loss: 0.4459910154342651
train--71/100 [79/1090] loss: 0.4331605553627014
train--71/100 [89/1090] loss: 0.4345646321773529
train--71/100 [99/1090] loss: 0.4389735162258148
train--71/100 [109/1090] loss: 0.4661194711923599
train--71/100 [119/1090] loss: 0.4332186669111252
train--71/100 [129/1090] loss: 0.45370075702667234
train--71/100 [139/1090] loss: 0.44069620966911316
train--71/100 [149/1090] loss: 0.4373013973236084
train--71/100 [159/1090] loss: 0.43846322000026705
train--71/100 [169/1090] loss: 0.4245175927877426
train--71/100 [179/1090] loss: 0.43503330945968627
train--71/100 [189/1090] loss: 0.4404219001531601
train--71/100 [199/1090] loss: 0.43421013057231905
train--71/100 [209/1090] loss: 0.44178254902362823
train--71/100 [219/1090] loss: 0.43442435562610626
train--71/100 [229/1090] loss: 0.4422529608011246
train--71/100 [239/1090] loss: 0.446934911608696
train--71/100 [249/1090] loss: 0.4233087867498398
train--71/100 [259/1090] loss: 0.41885298788547515
train--71/100 [269/1090] loss: 0.44430233240127565
train--71/100 [279/1090] loss: 0.4235465705394745
train--71/100 [289/1090] loss: 0.4291886270046234
train--71/100 [299/1090] loss: 0.4406406730413437
train--71/100 [309/1090] loss: 0.44951868057250977
train--71/100 [319/1090] loss: 0.4420282423496246
train--71/100 [329/1090] loss: 0.43376682996749877
train--71/100 [339/1090] loss: 0.4451929181814194
train--71/100 [349/1090] loss: 0.43864305019378663
train--71/100 [359/1090] loss: 0.4553279608488083
train--71/100 [369/1090] loss: 0.4474639892578125
train--71/100 [379/1090] loss: 0.44433833062648775
train--71/100 [389/1090] loss: 0.4405787199735641
train--71/100 [399/1090] loss: 0.43157938718795774
train--71/100 [409/1090] loss: 0.4415791779756546
train--71/100 [419/1090] loss: 0.4527182251214981
train--71/100 [429/1090] loss: 0.45606674551963805
train--71/100 [439/1090] loss: 0.43127753734588625
train--71/100 [449/1090] loss: 0.44098986089229586
train--71/100 [459/1090] loss: 0.4584790378808975
train--71/100 [469/1090] loss: 0.4227072179317474
train--71/100 [479/1090] loss: 0.4306951969861984
train--71/100 [489/1090] loss: 0.42528405487537385
train--71/100 [499/1090] loss: 0.42768736481666564
train--71/100 [509/1090] loss: 0.4383369207382202
train--71/100 [519/1090] loss: 0.44103931784629824
train--71/100 [529/1090] loss: 0.46086499094963074
train--71/100 [539/1090] loss: 0.43943747878074646
train--71/100 [549/1090] loss: 0.43617734014987947
train--71/100 [559/1090] loss: 0.42979728281497953
train--71/100 [569/1090] loss: 0.4619111180305481
train--71/100 [579/1090] loss: 0.44594737589359285
train--71/100 [589/1090] loss: 0.44983890652656555
train--71/100 [599/1090] loss: 0.4536503940820694
train--71/100 [609/1090] loss: 0.4355693727731705
train--71/100 [619/1090] loss: 0.44702140986919403
train--71/100 [629/1090] loss: 0.43553736209869387
train--71/100 [639/1090] loss: 0.4502133548259735
train--71/100 [649/1090] loss: 0.4442793488502502
train--71/100 [659/1090] loss: 0.4619231730699539
train--71/100 [669/1090] loss: 0.4593408197164536
train--71/100 [679/1090] loss: 0.4365741103887558
train--71/100 [689/1090] loss: 0.450825834274292
train--71/100 [699/1090] loss: 0.45345337986946105
train--71/100 [709/1090] loss: 0.42984718978405
train--71/100 [719/1090] loss: 0.4447798490524292
train--71/100 [729/1090] loss: 0.44079541563987734
train--71/100 [739/1090] loss: 0.4364595353603363
train--71/100 [749/1090] loss: 0.4472206592559814
train--71/100 [759/1090] loss: 0.4558984309434891
train--71/100 [769/1090] loss: 0.43696829676628113
train--71/100 [779/1090] loss: 0.428882372379303
train--71/100 [789/1090] loss: 0.4610654890537262
train--71/100 [799/1090] loss: 0.4333246946334839
train--71/100 [809/1090] loss: 0.4313885301351547
train--71/100 [819/1090] loss: 0.4348204404115677
train--71/100 [829/1090] loss: 0.4234736293554306
train--71/100 [839/1090] loss: 0.43401936888694764
train--71/100 [849/1090] loss: 0.4432122439146042
train--71/100 [859/1090] loss: 0.4373709797859192
train--71/100 [869/1090] loss: 0.4359219640493393
train--71/100 [879/1090] loss: 0.4428544551134109
train--71/100 [889/1090] loss: 0.43076864778995516
train--71/100 [899/1090] loss: 0.46132641434669497
train--71/100 [909/1090] loss: 0.4292944461107254
train--71/100 [919/1090] loss: 0.44092556536197663
train--71/100 [929/1090] loss: 0.4370949983596802
train--71/100 [939/1090] loss: 0.4605520129203796
train--71/100 [949/1090] loss: 0.4576159715652466
train--71/100 [959/1090] loss: 0.4285328298807144
train--71/100 [969/1090] loss: 0.441910919547081
train--71/100 [979/1090] loss: 0.4486916482448578
train--71/100 [989/1090] loss: 0.43883020281791685
train--71/100 [999/1090] loss: 0.4642137289047241
train--71/100 [1009/1090] loss: 0.4495106816291809
train--71/100 [1019/1090] loss: 0.4449272960424423
train--71/100 [1029/1090] loss: 0.4339891284704208
train--71/100 [1039/1090] loss: 0.4380116701126099
train--71/100 [1049/1090] loss: 0.4252935409545898
train--71/100 [1059/1090] loss: 0.4308550149202347
train--71/100 [1069/1090] loss: 0.43181384801864625
train--71/100 [1079/1090] loss: 0.4276185005903244
train--71/100 [1089/1090] loss: 0.4479025363922119
predicting model...
val--71/100 [10/1090] acc: 0.800390625
val--71/100 [20/1090] acc: 0.7994140625
val--71/100 [30/1090] acc: 0.7983072916666667
val--71/100 [40/1090] acc: 0.79814453125
val--71/100 [50/1090] acc: 0.7975
val--71/100 [60/1090] acc: 0.7966145833333333
val--71/100 [70/1090] acc: 0.796875
val--71/100 [80/1090] acc: 0.79609375
val--71/100 [90/1090] acc: 0.7966145833333333
val--71/100 [100/1090] acc: 0.797421875
val--71/100 [110/1090] acc: 0.7977627840909091
val--71/100 [120/1090] acc: 0.7973307291666667
val--71/100 [130/1090] acc: 0.7983774038461539
val--71/100 [140/1090] acc: 0.7983258928571428
val--71/100 [150/1090] acc: 0.7981770833333334
val--71/100 [160/1090] acc: 0.798291015625
val--71/100 [170/1090] acc: 0.7981617647058824
val--71/100 [180/1090] acc: 0.7980034722222222
val--71/100 [190/1090] acc: 0.7986225328947368
val--71/100 [200/1090] acc: 0.7987890625
val--71/100 [210/1090] acc: 0.7991629464285714
val--71/100 [220/1090] acc: 0.7981711647727273
val--71/100 [230/1090] acc: 0.7985903532608696
val--71/100 [240/1090] acc: 0.7983561197916667
val--71/100 [250/1090] acc: 0.798578125
val--71/100 [260/1090] acc: 0.7984975961538462
val--71/100 [270/1090] acc: 0.7989149305555555
val--71/100 [280/1090] acc: 0.7987723214285715
val--71/100 [290/1090] acc: 0.7987068965517241
val--71/100 [300/1090] acc: 0.79890625
val--71/100 [310/1090] acc: 0.798828125
val--71/100 [320/1090] acc: 0.79898681640625
val--71/100 [330/1090] acc: 0.7992424242424242
val--71/100 [340/1090] acc: 0.7992761948529412
val--71/100 [350/1090] acc: 0.799453125
val--71/100 [360/1090] acc: 0.7993055555555556
val--71/100 [370/1090] acc: 0.7993876689189189
val--71/100 [380/1090] acc: 0.7993215460526316
val--71/100 [390/1090] acc: 0.799258814102564
val--71/100 [400/1090] acc: 0.79921875
val--71/100 [410/1090] acc: 0.7994092987804878
val--71/100 [420/1090] acc: 0.7993024553571428
val--71/100 [430/1090] acc: 0.7990007267441861
val--71/100 [440/1090] acc: 0.7990323153409091
val--71/100 [450/1090] acc: 0.7988628472222222
val--71/100 [460/1090] acc: 0.7987007472826086
val--71/100 [470/1090] acc: 0.7986203457446809
val--71/100 [480/1090] acc: 0.7985921223958333
val--71/100 [490/1090] acc: 0.7987643494897959
val--71/100 [500/1090] acc: 0.7988671875
val--71/100 [510/1090] acc: 0.7987745098039216
val--71/100 [520/1090] acc: 0.7990685096153847
val--71/100 [530/1090] acc: 0.7990566037735849
val--71/100 [540/1090] acc: 0.7991608796296297
val--71/100 [550/1090] acc: 0.7990696022727273
val--71/100 [560/1090] acc: 0.798828125
val--71/100 [570/1090] acc: 0.7985540021929824
val--71/100 [580/1090] acc: 0.7985385237068966
val--71/100 [590/1090] acc: 0.7985103283898305
val--71/100 [600/1090] acc: 0.7984830729166666
val--71/100 [610/1090] acc: 0.7984246926229508
val--71/100 [620/1090] acc: 0.7983996975806451
val--71/100 [630/1090] acc: 0.7986359126984127
val--71/100 [640/1090] acc: 0.798785400390625
val--71/100 [650/1090] acc: 0.7987560096153846
val--71/100 [660/1090] acc: 0.7986564867424243
val--71/100 [670/1090] acc: 0.7984141791044777
val--71/100 [680/1090] acc: 0.7982823988970589
val--71/100 [690/1090] acc: 0.7984431612318841
val--71/100 [700/1090] acc: 0.7984095982142857
val--71/100 [710/1090] acc: 0.7982944542253522
val--71/100 [720/1090] acc: 0.79814453125
val--71/100 [730/1090] acc: 0.798068279109589
val--71/100 [740/1090] acc: 0.7980521537162162
val--71/100 [750/1090] acc: 0.7980677083333333
val--71/100 [760/1090] acc: 0.7982010690789474
val--71/100 [770/1090] acc: 0.7981939935064936
val--71/100 [780/1090] acc: 0.7980969551282051
val--71/100 [790/1090] acc: 0.7981160996835444
val--71/100 [800/1090] acc: 0.7983544921875
val--71/100 [810/1090] acc: 0.7984278549382716
val--71/100 [820/1090] acc: 0.7985280106707318
val--71/100 [830/1090] acc: 0.798597515060241
val--71/100 [840/1090] acc: 0.7985537574404762
val--71/100 [850/1090] acc: 0.798561580882353
val--71/100 [860/1090] acc: 0.7988690043604652
val--71/100 [870/1090] acc: 0.7988146551724138
val--71/100 [880/1090] acc: 0.7987881747159091
val--71/100 [890/1090] acc: 0.7988851825842697
val--71/100 [900/1090] acc: 0.7988628472222222
val--71/100 [910/1090] acc: 0.7988667582417582
val--71/100 [920/1090] acc: 0.7989087975543478
val--71/100 [930/1090] acc: 0.7989919354838709
val--71/100 [940/1090] acc: 0.7990068151595745
val--71/100 [950/1090] acc: 0.7989597039473684
val--71/100 [960/1090] acc: 0.7988932291666667
val--71/100 [970/1090] acc: 0.7988240979381444
val--71/100 [980/1090] acc: 0.7988360969387756
val--71/100 [990/1090] acc: 0.7987413194444445
val--71/100 [1000/1090] acc: 0.79865234375
val--71/100 [1010/1090] acc: 0.7984336324257426
val--71/100 [1020/1090] acc: 0.7985294117647059
val--71/100 [1030/1090] acc: 0.7985474817961165
val--71/100 [1040/1090] acc: 0.7985426682692308
val--71/100 [1050/1090] acc: 0.7986011904761905
val--71/100 [1060/1090] acc: 0.7985406839622642
val--71/100 [1070/1090] acc: 0.7985141647196262
val--71/100 [1080/1090] acc: 0.7984338831018518
val--71/100 [1090/1090] acc: 0.7982511467889908
epoch= 71, accuracy= 0.798251, rmse= 0.375687, auc= 0.857800
train--72/100 [9/1090] loss: 0.39483087956905366
train--72/100 [19/1090] loss: 0.4412055104970932
train--72/100 [29/1090] loss: 0.44462755024433137
train--72/100 [39/1090] loss: 0.4188156723976135
train--72/100 [49/1090] loss: 0.43553527891635896
train--72/100 [59/1090] loss: 0.4179715394973755
train--72/100 [69/1090] loss: 0.43223858177661895
train--72/100 [79/1090] loss: 0.41863581240177156
train--72/100 [89/1090] loss: 0.451653915643692
train--72/100 [99/1090] loss: 0.42957734167575834
train--72/100 [109/1090] loss: 0.4382724702358246
train--72/100 [119/1090] loss: 0.4552812486886978
train--72/100 [129/1090] loss: 0.4513018548488617
train--72/100 [139/1090] loss: 0.44040003716945647
train--72/100 [149/1090] loss: 0.4461826324462891
train--72/100 [159/1090] loss: 0.44322552978992463
train--72/100 [169/1090] loss: 0.43824841678142545
train--72/100 [179/1090] loss: 0.4442205250263214
train--72/100 [189/1090] loss: 0.4539203315973282
train--72/100 [199/1090] loss: 0.42108765840530393
train--72/100 [209/1090] loss: 0.4339449852705002
train--72/100 [219/1090] loss: 0.4328318238258362
train--72/100 [229/1090] loss: 0.43812463283538816
train--72/100 [239/1090] loss: 0.44563786387443544
train--72/100 [249/1090] loss: 0.44443894624710084
train--72/100 [259/1090] loss: 0.4442225515842438
train--72/100 [269/1090] loss: 0.45617902278900146
train--72/100 [279/1090] loss: 0.44440819323062897
train--72/100 [289/1090] loss: 0.4534421652555466
train--72/100 [299/1090] loss: 0.4243805319070816
train--72/100 [309/1090] loss: 0.4212056428194046
train--72/100 [319/1090] loss: 0.43561444878578187
train--72/100 [329/1090] loss: 0.4349066108465195
train--72/100 [339/1090] loss: 0.45533370673656465
train--72/100 [349/1090] loss: 0.439065083861351
train--72/100 [359/1090] loss: 0.4396087557077408
train--72/100 [369/1090] loss: 0.42179620563983916
train--72/100 [379/1090] loss: 0.4278138816356659
train--72/100 [389/1090] loss: 0.4524814009666443
train--72/100 [399/1090] loss: 0.44630846083164216
train--72/100 [409/1090] loss: 0.4252569884061813
train--72/100 [419/1090] loss: 0.4583856850862503
train--72/100 [429/1090] loss: 0.43455009162425995
train--72/100 [439/1090] loss: 0.44890330731868744
train--72/100 [449/1090] loss: 0.45063990354537964
train--72/100 [459/1090] loss: 0.41948914229869844
train--72/100 [469/1090] loss: 0.4432749718427658
train--72/100 [479/1090] loss: 0.433483824133873
train--72/100 [489/1090] loss: 0.4459852993488312
train--72/100 [499/1090] loss: 0.4320998042821884
train--72/100 [509/1090] loss: 0.43050951659679415
train--72/100 [519/1090] loss: 0.44983736574649813
train--72/100 [529/1090] loss: 0.43043452501296997
train--72/100 [539/1090] loss: 0.4366632103919983
train--72/100 [549/1090] loss: 0.4315831005573273
train--72/100 [559/1090] loss: 0.4502852261066437
train--72/100 [569/1090] loss: 0.43152285516262057
train--72/100 [579/1090] loss: 0.4344163715839386
train--72/100 [589/1090] loss: 0.4418483912944794
train--72/100 [599/1090] loss: 0.4218618154525757
train--72/100 [609/1090] loss: 0.4510455340147018
train--72/100 [619/1090] loss: 0.45659991204738615
train--72/100 [629/1090] loss: 0.4548067092895508
train--72/100 [639/1090] loss: 0.4278424769639969
train--72/100 [649/1090] loss: 0.44042899310588834
train--72/100 [659/1090] loss: 0.44449332654476165
train--72/100 [669/1090] loss: 0.4255869597196579
train--72/100 [679/1090] loss: 0.45496805012226105
train--72/100 [689/1090] loss: 0.4291353613138199
train--72/100 [699/1090] loss: 0.4375277578830719
train--72/100 [709/1090] loss: 0.432953006029129
train--72/100 [719/1090] loss: 0.4461286097764969
train--72/100 [729/1090] loss: 0.4424890846014023
train--72/100 [739/1090] loss: 0.41658100187778474
train--72/100 [749/1090] loss: 0.4315555214881897
train--72/100 [759/1090] loss: 0.43347431123256686
train--72/100 [769/1090] loss: 0.4501416653394699
train--72/100 [779/1090] loss: 0.43300039768218995
train--72/100 [789/1090] loss: 0.4592292129993439
train--72/100 [799/1090] loss: 0.4546536386013031
train--72/100 [809/1090] loss: 0.4317228376865387
train--72/100 [819/1090] loss: 0.4450597703456879
train--72/100 [829/1090] loss: 0.4510644435882568
train--72/100 [839/1090] loss: 0.4458657503128052
train--72/100 [849/1090] loss: 0.45796492993831633
train--72/100 [859/1090] loss: 0.4524895042181015
train--72/100 [869/1090] loss: 0.44262473881244657
train--72/100 [879/1090] loss: 0.42107376754283904
train--72/100 [889/1090] loss: 0.4438772231340408
train--72/100 [899/1090] loss: 0.441580593585968
train--72/100 [909/1090] loss: 0.44810054898262025
train--72/100 [919/1090] loss: 0.4676179468631744
train--72/100 [929/1090] loss: 0.4268507272005081
train--72/100 [939/1090] loss: 0.4447466492652893
train--72/100 [949/1090] loss: 0.4568091303110123
train--72/100 [959/1090] loss: 0.44422586262226105
train--72/100 [969/1090] loss: 0.44567935466766356
train--72/100 [979/1090] loss: 0.4482474118471146
train--72/100 [989/1090] loss: 0.43349096179008484
train--72/100 [999/1090] loss: 0.4534068822860718
train--72/100 [1009/1090] loss: 0.4439471662044525
train--72/100 [1019/1090] loss: 0.44906075596809386
train--72/100 [1029/1090] loss: 0.42647567093372346
train--72/100 [1039/1090] loss: 0.4311473876237869
train--72/100 [1049/1090] loss: 0.46072699427604674
train--72/100 [1059/1090] loss: 0.44279940128326417
train--72/100 [1069/1090] loss: 0.45537473261356354
train--72/100 [1079/1090] loss: 0.43566626906394956
train--72/100 [1089/1090] loss: 0.4517428070306778
predicting model...
val--72/100 [10/1090] acc: 0.79609375
val--72/100 [20/1090] acc: 0.7984375
val--72/100 [30/1090] acc: 0.7973958333333333
val--72/100 [40/1090] acc: 0.797265625
val--72/100 [50/1090] acc: 0.79671875
val--72/100 [60/1090] acc: 0.7959635416666667
val--72/100 [70/1090] acc: 0.7962611607142858
val--72/100 [80/1090] acc: 0.79599609375
val--72/100 [90/1090] acc: 0.7966579861111112
val--72/100 [100/1090] acc: 0.7976171875
val--72/100 [110/1090] acc: 0.7980823863636364
val--72/100 [120/1090] acc: 0.7975911458333333
val--72/100 [130/1090] acc: 0.7987980769230769
val--72/100 [140/1090] acc: 0.7988002232142857
val--72/100 [150/1090] acc: 0.79875
val--72/100 [160/1090] acc: 0.798876953125
val--72/100 [170/1090] acc: 0.7987362132352941
val--72/100 [180/1090] acc: 0.7985243055555555
val--72/100 [190/1090] acc: 0.7991776315789474
val--72/100 [200/1090] acc: 0.79939453125
val--72/100 [210/1090] acc: 0.7997767857142857
val--72/100 [220/1090] acc: 0.7988458806818182
val--72/100 [230/1090] acc: 0.7993036684782608
val--72/100 [240/1090] acc: 0.799072265625
val--72/100 [250/1090] acc: 0.799171875
val--72/100 [260/1090] acc: 0.7991286057692307
val--72/100 [270/1090] acc: 0.7994068287037037
val--72/100 [280/1090] acc: 0.7992745535714286
val--72/100 [290/1090] acc: 0.7992052801724138
val--72/100 [300/1090] acc: 0.7993489583333333
val--72/100 [310/1090] acc: 0.7991431451612904
val--72/100 [320/1090] acc: 0.79927978515625
val--72/100 [330/1090] acc: 0.7993844696969697
val--72/100 [340/1090] acc: 0.7995174632352942
val--72/100 [350/1090] acc: 0.7996875
val--72/100 [360/1090] acc: 0.7995876736111112
val--72/100 [370/1090] acc: 0.7996938344594594
val--72/100 [380/1090] acc: 0.7996504934210527
val--72/100 [390/1090] acc: 0.7995492788461539
val--72/100 [400/1090] acc: 0.79958984375
val--72/100 [410/1090] acc: 0.7997427591463414
val--72/100 [420/1090] acc: 0.7996372767857143
val--72/100 [430/1090] acc: 0.7993368459302326
val--72/100 [440/1090] acc: 0.79931640625
val--72/100 [450/1090] acc: 0.7990972222222222
val--72/100 [460/1090] acc: 0.7989385190217392
val--72/100 [470/1090] acc: 0.7988198138297873
val--72/100 [480/1090] acc: 0.7988037109375
val--72/100 [490/1090] acc: 0.7989078443877551
val--72/100 [500/1090] acc: 0.798984375
val--72/100 [510/1090] acc: 0.798828125
val--72/100 [520/1090] acc: 0.7991361177884615
val--72/100 [530/1090] acc: 0.7990860849056604
val--72/100 [540/1090] acc: 0.7991970486111111
val--72/100 [550/1090] acc: 0.7990838068181818
val--72/100 [560/1090] acc: 0.7988420758928572
val--72/100 [570/1090] acc: 0.7985677083333333
val--72/100 [580/1090] acc: 0.7985183189655173
val--72/100 [590/1090] acc: 0.7985235699152542
val--72/100 [600/1090] acc: 0.7985026041666666
val--72/100 [610/1090] acc: 0.7985079405737705
val--72/100 [620/1090] acc: 0.7984311995967742
val--72/100 [630/1090] acc: 0.7986793154761904
val--72/100 [640/1090] acc: 0.798846435546875
val--72/100 [650/1090] acc: 0.798828125
val--72/100 [660/1090] acc: 0.7987452651515151
val--72/100 [670/1090] acc: 0.7985074626865671
val--72/100 [680/1090] acc: 0.7983972886029411
val--72/100 [690/1090] acc: 0.798533740942029
val--72/100 [700/1090] acc: 0.7985100446428571
val--72/100 [710/1090] acc: 0.7983824823943662
val--72/100 [720/1090] acc: 0.7981825086805555
val--72/100 [730/1090] acc: 0.7980950342465754
val--72/100 [740/1090] acc: 0.7980521537162162
val--72/100 [750/1090] acc: 0.7980885416666667
val--72/100 [760/1090] acc: 0.7982113486842105
val--72/100 [770/1090] acc: 0.7981787743506493
val--72/100 [780/1090] acc: 0.7980919471153847
val--72/100 [790/1090] acc: 0.7981309335443038
val--72/100 [800/1090] acc: 0.7983837890625
val--72/100 [810/1090] acc: 0.7984519675925926
val--72/100 [820/1090] acc: 0.7985280106707318
val--72/100 [830/1090] acc: 0.7985786897590361
val--72/100 [840/1090] acc: 0.7985444568452381
val--72/100 [850/1090] acc: 0.7985753676470588
val--72/100 [860/1090] acc: 0.7988417514534883
val--72/100 [870/1090] acc: 0.7987652658045977
val--72/100 [880/1090] acc: 0.7987926136363637
val--72/100 [890/1090] acc: 0.7988983497191011
val--72/100 [900/1090] acc: 0.7988888888888889
val--72/100 [910/1090] acc: 0.7988968063186813
val--72/100 [920/1090] acc: 0.79892578125
val--72/100 [930/1090] acc: 0.7990045362903225
val--72/100 [940/1090] acc: 0.7990151263297872
val--72/100 [950/1090] acc: 0.7989597039473684
val--72/100 [960/1090] acc: 0.7988810221354167
val--72/100 [970/1090] acc: 0.798803962628866
val--72/100 [980/1090] acc: 0.7988480548469388
val--72/100 [990/1090] acc: 0.7987689393939394
val--72/100 [1000/1090] acc: 0.79866015625
val--72/100 [1010/1090] acc: 0.798483910891089
val--72/100 [1020/1090] acc: 0.7985600490196079
val--72/100 [1030/1090] acc: 0.7985740291262136
val--72/100 [1040/1090] acc: 0.7985990084134615
val--72/100 [1050/1090] acc: 0.7986346726190476
val--72/100 [1060/1090] acc: 0.798573850235849
val--72/100 [1070/1090] acc: 0.7985579731308411
val--72/100 [1080/1090] acc: 0.7984953703703703
val--72/100 [1090/1090] acc: 0.7982977350917431
epoch= 72, accuracy= 0.798298, rmse= 0.375584, auc= 0.857953
train--73/100 [9/1090] loss: 0.4196270227432251
train--73/100 [19/1090] loss: 0.4422720432281494
train--73/100 [29/1090] loss: 0.4342295408248901
train--73/100 [39/1090] loss: 0.4442711591720581
train--73/100 [49/1090] loss: 0.4388271629810333
train--73/100 [59/1090] loss: 0.4376050531864166
train--73/100 [69/1090] loss: 0.44709181785583496
train--73/100 [79/1090] loss: 0.4128859996795654
train--73/100 [89/1090] loss: 0.4448452442884445
train--73/100 [99/1090] loss: 0.4404029667377472
train--73/100 [109/1090] loss: 0.44285304844379425
train--73/100 [119/1090] loss: 0.42904458940029144
train--73/100 [129/1090] loss: 0.4323896050453186
train--73/100 [139/1090] loss: 0.44144339561462403
train--73/100 [149/1090] loss: 0.4318434774875641
train--73/100 [159/1090] loss: 0.448643958568573
train--73/100 [169/1090] loss: 0.4310118407011032
train--73/100 [179/1090] loss: 0.43174741566181185
train--73/100 [189/1090] loss: 0.43448724448680875
train--73/100 [199/1090] loss: 0.4399688959121704
train--73/100 [209/1090] loss: 0.41477641761302947
train--73/100 [219/1090] loss: 0.42717812955379486
train--73/100 [229/1090] loss: 0.44317329823970797
train--73/100 [239/1090] loss: 0.4436424165964127
train--73/100 [249/1090] loss: 0.4494756102561951
train--73/100 [259/1090] loss: 0.4261132597923279
train--73/100 [269/1090] loss: 0.44121338427066803
train--73/100 [279/1090] loss: 0.4543491452932358
train--73/100 [289/1090] loss: 0.43394698202610016
train--73/100 [299/1090] loss: 0.4489209294319153
train--73/100 [309/1090] loss: 0.44712822437286376
train--73/100 [319/1090] loss: 0.43949607014656067
train--73/100 [329/1090] loss: 0.439237043261528
train--73/100 [339/1090] loss: 0.4453069895505905
train--73/100 [349/1090] loss: 0.44448587000370027
train--73/100 [359/1090] loss: 0.431594580411911
train--73/100 [369/1090] loss: 0.46494453251361845
train--73/100 [379/1090] loss: 0.4596559971570969
train--73/100 [389/1090] loss: 0.4429596930742264
train--73/100 [399/1090] loss: 0.42647125124931334
train--73/100 [409/1090] loss: 0.4497186869382858
train--73/100 [419/1090] loss: 0.43325437903404235
train--73/100 [429/1090] loss: 0.43570097982883454
train--73/100 [439/1090] loss: 0.43339675664901733
train--73/100 [449/1090] loss: 0.4195056647062302
train--73/100 [459/1090] loss: 0.42420301139354705
train--73/100 [469/1090] loss: 0.43773681223392485
train--73/100 [479/1090] loss: 0.4489105075597763
train--73/100 [489/1090] loss: 0.47370918095111847
train--73/100 [499/1090] loss: 0.4205023437738419
train--73/100 [509/1090] loss: 0.43514952063560486
train--73/100 [519/1090] loss: 0.4431527525186539
train--73/100 [529/1090] loss: 0.4438168406486511
train--73/100 [539/1090] loss: 0.4342872858047485
train--73/100 [549/1090] loss: 0.4389124870300293
train--73/100 [559/1090] loss: 0.43463967740535736
train--73/100 [569/1090] loss: 0.436358779668808
train--73/100 [579/1090] loss: 0.4257815212011337
train--73/100 [589/1090] loss: 0.446967151761055
train--73/100 [599/1090] loss: 0.4356257975101471
train--73/100 [609/1090] loss: 0.4544644445180893
train--73/100 [619/1090] loss: 0.4308641701936722
train--73/100 [629/1090] loss: 0.43163779377937317
train--73/100 [639/1090] loss: 0.450094011425972
train--73/100 [649/1090] loss: 0.4447409093379974
train--73/100 [659/1090] loss: 0.43255349099636076
train--73/100 [669/1090] loss: 0.4491093397140503
train--73/100 [679/1090] loss: 0.45958265066146853
train--73/100 [689/1090] loss: 0.4408340483903885
train--73/100 [699/1090] loss: 0.42136879563331603
train--73/100 [709/1090] loss: 0.43463543653488157
train--73/100 [719/1090] loss: 0.4324637234210968
train--73/100 [729/1090] loss: 0.43610634207725524
train--73/100 [739/1090] loss: 0.4269712150096893
train--73/100 [749/1090] loss: 0.44183391630649566
train--73/100 [759/1090] loss: 0.4400911271572113
train--73/100 [769/1090] loss: 0.44602719247341155
train--73/100 [779/1090] loss: 0.4363321721553802
train--73/100 [789/1090] loss: 0.42672169804573057
train--73/100 [799/1090] loss: 0.4381733059883118
train--73/100 [809/1090] loss: 0.44586801826953887
train--73/100 [819/1090] loss: 0.45051172375679016
train--73/100 [829/1090] loss: 0.4442483723163605
train--73/100 [839/1090] loss: 0.4433704078197479
train--73/100 [849/1090] loss: 0.44359092116355897
train--73/100 [859/1090] loss: 0.4509301781654358
train--73/100 [869/1090] loss: 0.4299248784780502
train--73/100 [879/1090] loss: 0.43873563408851624
train--73/100 [889/1090] loss: 0.45243459939956665
train--73/100 [899/1090] loss: 0.44640102088451383
train--73/100 [909/1090] loss: 0.46776936650276185
train--73/100 [919/1090] loss: 0.4357557475566864
train--73/100 [929/1090] loss: 0.4497163861989975
train--73/100 [939/1090] loss: 0.4260567307472229
train--73/100 [949/1090] loss: 0.4328547090291977
train--73/100 [959/1090] loss: 0.45964138507843016
train--73/100 [969/1090] loss: 0.432334840297699
train--73/100 [979/1090] loss: 0.43241853415966036
train--73/100 [989/1090] loss: 0.466648930311203
train--73/100 [999/1090] loss: 0.4447170466184616
train--73/100 [1009/1090] loss: 0.4555038303136826
train--73/100 [1019/1090] loss: 0.45814518332481385
train--73/100 [1029/1090] loss: 0.4465978354215622
train--73/100 [1039/1090] loss: 0.43918967843055723
train--73/100 [1049/1090] loss: 0.44148026704788207
train--73/100 [1059/1090] loss: 0.42584248483181
train--73/100 [1069/1090] loss: 0.45607839822769164
train--73/100 [1079/1090] loss: 0.44110730588436126
train--73/100 [1089/1090] loss: 0.44055699110031127
predicting model...
val--73/100 [10/1090] acc: 0.79609375
val--73/100 [20/1090] acc: 0.7970703125
val--73/100 [30/1090] acc: 0.796484375
val--73/100 [40/1090] acc: 0.79677734375
val--73/100 [50/1090] acc: 0.796328125
val--73/100 [60/1090] acc: 0.7959635416666667
val--73/100 [70/1090] acc: 0.7962053571428571
val--73/100 [80/1090] acc: 0.795947265625
val--73/100 [90/1090] acc: 0.7963541666666667
val--73/100 [100/1090] acc: 0.7976171875
val--73/100 [110/1090] acc: 0.7980823863636364
val--73/100 [120/1090] acc: 0.79765625
val--73/100 [130/1090] acc: 0.7986478365384615
val--73/100 [140/1090] acc: 0.7985491071428571
val--73/100 [150/1090] acc: 0.7984375
val--73/100 [160/1090] acc: 0.7984375
val--73/100 [170/1090] acc: 0.7981617647058824
val--73/100 [180/1090] acc: 0.7980685763888888
val--73/100 [190/1090] acc: 0.7987870065789474
val--73/100 [200/1090] acc: 0.7990234375
val--73/100 [210/1090] acc: 0.799404761904762
val--73/100 [220/1090] acc: 0.7983664772727272
val--73/100 [230/1090] acc: 0.7988451086956522
val--73/100 [240/1090] acc: 0.7986653645833334
val--73/100 [250/1090] acc: 0.798828125
val--73/100 [260/1090] acc: 0.7987229567307692
val--73/100 [270/1090] acc: 0.7990451388888888
val--73/100 [280/1090] acc: 0.798828125
val--73/100 [290/1090] acc: 0.7987742456896552
val--73/100 [300/1090] acc: 0.7989322916666667
val--73/100 [310/1090] acc: 0.7987273185483871
val--73/100 [320/1090] acc: 0.79888916015625
val--73/100 [330/1090] acc: 0.7990411931818182
val--73/100 [340/1090] acc: 0.7991613051470589
val--73/100 [350/1090] acc: 0.7993638392857143
val--73/100 [360/1090] acc: 0.7993381076388889
val--73/100 [370/1090] acc: 0.7993982263513514
val--73/100 [380/1090] acc: 0.7994346217105263
val--73/100 [390/1090] acc: 0.7993289262820513
val--73/100 [400/1090] acc: 0.799326171875
val--73/100 [410/1090] acc: 0.7994664634146341
val--73/100 [420/1090] acc: 0.7993675595238096
val--73/100 [430/1090] acc: 0.7990734011627907
val--73/100 [440/1090] acc: 0.7990323153409091
val--73/100 [450/1090] acc: 0.7988975694444445
val--73/100 [460/1090] acc: 0.7987432065217391
val--73/100 [470/1090] acc: 0.7986452792553191
val--73/100 [480/1090] acc: 0.7986328125
val--73/100 [490/1090] acc: 0.7987404336734694
val--73/100 [500/1090] acc: 0.79884375
val--73/100 [510/1090] acc: 0.7987285539215686
val--73/100 [520/1090] acc: 0.7990159254807693
val--73/100 [530/1090] acc: 0.7989607900943396
val--73/100 [540/1090] acc: 0.7990668402777777
val--73/100 [550/1090] acc: 0.7989772727272727
val--73/100 [560/1090] acc: 0.7987583705357143
val--73/100 [570/1090] acc: 0.7985402960526315
val--73/100 [580/1090] acc: 0.7984846443965518
val--73/100 [590/1090] acc: 0.7984706038135593
val--73/100 [600/1090] acc: 0.7984895833333333
val--73/100 [610/1090] acc: 0.7984695184426229
val--73/100 [620/1090] acc: 0.7983933971774193
val--73/100 [630/1090] acc: 0.7986793154761904
val--73/100 [640/1090] acc: 0.798870849609375
val--73/100 [650/1090] acc: 0.7988701923076923
val--73/100 [660/1090] acc: 0.7987866950757576
val--73/100 [670/1090] acc: 0.7985482742537313
val--73/100 [680/1090] acc: 0.7984087775735295
val--73/100 [690/1090] acc: 0.7985450634057971
val--73/100 [700/1090] acc: 0.7985435267857143
val--73/100 [710/1090] acc: 0.7984375
val--73/100 [720/1090] acc: 0.7982584635416666
val--73/100 [730/1090] acc: 0.7981967037671233
val--73/100 [740/1090] acc: 0.7981630067567568
val--73/100 [750/1090] acc: 0.7981770833333334
val--73/100 [760/1090] acc: 0.7983295641447369
val--73/100 [770/1090] acc: 0.7983056006493506
val--73/100 [780/1090] acc: 0.7982271634615384
val--73/100 [790/1090] acc: 0.7982397151898735
val--73/100 [800/1090] acc: 0.798486328125
val--73/100 [810/1090] acc: 0.7985387731481481
val--73/100 [820/1090] acc: 0.798656631097561
val--73/100 [830/1090] acc: 0.7987010542168674
val--73/100 [840/1090] acc: 0.7986979166666667
val--73/100 [850/1090] acc: 0.7986948529411765
val--73/100 [860/1090] acc: 0.7989780159883721
val--73/100 [870/1090] acc: 0.7989179238505747
val--73/100 [880/1090] acc: 0.7989390980113636
val--73/100 [890/1090] acc: 0.7990344101123595
val--73/100 [900/1090] acc: 0.7990277777777778
val--73/100 [910/1090] acc: 0.7990255837912088
val--73/100 [920/1090] acc: 0.7990446671195652
val--73/100 [930/1090] acc: 0.799134744623656
val--73/100 [940/1090] acc: 0.7991481050531914
val--73/100 [950/1090] acc: 0.7990995065789473
val--73/100 [960/1090] acc: 0.7990315755208334
val--73/100 [970/1090] acc: 0.7989610180412371
val--73/100 [980/1090] acc: 0.7989915497448979
val--73/100 [990/1090] acc: 0.7989030934343434
val--73/100 [1000/1090] acc: 0.79877734375
val--73/100 [1010/1090] acc: 0.798565129950495
val--73/100 [1020/1090] acc: 0.7986443014705882
val--73/100 [1030/1090] acc: 0.7986688410194175
val--73/100 [1040/1090] acc: 0.7986703725961538
val--73/100 [1050/1090] acc: 0.7987202380952381
val--73/100 [1060/1090] acc: 0.7986512382075471
val--73/100 [1070/1090] acc: 0.7986346378504673
val--73/100 [1080/1090] acc: 0.7985713252314814
val--73/100 [1090/1090] acc: 0.7983980791284404
epoch= 73, accuracy= 0.798398, rmse= 0.375499, auc= 0.858018
train--74/100 [9/1090] loss: 0.40159972608089445
train--74/100 [19/1090] loss: 0.4384051650762558
train--74/100 [29/1090] loss: 0.43013784289360046
train--74/100 [39/1090] loss: 0.44321435391902925
train--74/100 [49/1090] loss: 0.4279899299144745
train--74/100 [59/1090] loss: 0.4397352308034897
train--74/100 [69/1090] loss: 0.4420509785413742
train--74/100 [79/1090] loss: 0.43509757816791533
train--74/100 [89/1090] loss: 0.44789588153362275
train--74/100 [99/1090] loss: 0.4219845950603485
train--74/100 [109/1090] loss: 0.450496107339859
train--74/100 [119/1090] loss: 0.44135602414608
train--74/100 [129/1090] loss: 0.4235198080539703
train--74/100 [139/1090] loss: 0.4530978828668594
train--74/100 [149/1090] loss: 0.43538951575756074
train--74/100 [159/1090] loss: 0.42510471642017367
train--74/100 [169/1090] loss: 0.44864850044250487
train--74/100 [179/1090] loss: 0.44493621289730073
train--74/100 [189/1090] loss: 0.45854480266571046
train--74/100 [199/1090] loss: 0.4300640016794205
train--74/100 [209/1090] loss: 0.4425710916519165
train--74/100 [219/1090] loss: 0.43707034885883334
train--74/100 [229/1090] loss: 0.4458177775144577
train--74/100 [239/1090] loss: 0.43064231872558595
train--74/100 [249/1090] loss: 0.4371019691228867
train--74/100 [259/1090] loss: 0.4401035636663437
train--74/100 [269/1090] loss: 0.44094279408454895
train--74/100 [279/1090] loss: 0.44535740911960603
train--74/100 [289/1090] loss: 0.43260340988636015
train--74/100 [299/1090] loss: 0.4422679990530014
train--74/100 [309/1090] loss: 0.44459393322467805
train--74/100 [319/1090] loss: 0.429620298743248
train--74/100 [329/1090] loss: 0.42974635660648347
train--74/100 [339/1090] loss: 0.4242719501256943
train--74/100 [349/1090] loss: 0.4468240082263947
train--74/100 [359/1090] loss: 0.45967203974723814
train--74/100 [369/1090] loss: 0.4436940461397171
train--74/100 [379/1090] loss: 0.4218092918395996
train--74/100 [389/1090] loss: 0.45012272894382477
train--74/100 [399/1090] loss: 0.42194257378578187
train--74/100 [409/1090] loss: 0.4503631204366684
train--74/100 [419/1090] loss: 0.4437069982290268
train--74/100 [429/1090] loss: 0.4375264525413513
train--74/100 [439/1090] loss: 0.4452016711235046
train--74/100 [449/1090] loss: 0.4577818363904953
train--74/100 [459/1090] loss: 0.4551918774843216
train--74/100 [469/1090] loss: 0.4568780422210693
train--74/100 [479/1090] loss: 0.43577470183372496
train--74/100 [489/1090] loss: 0.43665118515491486
train--74/100 [499/1090] loss: 0.431951180100441
train--74/100 [509/1090] loss: 0.4436023473739624
train--74/100 [519/1090] loss: 0.4286612689495087
train--74/100 [529/1090] loss: 0.4222856551408768
train--74/100 [539/1090] loss: 0.4414464712142944
train--74/100 [549/1090] loss: 0.43939059376716616
train--74/100 [559/1090] loss: 0.4526742696762085
train--74/100 [569/1090] loss: 0.41925167441368105
train--74/100 [579/1090] loss: 0.411253833770752
train--74/100 [589/1090] loss: 0.4459565818309784
train--74/100 [599/1090] loss: 0.45669926404953004
train--74/100 [609/1090] loss: 0.4391730517148972
train--74/100 [619/1090] loss: 0.4510368436574936
train--74/100 [629/1090] loss: 0.43215296864509584
train--74/100 [639/1090] loss: 0.4480369508266449
train--74/100 [649/1090] loss: 0.4445212990045547
train--74/100 [659/1090] loss: 0.4495820999145508
train--74/100 [669/1090] loss: 0.45756307542324065
train--74/100 [679/1090] loss: 0.4205153316259384
train--74/100 [689/1090] loss: 0.43036399483680726
train--74/100 [699/1090] loss: 0.4494496822357178
train--74/100 [709/1090] loss: 0.42360401451587676
train--74/100 [719/1090] loss: 0.4338866531848907
train--74/100 [729/1090] loss: 0.43810123205184937
train--74/100 [739/1090] loss: 0.4357047289609909
train--74/100 [749/1090] loss: 0.4529002010822296
train--74/100 [759/1090] loss: 0.4363007426261902
train--74/100 [769/1090] loss: 0.44850313365459443
train--74/100 [779/1090] loss: 0.440091547369957
train--74/100 [789/1090] loss: 0.4457156151533127
train--74/100 [799/1090] loss: 0.44814712703228
train--74/100 [809/1090] loss: 0.42469150722026827
train--74/100 [819/1090] loss: 0.4457759141921997
train--74/100 [829/1090] loss: 0.4351296633481979
train--74/100 [839/1090] loss: 0.45985797941684725
train--74/100 [849/1090] loss: 0.4586401581764221
train--74/100 [859/1090] loss: 0.43282934427261355
train--74/100 [869/1090] loss: 0.4324988931417465
train--74/100 [879/1090] loss: 0.4401488721370697
train--74/100 [889/1090] loss: 0.4357608497142792
train--74/100 [899/1090] loss: 0.4397576093673706
train--74/100 [909/1090] loss: 0.4358401447534561
train--74/100 [919/1090] loss: 0.43728777170181277
train--74/100 [929/1090] loss: 0.46420167982578275
train--74/100 [939/1090] loss: 0.4336149483919144
train--74/100 [949/1090] loss: 0.42574532628059386
train--74/100 [959/1090] loss: 0.43674607276916505
train--74/100 [969/1090] loss: 0.43059379756450655
train--74/100 [979/1090] loss: 0.4369643986225128
train--74/100 [989/1090] loss: 0.4314588487148285
train--74/100 [999/1090] loss: 0.45248006880283353
train--74/100 [1009/1090] loss: 0.4479651540517807
train--74/100 [1019/1090] loss: 0.4479760885238647
train--74/100 [1029/1090] loss: 0.44841005802154543
train--74/100 [1039/1090] loss: 0.4428874015808105
train--74/100 [1049/1090] loss: 0.4403547167778015
train--74/100 [1059/1090] loss: 0.4370228826999664
train--74/100 [1069/1090] loss: 0.45270441472530365
train--74/100 [1079/1090] loss: 0.45593769252300265
train--74/100 [1089/1090] loss: 0.44177271127700807
predicting model...
val--74/100 [10/1090] acc: 0.799609375
val--74/100 [20/1090] acc: 0.799609375
val--74/100 [30/1090] acc: 0.7983072916666667
val--74/100 [40/1090] acc: 0.7978515625
val--74/100 [50/1090] acc: 0.7975
val--74/100 [60/1090] acc: 0.7970052083333333
val--74/100 [70/1090] acc: 0.7974888392857142
val--74/100 [80/1090] acc: 0.797119140625
val--74/100 [90/1090] acc: 0.7975260416666666
val--74/100 [100/1090] acc: 0.7983984375
val--74/100 [110/1090] acc: 0.7987571022727272
val--74/100 [120/1090] acc: 0.79833984375
val--74/100 [130/1090] acc: 0.7992487980769231
val--74/100 [140/1090] acc: 0.7991908482142858
val--74/100 [150/1090] acc: 0.7991145833333333
val--74/100 [160/1090] acc: 0.7991455078125
val--74/100 [170/1090] acc: 0.7989200367647059
val--74/100 [180/1090] acc: 0.7987413194444445
val--74/100 [190/1090] acc: 0.7992804276315789
val--74/100 [200/1090] acc: 0.79966796875
val--74/100 [210/1090] acc: 0.8000744047619047
val--74/100 [220/1090] acc: 0.7991477272727273
val--74/100 [230/1090] acc: 0.7995754076086956
val--74/100 [240/1090] acc: 0.799365234375
val--74/100 [250/1090] acc: 0.799484375
val--74/100 [260/1090] acc: 0.7994290865384616
val--74/100 [270/1090] acc: 0.7996527777777778
val--74/100 [280/1090] acc: 0.7994001116071429
val--74/100 [290/1090] acc: 0.799286099137931
val--74/100 [300/1090] acc: 0.7994401041666667
val--74/100 [310/1090] acc: 0.7993195564516129
val--74/100 [320/1090] acc: 0.799462890625
val--74/100 [330/1090] acc: 0.7995975378787878
val--74/100 [340/1090] acc: 0.7996668198529412
val--74/100 [350/1090] acc: 0.79984375
val--74/100 [360/1090] acc: 0.79970703125
val--74/100 [370/1090] acc: 0.7997466216216216
val--74/100 [380/1090] acc: 0.7997738486842105
val--74/100 [390/1090] acc: 0.7996594551282051
val--74/100 [400/1090] acc: 0.79962890625
val--74/100 [410/1090] acc: 0.7996951219512195
val--74/100 [420/1090] acc: 0.7996744791666667
val--74/100 [430/1090] acc: 0.799327761627907
val--74/100 [440/1090] acc: 0.7992986505681818
val--74/100 [450/1090] acc: 0.7991753472222223
val--74/100 [460/1090] acc: 0.7990064538043479
val--74/100 [470/1090] acc: 0.7989694148936171
val--74/100 [480/1090] acc: 0.7989583333333333
val--74/100 [490/1090] acc: 0.7989716198979592
val--74/100 [500/1090] acc: 0.799125
val--74/100 [510/1090] acc: 0.7990196078431373
val--74/100 [520/1090] acc: 0.7993013822115385
val--74/100 [530/1090] acc: 0.7992777122641509
val--74/100 [540/1090] acc: 0.7993923611111111
val--74/100 [550/1090] acc: 0.7992897727272728
val--74/100 [560/1090] acc: 0.7990862165178572
val--74/100 [570/1090] acc: 0.7988349780701754
val--74/100 [580/1090] acc: 0.7988213900862069
val--74/100 [590/1090] acc: 0.7988413665254237
val--74/100 [600/1090] acc: 0.7987955729166667
val--74/100 [610/1090] acc: 0.7987192622950819
val--74/100 [620/1090] acc: 0.7986706149193549
val--74/100 [630/1090] acc: 0.798890128968254
val--74/100 [640/1090] acc: 0.799066162109375
val--74/100 [650/1090] acc: 0.7990685096153847
val--74/100 [660/1090] acc: 0.7990056818181818
val--74/100 [670/1090] acc: 0.7987756529850746
val--74/100 [680/1090] acc: 0.7986672794117647
val--74/100 [690/1090] acc: 0.7987941576086957
val--74/100 [700/1090] acc: 0.7988169642857142
val--74/100 [710/1090] acc: 0.7987235915492957
val--74/100 [720/1090] acc: 0.7985677083333333
val--74/100 [730/1090] acc: 0.7985177654109589
val--74/100 [740/1090] acc: 0.798463893581081
val--74/100 [750/1090] acc: 0.7984583333333334
val--74/100 [760/1090] acc: 0.7986276726973685
val--74/100 [770/1090] acc: 0.7986150568181818
val--74/100 [780/1090] acc: 0.7985326522435897
val--74/100 [790/1090] acc: 0.7985462816455696
val--74/100 [800/1090] acc: 0.7988037109375
val--74/100 [810/1090] acc: 0.798876350308642
val--74/100 [820/1090] acc: 0.7989900914634146
val--74/100 [830/1090] acc: 0.7990399096385542
val--74/100 [840/1090] acc: 0.7990234375
val--74/100 [850/1090] acc: 0.7990487132352941
val--74/100 [860/1090] acc: 0.7993413880813953
val--74/100 [870/1090] acc: 0.7992816091954023
val--74/100 [880/1090] acc: 0.7992764559659091
val--74/100 [890/1090] acc: 0.7993591994382022
val--74/100 [900/1090] acc: 0.7993229166666667
val--74/100 [910/1090] acc: 0.7993346497252747
val--74/100 [920/1090] acc: 0.7993503736413043
val--74/100 [930/1090] acc: 0.799445564516129
val--74/100 [940/1090] acc: 0.7994597739361702
val--74/100 [950/1090] acc: 0.7993955592105263
val--74/100 [960/1090] acc: 0.7993082682291667
val--74/100 [970/1090] acc: 0.7992268041237114
val--74/100 [980/1090] acc: 0.7992586096938775
val--74/100 [990/1090] acc: 0.7991714015151515
val--74/100 [1000/1090] acc: 0.799078125
val--74/100 [1010/1090] acc: 0.798855198019802
val--74/100 [1020/1090] acc: 0.7989276960784314
val--74/100 [1030/1090] acc: 0.7989570691747573
val--74/100 [1040/1090] acc: 0.7989445612980769
val--74/100 [1050/1090] acc: 0.7989880952380952
val--74/100 [1060/1090] acc: 0.7989276238207547
val--74/100 [1070/1090] acc: 0.7989011390186916
val--74/100 [1080/1090] acc: 0.798828125
val--74/100 [1090/1090] acc: 0.7986525229357798
epoch= 74, accuracy= 0.798653, rmse= 0.375484, auc= 0.858155
train--75/100 [9/1090] loss: 0.39543965756893157
train--75/100 [19/1090] loss: 0.44378058016300204
train--75/100 [29/1090] loss: 0.4283693253993988
train--75/100 [39/1090] loss: 0.4279812276363373
train--75/100 [49/1090] loss: 0.44271143078804015
train--75/100 [59/1090] loss: 0.4228121429681778
train--75/100 [69/1090] loss: 0.4361333101987839
train--75/100 [79/1090] loss: 0.43969227373600006
train--75/100 [89/1090] loss: 0.42146154642105105
train--75/100 [99/1090] loss: 0.4511466592550278
train--75/100 [109/1090] loss: 0.4490100085735321
train--75/100 [119/1090] loss: 0.44522745311260226
train--75/100 [129/1090] loss: 0.4302004903554916
train--75/100 [139/1090] loss: 0.4353049427270889
train--75/100 [149/1090] loss: 0.43194777965545655
train--75/100 [159/1090] loss: 0.4565019816160202
train--75/100 [169/1090] loss: 0.43206436932086945
train--75/100 [179/1090] loss: 0.41472606658935546
train--75/100 [189/1090] loss: 0.42989271581172944
train--75/100 [199/1090] loss: 0.4409007102251053
train--75/100 [209/1090] loss: 0.43862717747688296
train--75/100 [219/1090] loss: 0.45375833213329314
train--75/100 [229/1090] loss: 0.44185810983181
train--75/100 [239/1090] loss: 0.43420165181159975
train--75/100 [249/1090] loss: 0.44147658050060273
train--75/100 [259/1090] loss: 0.42929641008377073
train--75/100 [269/1090] loss: 0.4354917496442795
train--75/100 [279/1090] loss: 0.42452238500118256
train--75/100 [289/1090] loss: 0.4381436198949814
train--75/100 [299/1090] loss: 0.44982699751853944
train--75/100 [309/1090] loss: 0.43773328363895414
train--75/100 [319/1090] loss: 0.43985648453235626
train--75/100 [329/1090] loss: 0.43270029723644254
train--75/100 [339/1090] loss: 0.4593273550271988
train--75/100 [349/1090] loss: 0.43946481943130494
train--75/100 [359/1090] loss: 0.43036992847919464
train--75/100 [369/1090] loss: 0.44865878820419314
train--75/100 [379/1090] loss: 0.44385588467121123
train--75/100 [389/1090] loss: 0.4305335134267807
train--75/100 [399/1090] loss: 0.4500577986240387
train--75/100 [409/1090] loss: 0.43482291102409365
train--75/100 [419/1090] loss: 0.4400938659906387
train--75/100 [429/1090] loss: 0.4481460750102997
train--75/100 [439/1090] loss: 0.4284001290798187
train--75/100 [449/1090] loss: 0.4410232037305832
train--75/100 [459/1090] loss: 0.44127087891101835
train--75/100 [469/1090] loss: 0.43682393729686736
train--75/100 [479/1090] loss: 0.4258819311857224
train--75/100 [489/1090] loss: 0.42636496722698214
train--75/100 [499/1090] loss: 0.4349358528852463
train--75/100 [509/1090] loss: 0.44149872958660125
train--75/100 [519/1090] loss: 0.4340728849172592
train--75/100 [529/1090] loss: 0.4430482596158981
train--75/100 [539/1090] loss: 0.43411349058151244
train--75/100 [549/1090] loss: 0.44757531881332396
train--75/100 [559/1090] loss: 0.43895646929740906
train--75/100 [569/1090] loss: 0.4226048916578293
train--75/100 [579/1090] loss: 0.4170532673597336
train--75/100 [589/1090] loss: 0.4399537265300751
train--75/100 [599/1090] loss: 0.4376234769821167
train--75/100 [609/1090] loss: 0.45639367699623107
train--75/100 [619/1090] loss: 0.465535506606102
train--75/100 [629/1090] loss: 0.44056260883808135
train--75/100 [639/1090] loss: 0.4395313531160355
train--75/100 [649/1090] loss: 0.4122923195362091
train--75/100 [659/1090] loss: 0.4441919207572937
train--75/100 [669/1090] loss: 0.4388250708580017
train--75/100 [679/1090] loss: 0.45159328877925875
train--75/100 [689/1090] loss: 0.4418648391962051
train--75/100 [699/1090] loss: 0.4532556712627411
train--75/100 [709/1090] loss: 0.4405929625034332
train--75/100 [719/1090] loss: 0.4191243439912796
train--75/100 [729/1090] loss: 0.4201329261064529
train--75/100 [739/1090] loss: 0.43882560133934023
train--75/100 [749/1090] loss: 0.45728602409362795
train--75/100 [759/1090] loss: 0.4628008931875229
train--75/100 [769/1090] loss: 0.4530833512544632
train--75/100 [779/1090] loss: 0.43828666806221006
train--75/100 [789/1090] loss: 0.444141149520874
train--75/100 [799/1090] loss: 0.4390438050031662
train--75/100 [809/1090] loss: 0.4409174114465714
train--75/100 [819/1090] loss: 0.4654399067163467
train--75/100 [829/1090] loss: 0.43448940813541415
train--75/100 [839/1090] loss: 0.4391233891248703
train--75/100 [849/1090] loss: 0.44819784760475156
train--75/100 [859/1090] loss: 0.45023315846920015
train--75/100 [869/1090] loss: 0.4405040293931961
train--75/100 [879/1090] loss: 0.44418215453624726
train--75/100 [889/1090] loss: 0.44735444486141207
train--75/100 [899/1090] loss: 0.44334007799625397
train--75/100 [909/1090] loss: 0.43277851939201356
train--75/100 [919/1090] loss: 0.4276143670082092
train--75/100 [929/1090] loss: 0.457185697555542
train--75/100 [939/1090] loss: 0.44019476473331454
train--75/100 [949/1090] loss: 0.44306894242763517
train--75/100 [959/1090] loss: 0.44994201958179475
train--75/100 [969/1090] loss: 0.44486836791038514
train--75/100 [979/1090] loss: 0.43992555141448975
train--75/100 [989/1090] loss: 0.42516336143016814
train--75/100 [999/1090] loss: 0.43952597975730895
train--75/100 [1009/1090] loss: 0.4668259859085083
train--75/100 [1019/1090] loss: 0.45511597990989683
train--75/100 [1029/1090] loss: 0.44724343717098236
train--75/100 [1039/1090] loss: 0.4452083945274353
train--75/100 [1049/1090] loss: 0.44934967160224915
train--75/100 [1059/1090] loss: 0.4403382122516632
train--75/100 [1069/1090] loss: 0.44307454526424406
train--75/100 [1079/1090] loss: 0.44140976667404175
train--75/100 [1089/1090] loss: 0.44528465867042544
predicting model...
val--75/100 [10/1090] acc: 0.80078125
val--75/100 [20/1090] acc: 0.800390625
val--75/100 [30/1090] acc: 0.79921875
val--75/100 [40/1090] acc: 0.798828125
val--75/100 [50/1090] acc: 0.7978125
val--75/100 [60/1090] acc: 0.7973958333333333
val--75/100 [70/1090] acc: 0.7977678571428571
val--75/100 [80/1090] acc: 0.797412109375
val--75/100 [90/1090] acc: 0.7976128472222223
val--75/100 [100/1090] acc: 0.7983203125
val--75/100 [110/1090] acc: 0.7987571022727272
val--75/100 [120/1090] acc: 0.7982096354166667
val--75/100 [130/1090] acc: 0.7990685096153847
val--75/100 [140/1090] acc: 0.7988002232142857
val--75/100 [150/1090] acc: 0.7987760416666667
val--75/100 [160/1090] acc: 0.7989501953125
val--75/100 [170/1090] acc: 0.798828125
val--75/100 [180/1090] acc: 0.7986762152777778
val--75/100 [190/1090] acc: 0.7992393092105263
val--75/100 [200/1090] acc: 0.79955078125
val--75/100 [210/1090] acc: 0.7999255952380953
val--75/100 [220/1090] acc: 0.7989879261363636
val--75/100 [230/1090] acc: 0.7993716032608695
val--75/100 [240/1090] acc: 0.7991861979166667
val--75/100 [250/1090] acc: 0.799328125
val--75/100 [260/1090] acc: 0.7992788461538461
val--75/100 [270/1090] acc: 0.7995659722222223
val--75/100 [280/1090] acc: 0.7994140625
val--75/100 [290/1090] acc: 0.7993130387931034
val--75/100 [300/1090] acc: 0.7994661458333333
val--75/100 [310/1090] acc: 0.7993447580645161
val--75/100 [320/1090] acc: 0.79947509765625
val--75/100 [330/1090] acc: 0.7995501893939394
val--75/100 [340/1090] acc: 0.7996323529411765
val--75/100 [350/1090] acc: 0.7998325892857143
val--75/100 [360/1090] acc: 0.7996527777777778
val--75/100 [370/1090] acc: 0.7997255067567568
val--75/100 [380/1090] acc: 0.7997018914473685
val--75/100 [390/1090] acc: 0.7995793269230769
val--75/100 [400/1090] acc: 0.79953125
val--75/100 [410/1090] acc: 0.7996284298780488
val--75/100 [420/1090] acc: 0.7994791666666666
val--75/100 [430/1090] acc: 0.7992096656976744
val--75/100 [440/1090] acc: 0.7992631392045455
val--75/100 [450/1090] acc: 0.7991579861111111
val--75/100 [460/1090] acc: 0.7989724864130435
val--75/100 [470/1090] acc: 0.7988946143617022
val--75/100 [480/1090] acc: 0.798876953125
val--75/100 [490/1090] acc: 0.7989317602040816
val--75/100 [500/1090] acc: 0.7991015625
val--75/100 [510/1090] acc: 0.7989736519607843
val--75/100 [520/1090] acc: 0.7992337740384615
val--75/100 [530/1090] acc: 0.7991745283018868
val--75/100 [540/1090] acc: 0.7993055555555556
val--75/100 [550/1090] acc: 0.7991690340909091
val--75/100 [560/1090] acc: 0.7989676339285714
val--75/100 [570/1090] acc: 0.7987390350877193
val--75/100 [580/1090] acc: 0.7986799568965517
val--75/100 [590/1090] acc: 0.7986626059322034
val--75/100 [600/1090] acc: 0.79861328125
val--75/100 [610/1090] acc: 0.798578381147541
val--75/100 [620/1090] acc: 0.798538306451613
val--75/100 [630/1090] acc: 0.7988219246031746
val--75/100 [640/1090] acc: 0.7990234375
val--75/100 [650/1090] acc: 0.7990324519230769
val--75/100 [660/1090] acc: 0.799017518939394
val--75/100 [670/1090] acc: 0.7987989738805971
val--75/100 [680/1090] acc: 0.7986672794117647
val--75/100 [690/1090] acc: 0.7988111413043478
val--75/100 [700/1090] acc: 0.7988169642857142
val--75/100 [710/1090] acc: 0.798712588028169
val--75/100 [720/1090] acc: 0.79853515625
val--75/100 [730/1090] acc: 0.798480308219178
val--75/100 [740/1090] acc: 0.7984586148648649
val--75/100 [750/1090] acc: 0.7984635416666667
val--75/100 [760/1090] acc: 0.7986328125
val--75/100 [770/1090] acc: 0.798630275974026
val--75/100 [780/1090] acc: 0.7985426682692308
val--75/100 [790/1090] acc: 0.7985858386075949
val--75/100 [800/1090] acc: 0.798828125
val--75/100 [810/1090] acc: 0.7989101080246913
val--75/100 [820/1090] acc: 0.7990139100609757
val--75/100 [830/1090] acc: 0.7990775602409639
val--75/100 [840/1090] acc: 0.7990234375
val--75/100 [850/1090] acc: 0.7990395220588236
val--75/100 [860/1090] acc: 0.799305050872093
val--75/100 [870/1090] acc: 0.7992771192528736
val--75/100 [880/1090] acc: 0.7992720170454546
val--75/100 [890/1090] acc: 0.7993855337078651
val--75/100 [900/1090] acc: 0.7993663194444445
val--75/100 [910/1090] acc: 0.7993689903846154
val--75/100 [920/1090] acc: 0.7994013247282609
val--75/100 [930/1090] acc: 0.7994959677419354
val--75/100 [940/1090] acc: 0.7995013297872341
val--75/100 [950/1090] acc: 0.799436677631579
val--75/100 [960/1090] acc: 0.7993570963541666
val--75/100 [970/1090] acc: 0.7992952641752578
val--75/100 [980/1090] acc: 0.7993263711734694
val--75/100 [990/1090] acc: 0.7992424242424242
val--75/100 [1000/1090] acc: 0.7991328125
val--75/100 [1010/1090] acc: 0.7989170792079208
val--75/100 [1020/1090] acc: 0.7989698223039216
val--75/100 [1030/1090] acc: 0.7990025788834951
val--75/100 [1040/1090] acc: 0.7989858774038462
val--75/100 [1050/1090] acc: 0.7990513392857143
val--75/100 [1060/1090] acc: 0.7989939563679245
val--75/100 [1070/1090] acc: 0.7989558995327103
val--75/100 [1080/1090] acc: 0.7988823784722222
val--75/100 [1090/1090] acc: 0.7986883600917432
epoch= 75, accuracy= 0.798688, rmse= 0.375414, auc= 0.858199
train--76/100 [9/1090] loss: 0.3963789790868759
train--76/100 [19/1090] loss: 0.4413622260093689
train--76/100 [29/1090] loss: 0.4633952021598816
train--76/100 [39/1090] loss: 0.4338010162115097
train--76/100 [49/1090] loss: 0.4653997987508774
train--76/100 [59/1090] loss: 0.42381168007850645
train--76/100 [69/1090] loss: 0.4514710038900375
train--76/100 [79/1090] loss: 0.4313297808170319
train--76/100 [89/1090] loss: 0.4528546303510666
train--76/100 [99/1090] loss: 0.43292535841464996
train--76/100 [109/1090] loss: 0.4214050143957138
train--76/100 [119/1090] loss: 0.43986577689647677
train--76/100 [129/1090] loss: 0.43571680784225464
train--76/100 [139/1090] loss: 0.4279938519001007
train--76/100 [149/1090] loss: 0.4360064804553986
train--76/100 [159/1090] loss: 0.4213665187358856
train--76/100 [169/1090] loss: 0.42376421988010404
train--76/100 [179/1090] loss: 0.450948691368103
train--76/100 [189/1090] loss: 0.44976289570331573
train--76/100 [199/1090] loss: 0.4281252533197403
train--76/100 [209/1090] loss: 0.45032047629356386
train--76/100 [219/1090] loss: 0.4544646590948105
train--76/100 [229/1090] loss: 0.44972931742668154
train--76/100 [239/1090] loss: 0.4432029724121094
train--76/100 [249/1090] loss: 0.43650634288787843
train--76/100 [259/1090] loss: 0.4642819732427597
train--76/100 [269/1090] loss: 0.44717914462089536
train--76/100 [279/1090] loss: 0.44655872583389283
train--76/100 [289/1090] loss: 0.4402883380651474
train--76/100 [299/1090] loss: 0.45361486077308655
train--76/100 [309/1090] loss: 0.4505819261074066
train--76/100 [319/1090] loss: 0.4454982578754425
train--76/100 [329/1090] loss: 0.4485196381807327
train--76/100 [339/1090] loss: 0.431896311044693
train--76/100 [349/1090] loss: 0.45131832659244536
train--76/100 [359/1090] loss: 0.42436001598834994
train--76/100 [369/1090] loss: 0.4430748999118805
train--76/100 [379/1090] loss: 0.4444113314151764
train--76/100 [389/1090] loss: 0.4346973419189453
train--76/100 [399/1090] loss: 0.4499035716056824
train--76/100 [409/1090] loss: 0.4449539452791214
train--76/100 [419/1090] loss: 0.43217573761940004
train--76/100 [429/1090] loss: 0.43756004273891447
train--76/100 [439/1090] loss: 0.44412160813808443
train--76/100 [449/1090] loss: 0.4582651495933533
train--76/100 [459/1090] loss: 0.43749522864818574
train--76/100 [469/1090] loss: 0.4375525414943695
train--76/100 [479/1090] loss: 0.43863244354724884
train--76/100 [489/1090] loss: 0.415188604593277
train--76/100 [499/1090] loss: 0.43940161168575287
train--76/100 [509/1090] loss: 0.41768228709697724
train--76/100 [519/1090] loss: 0.45155192315578463
train--76/100 [529/1090] loss: 0.44142040610313416
train--76/100 [539/1090] loss: 0.43719262182712554
train--76/100 [549/1090] loss: 0.44244886338710787
train--76/100 [559/1090] loss: 0.4300271928310394
train--76/100 [569/1090] loss: 0.4170143485069275
train--76/100 [579/1090] loss: 0.43588590025901797
train--76/100 [589/1090] loss: 0.43935375809669497
train--76/100 [599/1090] loss: 0.45077277421951295
train--76/100 [609/1090] loss: 0.4406160652637482
train--76/100 [619/1090] loss: 0.447608208656311
train--76/100 [629/1090] loss: 0.44302847385406496
train--76/100 [639/1090] loss: 0.4413517892360687
train--76/100 [649/1090] loss: 0.4142694056034088
train--76/100 [659/1090] loss: 0.42671945691108704
train--76/100 [669/1090] loss: 0.4602587819099426
train--76/100 [679/1090] loss: 0.44020246267318724
train--76/100 [689/1090] loss: 0.44769450426101687
train--76/100 [699/1090] loss: 0.4136794596910477
train--76/100 [709/1090] loss: 0.4374213725328445
train--76/100 [719/1090] loss: 0.4464182287454605
train--76/100 [729/1090] loss: 0.4460024803876877
train--76/100 [739/1090] loss: 0.44423153400421145
train--76/100 [749/1090] loss: 0.4535399556159973
train--76/100 [759/1090] loss: 0.43752788603305814
train--76/100 [769/1090] loss: 0.4446971207857132
train--76/100 [779/1090] loss: 0.4375675439834595
train--76/100 [789/1090] loss: 0.4234503209590912
train--76/100 [799/1090] loss: 0.4305528849363327
train--76/100 [809/1090] loss: 0.44612949788570405
train--76/100 [819/1090] loss: 0.42885627746582033
train--76/100 [829/1090] loss: 0.4282952338457108
train--76/100 [839/1090] loss: 0.44562693536281583
train--76/100 [849/1090] loss: 0.4356945604085922
train--76/100 [859/1090] loss: 0.4390707403421402
train--76/100 [869/1090] loss: 0.4502988427877426
train--76/100 [879/1090] loss: 0.4378785014152527
train--76/100 [889/1090] loss: 0.4279887318611145
train--76/100 [899/1090] loss: 0.43446859419345857
train--76/100 [909/1090] loss: 0.4487513929605484
train--76/100 [919/1090] loss: 0.4278011381626129
train--76/100 [929/1090] loss: 0.44829346537590026
train--76/100 [939/1090] loss: 0.4545092463493347
train--76/100 [949/1090] loss: 0.4295033663511276
train--76/100 [959/1090] loss: 0.45860277116298676
train--76/100 [969/1090] loss: 0.4300736039876938
train--76/100 [979/1090] loss: 0.4385396480560303
train--76/100 [989/1090] loss: 0.44353132843971255
train--76/100 [999/1090] loss: 0.4329152017831802
train--76/100 [1009/1090] loss: 0.4499570518732071
train--76/100 [1019/1090] loss: 0.42137683629989625
train--76/100 [1029/1090] loss: 0.44216410517692567
train--76/100 [1039/1090] loss: 0.4423689663410187
train--76/100 [1049/1090] loss: 0.42739029228687286
train--76/100 [1059/1090] loss: 0.43862150311470033
train--76/100 [1069/1090] loss: 0.4436186790466309
train--76/100 [1079/1090] loss: 0.4396810382604599
train--76/100 [1089/1090] loss: 0.4587003082036972
predicting model...
val--76/100 [10/1090] acc: 0.801953125
val--76/100 [20/1090] acc: 0.802734375
val--76/100 [30/1090] acc: 0.8005208333333333
val--76/100 [40/1090] acc: 0.79990234375
val--76/100 [50/1090] acc: 0.798984375
val--76/100 [60/1090] acc: 0.7985026041666666
val--76/100 [70/1090] acc: 0.7985491071428571
val--76/100 [80/1090] acc: 0.798095703125
val--76/100 [90/1090] acc: 0.7983506944444444
val--76/100 [100/1090] acc: 0.7990625
val--76/100 [110/1090] acc: 0.7992542613636363
val--76/100 [120/1090] acc: 0.7987955729166667
val--76/100 [130/1090] acc: 0.7997896634615385
val--76/100 [140/1090] acc: 0.799609375
val--76/100 [150/1090] acc: 0.7995572916666667
val--76/100 [160/1090] acc: 0.7996826171875
val--76/100 [170/1090] acc: 0.7994485294117647
val--76/100 [180/1090] acc: 0.79921875
val--76/100 [190/1090] acc: 0.7999588815789473
val--76/100 [200/1090] acc: 0.80025390625
val--76/100 [210/1090] acc: 0.8006324404761904
val--76/100 [220/1090] acc: 0.7995916193181818
val--76/100 [230/1090] acc: 0.8
val--76/100 [240/1090] acc: 0.7998209635416667
val--76/100 [250/1090] acc: 0.799921875
val--76/100 [260/1090] acc: 0.7997896634615385
val--76/100 [270/1090] acc: 0.8001012731481482
val--76/100 [280/1090] acc: 0.7999581473214286
val--76/100 [290/1090] acc: 0.7998248922413793
val--76/100 [300/1090] acc: 0.7999739583333333
val--76/100 [310/1090] acc: 0.7998109879032258
val--76/100 [320/1090] acc: 0.79991455078125
val--76/100 [330/1090] acc: 0.8000473484848485
val--76/100 [340/1090] acc: 0.8001608455882353
val--76/100 [350/1090] acc: 0.8002790178571428
val--76/100 [360/1090] acc: 0.8001302083333334
val--76/100 [370/1090] acc: 0.8002005912162162
val--76/100 [380/1090] acc: 0.8002672697368421
val--76/100 [390/1090] acc: 0.8000701121794872
val--76/100 [400/1090] acc: 0.799970703125
val--76/100 [410/1090] acc: 0.800047637195122
val--76/100 [420/1090] acc: 0.7998790922619048
val--76/100 [430/1090] acc: 0.7995639534883721
val--76/100 [440/1090] acc: 0.7995916193181818
val--76/100 [450/1090] acc: 0.7994878472222222
val--76/100 [460/1090] acc: 0.7992951766304348
val--76/100 [470/1090] acc: 0.7992021276595744
val--76/100 [480/1090] acc: 0.7991780598958333
val--76/100 [490/1090] acc: 0.79921875
val--76/100 [500/1090] acc: 0.7993203125
val--76/100 [510/1090] acc: 0.7992417279411764
val--76/100 [520/1090] acc: 0.799481670673077
val--76/100 [530/1090] acc: 0.7994177476415094
val--76/100 [540/1090] acc: 0.7995659722222223
val--76/100 [550/1090] acc: 0.7994602272727273
val--76/100 [560/1090] acc: 0.7992536272321429
val--76/100 [570/1090] acc: 0.7990542763157895
val--76/100 [580/1090] acc: 0.7989964978448276
val--76/100 [590/1090] acc: 0.7989671610169492
val--76/100 [600/1090] acc: 0.79892578125
val--76/100 [610/1090] acc: 0.7988665471311476
val--76/100 [620/1090] acc: 0.7988533266129032
val--76/100 [630/1090] acc: 0.7991319444444445
val--76/100 [640/1090] acc: 0.799371337890625
val--76/100 [650/1090] acc: 0.7993329326923077
val--76/100 [660/1090] acc: 0.7992720170454546
val--76/100 [670/1090] acc: 0.7990496735074627
val--76/100 [680/1090] acc: 0.7989200367647059
val--76/100 [690/1090] acc: 0.7990602355072464
val--76/100 [700/1090] acc: 0.7990513392857143
val--76/100 [710/1090] acc: 0.7989161531690141
val--76/100 [720/1090] acc: 0.7987684461805555
val--76/100 [730/1090] acc: 0.7987318065068493
val--76/100 [740/1090] acc: 0.7986961570945946
val--76/100 [750/1090] acc: 0.798703125
val--76/100 [760/1090] acc: 0.7988589638157895
val--76/100 [770/1090] acc: 0.798828125
val--76/100 [780/1090] acc: 0.7987079326923077
val--76/100 [790/1090] acc: 0.7987242879746835
val--76/100 [800/1090] acc: 0.79896484375
val--76/100 [810/1090] acc: 0.7990258487654321
val--76/100 [820/1090] acc: 0.7991377667682927
val--76/100 [830/1090] acc: 0.7992140436746988
val--76/100 [840/1090] acc: 0.7991861979166667
val--76/100 [850/1090] acc: 0.7992095588235294
val--76/100 [860/1090] acc: 0.7994912790697675
val--76/100 [870/1090] acc: 0.799456716954023
val--76/100 [880/1090] acc: 0.7994762073863636
val--76/100 [890/1090] acc: 0.7995654845505618
val--76/100 [900/1090] acc: 0.7995572916666667
val--76/100 [910/1090] acc: 0.7995449862637363
val--76/100 [920/1090] acc: 0.7995669157608696
val--76/100 [930/1090] acc: 0.7996597782258065
val--76/100 [940/1090] acc: 0.7996717087765958
val--76/100 [950/1090] acc: 0.7996011513157895
val--76/100 [960/1090] acc: 0.7995157877604167
val--76/100 [970/1090] acc: 0.7994321842783505
val--76/100 [980/1090] acc: 0.7994818239795919
val--76/100 [990/1090] acc: 0.7993923611111111
val--76/100 [1000/1090] acc: 0.79930078125
val--76/100 [1010/1090] acc: 0.7990949876237624
val--76/100 [1020/1090] acc: 0.7991651348039216
val--76/100 [1030/1090] acc: 0.7991656553398059
val--76/100 [1040/1090] acc: 0.7991473858173077
val--76/100 [1050/1090] acc: 0.7992224702380952
val--76/100 [1060/1090] acc: 0.7991376768867925
val--76/100 [1070/1090] acc: 0.7991165303738318
val--76/100 [1080/1090] acc: 0.7990559895833333
val--76/100 [1090/1090] acc: 0.798860378440367
epoch= 76, accuracy= 0.798860, rmse= 0.375365, auc= 0.858313
train--77/100 [9/1090] loss: 0.4258545458316803
train--77/100 [19/1090] loss: 0.45367537438869476
train--77/100 [29/1090] loss: 0.4397388815879822
train--77/100 [39/1090] loss: 0.42974396646022794
train--77/100 [49/1090] loss: 0.44011077880859373
train--77/100 [59/1090] loss: 0.4475156605243683
train--77/100 [69/1090] loss: 0.4288479149341583
train--77/100 [79/1090] loss: 0.4437951177358627
train--77/100 [89/1090] loss: 0.42824009358882903
train--77/100 [99/1090] loss: 0.4506337195634842
train--77/100 [109/1090] loss: 0.45418524742126465
train--77/100 [119/1090] loss: 0.41734103858470917
train--77/100 [129/1090] loss: 0.43480938374996186
train--77/100 [139/1090] loss: 0.44730178117752073
train--77/100 [149/1090] loss: 0.43459797501564024
train--77/100 [159/1090] loss: 0.4205742418766022
train--77/100 [169/1090] loss: 0.42792239487171174
train--77/100 [179/1090] loss: 0.4283132880926132
train--77/100 [189/1090] loss: 0.4327371805906296
train--77/100 [199/1090] loss: 0.4217897683382034
train--77/100 [209/1090] loss: 0.42832399904727936
train--77/100 [219/1090] loss: 0.4282651782035828
train--77/100 [229/1090] loss: 0.4247317463159561
train--77/100 [239/1090] loss: 0.45131767392158506
train--77/100 [249/1090] loss: 0.4263797998428345
train--77/100 [259/1090] loss: 0.43945458233356477
train--77/100 [269/1090] loss: 0.421914154291153
train--77/100 [279/1090] loss: 0.4433619171380997
train--77/100 [289/1090] loss: 0.4353168487548828
train--77/100 [299/1090] loss: 0.4196320056915283
train--77/100 [309/1090] loss: 0.4353319495916367
train--77/100 [319/1090] loss: 0.44076099395751955
train--77/100 [329/1090] loss: 0.44744396209716797
train--77/100 [339/1090] loss: 0.447446671128273
train--77/100 [349/1090] loss: 0.43178452253341676
train--77/100 [359/1090] loss: 0.4388343870639801
train--77/100 [369/1090] loss: 0.44546682834625245
train--77/100 [379/1090] loss: 0.43952910602092743
train--77/100 [389/1090] loss: 0.4418178707361221
train--77/100 [399/1090] loss: 0.44921648800373076
train--77/100 [409/1090] loss: 0.4425332576036453
train--77/100 [419/1090] loss: 0.41081381142139434
train--77/100 [429/1090] loss: 0.4587931662797928
train--77/100 [439/1090] loss: 0.44473573863506316
train--77/100 [449/1090] loss: 0.45980831384658816
train--77/100 [459/1090] loss: 0.43590773940086364
train--77/100 [469/1090] loss: 0.411263108253479
train--77/100 [479/1090] loss: 0.45618861019611356
train--77/100 [489/1090] loss: 0.45097332894802095
train--77/100 [499/1090] loss: 0.42488897740840914
train--77/100 [509/1090] loss: 0.4441537618637085
train--77/100 [519/1090] loss: 0.4520721912384033
train--77/100 [529/1090] loss: 0.45578897595405576
train--77/100 [539/1090] loss: 0.45782372951507566
train--77/100 [549/1090] loss: 0.45034206509590147
train--77/100 [559/1090] loss: 0.45369450747966766
train--77/100 [569/1090] loss: 0.43297727704048156
train--77/100 [579/1090] loss: 0.44923592209815977
train--77/100 [589/1090] loss: 0.4310909241437912
train--77/100 [599/1090] loss: 0.4503476440906525
train--77/100 [609/1090] loss: 0.44523678719997406
train--77/100 [619/1090] loss: 0.4394740372896194
train--77/100 [629/1090] loss: 0.438363653421402
train--77/100 [639/1090] loss: 0.4400433599948883
train--77/100 [649/1090] loss: 0.4240579456090927
train--77/100 [659/1090] loss: 0.4562582165002823
train--77/100 [669/1090] loss: 0.42865159809589387
train--77/100 [679/1090] loss: 0.4465423941612244
train--77/100 [689/1090] loss: 0.43674557507038114
train--77/100 [699/1090] loss: 0.42635863125324247
train--77/100 [709/1090] loss: 0.42186484336853025
train--77/100 [719/1090] loss: 0.4601494789123535
train--77/100 [729/1090] loss: 0.44348802268505094
train--77/100 [739/1090] loss: 0.45313146710395813
train--77/100 [749/1090] loss: 0.4641849249601364
train--77/100 [759/1090] loss: 0.4380835384130478
train--77/100 [769/1090] loss: 0.4332659363746643
train--77/100 [779/1090] loss: 0.4528362303972244
train--77/100 [789/1090] loss: 0.4550210565328598
train--77/100 [799/1090] loss: 0.4322083294391632
train--77/100 [809/1090] loss: 0.43682959377765657
train--77/100 [819/1090] loss: 0.42408316135406493
train--77/100 [829/1090] loss: 0.4551319420337677
train--77/100 [839/1090] loss: 0.4281046062707901
train--77/100 [849/1090] loss: 0.4389778196811676
train--77/100 [859/1090] loss: 0.4352251559495926
train--77/100 [869/1090] loss: 0.4469648152589798
train--77/100 [879/1090] loss: 0.4297689735889435
train--77/100 [889/1090] loss: 0.43908551633358
train--77/100 [899/1090] loss: 0.4551746755838394
train--77/100 [909/1090] loss: 0.4600490391254425
train--77/100 [919/1090] loss: 0.4408443599939346
train--77/100 [929/1090] loss: 0.46133760213851926
train--77/100 [939/1090] loss: 0.43531252145767213
train--77/100 [949/1090] loss: 0.42262279987335205
train--77/100 [959/1090] loss: 0.43590339422225954
train--77/100 [969/1090] loss: 0.46420093178749083
train--77/100 [979/1090] loss: 0.43784502148628235
train--77/100 [989/1090] loss: 0.4336273729801178
train--77/100 [999/1090] loss: 0.43374728560447695
train--77/100 [1009/1090] loss: 0.4233847588300705
train--77/100 [1019/1090] loss: 0.43096449673175813
train--77/100 [1029/1090] loss: 0.4310947597026825
train--77/100 [1039/1090] loss: 0.4394022971391678
train--77/100 [1049/1090] loss: 0.4522934466600418
train--77/100 [1059/1090] loss: 0.44428859651088715
train--77/100 [1069/1090] loss: 0.43358193039894105
train--77/100 [1079/1090] loss: 0.444211819767952
train--77/100 [1089/1090] loss: 0.4394940108060837
predicting model...
val--77/100 [10/1090] acc: 0.80234375
val--77/100 [20/1090] acc: 0.801953125
val--77/100 [30/1090] acc: 0.8
val--77/100 [40/1090] acc: 0.79990234375
val--77/100 [50/1090] acc: 0.798203125
val--77/100 [60/1090] acc: 0.7978515625
val--77/100 [70/1090] acc: 0.7981584821428571
val--77/100 [80/1090] acc: 0.797802734375
val--77/100 [90/1090] acc: 0.7983506944444444
val--77/100 [100/1090] acc: 0.7991796875
val--77/100 [110/1090] acc: 0.7989701704545454
val--77/100 [120/1090] acc: 0.7986653645833334
val--77/100 [130/1090] acc: 0.7995192307692308
val--77/100 [140/1090] acc: 0.7992466517857143
val--77/100 [150/1090] acc: 0.7992708333333334
val--77/100 [160/1090] acc: 0.799267578125
val--77/100 [170/1090] acc: 0.7990579044117647
val--77/100 [180/1090] acc: 0.7986545138888889
val--77/100 [190/1090] acc: 0.7993832236842106
val--77/100 [200/1090] acc: 0.79974609375
val--77/100 [210/1090] acc: 0.8000744047619047
val--77/100 [220/1090] acc: 0.7991122159090909
val--77/100 [230/1090] acc: 0.7994904891304347
val--77/100 [240/1090] acc: 0.7992350260416666
val--77/100 [250/1090] acc: 0.7994375
val--77/100 [260/1090] acc: 0.7993539663461539
val--77/100 [270/1090] acc: 0.7997395833333333
val--77/100 [280/1090] acc: 0.7996372767857143
val--77/100 [290/1090] acc: 0.7995554956896552
val--77/100 [300/1090] acc: 0.7997265625
val--77/100 [310/1090] acc: 0.7995967741935484
val--77/100 [320/1090] acc: 0.7996337890625
val--77/100 [330/1090] acc: 0.7998224431818182
val--77/100 [340/1090] acc: 0.7998621323529411
val--77/100 [350/1090] acc: 0.7999665178571429
val--77/100 [360/1090] acc: 0.7998480902777778
val--77/100 [370/1090] acc: 0.7999049831081081
val--77/100 [380/1090] acc: 0.7998663651315789
val--77/100 [390/1090] acc: 0.7996995192307692
val--77/100 [400/1090] acc: 0.79970703125
val--77/100 [410/1090] acc: 0.7998380335365853
val--77/100 [420/1090] acc: 0.7996372767857143
val--77/100 [430/1090] acc: 0.7993640988372093
val--77/100 [440/1090] acc: 0.7993696732954545
val--77/100 [450/1090] acc: 0.7992447916666666
val--77/100 [460/1090] acc: 0.7991168478260869
val--77/100 [470/1090] acc: 0.7990608377659575
val--77/100 [480/1090] acc: 0.7989908854166666
val--77/100 [490/1090] acc: 0.7990513392857143
val--77/100 [500/1090] acc: 0.7991875
val--77/100 [510/1090] acc: 0.7990579044117647
val--77/100 [520/1090] acc: 0.7993464543269231
val--77/100 [530/1090] acc: 0.7993145636792452
val--77/100 [540/1090] acc: 0.7994068287037037
val--77/100 [550/1090] acc: 0.7992400568181818
val--77/100 [560/1090] acc: 0.7990094866071429
val--77/100 [570/1090] acc: 0.7987733004385965
val--77/100 [580/1090] acc: 0.7987540409482758
val--77/100 [590/1090] acc: 0.7987685381355932
val--77/100 [600/1090] acc: 0.7987174479166667
val--77/100 [610/1090] acc: 0.798687243852459
val--77/100 [620/1090] acc: 0.7986706149193549
val--77/100 [630/1090] acc: 0.7989459325396825
val--77/100 [640/1090] acc: 0.7991455078125
val--77/100 [650/1090] acc: 0.7991466346153846
val--77/100 [660/1090] acc: 0.7990707859848485
val--77/100 [670/1090] acc: 0.7988222947761194
val--77/100 [680/1090] acc: 0.7986845128676471
val--77/100 [690/1090] acc: 0.7988224637681159
val--77/100 [700/1090] acc: 0.7988113839285714
val--77/100 [710/1090] acc: 0.7987070862676057
val--77/100 [720/1090] acc: 0.7985243055555555
val--77/100 [730/1090] acc: 0.798480308219178
val--77/100 [740/1090] acc: 0.7984058277027027
val--77/100 [750/1090] acc: 0.7984479166666667
val--77/100 [760/1090] acc: 0.7986225328947368
val--77/100 [770/1090] acc: 0.7985998376623377
val--77/100 [780/1090] acc: 0.7985176282051282
val--77/100 [790/1090] acc: 0.7985611155063291
val--77/100 [800/1090] acc: 0.798818359375
val--77/100 [810/1090] acc: 0.7988618827160494
val--77/100 [820/1090] acc: 0.7989519817073171
val--77/100 [830/1090] acc: 0.7990163780120482
val--77/100 [840/1090] acc: 0.7989955357142857
val--77/100 [850/1090] acc: 0.7990257352941177
val--77/100 [860/1090] acc: 0.7993413880813953
val--77/100 [870/1090] acc: 0.799286099137931
val--77/100 [880/1090] acc: 0.79931640625
val--77/100 [890/1090] acc: 0.7994074789325842
val--77/100 [900/1090] acc: 0.799375
val--77/100 [910/1090] acc: 0.7993689903846154
val--77/100 [920/1090] acc: 0.799409816576087
val--77/100 [930/1090] acc: 0.7995127688172043
val--77/100 [940/1090] acc: 0.7995096409574468
val--77/100 [950/1090] acc: 0.7994490131578947
val--77/100 [960/1090] acc: 0.7993693033854167
val--77/100 [970/1090] acc: 0.7992872100515463
val--77/100 [980/1090] acc: 0.7993263711734694
val--77/100 [990/1090] acc: 0.7992266414141415
val--77/100 [1000/1090] acc: 0.79910546875
val--77/100 [1010/1090] acc: 0.7988706683168317
val--77/100 [1020/1090] acc: 0.7989276960784314
val--77/100 [1030/1090] acc: 0.7989570691747573
val--77/100 [1040/1090] acc: 0.7989370492788461
val--77/100 [1050/1090] acc: 0.7990066964285715
val--77/100 [1060/1090] acc: 0.7989313089622642
val--77/100 [1070/1090] acc: 0.7989193925233645
val--77/100 [1080/1090] acc: 0.7988317418981481
val--77/100 [1090/1090] acc: 0.7986453555045872
epoch= 77, accuracy= 0.798645, rmse= 0.375343, auc= 0.858223
train--78/100 [9/1090] loss: 0.40936470329761504
train--78/100 [19/1090] loss: 0.43229744732379916
train--78/100 [29/1090] loss: 0.44312075078487395
train--78/100 [39/1090] loss: 0.4479020059108734
train--78/100 [49/1090] loss: 0.42722971439361573
train--78/100 [59/1090] loss: 0.4407073736190796
train--78/100 [69/1090] loss: 0.43146670460700987
train--78/100 [79/1090] loss: 0.44546287059783934
train--78/100 [89/1090] loss: 0.441719126701355
train--78/100 [99/1090] loss: 0.4404803693294525
train--78/100 [109/1090] loss: 0.4406235456466675
train--78/100 [119/1090] loss: 0.4376707136631012
train--78/100 [129/1090] loss: 0.4237060546875
train--78/100 [139/1090] loss: 0.4249537527561188
train--78/100 [149/1090] loss: 0.4301320374011993
train--78/100 [159/1090] loss: 0.44163290560245516
train--78/100 [169/1090] loss: 0.4449940949678421
train--78/100 [179/1090] loss: 0.44308320581912997
train--78/100 [189/1090] loss: 0.43518774807453153
train--78/100 [199/1090] loss: 0.4465802699327469
train--78/100 [209/1090] loss: 0.4506040632724762
train--78/100 [219/1090] loss: 0.4400771349668503
train--78/100 [229/1090] loss: 0.43823619484901427
train--78/100 [239/1090] loss: 0.4361175686120987
train--78/100 [249/1090] loss: 0.448934531211853
train--78/100 [259/1090] loss: 0.4380233585834503
train--78/100 [269/1090] loss: 0.4427100598812103
train--78/100 [279/1090] loss: 0.4291072368621826
train--78/100 [289/1090] loss: 0.442947068810463
train--78/100 [299/1090] loss: 0.42983137965202334
train--78/100 [309/1090] loss: 0.43398630917072295
train--78/100 [319/1090] loss: 0.43689244985580444
train--78/100 [329/1090] loss: 0.4345523834228516
train--78/100 [339/1090] loss: 0.42825105488300325
train--78/100 [349/1090] loss: 0.4408160597085953
train--78/100 [359/1090] loss: 0.4408009499311447
train--78/100 [369/1090] loss: 0.4279001444578171
train--78/100 [379/1090] loss: 0.43669413328170775
train--78/100 [389/1090] loss: 0.4323847383260727
train--78/100 [399/1090] loss: 0.4338087648153305
train--78/100 [409/1090] loss: 0.44830926358699796
train--78/100 [419/1090] loss: 0.4383243560791016
train--78/100 [429/1090] loss: 0.4266763120889664
train--78/100 [439/1090] loss: 0.45332220792770384
train--78/100 [449/1090] loss: 0.4487013310194016
train--78/100 [459/1090] loss: 0.4469749480485916
train--78/100 [469/1090] loss: 0.4407630950212479
train--78/100 [479/1090] loss: 0.42576121389865873
train--78/100 [489/1090] loss: 0.4274959206581116
train--78/100 [499/1090] loss: 0.44356330633163454
train--78/100 [509/1090] loss: 0.4302855283021927
train--78/100 [519/1090] loss: 0.45432406663894653
train--78/100 [529/1090] loss: 0.43811768889427183
train--78/100 [539/1090] loss: 0.44544821977615356
train--78/100 [549/1090] loss: 0.4424676924943924
train--78/100 [559/1090] loss: 0.4381234377622604
train--78/100 [569/1090] loss: 0.43423415124416354
train--78/100 [579/1090] loss: 0.4493719875812531
train--78/100 [589/1090] loss: 0.4497531086206436
train--78/100 [599/1090] loss: 0.43869238197803495
train--78/100 [609/1090] loss: 0.41960286200046537
train--78/100 [619/1090] loss: 0.4280715674161911
train--78/100 [629/1090] loss: 0.4421149790287018
train--78/100 [639/1090] loss: 0.4434261411428452
train--78/100 [649/1090] loss: 0.4407940566539764
train--78/100 [659/1090] loss: 0.4561458617448807
train--78/100 [669/1090] loss: 0.4545095920562744
train--78/100 [679/1090] loss: 0.439311158657074
train--78/100 [689/1090] loss: 0.4428102493286133
train--78/100 [699/1090] loss: 0.4511144757270813
train--78/100 [709/1090] loss: 0.4256154626607895
train--78/100 [719/1090] loss: 0.46085824966430666
train--78/100 [729/1090] loss: 0.4605885922908783
train--78/100 [739/1090] loss: 0.4292333126068115
train--78/100 [749/1090] loss: 0.43066619634628295
train--78/100 [759/1090] loss: 0.43673714995384216
train--78/100 [769/1090] loss: 0.4372875034809113
train--78/100 [779/1090] loss: 0.45565134286880493
train--78/100 [789/1090] loss: 0.43102401196956636
train--78/100 [799/1090] loss: 0.4649843156337738
train--78/100 [809/1090] loss: 0.4359569251537323
train--78/100 [819/1090] loss: 0.4375201940536499
train--78/100 [829/1090] loss: 0.46367289423942565
train--78/100 [839/1090] loss: 0.4470284402370453
train--78/100 [849/1090] loss: 0.4477991223335266
train--78/100 [859/1090] loss: 0.4292786121368408
train--78/100 [869/1090] loss: 0.43406848311424256
train--78/100 [879/1090] loss: 0.4442331790924072
train--78/100 [889/1090] loss: 0.43289209008216856
train--78/100 [899/1090] loss: 0.43398328125476837
train--78/100 [909/1090] loss: 0.44060595631599425
train--78/100 [919/1090] loss: 0.4657671689987183
train--78/100 [929/1090] loss: 0.4268423914909363
train--78/100 [939/1090] loss: 0.45262039005756377
train--78/100 [949/1090] loss: 0.4339993327856064
train--78/100 [959/1090] loss: 0.4391780734062195
train--78/100 [969/1090] loss: 0.43127226233482363
train--78/100 [979/1090] loss: 0.44240838587284087
train--78/100 [989/1090] loss: 0.4505201667547226
train--78/100 [999/1090] loss: 0.43518895506858823
train--78/100 [1009/1090] loss: 0.4331942707300186
train--78/100 [1019/1090] loss: 0.44285487234592436
train--78/100 [1029/1090] loss: 0.4383466005325317
train--78/100 [1039/1090] loss: 0.4441249281167984
train--78/100 [1049/1090] loss: 0.4413688898086548
train--78/100 [1059/1090] loss: 0.4236512094736099
train--78/100 [1069/1090] loss: 0.4202465981245041
train--78/100 [1079/1090] loss: 0.4280903071165085
train--78/100 [1089/1090] loss: 0.44495580792427064
predicting model...
val--78/100 [10/1090] acc: 0.799609375
val--78/100 [20/1090] acc: 0.7994140625
val--78/100 [30/1090] acc: 0.7981770833333334
val--78/100 [40/1090] acc: 0.7984375
val--78/100 [50/1090] acc: 0.7975
val--78/100 [60/1090] acc: 0.7970703125
val--78/100 [70/1090] acc: 0.7972098214285714
val--78/100 [80/1090] acc: 0.7966796875
val--78/100 [90/1090] acc: 0.7970486111111111
val--78/100 [100/1090] acc: 0.798203125
val--78/100 [110/1090] acc: 0.7984019886363637
val--78/100 [120/1090] acc: 0.7978841145833333
val--78/100 [130/1090] acc: 0.7989182692307693
val--78/100 [140/1090] acc: 0.7986328125
val--78/100 [150/1090] acc: 0.79875
val--78/100 [160/1090] acc: 0.798876953125
val--78/100 [170/1090] acc: 0.7987362132352941
val--78/100 [180/1090] acc: 0.7985460069444444
val--78/100 [190/1090] acc: 0.7993009868421053
val--78/100 [200/1090] acc: 0.7995703125
val--78/100 [210/1090] acc: 0.7999627976190476
val--78/100 [220/1090] acc: 0.7990234375
val--78/100 [230/1090] acc: 0.799422554347826
val--78/100 [240/1090] acc: 0.7992024739583333
val--78/100 [250/1090] acc: 0.799421875
val--78/100 [260/1090] acc: 0.7992938701923077
val--78/100 [270/1090] acc: 0.7995804398148149
val--78/100 [280/1090] acc: 0.7994419642857142
val--78/100 [290/1090] acc: 0.7993534482758621
val--78/100 [300/1090] acc: 0.79953125
val--78/100 [310/1090] acc: 0.7993321572580645
val--78/100 [320/1090] acc: 0.79954833984375
val--78/100 [330/1090] acc: 0.7996212121212121
val--78/100 [340/1090] acc: 0.7997012867647059
val--78/100 [350/1090] acc: 0.7999553571428571
val--78/100 [360/1090] acc: 0.7998155381944444
val--78/100 [370/1090] acc: 0.7998627533783784
val--78/100 [380/1090] acc: 0.7999691611842106
val--78/100 [390/1090] acc: 0.7998297275641025
val--78/100 [400/1090] acc: 0.799794921875
val--78/100 [410/1090] acc: 0.7999047256097561
val--78/100 [420/1090] acc: 0.7997395833333333
val--78/100 [430/1090] acc: 0.7994004360465117
val--78/100 [440/1090] acc: 0.7994406960227273
val--78/100 [450/1090] acc: 0.7993055555555556
val--78/100 [460/1090] acc: 0.7991508152173913
val--78/100 [470/1090] acc: 0.799077460106383
val--78/100 [480/1090] acc: 0.7990559895833333
val--78/100 [490/1090] acc: 0.7991390306122449
val--78/100 [500/1090] acc: 0.799265625
val--78/100 [510/1090] acc: 0.7991268382352941
val--78/100 [520/1090] acc: 0.7994215745192308
val--78/100 [530/1090] acc: 0.7993145636792452
val--78/100 [540/1090] acc: 0.7993923611111111
val--78/100 [550/1090] acc: 0.799247159090909
val--78/100 [560/1090] acc: 0.799072265625
val--78/100 [570/1090] acc: 0.798780153508772
val--78/100 [580/1090] acc: 0.7987271012931034
val--78/100 [590/1090] acc: 0.7987089512711865
val--78/100 [600/1090] acc: 0.7986848958333334
val--78/100 [610/1090] acc: 0.798655225409836
val--78/100 [620/1090] acc: 0.7986139112903226
val--78/100 [630/1090] acc: 0.7988777281746032
val--78/100 [640/1090] acc: 0.7990478515625
val--78/100 [650/1090] acc: 0.7990264423076923
val--78/100 [660/1090] acc: 0.7989583333333333
val--78/100 [670/1090] acc: 0.7987756529850746
val--78/100 [680/1090] acc: 0.7986155790441176
val--78/100 [690/1090] acc: 0.7987432065217391
val--78/100 [700/1090] acc: 0.7987555803571429
val--78/100 [710/1090] acc: 0.7985915492957747
val--78/100 [720/1090] acc: 0.7984320746527778
val--78/100 [730/1090] acc: 0.798416095890411
val--78/100 [740/1090] acc: 0.798363597972973
val--78/100 [750/1090] acc: 0.798375
val--78/100 [760/1090] acc: 0.7985248766447368
val--78/100 [770/1090] acc: 0.7984831574675325
val--78/100 [780/1090] acc: 0.7983924278846154
val--78/100 [790/1090] acc: 0.7983979430379747
val--78/100 [800/1090] acc: 0.79865234375
val--78/100 [810/1090] acc: 0.7986786265432099
val--78/100 [820/1090] acc: 0.7987661966463414
val--78/100 [830/1090] acc: 0.798828125
val--78/100 [840/1090] acc: 0.7988002232142857
val--78/100 [850/1090] acc: 0.7988143382352941
val--78/100 [860/1090] acc: 0.7991006540697675
val--78/100 [870/1090] acc: 0.7990750718390804
val--78/100 [880/1090] acc: 0.7990767045454545
val--78/100 [890/1090] acc: 0.7991397471910112
val--78/100 [900/1090] acc: 0.7991102430555556
val--78/100 [910/1090] acc: 0.7991071428571429
val--78/100 [920/1090] acc: 0.7991338315217391
val--78/100 [930/1090] acc: 0.7992481518817204
val--78/100 [940/1090] acc: 0.7992686170212766
val--78/100 [950/1090] acc: 0.7992269736842105
val--78/100 [960/1090] acc: 0.7991617838541667
val--78/100 [970/1090] acc: 0.79909793814433
val--78/100 [980/1090] acc: 0.7991230867346939
val--78/100 [990/1090] acc: 0.7990372474747475
val--78/100 [1000/1090] acc: 0.798921875
val--78/100 [1010/1090] acc: 0.7986966274752475
val--78/100 [1020/1090] acc: 0.798766850490196
val--78/100 [1030/1090] acc: 0.7987826152912622
val--78/100 [1040/1090] acc: 0.7987868088942308
val--78/100 [1050/1090] acc: 0.7988244047619047
val--78/100 [1060/1090] acc: 0.7987691627358491
val--78/100 [1070/1090] acc: 0.7987405081775701
val--78/100 [1080/1090] acc: 0.7986870659722223
val--78/100 [1090/1090] acc: 0.7985235091743119
epoch= 78, accuracy= 0.798524, rmse= 0.375235, auc= 0.858364
train--79/100 [9/1090] loss: 0.3694563955068588
train--79/100 [19/1090] loss: 0.4345886081457138
train--79/100 [29/1090] loss: 0.4427160382270813
train--79/100 [39/1090] loss: 0.4268494486808777
train--79/100 [49/1090] loss: 0.42575441896915434
train--79/100 [59/1090] loss: 0.4436107575893402
train--79/100 [69/1090] loss: 0.44093631505966185
train--79/100 [79/1090] loss: 0.45657103061676024
train--79/100 [89/1090] loss: 0.44061496257781985
train--79/100 [99/1090] loss: 0.4396191269159317
train--79/100 [109/1090] loss: 0.43277187943458556
train--79/100 [119/1090] loss: 0.42537673115730285
train--79/100 [129/1090] loss: 0.4476603776216507
train--79/100 [139/1090] loss: 0.42998331785202026
train--79/100 [149/1090] loss: 0.43092540502548216
train--79/100 [159/1090] loss: 0.4316209018230438
train--79/100 [169/1090] loss: 0.43603022694587706
train--79/100 [179/1090] loss: 0.42780655026435854
train--79/100 [189/1090] loss: 0.44936600923538206
train--79/100 [199/1090] loss: 0.4248966366052628
train--79/100 [209/1090] loss: 0.4257110744714737
train--79/100 [219/1090] loss: 0.43776909112930296
train--79/100 [229/1090] loss: 0.4352391600608826
train--79/100 [239/1090] loss: 0.42190520763397216
train--79/100 [249/1090] loss: 0.4390086650848389
train--79/100 [259/1090] loss: 0.4391506463289261
train--79/100 [269/1090] loss: 0.44719667732715607
train--79/100 [279/1090] loss: 0.4356681525707245
train--79/100 [289/1090] loss: 0.42735629379749296
train--79/100 [299/1090] loss: 0.43173655271530154
train--79/100 [309/1090] loss: 0.4368383824825287
train--79/100 [319/1090] loss: 0.44749106764793395
train--79/100 [329/1090] loss: 0.4387108087539673
train--79/100 [339/1090] loss: 0.4231571167707443
train--79/100 [349/1090] loss: 0.4231661021709442
train--79/100 [359/1090] loss: 0.4472871035337448
train--79/100 [369/1090] loss: 0.447201544046402
train--79/100 [379/1090] loss: 0.4536650627851486
train--79/100 [389/1090] loss: 0.438862943649292
train--79/100 [399/1090] loss: 0.4345048278570175
train--79/100 [409/1090] loss: 0.4249296814203262
train--79/100 [419/1090] loss: 0.41415990591049195
train--79/100 [429/1090] loss: 0.4480806767940521
train--79/100 [439/1090] loss: 0.4451015591621399
train--79/100 [449/1090] loss: 0.4314844816923141
train--79/100 [459/1090] loss: 0.43183382153511046
train--79/100 [469/1090] loss: 0.433114555478096
train--79/100 [479/1090] loss: 0.4334783047437668
train--79/100 [489/1090] loss: 0.43894902169704436
train--79/100 [499/1090] loss: 0.4384235739707947
train--79/100 [509/1090] loss: 0.4468786895275116
train--79/100 [519/1090] loss: 0.44779224395751954
train--79/100 [529/1090] loss: 0.4358926624059677
train--79/100 [539/1090] loss: 0.43125138282775877
train--79/100 [549/1090] loss: 0.4372700065374374
train--79/100 [559/1090] loss: 0.4746190011501312
train--79/100 [569/1090] loss: 0.44531661570072173
train--79/100 [579/1090] loss: 0.468846994638443
train--79/100 [589/1090] loss: 0.4364884853363037
train--79/100 [599/1090] loss: 0.4620872288942337
train--79/100 [609/1090] loss: 0.43048734962940216
train--79/100 [619/1090] loss: 0.4259050339460373
train--79/100 [629/1090] loss: 0.428147754073143
train--79/100 [639/1090] loss: 0.4748258650302887
train--79/100 [649/1090] loss: 0.4511156022548676
train--79/100 [659/1090] loss: 0.4354034036397934
train--79/100 [669/1090] loss: 0.4367920458316803
train--79/100 [679/1090] loss: 0.45342698991298674
train--79/100 [689/1090] loss: 0.4386266738176346
train--79/100 [699/1090] loss: 0.460767525434494
train--79/100 [709/1090] loss: 0.4307857185602188
train--79/100 [719/1090] loss: 0.45132023096084595
train--79/100 [729/1090] loss: 0.4577405482530594
train--79/100 [739/1090] loss: 0.428435742855072
train--79/100 [749/1090] loss: 0.44168274402618407
train--79/100 [759/1090] loss: 0.43269656002521517
train--79/100 [769/1090] loss: 0.4317004084587097
train--79/100 [779/1090] loss: 0.46883662343025206
train--79/100 [789/1090] loss: 0.4544918924570084
train--79/100 [799/1090] loss: 0.4130359649658203
train--79/100 [809/1090] loss: 0.43653562366962434
train--79/100 [819/1090] loss: 0.42933682501316073
train--79/100 [829/1090] loss: 0.43480847775936127
train--79/100 [839/1090] loss: 0.437254798412323
train--79/100 [849/1090] loss: 0.4532807469367981
train--79/100 [859/1090] loss: 0.45601139664649964
train--79/100 [869/1090] loss: 0.44133091270923613
train--79/100 [879/1090] loss: 0.44399322271347047
train--79/100 [889/1090] loss: 0.42919797003269194
train--79/100 [899/1090] loss: 0.4357179760932922
train--79/100 [909/1090] loss: 0.4293405771255493
train--79/100 [919/1090] loss: 0.44684035181999204
train--79/100 [929/1090] loss: 0.45161859691143036
train--79/100 [939/1090] loss: 0.44263373613357543
train--79/100 [949/1090] loss: 0.4508452922105789
train--79/100 [959/1090] loss: 0.4517141759395599
train--79/100 [969/1090] loss: 0.4685502231121063
train--79/100 [979/1090] loss: 0.4159473717212677
train--79/100 [989/1090] loss: 0.4418497920036316
train--79/100 [999/1090] loss: 0.4290962517261505
train--79/100 [1009/1090] loss: 0.4335183620452881
train--79/100 [1019/1090] loss: 0.4479056090116501
train--79/100 [1029/1090] loss: 0.4427903562784195
train--79/100 [1039/1090] loss: 0.4320936739444733
train--79/100 [1049/1090] loss: 0.44982938170433046
train--79/100 [1059/1090] loss: 0.4501448631286621
train--79/100 [1069/1090] loss: 0.4558949649333954
train--79/100 [1079/1090] loss: 0.44036526083946226
train--79/100 [1089/1090] loss: 0.4266384929418564
predicting model...
val--79/100 [10/1090] acc: 0.803515625
val--79/100 [20/1090] acc: 0.8029296875
val--79/100 [30/1090] acc: 0.800390625
val--79/100 [40/1090] acc: 0.8
val--79/100 [50/1090] acc: 0.79890625
val--79/100 [60/1090] acc: 0.7981119791666667
val--79/100 [70/1090] acc: 0.7982700892857143
val--79/100 [80/1090] acc: 0.79765625
val--79/100 [90/1090] acc: 0.7979600694444444
val--79/100 [100/1090] acc: 0.798828125
val--79/100 [110/1090] acc: 0.7989701704545454
val--79/100 [120/1090] acc: 0.7984049479166667
val--79/100 [130/1090] acc: 0.7994290865384616
val--79/100 [140/1090] acc: 0.7992466517857143
val--79/100 [150/1090] acc: 0.7990625
val--79/100 [160/1090] acc: 0.79912109375
val--79/100 [170/1090] acc: 0.7988970588235295
val--79/100 [180/1090] acc: 0.7986762152777778
val--79/100 [190/1090] acc: 0.7993626644736842
val--79/100 [200/1090] acc: 0.79955078125
val--79/100 [210/1090] acc: 0.8
val--79/100 [220/1090] acc: 0.7991654829545455
val--79/100 [230/1090] acc: 0.7995754076086956
val--79/100 [240/1090] acc: 0.7994303385416667
val--79/100 [250/1090] acc: 0.799546875
val--79/100 [260/1090] acc: 0.7994140625
val--79/100 [270/1090] acc: 0.7997540509259259
val--79/100 [280/1090] acc: 0.7996233258928571
val--79/100 [290/1090] acc: 0.7995554956896552
val--79/100 [300/1090] acc: 0.7998177083333333
val--79/100 [310/1090] acc: 0.7996723790322581
val--79/100 [320/1090] acc: 0.79984130859375
val--79/100 [330/1090] acc: 0.7999644886363636
val--79/100 [340/1090] acc: 0.8000919117647058
val--79/100 [350/1090] acc: 0.8002455357142857
val--79/100 [360/1090] acc: 0.8001085069444445
val--79/100 [370/1090] acc: 0.8002111486486486
val--79/100 [380/1090] acc: 0.8002261513157894
val--79/100 [390/1090] acc: 0.8000901442307692
val--79/100 [400/1090] acc: 0.800078125
val--79/100 [410/1090] acc: 0.8001810213414634
val--79/100 [420/1090] acc: 0.8000558035714286
val--79/100 [430/1090] acc: 0.7997365552325582
val--79/100 [440/1090] acc: 0.7997869318181818
val--79/100 [450/1090] acc: 0.7996354166666667
val--79/100 [460/1090] acc: 0.7994395380434782
val--79/100 [470/1090] acc: 0.799360039893617
val--79/100 [480/1090] acc: 0.7993570963541666
val--79/100 [490/1090] acc: 0.7993861607142857
val--79/100 [500/1090] acc: 0.799546875
val--79/100 [510/1090] acc: 0.7994178921568628
val--79/100 [520/1090] acc: 0.7996619591346154
val--79/100 [530/1090] acc: 0.799609375
val--79/100 [540/1090] acc: 0.7997540509259259
val--79/100 [550/1090] acc: 0.799609375
val--79/100 [560/1090] acc: 0.7994419642857142
val--79/100 [570/1090] acc: 0.7992050438596491
val--79/100 [580/1090] acc: 0.7991783405172413
val--79/100 [590/1090] acc: 0.7991591631355932
val--79/100 [600/1090] acc: 0.79908203125
val--79/100 [610/1090] acc: 0.7990074282786885
val--79/100 [620/1090] acc: 0.7989793346774193
val--79/100 [630/1090] acc: 0.7992373511904762
val--79/100 [640/1090] acc: 0.799420166015625
val--79/100 [650/1090] acc: 0.799405048076923
val--79/100 [660/1090] acc: 0.7993607954545454
val--79/100 [670/1090] acc: 0.7991312966417911
val--79/100 [680/1090] acc: 0.7989487591911765
val--79/100 [690/1090] acc: 0.7990942028985507
val--79/100 [700/1090] acc: 0.7991071428571429
val--79/100 [710/1090] acc: 0.7990041813380282
val--79/100 [720/1090] acc: 0.798828125
val--79/100 [730/1090] acc: 0.7987906678082192
val--79/100 [740/1090] acc: 0.7987436655405405
val--79/100 [750/1090] acc: 0.7987395833333333
val--79/100 [760/1090] acc: 0.7989514802631579
val--79/100 [770/1090] acc: 0.7989092938311688
val--79/100 [780/1090] acc: 0.798818108974359
val--79/100 [790/1090] acc: 0.7988330696202531
val--79/100 [800/1090] acc: 0.799072265625
val--79/100 [810/1090] acc: 0.7991271219135803
val--79/100 [820/1090] acc: 0.7991996951219512
val--79/100 [830/1090] acc: 0.7992564006024097
val--79/100 [840/1090] acc: 0.799214099702381
val--79/100 [850/1090] acc: 0.7992463235294117
val--79/100 [860/1090] acc: 0.7995139898255814
val--79/100 [870/1090] acc: 0.7994926364942528
val--79/100 [880/1090] acc: 0.7994939630681818
val--79/100 [890/1090] acc: 0.7995786516853932
val--79/100 [900/1090] acc: 0.7995442708333333
val--79/100 [910/1090] acc: 0.799527815934066
val--79/100 [920/1090] acc: 0.7995754076086956
val--79/100 [930/1090] acc: 0.7996639784946237
val--79/100 [940/1090] acc: 0.7996550864361702
val--79/100 [950/1090] acc: 0.7996134868421053
val--79/100 [960/1090] acc: 0.7995524088541667
val--79/100 [970/1090] acc: 0.7994845360824743
val--79/100 [980/1090] acc: 0.7995176977040817
val--79/100 [990/1090] acc: 0.7994160353535353
val--79/100 [1000/1090] acc: 0.79933984375
val--79/100 [1010/1090] acc: 0.7991220606435644
val--79/100 [1020/1090] acc: 0.7992110906862745
val--79/100 [1030/1090] acc: 0.7992452973300971
val--79/100 [1040/1090] acc: 0.7992149939903846
val--79/100 [1050/1090] acc: 0.7992745535714286
val--79/100 [1060/1090] acc: 0.7992040094339623
val--79/100 [1070/1090] acc: 0.799174941588785
val--79/100 [1080/1090] acc: 0.799095775462963
val--79/100 [1090/1090] acc: 0.798903383027523
epoch= 79, accuracy= 0.798903, rmse= 0.375200, auc= 0.858548
train--80/100 [9/1090] loss: 0.3987651139497757
train--80/100 [19/1090] loss: 0.4390893906354904
train--80/100 [29/1090] loss: 0.4438312917947769
train--80/100 [39/1090] loss: 0.43586086332798
train--80/100 [49/1090] loss: 0.4322164863348007
train--80/100 [59/1090] loss: 0.44188584983348844
train--80/100 [69/1090] loss: 0.4317989140748978
train--80/100 [79/1090] loss: 0.453504478931427
train--80/100 [89/1090] loss: 0.4492954879999161
train--80/100 [99/1090] loss: 0.43227380216121675
train--80/100 [109/1090] loss: 0.44168593287467955
train--80/100 [119/1090] loss: 0.43838460445404054
train--80/100 [129/1090] loss: 0.43894297778606417
train--80/100 [139/1090] loss: 0.42876476645469663
train--80/100 [149/1090] loss: 0.4444231420755386
train--80/100 [159/1090] loss: 0.4279675245285034
train--80/100 [169/1090] loss: 0.4354279786348343
train--80/100 [179/1090] loss: 0.44337739050388336
train--80/100 [189/1090] loss: 0.43055312931537626
train--80/100 [199/1090] loss: 0.4373655468225479
train--80/100 [209/1090] loss: 0.44487641751766205
train--80/100 [219/1090] loss: 0.4401505321264267
train--80/100 [229/1090] loss: 0.4456557512283325
train--80/100 [239/1090] loss: 0.4345129311084747
train--80/100 [249/1090] loss: 0.44763195514678955
train--80/100 [259/1090] loss: 0.4230108827352524
train--80/100 [269/1090] loss: 0.42570033967494963
train--80/100 [279/1090] loss: 0.43387643396854403
train--80/100 [289/1090] loss: 0.4327062636613846
train--80/100 [299/1090] loss: 0.43735956251621244
train--80/100 [309/1090] loss: 0.4356473505496979
train--80/100 [319/1090] loss: 0.4326983720064163
train--80/100 [329/1090] loss: 0.43581142127513883
train--80/100 [339/1090] loss: 0.43891033828258513
train--80/100 [349/1090] loss: 0.4429131209850311
train--80/100 [359/1090] loss: 0.4434954345226288
train--80/100 [369/1090] loss: 0.4218093454837799
train--80/100 [379/1090] loss: 0.44103965163230896
train--80/100 [389/1090] loss: 0.4372500509023666
train--80/100 [399/1090] loss: 0.44420333206653595
train--80/100 [409/1090] loss: 0.4152255058288574
train--80/100 [419/1090] loss: 0.43024323880672455
train--80/100 [429/1090] loss: 0.46646277606487274
train--80/100 [439/1090] loss: 0.4531893193721771
train--80/100 [449/1090] loss: 0.4441873639822006
train--80/100 [459/1090] loss: 0.4321236252784729
train--80/100 [469/1090] loss: 0.4308115065097809
train--80/100 [479/1090] loss: 0.45210631787776945
train--80/100 [489/1090] loss: 0.44352251291275024
train--80/100 [499/1090] loss: 0.4216888129711151
train--80/100 [509/1090] loss: 0.452438884973526
train--80/100 [519/1090] loss: 0.4434045910835266
train--80/100 [529/1090] loss: 0.42682839632034303
train--80/100 [539/1090] loss: 0.4336166650056839
train--80/100 [549/1090] loss: 0.45651326775550843
train--80/100 [559/1090] loss: 0.4285900354385376
train--80/100 [569/1090] loss: 0.4294527441263199
train--80/100 [579/1090] loss: 0.45586402118206026
train--80/100 [589/1090] loss: 0.44661434590816496
train--80/100 [599/1090] loss: 0.4350078970193863
train--80/100 [609/1090] loss: 0.44360998272895813
train--80/100 [619/1090] loss: 0.43940667510032655
train--80/100 [629/1090] loss: 0.43694357872009276
train--80/100 [639/1090] loss: 0.42962255477905276
train--80/100 [649/1090] loss: 0.4348673164844513
train--80/100 [659/1090] loss: 0.43384588658809664
train--80/100 [669/1090] loss: 0.43607560992240907
train--80/100 [679/1090] loss: 0.442032054066658
train--80/100 [689/1090] loss: 0.42463336884975433
train--80/100 [699/1090] loss: 0.4434137254953384
train--80/100 [709/1090] loss: 0.430885910987854
train--80/100 [719/1090] loss: 0.44538539052009585
train--80/100 [729/1090] loss: 0.4310318499803543
train--80/100 [739/1090] loss: 0.45859177112579347
train--80/100 [749/1090] loss: 0.42866508662700653
train--80/100 [759/1090] loss: 0.4491685122251511
train--80/100 [769/1090] loss: 0.45065467357635497
train--80/100 [779/1090] loss: 0.4453981250524521
train--80/100 [789/1090] loss: 0.45321336686611174
train--80/100 [799/1090] loss: 0.4473876923322678
train--80/100 [809/1090] loss: 0.45065217912197114
train--80/100 [819/1090] loss: 0.44298821687698364
train--80/100 [829/1090] loss: 0.4256865203380585
train--80/100 [839/1090] loss: 0.4491056323051453
train--80/100 [849/1090] loss: 0.43546396493911743
train--80/100 [859/1090] loss: 0.45607125461101533
train--80/100 [869/1090] loss: 0.4355641394853592
train--80/100 [879/1090] loss: 0.43861229717731476
train--80/100 [889/1090] loss: 0.43199814260005953
train--80/100 [899/1090] loss: 0.4506994217634201
train--80/100 [909/1090] loss: 0.43612703680992126
train--80/100 [919/1090] loss: 0.45049311220645905
train--80/100 [929/1090] loss: 0.44299285411834716
train--80/100 [939/1090] loss: 0.44824727177619933
train--80/100 [949/1090] loss: 0.4346489280462265
train--80/100 [959/1090] loss: 0.43435358107089994
train--80/100 [969/1090] loss: 0.45440655648708345
train--80/100 [979/1090] loss: 0.4425826966762543
train--80/100 [989/1090] loss: 0.4319664776325226
train--80/100 [999/1090] loss: 0.43786031305789946
train--80/100 [1009/1090] loss: 0.43873344659805297
train--80/100 [1019/1090] loss: 0.4293557107448578
train--80/100 [1029/1090] loss: 0.4453863620758057
train--80/100 [1039/1090] loss: 0.4412697672843933
train--80/100 [1049/1090] loss: 0.45666446089744567
train--80/100 [1059/1090] loss: 0.42656598687171937
train--80/100 [1069/1090] loss: 0.4435788482427597
train--80/100 [1079/1090] loss: 0.43187167346477506
train--80/100 [1089/1090] loss: 0.438968351483345
predicting model...
val--80/100 [10/1090] acc: 0.799609375
val--80/100 [20/1090] acc: 0.8015625
val--80/100 [30/1090] acc: 0.8001302083333334
val--80/100 [40/1090] acc: 0.79921875
val--80/100 [50/1090] acc: 0.79796875
val--80/100 [60/1090] acc: 0.7975911458333333
val--80/100 [70/1090] acc: 0.7978236607142857
val--80/100 [80/1090] acc: 0.7974609375
val--80/100 [90/1090] acc: 0.79765625
val--80/100 [100/1090] acc: 0.798671875
val--80/100 [110/1090] acc: 0.7991122159090909
val--80/100 [120/1090] acc: 0.7986328125
val--80/100 [130/1090] acc: 0.7993990384615385
val--80/100 [140/1090] acc: 0.7993303571428572
val--80/100 [150/1090] acc: 0.7993229166666667
val--80/100 [160/1090] acc: 0.799462890625
val--80/100 [170/1090] acc: 0.7993336397058823
val--80/100 [180/1090] acc: 0.7990451388888888
val--80/100 [190/1090] acc: 0.7997532894736842
val--80/100 [200/1090] acc: 0.79998046875
val--80/100 [210/1090] acc: 0.8003720238095238
val--80/100 [220/1090] acc: 0.7995205965909091
val--80/100 [230/1090] acc: 0.8000339673913044
val--80/100 [240/1090] acc: 0.7998209635416667
val--80/100 [250/1090] acc: 0.80003125
val--80/100 [260/1090] acc: 0.7999849759615385
val--80/100 [270/1090] acc: 0.8003038194444444
val--80/100 [280/1090] acc: 0.8001116071428571
val--80/100 [290/1090] acc: 0.800067349137931
val--80/100 [300/1090] acc: 0.8002213541666666
val--80/100 [310/1090] acc: 0.8000756048387097
val--80/100 [320/1090] acc: 0.8001953125
val--80/100 [330/1090] acc: 0.8003314393939394
val--80/100 [340/1090] acc: 0.8004021139705882
val--80/100 [350/1090] acc: 0.8005915178571429
val--80/100 [360/1090] acc: 0.8004448784722222
val--80/100 [370/1090] acc: 0.8004961993243244
val--80/100 [380/1090] acc: 0.8004831414473684
val--80/100 [390/1090] acc: 0.8003806089743589
val--80/100 [400/1090] acc: 0.8003125
val--80/100 [410/1090] acc: 0.8004287347560975
val--80/100 [420/1090] acc: 0.8002697172619048
val--80/100 [430/1090] acc: 0.7999636627906976
val--80/100 [440/1090] acc: 0.7999822443181818
val--80/100 [450/1090] acc: 0.7997829861111111
val--80/100 [460/1090] acc: 0.799609375
val--80/100 [470/1090] acc: 0.7995096409574468
val--80/100 [480/1090] acc: 0.7995361328125
val--80/100 [490/1090] acc: 0.7995854591836735
val--80/100 [500/1090] acc: 0.7997265625
val--80/100 [510/1090] acc: 0.7995863970588235
val--80/100 [520/1090] acc: 0.7998647836538462
val--80/100 [530/1090] acc: 0.7998083726415094
val--80/100 [540/1090] acc: 0.7999421296296296
val--80/100 [550/1090] acc: 0.7997514204545455
val--80/100 [560/1090] acc: 0.7995186941964286
val--80/100 [570/1090] acc: 0.799266721491228
val--80/100 [580/1090] acc: 0.7992658943965517
val--80/100 [590/1090] acc: 0.7992717161016949
val--80/100 [600/1090] acc: 0.79921875
val--80/100 [610/1090] acc: 0.7991675204918033
val--80/100 [620/1090] acc: 0.7991431451612904
val--80/100 [630/1090] acc: 0.7993923611111111
val--80/100 [640/1090] acc: 0.7995849609375
val--80/100 [650/1090] acc: 0.7995793269230769
val--80/100 [660/1090] acc: 0.7994791666666666
val--80/100 [670/1090] acc: 0.799277052238806
val--80/100 [680/1090] acc: 0.7991153492647058
val--80/100 [690/1090] acc: 0.7992527173913043
val--80/100 [700/1090] acc: 0.7992633928571429
val--80/100 [710/1090] acc: 0.7991692341549296
val--80/100 [720/1090] acc: 0.7990125868055555
val--80/100 [730/1090] acc: 0.7989190924657534
val--80/100 [740/1090] acc: 0.7988334037162163
val--80/100 [750/1090] acc: 0.7988645833333333
val--80/100 [760/1090] acc: 0.7990337171052632
val--80/100 [770/1090] acc: 0.7990158279220779
val--80/100 [780/1090] acc: 0.7989182692307693
val--80/100 [790/1090] acc: 0.7989369066455696
val--80/100 [800/1090] acc: 0.799169921875
val--80/100 [810/1090] acc: 0.79921875
val--80/100 [820/1090] acc: 0.7993044969512195
val--80/100 [830/1090] acc: 0.799378765060241
val--80/100 [840/1090] acc: 0.7993582589285714
val--80/100 [850/1090] acc: 0.7993704044117647
val--80/100 [860/1090] acc: 0.7996865915697674
val--80/100 [870/1090] acc: 0.7996318247126437
val--80/100 [880/1090] acc: 0.7996448863636364
val--80/100 [890/1090] acc: 0.7997410463483146
val--80/100 [900/1090] acc: 0.7997048611111112
val--80/100 [910/1090] acc: 0.7997252747252748
val--80/100 [920/1090] acc: 0.7997452445652173
val--80/100 [930/1090] acc: 0.7998319892473118
val--80/100 [940/1090] acc: 0.7998213098404255
val--80/100 [950/1090] acc: 0.7997779605263158
val--80/100 [960/1090] acc: 0.79971923828125
val--80/100 [970/1090] acc: 0.7996415914948454
val--80/100 [980/1090] acc: 0.7996851084183674
val--80/100 [990/1090] acc: 0.799609375
val--80/100 [1000/1090] acc: 0.79952734375
val--80/100 [1010/1090] acc: 0.7993038366336633
val--80/100 [1020/1090] acc: 0.7993795955882353
val--80/100 [1030/1090] acc: 0.7993932038834951
val--80/100 [1040/1090] acc: 0.799395282451923
val--80/100 [1050/1090] acc: 0.7994419642857142
val--80/100 [1060/1090] acc: 0.7993772110849057
val--80/100 [1070/1090] acc: 0.799357476635514
val--80/100 [1080/1090] acc: 0.799291087962963
val--80/100 [1090/1090] acc: 0.7991112385321101
epoch= 80, accuracy= 0.799111, rmse= 0.375042, auc= 0.858681
train--81/100 [9/1090] loss: 0.3787684261798859
train--81/100 [19/1090] loss: 0.4194071054458618
train--81/100 [29/1090] loss: 0.4457038134336472
train--81/100 [39/1090] loss: 0.4326087772846222
train--81/100 [49/1090] loss: 0.4240126460790634
train--81/100 [59/1090] loss: 0.4349131375551224
train--81/100 [69/1090] loss: 0.43343612253665925
train--81/100 [79/1090] loss: 0.4405406951904297
train--81/100 [89/1090] loss: 0.441278812289238
train--81/100 [99/1090] loss: 0.43803193867206575
train--81/100 [109/1090] loss: 0.440164116024971
train--81/100 [119/1090] loss: 0.41146065592765807
train--81/100 [129/1090] loss: 0.43793419897556307
train--81/100 [139/1090] loss: 0.43858120739459994
train--81/100 [149/1090] loss: 0.42801934480667114
train--81/100 [159/1090] loss: 0.45652641355991364
train--81/100 [169/1090] loss: 0.4505309104919434
train--81/100 [179/1090] loss: 0.43514624834060667
train--81/100 [189/1090] loss: 0.44118323624134065
train--81/100 [199/1090] loss: 0.4399722099304199
train--81/100 [209/1090] loss: 0.43433721363544464
train--81/100 [219/1090] loss: 0.40435574352741244
train--81/100 [229/1090] loss: 0.44907587170600893
train--81/100 [239/1090] loss: 0.4459098607301712
train--81/100 [249/1090] loss: 0.4261266827583313
train--81/100 [259/1090] loss: 0.44945134222507477
train--81/100 [269/1090] loss: 0.4369603097438812
train--81/100 [279/1090] loss: 0.4516312271356583
train--81/100 [289/1090] loss: 0.44434486925601957
train--81/100 [299/1090] loss: 0.43787144124507904
train--81/100 [309/1090] loss: 0.44530501365661623
train--81/100 [319/1090] loss: 0.4448997288942337
train--81/100 [329/1090] loss: 0.45052439868450167
train--81/100 [339/1090] loss: 0.4477657854557037
train--81/100 [349/1090] loss: 0.4427895933389664
train--81/100 [359/1090] loss: 0.44349002838134766
train--81/100 [369/1090] loss: 0.4465101569890976
train--81/100 [379/1090] loss: 0.42540841102600097
train--81/100 [389/1090] loss: 0.43361978232860565
train--81/100 [399/1090] loss: 0.42603449523448944
train--81/100 [409/1090] loss: 0.42408575415611266
train--81/100 [419/1090] loss: 0.4203816384077072
train--81/100 [429/1090] loss: 0.4235097229480743
train--81/100 [439/1090] loss: 0.4296647787094116
train--81/100 [449/1090] loss: 0.4492020905017853
train--81/100 [459/1090] loss: 0.4539307504892349
train--81/100 [469/1090] loss: 0.43826964199543
train--81/100 [479/1090] loss: 0.4268366456031799
train--81/100 [489/1090] loss: 0.44636147320270536
train--81/100 [499/1090] loss: 0.4284699261188507
train--81/100 [509/1090] loss: 0.45056891441345215
train--81/100 [519/1090] loss: 0.44752585589885713
train--81/100 [529/1090] loss: 0.4390000343322754
train--81/100 [539/1090] loss: 0.4437190294265747
train--81/100 [549/1090] loss: 0.4354347467422485
train--81/100 [559/1090] loss: 0.44372430741786956
train--81/100 [569/1090] loss: 0.43809235394001006
train--81/100 [579/1090] loss: 0.4369478851556778
train--81/100 [589/1090] loss: 0.43002271056175234
train--81/100 [599/1090] loss: 0.4474960118532181
train--81/100 [609/1090] loss: 0.44411824345588685
train--81/100 [619/1090] loss: 0.4464056879281998
train--81/100 [629/1090] loss: 0.4410846263170242
train--81/100 [639/1090] loss: 0.42902761697769165
train--81/100 [649/1090] loss: 0.45498896539211275
train--81/100 [659/1090] loss: 0.4400633633136749
train--81/100 [669/1090] loss: 0.4353839188814163
train--81/100 [679/1090] loss: 0.4343807339668274
train--81/100 [689/1090] loss: 0.46004194021224976
train--81/100 [699/1090] loss: 0.42292203903198244
train--81/100 [709/1090] loss: 0.45066081285476683
train--81/100 [719/1090] loss: 0.4319177567958832
train--81/100 [729/1090] loss: 0.4382272809743881
train--81/100 [739/1090] loss: 0.43336592316627504
train--81/100 [749/1090] loss: 0.4505767971277237
train--81/100 [759/1090] loss: 0.43850543797016145
train--81/100 [769/1090] loss: 0.4505996346473694
train--81/100 [779/1090] loss: 0.44084690809249877
train--81/100 [789/1090] loss: 0.44173823297023773
train--81/100 [799/1090] loss: 0.42053656876087187
train--81/100 [809/1090] loss: 0.42877015471458435
train--81/100 [819/1090] loss: 0.44447254836559297
train--81/100 [829/1090] loss: 0.4497332811355591
train--81/100 [839/1090] loss: 0.45553889870643616
train--81/100 [849/1090] loss: 0.44800076484680174
train--81/100 [859/1090] loss: 0.43919551372528076
train--81/100 [869/1090] loss: 0.4561423063278198
train--81/100 [879/1090] loss: 0.4414762854576111
train--81/100 [889/1090] loss: 0.46026977002620695
train--81/100 [899/1090] loss: 0.432596230506897
train--81/100 [909/1090] loss: 0.43566994071006776
train--81/100 [919/1090] loss: 0.43966456055641173
train--81/100 [929/1090] loss: 0.4418671250343323
train--81/100 [939/1090] loss: 0.42467606961727145
train--81/100 [949/1090] loss: 0.4293645918369293
train--81/100 [959/1090] loss: 0.43602083027362826
train--81/100 [969/1090] loss: 0.44941853284835814
train--81/100 [979/1090] loss: 0.43136988282203675
train--81/100 [989/1090] loss: 0.4275353133678436
train--81/100 [999/1090] loss: 0.4369181990623474
train--81/100 [1009/1090] loss: 0.42724116146564484
train--81/100 [1019/1090] loss: 0.442825049161911
train--81/100 [1029/1090] loss: 0.4462541788816452
train--81/100 [1039/1090] loss: 0.4464431285858154
train--81/100 [1049/1090] loss: 0.45470651388168337
train--81/100 [1059/1090] loss: 0.45080875754356386
train--81/100 [1069/1090] loss: 0.4637713760137558
train--81/100 [1079/1090] loss: 0.449798458814621
train--81/100 [1089/1090] loss: 0.4340475469827652
predicting model...
val--81/100 [10/1090] acc: 0.799609375
val--81/100 [20/1090] acc: 0.8005859375
val--81/100 [30/1090] acc: 0.7994791666666666
val--81/100 [40/1090] acc: 0.7994140625
val--81/100 [50/1090] acc: 0.79828125
val--81/100 [60/1090] acc: 0.7975911458333333
val--81/100 [70/1090] acc: 0.7978236607142857
val--81/100 [80/1090] acc: 0.79716796875
val--81/100 [90/1090] acc: 0.7973958333333333
val--81/100 [100/1090] acc: 0.7982421875
val--81/100 [110/1090] acc: 0.7985440340909091
val--81/100 [120/1090] acc: 0.7980794270833333
val--81/100 [130/1090] acc: 0.7990084134615385
val--81/100 [140/1090] acc: 0.7988560267857143
val--81/100 [150/1090] acc: 0.7986197916666666
val--81/100 [160/1090] acc: 0.7988525390625
val--81/100 [170/1090] acc: 0.7986672794117647
val--81/100 [180/1090] acc: 0.7985026041666666
val--81/100 [190/1090] acc: 0.7990131578947368
val--81/100 [200/1090] acc: 0.7992578125
val--81/100 [210/1090] acc: 0.7996279761904762
val--81/100 [220/1090] acc: 0.7987926136363637
val--81/100 [230/1090] acc: 0.7992357336956522
val--81/100 [240/1090] acc: 0.7990397135416667
val--81/100 [250/1090] acc: 0.79921875
val--81/100 [260/1090] acc: 0.7992337740384615
val--81/100 [270/1090] acc: 0.7996383101851852
val--81/100 [280/1090] acc: 0.7995256696428571
val--81/100 [290/1090] acc: 0.7993534482758621
val--81/100 [300/1090] acc: 0.7994791666666666
val--81/100 [310/1090] acc: 0.7993573588709677
val--81/100 [320/1090] acc: 0.79952392578125
val--81/100 [330/1090] acc: 0.7996212121212121
val--81/100 [340/1090] acc: 0.7997587316176471
val--81/100 [350/1090] acc: 0.7999441964285714
val--81/100 [360/1090] acc: 0.7998263888888889
val--81/100 [370/1090] acc: 0.7998838682432432
val--81/100 [380/1090] acc: 0.7999383223684211
val--81/100 [390/1090] acc: 0.7997896634615385
val--81/100 [400/1090] acc: 0.79978515625
val--81/100 [410/1090] acc: 0.799876143292683
val--81/100 [420/1090] acc: 0.7997953869047619
val--81/100 [430/1090] acc: 0.7995367005813954
val--81/100 [440/1090] acc: 0.79951171875
val--81/100 [450/1090] acc: 0.799375
val--81/100 [460/1090] acc: 0.799210258152174
val--81/100 [470/1090] acc: 0.7990940824468085
val--81/100 [480/1090] acc: 0.7990804036458333
val--81/100 [490/1090] acc: 0.7991230867346939
val--81/100 [500/1090] acc: 0.799265625
val--81/100 [510/1090] acc: 0.7991498161764706
val--81/100 [520/1090] acc: 0.7993990384615385
val--81/100 [530/1090] acc: 0.7993514150943396
val--81/100 [540/1090] acc: 0.7994719328703703
val--81/100 [550/1090] acc: 0.7993323863636363
val--81/100 [560/1090] acc: 0.7991420200892857
val--81/100 [570/1090] acc: 0.7989240679824562
val--81/100 [580/1090] acc: 0.7989089439655173
val--81/100 [590/1090] acc: 0.7988810911016949
val--81/100 [600/1090] acc: 0.7988020833333334
val--81/100 [610/1090] acc: 0.7987768954918033
val--81/100 [620/1090] acc: 0.7987651209677419
val--81/100 [630/1090] acc: 0.7990203373015873
val--81/100 [640/1090] acc: 0.799224853515625
val--81/100 [650/1090] acc: 0.7992608173076923
val--81/100 [660/1090] acc: 0.7992128314393939
val--81/100 [670/1090] acc: 0.7990088619402985
val--81/100 [680/1090] acc: 0.7988683363970588
val--81/100 [690/1090] acc: 0.7989923007246377
val--81/100 [700/1090] acc: 0.7990513392857143
val--81/100 [710/1090] acc: 0.7989546654929578
val--81/100 [720/1090] acc: 0.7988118489583333
val--81/100 [730/1090] acc: 0.7987906678082192
val--81/100 [740/1090] acc: 0.7987278293918919
val--81/100 [750/1090] acc: 0.7986979166666667
val--81/100 [760/1090] acc: 0.7988692434210526
val--81/100 [770/1090] acc: 0.7988433441558441
val--81/100 [780/1090] acc: 0.7987379807692307
val--81/100 [790/1090] acc: 0.7987539556962026
val--81/100 [800/1090] acc: 0.7989892578125
val--81/100 [810/1090] acc: 0.7990258487654321
val--81/100 [820/1090] acc: 0.7991139481707317
val--81/100 [830/1090] acc: 0.7991763930722892
val--81/100 [840/1090] acc: 0.7991629464285714
val--81/100 [850/1090] acc: 0.7992095588235294
val--81/100 [860/1090] acc: 0.7994958212209302
val--81/100 [870/1090] acc: 0.7994836566091954
val--81/100 [880/1090] acc: 0.7994806463068181
val--81/100 [890/1090] acc: 0.7995698735955056
val--81/100 [900/1090] acc: 0.7995269097222222
val--81/100 [910/1090] acc: 0.799527815934066
val--81/100 [920/1090] acc: 0.7995499320652174
val--81/100 [930/1090] acc: 0.7996555779569893
val--81/100 [940/1090] acc: 0.7996467752659574
val--81/100 [950/1090] acc: 0.7996011513157895
val--81/100 [960/1090] acc: 0.7995198567708334
val--81/100 [970/1090] acc: 0.7994281572164949
val--81/100 [980/1090] acc: 0.7994778380102041
val--81/100 [990/1090] acc: 0.7993765782828283
val--81/100 [1000/1090] acc: 0.79926171875
val--81/100 [1010/1090] acc: 0.7990060334158415
val--81/100 [1020/1090] acc: 0.7990579044117647
val--81/100 [1030/1090] acc: 0.7990860133495146
val--81/100 [1040/1090] acc: 0.7990910456730769
val--81/100 [1050/1090] acc: 0.7991331845238095
val--81/100 [1060/1090] acc: 0.7991045106132075
val--81/100 [1070/1090] acc: 0.7990909754672897
val--81/100 [1080/1090] acc: 0.7990270543981481
val--81/100 [1090/1090] acc: 0.798849627293578
epoch= 81, accuracy= 0.798850, rmse= 0.375108, auc= 0.858729
train--82/100 [9/1090] loss: 0.3984220951795578
train--82/100 [19/1090] loss: 0.44847982823848725
train--82/100 [29/1090] loss: 0.43363055884838103
train--82/100 [39/1090] loss: 0.4281470090150833
train--82/100 [49/1090] loss: 0.442292320728302
train--82/100 [59/1090] loss: 0.432431748509407
train--82/100 [69/1090] loss: 0.4471362352371216
train--82/100 [79/1090] loss: 0.4346324235200882
train--82/100 [89/1090] loss: 0.42133346796035764
train--82/100 [99/1090] loss: 0.44077121913433076
train--82/100 [109/1090] loss: 0.4310223549604416
train--82/100 [119/1090] loss: 0.4256002366542816
train--82/100 [129/1090] loss: 0.4409048408269882
train--82/100 [139/1090] loss: 0.44499551653862
train--82/100 [149/1090] loss: 0.42680073976516725
train--82/100 [159/1090] loss: 0.42961912155151366
train--82/100 [169/1090] loss: 0.4481241047382355
train--82/100 [179/1090] loss: 0.4169769883155823
train--82/100 [189/1090] loss: 0.43366608321666716
train--82/100 [199/1090] loss: 0.43407148122787476
train--82/100 [209/1090] loss: 0.4241816133260727
train--82/100 [219/1090] loss: 0.44394572675228117
train--82/100 [229/1090] loss: 0.4430520385503769
train--82/100 [239/1090] loss: 0.4376662164926529
train--82/100 [249/1090] loss: 0.4428211569786072
train--82/100 [259/1090] loss: 0.4196023494005203
train--82/100 [269/1090] loss: 0.4521237164735794
train--82/100 [279/1090] loss: 0.4316645324230194
train--82/100 [289/1090] loss: 0.44247173368930814
train--82/100 [299/1090] loss: 0.4430790990591049
train--82/100 [309/1090] loss: 0.4269628614187241
train--82/100 [319/1090] loss: 0.4251801073551178
train--82/100 [329/1090] loss: 0.45244363844394686
train--82/100 [339/1090] loss: 0.43747764825820923
train--82/100 [349/1090] loss: 0.43551120162010193
train--82/100 [359/1090] loss: 0.4384859770536423
train--82/100 [369/1090] loss: 0.431119441986084
train--82/100 [379/1090] loss: 0.42606141269207
train--82/100 [389/1090] loss: 0.45234540700912473
train--82/100 [399/1090] loss: 0.420907136797905
train--82/100 [409/1090] loss: 0.42228377163410186
train--82/100 [419/1090] loss: 0.4428150594234467
train--82/100 [429/1090] loss: 0.4309328943490982
train--82/100 [439/1090] loss: 0.4259563863277435
train--82/100 [449/1090] loss: 0.4571519047021866
train--82/100 [459/1090] loss: 0.4311566799879074
train--82/100 [469/1090] loss: 0.4240369856357574
train--82/100 [479/1090] loss: 0.43796481788158415
train--82/100 [489/1090] loss: 0.4347303479909897
train--82/100 [499/1090] loss: 0.4446427583694458
train--82/100 [509/1090] loss: 0.4543732047080994
train--82/100 [519/1090] loss: 0.46091400980949404
train--82/100 [529/1090] loss: 0.44827575981616974
train--82/100 [539/1090] loss: 0.4499499320983887
train--82/100 [549/1090] loss: 0.45865997970104216
train--82/100 [559/1090] loss: 0.45170716643333436
train--82/100 [569/1090] loss: 0.43822515606880186
train--82/100 [579/1090] loss: 0.4405991196632385
train--82/100 [589/1090] loss: 0.4317032366991043
train--82/100 [599/1090] loss: 0.4412120908498764
train--82/100 [609/1090] loss: 0.44274788200855253
train--82/100 [619/1090] loss: 0.44104075729846953
train--82/100 [629/1090] loss: 0.43280152082443235
train--82/100 [639/1090] loss: 0.4265895575284958
train--82/100 [649/1090] loss: 0.4495620310306549
train--82/100 [659/1090] loss: 0.4527747958898544
train--82/100 [669/1090] loss: 0.44617863595485685
train--82/100 [679/1090] loss: 0.4323206841945648
train--82/100 [689/1090] loss: 0.4455594778060913
train--82/100 [699/1090] loss: 0.45295370519161227
train--82/100 [709/1090] loss: 0.43450319170951845
train--82/100 [719/1090] loss: 0.4672495752573013
train--82/100 [729/1090] loss: 0.4214030593633652
train--82/100 [739/1090] loss: 0.45141600966453554
train--82/100 [749/1090] loss: 0.42965676486492155
train--82/100 [759/1090] loss: 0.43190965950489046
train--82/100 [769/1090] loss: 0.44230344593524934
train--82/100 [779/1090] loss: 0.4319610774517059
train--82/100 [789/1090] loss: 0.45234894156455996
train--82/100 [799/1090] loss: 0.4289658278226852
train--82/100 [809/1090] loss: 0.42952144145965576
train--82/100 [819/1090] loss: 0.4575865566730499
train--82/100 [829/1090] loss: 0.43653336465358733
train--82/100 [839/1090] loss: 0.43134777545928954
train--82/100 [849/1090] loss: 0.443289515376091
train--82/100 [859/1090] loss: 0.45299955904483796
train--82/100 [869/1090] loss: 0.4498358219861984
train--82/100 [879/1090] loss: 0.43686291575431824
train--82/100 [889/1090] loss: 0.44281995594501494
train--82/100 [899/1090] loss: 0.44051640331745145
train--82/100 [909/1090] loss: 0.44092603027820587
train--82/100 [919/1090] loss: 0.4518425464630127
train--82/100 [929/1090] loss: 0.4237769961357117
train--82/100 [939/1090] loss: 0.4504319280385971
train--82/100 [949/1090] loss: 0.4393519788980484
train--82/100 [959/1090] loss: 0.4526388645172119
train--82/100 [969/1090] loss: 0.41672580540180204
train--82/100 [979/1090] loss: 0.44691537916660307
train--82/100 [989/1090] loss: 0.422788143157959
train--82/100 [999/1090] loss: 0.4429144233465195
train--82/100 [1009/1090] loss: 0.44310806393623353
train--82/100 [1019/1090] loss: 0.4383155941963196
train--82/100 [1029/1090] loss: 0.45237756371498106
train--82/100 [1039/1090] loss: 0.4314576506614685
train--82/100 [1049/1090] loss: 0.4381766378879547
train--82/100 [1059/1090] loss: 0.44587217569351195
train--82/100 [1069/1090] loss: 0.44348510205745695
train--82/100 [1079/1090] loss: 0.44632546603679657
train--82/100 [1089/1090] loss: 0.452352249622345
predicting model...
val--82/100 [10/1090] acc: 0.800390625
val--82/100 [20/1090] acc: 0.802734375
val--82/100 [30/1090] acc: 0.8005208333333333
val--82/100 [40/1090] acc: 0.79970703125
val--82/100 [50/1090] acc: 0.799140625
val--82/100 [60/1090] acc: 0.7983723958333333
val--82/100 [70/1090] acc: 0.7987723214285715
val--82/100 [80/1090] acc: 0.7978515625
val--82/100 [90/1090] acc: 0.7977430555555556
val--82/100 [100/1090] acc: 0.7986328125
val--82/100 [110/1090] acc: 0.7988636363636363
val--82/100 [120/1090] acc: 0.7984049479166667
val--82/100 [130/1090] acc: 0.79921875
val--82/100 [140/1090] acc: 0.7991629464285714
val--82/100 [150/1090] acc: 0.7990625
val--82/100 [160/1090] acc: 0.799169921875
val--82/100 [170/1090] acc: 0.7990119485294118
val--82/100 [180/1090] acc: 0.7987413194444445
val--82/100 [190/1090] acc: 0.7994037828947368
val--82/100 [200/1090] acc: 0.79974609375
val--82/100 [210/1090] acc: 0.8001860119047619
val--82/100 [220/1090] acc: 0.7992365056818181
val--82/100 [230/1090] acc: 0.7998641304347827
val--82/100 [240/1090] acc: 0.7997884114583333
val--82/100 [250/1090] acc: 0.80003125
val--82/100 [260/1090] acc: 0.8000300480769231
val--82/100 [270/1090] acc: 0.800390625
val--82/100 [280/1090] acc: 0.8002511160714286
val--82/100 [290/1090] acc: 0.800134698275862
val--82/100 [300/1090] acc: 0.8002864583333333
val--82/100 [310/1090] acc: 0.8001890120967742
val--82/100 [320/1090] acc: 0.8003173828125
val--82/100 [330/1090] acc: 0.8004261363636364
val--82/100 [340/1090] acc: 0.8005744485294117
val--82/100 [350/1090] acc: 0.80078125
val--82/100 [360/1090] acc: 0.8006293402777778
val--82/100 [370/1090] acc: 0.8006440033783784
val--82/100 [380/1090] acc: 0.8007298519736842
val--82/100 [390/1090] acc: 0.8006510416666667
val--82/100 [400/1090] acc: 0.800556640625
val--82/100 [410/1090] acc: 0.8007145579268292
val--82/100 [420/1090] acc: 0.8006045386904762
val--82/100 [430/1090] acc: 0.8003179505813953
val--82/100 [440/1090] acc: 0.8003196022727272
val--82/100 [450/1090] acc: 0.8001302083333334
val--82/100 [460/1090] acc: 0.7999320652173914
val--82/100 [470/1090] acc: 0.7998005319148936
val--82/100 [480/1090] acc: 0.7997802734375
val--82/100 [490/1090] acc: 0.7998086734693878
val--82/100 [500/1090] acc: 0.7999296875
val--82/100 [510/1090] acc: 0.7998468137254902
val--82/100 [520/1090] acc: 0.8001051682692307
val--82/100 [530/1090] acc: 0.7999926297169812
val--82/100 [540/1090] acc: 0.8001229745370371
val--82/100 [550/1090] acc: 0.7999502840909091
val--82/100 [560/1090] acc: 0.7997279575892857
val--82/100 [570/1090] acc: 0.7994860197368421
val--82/100 [580/1090] acc: 0.7994612068965518
val--82/100 [590/1090] acc: 0.7994306144067796
val--82/100 [600/1090] acc: 0.7993359375
val--82/100 [610/1090] acc: 0.7992635758196721
val--82/100 [620/1090] acc: 0.7991809475806452
val--82/100 [630/1090] acc: 0.7994109623015873
val--82/100 [640/1090] acc: 0.799566650390625
val--82/100 [650/1090] acc: 0.7995372596153846
val--82/100 [660/1090] acc: 0.7995146780303031
val--82/100 [670/1090] acc: 0.7993003731343283
val--82/100 [680/1090] acc: 0.799167049632353
val--82/100 [690/1090] acc: 0.799314990942029
val--82/100 [700/1090] acc: 0.7993582589285714
val--82/100 [710/1090] acc: 0.7992682658450704
val--82/100 [720/1090] acc: 0.7990939670138889
val--82/100 [730/1090] acc: 0.7990314640410959
val--82/100 [740/1090] acc: 0.7989600929054054
val--82/100 [750/1090] acc: 0.7989739583333333
val--82/100 [760/1090] acc: 0.7991262335526316
val--82/100 [770/1090] acc: 0.7990868506493507
val--82/100 [780/1090] acc: 0.7989683493589743
val--82/100 [790/1090] acc: 0.7989863528481013
val--82/100 [800/1090] acc: 0.79919921875
val--82/100 [810/1090] acc: 0.7992476851851852
val--82/100 [820/1090] acc: 0.7993283155487805
val--82/100 [830/1090] acc: 0.7993693524096386
val--82/100 [840/1090] acc: 0.7993396577380952
val--82/100 [850/1090] acc: 0.7993428308823529
val--82/100 [860/1090] acc: 0.7996457122093024
val--82/100 [870/1090] acc: 0.7995824353448275
val--82/100 [880/1090] acc: 0.7995916193181818
val--82/100 [890/1090] acc: 0.7996795997191011
val--82/100 [900/1090] acc: 0.7996440972222222
val--82/100 [910/1090] acc: 0.7996437156593407
val--82/100 [920/1090] acc: 0.7996773097826086
val--82/100 [930/1090] acc: 0.7997605846774194
val--82/100 [940/1090] acc: 0.7997381981382978
val--82/100 [950/1090] acc: 0.7996751644736843
val--82/100 [960/1090] acc: 0.7995930989583333
val--82/100 [970/1090] acc: 0.7995288337628866
val--82/100 [980/1090] acc: 0.7995575573979592
val--82/100 [990/1090] acc: 0.7994673295454545
val--82/100 [1000/1090] acc: 0.79936328125
val--82/100 [1010/1090] acc: 0.799137530940594
val--82/100 [1020/1090] acc: 0.7991919424019608
val--82/100 [1030/1090] acc: 0.7992111650485437
val--82/100 [1040/1090] acc: 0.7992074819711539
val--82/100 [1050/1090] acc: 0.7992522321428571
val--82/100 [1060/1090] acc: 0.79921875
val--82/100 [1070/1090] acc: 0.7992041471962616
val--82/100 [1080/1090] acc: 0.7991283275462963
val--82/100 [1090/1090] acc: 0.7989428038990826
epoch= 82, accuracy= 0.798943, rmse= 0.374947, auc= 0.858851
train--83/100 [9/1090] loss: 0.38880573213100433
train--83/100 [19/1090] loss: 0.4249953359365463
train--83/100 [29/1090] loss: 0.4443469852209091
train--83/100 [39/1090] loss: 0.4406375586986542
train--83/100 [49/1090] loss: 0.45302487909793854
train--83/100 [59/1090] loss: 0.43212641179561617
train--83/100 [69/1090] loss: 0.43513341546058654
train--83/100 [79/1090] loss: 0.4425168752670288
train--83/100 [89/1090] loss: 0.43047126233577726
train--83/100 [99/1090] loss: 0.4331900030374527
train--83/100 [109/1090] loss: 0.42293516397476194
train--83/100 [119/1090] loss: 0.435991969704628
train--83/100 [129/1090] loss: 0.4287522464990616
train--83/100 [139/1090] loss: 0.42901932895183564
train--83/100 [149/1090] loss: 0.43947001099586486
train--83/100 [159/1090] loss: 0.4333942770957947
train--83/100 [169/1090] loss: 0.44710410833358766
train--83/100 [179/1090] loss: 0.4291515380144119
train--83/100 [189/1090] loss: 0.4505715876817703
train--83/100 [199/1090] loss: 0.43651171326637267
train--83/100 [209/1090] loss: 0.43852116763591764
train--83/100 [219/1090] loss: 0.44909835755825045
train--83/100 [229/1090] loss: 0.4581968456506729
train--83/100 [239/1090] loss: 0.45650154650211333
train--83/100 [249/1090] loss: 0.44490269422531126
train--83/100 [259/1090] loss: 0.4353675127029419
train--83/100 [269/1090] loss: 0.4506337493658066
train--83/100 [279/1090] loss: 0.4446500688791275
train--83/100 [289/1090] loss: 0.4295932620763779
train--83/100 [299/1090] loss: 0.4467766731977463
train--83/100 [309/1090] loss: 0.4288903594017029
train--83/100 [319/1090] loss: 0.4484264373779297
train--83/100 [329/1090] loss: 0.4510650783777237
train--83/100 [339/1090] loss: 0.44564107060432434
train--83/100 [349/1090] loss: 0.4563660115003586
train--83/100 [359/1090] loss: 0.44853813052177427
train--83/100 [369/1090] loss: 0.4419429451227188
train--83/100 [379/1090] loss: 0.4454093873500824
train--83/100 [389/1090] loss: 0.4248185157775879
train--83/100 [399/1090] loss: 0.42540774047374724
train--83/100 [409/1090] loss: 0.45695591270923613
train--83/100 [419/1090] loss: 0.422372505068779
train--83/100 [429/1090] loss: 0.4509333401918411
train--83/100 [439/1090] loss: 0.45757039487361906
train--83/100 [449/1090] loss: 0.44916030764579773
train--83/100 [459/1090] loss: 0.43915279805660246
train--83/100 [469/1090] loss: 0.43901346027851107
train--83/100 [479/1090] loss: 0.46911833584308626
train--83/100 [489/1090] loss: 0.43463111817836764
train--83/100 [499/1090] loss: 0.43532300293445586
train--83/100 [509/1090] loss: 0.4097095251083374
train--83/100 [519/1090] loss: 0.4719348520040512
train--83/100 [529/1090] loss: 0.44972207248210905
train--83/100 [539/1090] loss: 0.4341163784265518
train--83/100 [549/1090] loss: 0.4212925136089325
train--83/100 [559/1090] loss: 0.42868597209453585
train--83/100 [569/1090] loss: 0.4403862714767456
train--83/100 [579/1090] loss: 0.4253340184688568
train--83/100 [589/1090] loss: 0.42555962800979613
train--83/100 [599/1090] loss: 0.4451501190662384
train--83/100 [609/1090] loss: 0.43023615777492524
train--83/100 [619/1090] loss: 0.41980463564395903
train--83/100 [629/1090] loss: 0.43130157291889193
train--83/100 [639/1090] loss: 0.447981071472168
train--83/100 [649/1090] loss: 0.44458985030651094
train--83/100 [659/1090] loss: 0.44256394505500796
train--83/100 [669/1090] loss: 0.44868152439594267
train--83/100 [679/1090] loss: 0.4448434740304947
train--83/100 [689/1090] loss: 0.4427975356578827
train--83/100 [699/1090] loss: 0.4340449899435043
train--83/100 [709/1090] loss: 0.4348957270383835
train--83/100 [719/1090] loss: 0.42782144248485565
train--83/100 [729/1090] loss: 0.4246419370174408
train--83/100 [739/1090] loss: 0.4381126523017883
train--83/100 [749/1090] loss: 0.43725059628486634
train--83/100 [759/1090] loss: 0.44675601422786715
train--83/100 [769/1090] loss: 0.44723361134529116
train--83/100 [779/1090] loss: 0.449953556060791
train--83/100 [789/1090] loss: 0.42310451567173
train--83/100 [799/1090] loss: 0.43063307404518125
train--83/100 [809/1090] loss: 0.42774541676044464
train--83/100 [819/1090] loss: 0.44853716492652895
train--83/100 [829/1090] loss: 0.46171083450317385
train--83/100 [839/1090] loss: 0.4353810429573059
train--83/100 [849/1090] loss: 0.42928139865398407
train--83/100 [859/1090] loss: 0.43368211686611174
train--83/100 [869/1090] loss: 0.4334973245859146
train--83/100 [879/1090] loss: 0.45564723908901217
train--83/100 [889/1090] loss: 0.4463641047477722
train--83/100 [899/1090] loss: 0.4257402092218399
train--83/100 [909/1090] loss: 0.42544696033000945
train--83/100 [919/1090] loss: 0.4575889080762863
train--83/100 [929/1090] loss: 0.4210952281951904
train--83/100 [939/1090] loss: 0.4548935920000076
train--83/100 [949/1090] loss: 0.43805173635482786
train--83/100 [959/1090] loss: 0.4283228307962418
train--83/100 [969/1090] loss: 0.4336870163679123
train--83/100 [979/1090] loss: 0.4404513120651245
train--83/100 [989/1090] loss: 0.4240063488483429
train--83/100 [999/1090] loss: 0.44202364683151246
train--83/100 [1009/1090] loss: 0.44668896198272706
train--83/100 [1019/1090] loss: 0.4344401746988297
train--83/100 [1029/1090] loss: 0.4451144188642502
train--83/100 [1039/1090] loss: 0.4350798726081848
train--83/100 [1049/1090] loss: 0.44436911344528196
train--83/100 [1059/1090] loss: 0.4250833123922348
train--83/100 [1069/1090] loss: 0.427369624376297
train--83/100 [1079/1090] loss: 0.43494548499584196
train--83/100 [1089/1090] loss: 0.44981966614723207
predicting model...
val--83/100 [10/1090] acc: 0.8
val--83/100 [20/1090] acc: 0.8
val--83/100 [30/1090] acc: 0.798828125
val--83/100 [40/1090] acc: 0.798828125
val--83/100 [50/1090] acc: 0.798671875
val--83/100 [60/1090] acc: 0.7978515625
val--83/100 [70/1090] acc: 0.7981026785714286
val--83/100 [80/1090] acc: 0.79716796875
val--83/100 [90/1090] acc: 0.7975260416666666
val--83/100 [100/1090] acc: 0.7985546875
val--83/100 [110/1090] acc: 0.7987571022727272
val--83/100 [120/1090] acc: 0.7983072916666667
val--83/100 [130/1090] acc: 0.7992487980769231
val--83/100 [140/1090] acc: 0.7992466517857143
val--83/100 [150/1090] acc: 0.7991666666666667
val--83/100 [160/1090] acc: 0.79921875
val--83/100 [170/1090] acc: 0.7990349264705883
val--83/100 [180/1090] acc: 0.7986979166666667
val--83/100 [190/1090] acc: 0.7993626644736842
val--83/100 [200/1090] acc: 0.7997265625
val--83/100 [210/1090] acc: 0.8001488095238095
val--83/100 [220/1090] acc: 0.7992720170454546
val--83/100 [230/1090] acc: 0.7997282608695652
val--83/100 [240/1090] acc: 0.7996419270833334
val--83/100 [250/1090] acc: 0.799765625
val--83/100 [260/1090] acc: 0.7997445913461538
val--83/100 [270/1090] acc: 0.8000868055555556
val--83/100 [280/1090] acc: 0.7999720982142857
val--83/100 [290/1090] acc: 0.799865301724138
val--83/100 [300/1090] acc: 0.8000911458333333
val--83/100 [310/1090] acc: 0.7999747983870967
val--83/100 [320/1090] acc: 0.80013427734375
val--83/100 [330/1090] acc: 0.8002249053030303
val--83/100 [340/1090] acc: 0.8003331801470588
val--83/100 [350/1090] acc: 0.8005245535714286
val--83/100 [360/1090] acc: 0.8003146701388889
val--83/100 [370/1090] acc: 0.8003800675675675
val--83/100 [380/1090] acc: 0.8004831414473684
val--83/100 [390/1090] acc: 0.800350560897436
val--83/100 [400/1090] acc: 0.800283203125
val--83/100 [410/1090] acc: 0.800390625
val--83/100 [420/1090] acc: 0.8002604166666667
val--83/100 [430/1090] acc: 0.7999454941860465
val--83/100 [440/1090] acc: 0.7999556107954545
val--83/100 [450/1090] acc: 0.799765625
val--83/100 [460/1090] acc: 0.7995754076086956
val--83/100 [470/1090] acc: 0.7994514627659575
val--83/100 [480/1090] acc: 0.7994222005208333
val--83/100 [490/1090] acc: 0.7994579081632653
val--83/100 [500/1090] acc: 0.7995859375
val--83/100 [510/1090] acc: 0.7994332107843137
val--83/100 [520/1090] acc: 0.7996995192307692
val--83/100 [530/1090] acc: 0.799609375
val--83/100 [540/1090] acc: 0.7997106481481482
val--83/100 [550/1090] acc: 0.7995383522727273
val--83/100 [560/1090] acc: 0.7993443080357143
val--83/100 [570/1090] acc: 0.7991502192982456
val--83/100 [580/1090] acc: 0.7991311961206896
val--83/100 [590/1090] acc: 0.7991260593220338
val--83/100 [600/1090] acc: 0.7991145833333333
val--83/100 [610/1090] acc: 0.7990842725409836
val--83/100 [620/1090] acc: 0.7990171370967742
val--83/100 [630/1090] acc: 0.7992559523809524
val--83/100 [640/1090] acc: 0.79942626953125
val--83/100 [650/1090] acc: 0.7994290865384616
val--83/100 [660/1090] acc: 0.7993726325757575
val--83/100 [670/1090] acc: 0.799160447761194
val--83/100 [680/1090] acc: 0.7990464154411765
val--83/100 [690/1090] acc: 0.7991904438405797
val--83/100 [700/1090] acc: 0.7991964285714286
val--83/100 [710/1090] acc: 0.7990757042253521
val--83/100 [720/1090] acc: 0.79892578125
val--83/100 [730/1090] acc: 0.7988816352739726
val--83/100 [740/1090] acc: 0.7988228462837837
val--83/100 [750/1090] acc: 0.7988072916666666
val--83/100 [760/1090] acc: 0.7989771792763158
val--83/100 [770/1090] acc: 0.7989600243506494
val--83/100 [780/1090] acc: 0.7988832131410256
val--83/100 [790/1090] acc: 0.7988825158227848
val--83/100 [800/1090] acc: 0.79912109375
val--83/100 [810/1090] acc: 0.7991849922839506
val--83/100 [820/1090] acc: 0.7993092606707317
val--83/100 [830/1090] acc: 0.7993834713855422
val--83/100 [840/1090] acc: 0.7993350074404761
val--83/100 [850/1090] acc: 0.7993658088235294
val--83/100 [860/1090] acc: 0.799672965116279
val--83/100 [870/1090] acc: 0.7996138649425287
val--83/100 [880/1090] acc: 0.7996138139204545
val--83/100 [890/1090] acc: 0.7996883778089887
val--83/100 [900/1090] acc: 0.7996831597222223
val--83/100 [910/1090] acc: 0.7996780563186813
val--83/100 [920/1090] acc: 0.799711277173913
val--83/100 [930/1090] acc: 0.7998025873655914
val--83/100 [940/1090] acc: 0.7997797539893617
val--83/100 [950/1090] acc: 0.7997203947368421
val--83/100 [960/1090] acc: 0.7996541341145833
val--83/100 [970/1090] acc: 0.799573131443299
val--83/100 [980/1090] acc: 0.7996213329081633
val--83/100 [990/1090] acc: 0.7995344065656566
val--83/100 [1000/1090] acc: 0.799453125
val--83/100 [1010/1090] acc: 0.7992342202970297
val--83/100 [1020/1090] acc: 0.7992991727941177
val--83/100 [1030/1090] acc: 0.7993287317961165
val--83/100 [1040/1090] acc: 0.7993276742788461
val--83/100 [1050/1090] acc: 0.799345238095238
val--83/100 [1060/1090] acc: 0.7992961379716981
val--83/100 [1070/1090] acc: 0.799288113317757
val--83/100 [1080/1090] acc: 0.7992368344907408
val--83/100 [1090/1090] acc: 0.7990646502293578
epoch= 83, accuracy= 0.799065, rmse= 0.374892, auc= 0.858883
train--84/100 [9/1090] loss: 0.3952156245708466
train--84/100 [19/1090] loss: 0.4259204000234604
train--84/100 [29/1090] loss: 0.43640509247779846
train--84/100 [39/1090] loss: 0.4424051582813263
train--84/100 [49/1090] loss: 0.4375668317079544
train--84/100 [59/1090] loss: 0.4436953872442245
train--84/100 [69/1090] loss: 0.4303878486156464
train--84/100 [79/1090] loss: 0.4516779869794846
train--84/100 [89/1090] loss: 0.41732079684734347
train--84/100 [99/1090] loss: 0.43289485573768616
train--84/100 [109/1090] loss: 0.42318201065063477
train--84/100 [119/1090] loss: 0.4357272446155548
train--84/100 [129/1090] loss: 0.433586984872818
train--84/100 [139/1090] loss: 0.4492585718631744
train--84/100 [149/1090] loss: 0.4413449078798294
train--84/100 [159/1090] loss: 0.44970034062862396
train--84/100 [169/1090] loss: 0.4337709337472916
train--84/100 [179/1090] loss: 0.43396328389644623
train--84/100 [189/1090] loss: 0.44293656647205354
train--84/100 [199/1090] loss: 0.42502845227718355
train--84/100 [209/1090] loss: 0.4302055686712265
train--84/100 [219/1090] loss: 0.42827798426151276
train--84/100 [229/1090] loss: 0.43764708936214447
train--84/100 [239/1090] loss: 0.4296288102865219
train--84/100 [249/1090] loss: 0.41966395974159243
train--84/100 [259/1090] loss: 0.42979335188865664
train--84/100 [269/1090] loss: 0.456111752986908
train--84/100 [279/1090] loss: 0.44235328733921053
train--84/100 [289/1090] loss: 0.44609147906303404
train--84/100 [299/1090] loss: 0.44433510303497314
train--84/100 [309/1090] loss: 0.43410291969776155
train--84/100 [319/1090] loss: 0.44048742949962616
train--84/100 [329/1090] loss: 0.447419273853302
train--84/100 [339/1090] loss: 0.42126688957214353
train--84/100 [349/1090] loss: 0.4145039051771164
train--84/100 [359/1090] loss: 0.430870446562767
train--84/100 [369/1090] loss: 0.45073117315769196
train--84/100 [379/1090] loss: 0.414484041929245
train--84/100 [389/1090] loss: 0.4457848399877548
train--84/100 [399/1090] loss: 0.4321547567844391
train--84/100 [409/1090] loss: 0.4380801826715469
train--84/100 [419/1090] loss: 0.4404668092727661
train--84/100 [429/1090] loss: 0.4498982518911362
train--84/100 [439/1090] loss: 0.42538261115550996
train--84/100 [449/1090] loss: 0.4361795634031296
train--84/100 [459/1090] loss: 0.4371705651283264
train--84/100 [469/1090] loss: 0.450245726108551
train--84/100 [479/1090] loss: 0.4461256891489029
train--84/100 [489/1090] loss: 0.44872083365917204
train--84/100 [499/1090] loss: 0.42758411169052124
train--84/100 [509/1090] loss: 0.42860350012779236
train--84/100 [519/1090] loss: 0.44161379635334014
train--84/100 [529/1090] loss: 0.42066592276096343
train--84/100 [539/1090] loss: 0.4363467186689377
train--84/100 [549/1090] loss: 0.4333379328250885
train--84/100 [559/1090] loss: 0.4398790240287781
train--84/100 [569/1090] loss: 0.4447720855474472
train--84/100 [579/1090] loss: 0.44926732778549194
train--84/100 [589/1090] loss: 0.44664986729621886
train--84/100 [599/1090] loss: 0.4510204344987869
train--84/100 [609/1090] loss: 0.4388440102338791
train--84/100 [619/1090] loss: 0.44206117689609525
train--84/100 [629/1090] loss: 0.4553169310092926
train--84/100 [639/1090] loss: 0.41968539655208587
train--84/100 [649/1090] loss: 0.4565525323152542
train--84/100 [659/1090] loss: 0.4324371337890625
train--84/100 [669/1090] loss: 0.44395457208156586
train--84/100 [679/1090] loss: 0.4332019478082657
train--84/100 [689/1090] loss: 0.42872729897499084
train--84/100 [699/1090] loss: 0.4308078497648239
train--84/100 [709/1090] loss: 0.44675853848457336
train--84/100 [719/1090] loss: 0.43283714950084684
train--84/100 [729/1090] loss: 0.45025272369384767
train--84/100 [739/1090] loss: 0.4395425468683243
train--84/100 [749/1090] loss: 0.4478236764669418
train--84/100 [759/1090] loss: 0.4581033974885941
train--84/100 [769/1090] loss: 0.4435889065265656
train--84/100 [779/1090] loss: 0.4348235040903091
train--84/100 [789/1090] loss: 0.4223921179771423
train--84/100 [799/1090] loss: 0.4418802946805954
train--84/100 [809/1090] loss: 0.4359486043453217
train--84/100 [819/1090] loss: 0.4570519715547562
train--84/100 [829/1090] loss: 0.43912834823131563
train--84/100 [839/1090] loss: 0.4430841565132141
train--84/100 [849/1090] loss: 0.43472704887390134
train--84/100 [859/1090] loss: 0.45500418841838836
train--84/100 [869/1090] loss: 0.4333929121494293
train--84/100 [879/1090] loss: 0.440354460477829
train--84/100 [889/1090] loss: 0.45278758704662325
train--84/100 [899/1090] loss: 0.4485134959220886
train--84/100 [909/1090] loss: 0.44098918735980985
train--84/100 [919/1090] loss: 0.437203922867775
train--84/100 [929/1090] loss: 0.45784578323364256
train--84/100 [939/1090] loss: 0.43620729446411133
train--84/100 [949/1090] loss: 0.4300606906414032
train--84/100 [959/1090] loss: 0.44761110544204713
train--84/100 [969/1090] loss: 0.4473532050848007
train--84/100 [979/1090] loss: 0.4564277321100235
train--84/100 [989/1090] loss: 0.4437271922826767
train--84/100 [999/1090] loss: 0.42217260003089907
train--84/100 [1009/1090] loss: 0.4513194441795349
train--84/100 [1019/1090] loss: 0.434595450758934
train--84/100 [1029/1090] loss: 0.44837021827697754
train--84/100 [1039/1090] loss: 0.4447737783193588
train--84/100 [1049/1090] loss: 0.4266474604606628
train--84/100 [1059/1090] loss: 0.4477695822715759
train--84/100 [1069/1090] loss: 0.42704994082450864
train--84/100 [1079/1090] loss: 0.4475272595882416
train--84/100 [1089/1090] loss: 0.4422258585691452
predicting model...
val--84/100 [10/1090] acc: 0.8015625
val--84/100 [20/1090] acc: 0.80078125
val--84/100 [30/1090] acc: 0.7994791666666666
val--84/100 [40/1090] acc: 0.79912109375
val--84/100 [50/1090] acc: 0.798515625
val--84/100 [60/1090] acc: 0.7978515625
val--84/100 [70/1090] acc: 0.7979910714285714
val--84/100 [80/1090] acc: 0.797314453125
val--84/100 [90/1090] acc: 0.7977430555555556
val--84/100 [100/1090] acc: 0.798671875
val--84/100 [110/1090] acc: 0.7989346590909091
val--84/100 [120/1090] acc: 0.7985026041666666
val--84/100 [130/1090] acc: 0.7993389423076923
val--84/100 [140/1090] acc: 0.79921875
val--84/100 [150/1090] acc: 0.7993229166666667
val--84/100 [160/1090] acc: 0.799365234375
val--84/100 [170/1090] acc: 0.79921875
val--84/100 [180/1090] acc: 0.7989583333333333
val--84/100 [190/1090] acc: 0.7996299342105263
val--84/100 [200/1090] acc: 0.79984375
val--84/100 [210/1090] acc: 0.8001860119047619
val--84/100 [220/1090] acc: 0.7993075284090909
val--84/100 [230/1090] acc: 0.7996942934782608
val--84/100 [240/1090] acc: 0.7995930989583333
val--84/100 [250/1090] acc: 0.79975
val--84/100 [260/1090] acc: 0.7997145432692307
val--84/100 [270/1090] acc: 0.800072337962963
val--84/100 [280/1090] acc: 0.7999581473214286
val--84/100 [290/1090] acc: 0.799865301724138
val--84/100 [300/1090] acc: 0.8000520833333333
val--84/100 [310/1090] acc: 0.7998865927419355
val--84/100 [320/1090] acc: 0.8000244140625
val--84/100 [330/1090] acc: 0.8001420454545455
val--84/100 [340/1090] acc: 0.8001493566176471
val--84/100 [350/1090] acc: 0.8002901785714286
val--84/100 [360/1090] acc: 0.8001519097222223
val--84/100 [370/1090] acc: 0.8002005912162162
val--84/100 [380/1090] acc: 0.8002467105263158
val--84/100 [390/1090] acc: 0.8001502403846154
val--84/100 [400/1090] acc: 0.800107421875
val--84/100 [410/1090] acc: 0.8001810213414634
val--84/100 [420/1090] acc: 0.8000465029761905
val--84/100 [430/1090] acc: 0.799781976744186
val--84/100 [440/1090] acc: 0.7998135653409091
val--84/100 [450/1090] acc: 0.7996440972222222
val--84/100 [460/1090] acc: 0.7994819972826087
val--84/100 [470/1090] acc: 0.7994099069148937
val--84/100 [480/1090] acc: 0.7993896484375
val--84/100 [490/1090] acc: 0.7994339923469388
val--84/100 [500/1090] acc: 0.799609375
val--84/100 [510/1090] acc: 0.7995021446078432
val--84/100 [520/1090] acc: 0.7997971754807692
val--84/100 [530/1090] acc: 0.7997125589622641
val--84/100 [540/1090] acc: 0.7997757523148148
val--84/100 [550/1090] acc: 0.7995809659090909
val--84/100 [560/1090] acc: 0.7993791852678571
val--84/100 [570/1090] acc: 0.7991228070175439
val--84/100 [580/1090] acc: 0.7990773168103448
val--84/100 [590/1090] acc: 0.7990797139830509
val--84/100 [600/1090] acc: 0.7990299479166667
val--84/100 [610/1090] acc: 0.799001024590164
val--84/100 [620/1090] acc: 0.7989667338709677
val--84/100 [630/1090] acc: 0.7991939484126984
val--84/100 [640/1090] acc: 0.799346923828125
val--84/100 [650/1090] acc: 0.7993629807692307
val--84/100 [660/1090] acc: 0.7992720170454546
val--84/100 [670/1090] acc: 0.799102145522388
val--84/100 [680/1090] acc: 0.7990004595588235
val--84/100 [690/1090] acc: 0.7991508152173913
val--84/100 [700/1090] acc: 0.7991685267857143
val--84/100 [710/1090] acc: 0.7990702024647888
val--84/100 [720/1090] acc: 0.7989366319444444
val--84/100 [730/1090] acc: 0.7989137414383561
val--84/100 [740/1090] acc: 0.7988597972972973
val--84/100 [750/1090] acc: 0.7989010416666666
val--84/100 [760/1090] acc: 0.799085115131579
val--84/100 [770/1090] acc: 0.799020900974026
val--84/100 [780/1090] acc: 0.7989383012820512
val--84/100 [790/1090] acc: 0.798946795886076
val--84/100 [800/1090] acc: 0.799189453125
val--84/100 [810/1090] acc: 0.7992476851851852
val--84/100 [820/1090] acc: 0.7993568978658536
val--84/100 [830/1090] acc: 0.799402296686747
val--84/100 [840/1090] acc: 0.7993815104166667
val--84/100 [850/1090] acc: 0.7993933823529412
val--84/100 [860/1090] acc: 0.799695675872093
val--84/100 [870/1090] acc: 0.7996677442528736
val--84/100 [880/1090] acc: 0.7996759588068182
val--84/100 [890/1090] acc: 0.7997454353932584
val--84/100 [900/1090] acc: 0.7997178819444445
val--84/100 [910/1090] acc: 0.7997381524725274
val--84/100 [920/1090] acc: 0.7997579823369565
val--84/100 [930/1090] acc: 0.7998739919354839
val--84/100 [940/1090] acc: 0.7998296210106383
val--84/100 [950/1090] acc: 0.7998026315789474
val--84/100 [960/1090] acc: 0.7997517903645833
val--84/100 [970/1090] acc: 0.799693943298969
val--84/100 [980/1090] acc: 0.7997289540816327
val--84/100 [990/1090] acc: 0.7996448863636364
val--84/100 [1000/1090] acc: 0.79955078125
val--84/100 [1010/1090] acc: 0.7993309096534653
val--84/100 [1020/1090] acc: 0.7993987438725491
val--84/100 [1030/1090] acc: 0.7994159587378641
val--84/100 [1040/1090] acc: 0.7994290865384616
val--84/100 [1050/1090] acc: 0.7994605654761905
val--84/100 [1060/1090] acc: 0.7994030070754717
val--84/100 [1070/1090] acc: 0.7993501752336448
val--84/100 [1080/1090] acc: 0.7992766203703704
val--84/100 [1090/1090] acc: 0.7991076548165138
epoch= 84, accuracy= 0.799108, rmse= 0.374819, auc= 0.859003
train--85/100 [9/1090] loss: 0.3870345205068588
train--85/100 [19/1090] loss: 0.4426147699356079
train--85/100 [29/1090] loss: 0.42751547396183015
train--85/100 [39/1090] loss: 0.4429928004741669
train--85/100 [49/1090] loss: 0.4203218907117844
train--85/100 [59/1090] loss: 0.44672670066356657
train--85/100 [69/1090] loss: 0.41925373375415803
train--85/100 [79/1090] loss: 0.43718025982379916
train--85/100 [89/1090] loss: 0.4499735295772552
train--85/100 [99/1090] loss: 0.43500036001205444
train--85/100 [109/1090] loss: 0.4375969558954239
train--85/100 [119/1090] loss: 0.4204275876283646
train--85/100 [129/1090] loss: 0.43778451681137087
train--85/100 [139/1090] loss: 0.4220878124237061
train--85/100 [149/1090] loss: 0.42542622685432435
train--85/100 [159/1090] loss: 0.4163088291883469
train--85/100 [169/1090] loss: 0.44470469653606415
train--85/100 [179/1090] loss: 0.4301537960767746
train--85/100 [189/1090] loss: 0.43542938828468325
train--85/100 [199/1090] loss: 0.40510655343532564
train--85/100 [209/1090] loss: 0.4325199484825134
train--85/100 [219/1090] loss: 0.42575173676013944
train--85/100 [229/1090] loss: 0.4339566886425018
train--85/100 [239/1090] loss: 0.4173169255256653
train--85/100 [249/1090] loss: 0.43367262184619904
train--85/100 [259/1090] loss: 0.4368008404970169
train--85/100 [269/1090] loss: 0.44663525819778443
train--85/100 [279/1090] loss: 0.44184680879116056
train--85/100 [289/1090] loss: 0.45353868007659914
train--85/100 [299/1090] loss: 0.4444326996803284
train--85/100 [309/1090] loss: 0.44048890471458435
train--85/100 [319/1090] loss: 0.4415436923503876
train--85/100 [329/1090] loss: 0.45717640221118927
train--85/100 [339/1090] loss: 0.46093437969684603
train--85/100 [349/1090] loss: 0.43185601234436033
train--85/100 [359/1090] loss: 0.4475666284561157
train--85/100 [369/1090] loss: 0.4442849397659302
train--85/100 [379/1090] loss: 0.4457250565290451
train--85/100 [389/1090] loss: 0.4356389582157135
train--85/100 [399/1090] loss: 0.44576776027679443
train--85/100 [409/1090] loss: 0.4253337115049362
train--85/100 [419/1090] loss: 0.4392067760229111
train--85/100 [429/1090] loss: 0.4361298382282257
train--85/100 [439/1090] loss: 0.4371039628982544
train--85/100 [449/1090] loss: 0.444648814201355
train--85/100 [459/1090] loss: 0.43135714530944824
train--85/100 [469/1090] loss: 0.4351880818605423
train--85/100 [479/1090] loss: 0.43854101598262785
train--85/100 [489/1090] loss: 0.43149380683898925
train--85/100 [499/1090] loss: 0.4437491327524185
train--85/100 [509/1090] loss: 0.43518038988113406
train--85/100 [519/1090] loss: 0.4323722094297409
train--85/100 [529/1090] loss: 0.43646131455898285
train--85/100 [539/1090] loss: 0.4287958055734634
train--85/100 [549/1090] loss: 0.42791362702846525
train--85/100 [559/1090] loss: 0.4424990266561508
train--85/100 [569/1090] loss: 0.43927296102046964
train--85/100 [579/1090] loss: 0.4374140650033951
train--85/100 [589/1090] loss: 0.443427574634552
train--85/100 [599/1090] loss: 0.44609714448452
train--85/100 [609/1090] loss: 0.45127456486225126
train--85/100 [619/1090] loss: 0.42089609503746034
train--85/100 [629/1090] loss: 0.4227209031581879
train--85/100 [639/1090] loss: 0.4332795023918152
train--85/100 [649/1090] loss: 0.436865308880806
train--85/100 [659/1090] loss: 0.43957059681415556
train--85/100 [669/1090] loss: 0.43686980903148653
train--85/100 [679/1090] loss: 0.4490118235349655
train--85/100 [689/1090] loss: 0.44206479489803313
train--85/100 [699/1090] loss: 0.4471571296453476
train--85/100 [709/1090] loss: 0.4299857199192047
train--85/100 [719/1090] loss: 0.44515807926654816
train--85/100 [729/1090] loss: 0.4472800105810165
train--85/100 [739/1090] loss: 0.4452603578567505
train--85/100 [749/1090] loss: 0.4578339844942093
train--85/100 [759/1090] loss: 0.43830745816230776
train--85/100 [769/1090] loss: 0.4430999219417572
train--85/100 [779/1090] loss: 0.43819169104099276
train--85/100 [789/1090] loss: 0.4521305948495865
train--85/100 [799/1090] loss: 0.43422979712486265
train--85/100 [809/1090] loss: 0.43546507954597474
train--85/100 [819/1090] loss: 0.4329189121723175
train--85/100 [829/1090] loss: 0.4269914746284485
train--85/100 [839/1090] loss: 0.42615523636341096
train--85/100 [849/1090] loss: 0.43116478323936464
train--85/100 [859/1090] loss: 0.455945885181427
train--85/100 [869/1090] loss: 0.4443072408437729
train--85/100 [879/1090] loss: 0.4351968437433243
train--85/100 [889/1090] loss: 0.4458339184522629
train--85/100 [899/1090] loss: 0.43465326726436615
train--85/100 [909/1090] loss: 0.435065022110939
train--85/100 [919/1090] loss: 0.4347997009754181
train--85/100 [929/1090] loss: 0.4476262032985687
train--85/100 [939/1090] loss: 0.45862739384174345
train--85/100 [949/1090] loss: 0.4538266837596893
train--85/100 [959/1090] loss: 0.4680787056684494
train--85/100 [969/1090] loss: 0.44873891174793246
train--85/100 [979/1090] loss: 0.4323145806789398
train--85/100 [989/1090] loss: 0.4459524184465408
train--85/100 [999/1090] loss: 0.4626240670681
train--85/100 [1009/1090] loss: 0.43527225255966184
train--85/100 [1019/1090] loss: 0.4325946033000946
train--85/100 [1029/1090] loss: 0.4431309223175049
train--85/100 [1039/1090] loss: 0.44345997273921967
train--85/100 [1049/1090] loss: 0.45569565892219543
train--85/100 [1059/1090] loss: 0.4260993927717209
train--85/100 [1069/1090] loss: 0.4414402335882187
train--85/100 [1079/1090] loss: 0.45213052332401277
train--85/100 [1089/1090] loss: 0.4471148639917374
predicting model...
val--85/100 [10/1090] acc: 0.801171875
val--85/100 [20/1090] acc: 0.800390625
val--85/100 [30/1090] acc: 0.7986979166666667
val--85/100 [40/1090] acc: 0.7986328125
val--85/100 [50/1090] acc: 0.79796875
val--85/100 [60/1090] acc: 0.7973307291666667
val--85/100 [70/1090] acc: 0.7976004464285714
val--85/100 [80/1090] acc: 0.79697265625
val--85/100 [90/1090] acc: 0.7971788194444445
val--85/100 [100/1090] acc: 0.798359375
val--85/100 [110/1090] acc: 0.7985795454545455
val--85/100 [120/1090] acc: 0.79814453125
val--85/100 [130/1090] acc: 0.7990685096153847
val--85/100 [140/1090] acc: 0.7989955357142857
val--85/100 [150/1090] acc: 0.798984375
val--85/100 [160/1090] acc: 0.799169921875
val--85/100 [170/1090] acc: 0.7991038602941176
val--85/100 [180/1090] acc: 0.7988498263888889
val--85/100 [190/1090] acc: 0.7994449013157895
val--85/100 [200/1090] acc: 0.79970703125
val--85/100 [210/1090] acc: 0.8001860119047619
val--85/100 [220/1090] acc: 0.7992897727272728
val--85/100 [230/1090] acc: 0.7998301630434783
val--85/100 [240/1090] acc: 0.7996744791666667
val--85/100 [250/1090] acc: 0.799828125
val--85/100 [260/1090] acc: 0.7997145432692307
val--85/100 [270/1090] acc: 0.800072337962963
val--85/100 [280/1090] acc: 0.8000279017857143
val--85/100 [290/1090] acc: 0.799932650862069
val--85/100 [300/1090] acc: 0.8001041666666666
val--85/100 [310/1090] acc: 0.7999747983870967
val--85/100 [320/1090] acc: 0.8000732421875
val--85/100 [330/1090] acc: 0.8002130681818181
val--85/100 [340/1090] acc: 0.8002297794117647
val--85/100 [350/1090] acc: 0.8004464285714286
val--85/100 [360/1090] acc: 0.8003689236111111
val--85/100 [370/1090] acc: 0.8004328547297297
val--85/100 [380/1090] acc: 0.800452302631579
val--85/100 [390/1090] acc: 0.8003305288461539
val--85/100 [400/1090] acc: 0.800322265625
val--85/100 [410/1090] acc: 0.8004382621951219
val--85/100 [420/1090] acc: 0.8002976190476191
val--85/100 [430/1090] acc: 0.8000545058139535
val--85/100 [440/1090] acc: 0.8000621448863636
val--85/100 [450/1090] acc: 0.7998958333333334
val--85/100 [460/1090] acc: 0.7997537364130435
val--85/100 [470/1090] acc: 0.7996343085106383
val--85/100 [480/1090] acc: 0.7996175130208333
val--85/100 [490/1090] acc: 0.799657206632653
val--85/100 [500/1090] acc: 0.7998515625
val--85/100 [510/1090] acc: 0.7997089460784313
val--85/100 [520/1090] acc: 0.7999774639423077
val--85/100 [530/1090] acc: 0.799889445754717
val--85/100 [540/1090] acc: 0.7999565972222222
val--85/100 [550/1090] acc: 0.7997869318181818
val--85/100 [560/1090] acc: 0.7995814732142857
val--85/100 [570/1090] acc: 0.7993215460526316
val--85/100 [580/1090] acc: 0.7992928340517241
val--85/100 [590/1090] acc: 0.7992452330508475
val--85/100 [600/1090] acc: 0.7991796875
val--85/100 [610/1090] acc: 0.7991419057377049
val--85/100 [620/1090] acc: 0.7990990423387097
val--85/100 [630/1090] acc: 0.7993365575396826
val--85/100 [640/1090] acc: 0.7994873046875
val--85/100 [650/1090] acc: 0.7994891826923077
val--85/100 [660/1090] acc: 0.7993963068181819
val--85/100 [670/1090] acc: 0.79921875
val--85/100 [680/1090] acc: 0.79912109375
val--85/100 [690/1090] acc: 0.7992697010869565
val--85/100 [700/1090] acc: 0.7992578125
val--85/100 [710/1090] acc: 0.7991252200704225
val--85/100 [720/1090] acc: 0.7989908854166666
val--85/100 [730/1090] acc: 0.7989351455479452
val--85/100 [740/1090] acc: 0.7988967483108108
val--85/100 [750/1090] acc: 0.7989635416666667
val--85/100 [760/1090] acc: 0.7991416529605263
val--85/100 [770/1090] acc: 0.7990969967532467
val--85/100 [780/1090] acc: 0.7990234375
val--85/100 [790/1090] acc: 0.7990357990506329
val--85/100 [800/1090] acc: 0.799267578125
val--85/100 [810/1090] acc: 0.799291087962963
val--85/100 [820/1090] acc: 0.7993950076219513
val--85/100 [830/1090] acc: 0.7994587725903615
val--85/100 [840/1090] acc: 0.7994326636904762
val--85/100 [850/1090] acc: 0.799420955882353
val--85/100 [860/1090] acc: 0.7996911337209303
val--85/100 [870/1090] acc: 0.7996452945402299
val--85/100 [880/1090] acc: 0.7996937144886364
val--85/100 [890/1090] acc: 0.7997454353932584
val--85/100 [900/1090] acc: 0.7997135416666666
val--85/100 [910/1090] acc: 0.7997252747252748
val--85/100 [920/1090] acc: 0.7997579823369565
val--85/100 [930/1090] acc: 0.7998613911290322
val--85/100 [940/1090] acc: 0.7998420877659574
val--85/100 [950/1090] acc: 0.7998190789473684
val--85/100 [960/1090] acc: 0.7997517903645833
val--85/100 [970/1090] acc: 0.7996778350515464
val--85/100 [980/1090] acc: 0.7996930803571428
val--85/100 [990/1090] acc: 0.7995857007575757
val--85/100 [1000/1090] acc: 0.7994765625
val--85/100 [1010/1090] acc: 0.7992767636138614
val--85/100 [1020/1090] acc: 0.7993336397058823
val--85/100 [1030/1090] acc: 0.7993476941747573
val--85/100 [1040/1090] acc: 0.7993464543269231
val--85/100 [1050/1090] acc: 0.7993675595238096
val--85/100 [1060/1090] acc: 0.7993145636792452
val--85/100 [1070/1090] acc: 0.7992735105140187
val--85/100 [1080/1090] acc: 0.7991970486111111
val--85/100 [1090/1090] acc: 0.7990323967889909
epoch= 85, accuracy= 0.799032, rmse= 0.374767, auc= 0.859078
train--86/100 [9/1090] loss: 0.3920333802700043
train--86/100 [19/1090] loss: 0.4483604937791824
train--86/100 [29/1090] loss: 0.4334226995706558
train--86/100 [39/1090] loss: 0.41956254541873933
train--86/100 [49/1090] loss: 0.43304112255573274
train--86/100 [59/1090] loss: 0.4261086851358414
train--86/100 [69/1090] loss: 0.42232670187950133
train--86/100 [79/1090] loss: 0.43977974355220795
train--86/100 [89/1090] loss: 0.44531184434890747
train--86/100 [99/1090] loss: 0.4229271739721298
train--86/100 [109/1090] loss: 0.432846999168396
train--86/100 [119/1090] loss: 0.4212268561124802
train--86/100 [129/1090] loss: 0.4401502937078476
train--86/100 [139/1090] loss: 0.4324792861938477
train--86/100 [149/1090] loss: 0.4264938473701477
train--86/100 [159/1090] loss: 0.41411846578121186
train--86/100 [169/1090] loss: 0.44122580289840696
train--86/100 [179/1090] loss: 0.4285451829433441
train--86/100 [189/1090] loss: 0.4564050793647766
train--86/100 [199/1090] loss: 0.4440533995628357
train--86/100 [209/1090] loss: 0.44166171848773955
train--86/100 [219/1090] loss: 0.4270052969455719
train--86/100 [229/1090] loss: 0.4248833417892456
train--86/100 [239/1090] loss: 0.4191759407520294
train--86/100 [249/1090] loss: 0.43994131982326506
train--86/100 [259/1090] loss: 0.43236568868160247
train--86/100 [269/1090] loss: 0.44286441802978516
train--86/100 [279/1090] loss: 0.4349893182516098
train--86/100 [289/1090] loss: 0.43373910784721376
train--86/100 [299/1090] loss: 0.42671758830547335
train--86/100 [309/1090] loss: 0.4341519236564636
train--86/100 [319/1090] loss: 0.42089305222034457
train--86/100 [329/1090] loss: 0.4344300955533981
train--86/100 [339/1090] loss: 0.4149123251438141
train--86/100 [349/1090] loss: 0.45385484397411346
train--86/100 [359/1090] loss: 0.4267983466386795
train--86/100 [369/1090] loss: 0.4534570395946503
train--86/100 [379/1090] loss: 0.4402559489011765
train--86/100 [389/1090] loss: 0.4346041440963745
train--86/100 [399/1090] loss: 0.417918261885643
train--86/100 [409/1090] loss: 0.4257995426654816
train--86/100 [419/1090] loss: 0.4369980365037918
train--86/100 [429/1090] loss: 0.43090341687202455
train--86/100 [439/1090] loss: 0.4184229463338852
train--86/100 [449/1090] loss: 0.45310007631778715
train--86/100 [459/1090] loss: 0.4526001691818237
train--86/100 [469/1090] loss: 0.42046811282634733
train--86/100 [479/1090] loss: 0.44216577112674715
train--86/100 [489/1090] loss: 0.4309451311826706
train--86/100 [499/1090] loss: 0.45278907418251035
train--86/100 [509/1090] loss: 0.43797125816345217
train--86/100 [519/1090] loss: 0.430851086974144
train--86/100 [529/1090] loss: 0.42682150900363924
train--86/100 [539/1090] loss: 0.44036117792129514
train--86/100 [549/1090] loss: 0.4330731451511383
train--86/100 [559/1090] loss: 0.44305068254470825
train--86/100 [569/1090] loss: 0.43891464471817015
train--86/100 [579/1090] loss: 0.4527034044265747
train--86/100 [589/1090] loss: 0.45927405059337617
train--86/100 [599/1090] loss: 0.4559832215309143
train--86/100 [609/1090] loss: 0.44204384088516235
train--86/100 [619/1090] loss: 0.4513416886329651
train--86/100 [629/1090] loss: 0.44143386781215666
train--86/100 [639/1090] loss: 0.44720204174518585
train--86/100 [649/1090] loss: 0.41900242269039156
train--86/100 [659/1090] loss: 0.43069554269313814
train--86/100 [669/1090] loss: 0.43220522403717043
train--86/100 [679/1090] loss: 0.4381014138460159
train--86/100 [689/1090] loss: 0.44368820190429686
train--86/100 [699/1090] loss: 0.43668501973152163
train--86/100 [709/1090] loss: 0.44608994722366335
train--86/100 [719/1090] loss: 0.43936010003089904
train--86/100 [729/1090] loss: 0.4359914481639862
train--86/100 [739/1090] loss: 0.43080114722251894
train--86/100 [749/1090] loss: 0.42562018930912016
train--86/100 [759/1090] loss: 0.4440134853124619
train--86/100 [769/1090] loss: 0.4302777647972107
train--86/100 [779/1090] loss: 0.44823381006717683
train--86/100 [789/1090] loss: 0.43425687551498415
train--86/100 [799/1090] loss: 0.45873963534832
train--86/100 [809/1090] loss: 0.4537902444601059
train--86/100 [819/1090] loss: 0.43919522762298585
train--86/100 [829/1090] loss: 0.4649644196033478
train--86/100 [839/1090] loss: 0.46102698147296906
train--86/100 [849/1090] loss: 0.4303734600543976
train--86/100 [859/1090] loss: 0.44620477855205537
train--86/100 [869/1090] loss: 0.43373672366142274
train--86/100 [879/1090] loss: 0.4317132532596588
train--86/100 [889/1090] loss: 0.4361742973327637
train--86/100 [899/1090] loss: 0.45305171608924866
train--86/100 [909/1090] loss: 0.4686216562986374
train--86/100 [919/1090] loss: 0.4419854611158371
train--86/100 [929/1090] loss: 0.4551905125379562
train--86/100 [939/1090] loss: 0.42600647211074827
train--86/100 [949/1090] loss: 0.4623557686805725
train--86/100 [959/1090] loss: 0.44893443286418916
train--86/100 [969/1090] loss: 0.44387399554252627
train--86/100 [979/1090] loss: 0.4452363282442093
train--86/100 [989/1090] loss: 0.436634948849678
train--86/100 [999/1090] loss: 0.4550289839506149
train--86/100 [1009/1090] loss: 0.44408099055290223
train--86/100 [1019/1090] loss: 0.4421589285135269
train--86/100 [1029/1090] loss: 0.4629321277141571
train--86/100 [1039/1090] loss: 0.45439969599246977
train--86/100 [1049/1090] loss: 0.44112334251403806
train--86/100 [1059/1090] loss: 0.43547333478927613
train--86/100 [1069/1090] loss: 0.43878856003284455
train--86/100 [1079/1090] loss: 0.4372692734003067
train--86/100 [1089/1090] loss: 0.43146773874759675
predicting model...
val--86/100 [10/1090] acc: 0.801171875
val--86/100 [20/1090] acc: 0.8013671875
val--86/100 [30/1090] acc: 0.79921875
val--86/100 [40/1090] acc: 0.7990234375
val--86/100 [50/1090] acc: 0.798515625
val--86/100 [60/1090] acc: 0.7977864583333333
val--86/100 [70/1090] acc: 0.7979352678571429
val--86/100 [80/1090] acc: 0.797216796875
val--86/100 [90/1090] acc: 0.7975694444444444
val--86/100 [100/1090] acc: 0.79859375
val--86/100 [110/1090] acc: 0.7987215909090909
val--86/100 [120/1090] acc: 0.7981770833333334
val--86/100 [130/1090] acc: 0.7990685096153847
val--86/100 [140/1090] acc: 0.7989676339285714
val--86/100 [150/1090] acc: 0.7986979166666667
val--86/100 [160/1090] acc: 0.7988037109375
val--86/100 [170/1090] acc: 0.7987821691176471
val--86/100 [180/1090] acc: 0.7986328125
val--86/100 [190/1090] acc: 0.7993626644736842
val--86/100 [200/1090] acc: 0.79966796875
val--86/100 [210/1090] acc: 0.8000744047619047
val--86/100 [220/1090] acc: 0.7993075284090909
val--86/100 [230/1090] acc: 0.7997452445652173
val--86/100 [240/1090] acc: 0.7995930989583333
val--86/100 [250/1090] acc: 0.79990625
val--86/100 [260/1090] acc: 0.7998948317307693
val--86/100 [270/1090] acc: 0.8002893518518519
val--86/100 [280/1090] acc: 0.8001395089285714
val--86/100 [290/1090] acc: 0.7999865301724138
val--86/100 [300/1090] acc: 0.8000911458333333
val--86/100 [310/1090] acc: 0.7998487903225806
val--86/100 [320/1090] acc: 0.8
val--86/100 [330/1090] acc: 0.8001302083333334
val--86/100 [340/1090] acc: 0.8002527573529412
val--86/100 [350/1090] acc: 0.8004241071428572
val--86/100 [360/1090] acc: 0.8003255208333333
val--86/100 [370/1090] acc: 0.8003800675675675
val--86/100 [380/1090] acc: 0.8004317434210526
val--86/100 [390/1090] acc: 0.8002804487179487
val--86/100 [400/1090] acc: 0.80021484375
val--86/100 [410/1090] acc: 0.800266768292683
val--86/100 [420/1090] acc: 0.8001674107142858
val--86/100 [430/1090] acc: 0.7999545784883721
val--86/100 [440/1090] acc: 0.7999822443181818
val--86/100 [450/1090] acc: 0.7999045138888888
val--86/100 [460/1090] acc: 0.7997282608695652
val--86/100 [470/1090] acc: 0.7995595079787234
val--86/100 [480/1090] acc: 0.7995524088541667
val--86/100 [490/1090] acc: 0.7995695153061224
val--86/100 [500/1090] acc: 0.7997265625
val--86/100 [510/1090] acc: 0.7996170343137254
val--86/100 [520/1090] acc: 0.7998873197115385
val--86/100 [530/1090] acc: 0.7997641509433963
val--86/100 [540/1090] acc: 0.7998770254629629
val--86/100 [550/1090] acc: 0.7996803977272727
val--86/100 [560/1090] acc: 0.7995256696428571
val--86/100 [570/1090] acc: 0.7992941337719298
val--86/100 [580/1090] acc: 0.7993130387931034
val--86/100 [590/1090] acc: 0.7992717161016949
val--86/100 [600/1090] acc: 0.7992122395833333
val--86/100 [610/1090] acc: 0.7991611168032787
val--86/100 [620/1090] acc: 0.7991053427419355
val--86/100 [630/1090] acc: 0.7993303571428572
val--86/100 [640/1090] acc: 0.79949951171875
val--86/100 [650/1090] acc: 0.7994951923076923
val--86/100 [660/1090] acc: 0.7993963068181819
val--86/100 [670/1090] acc: 0.7991662779850747
val--86/100 [680/1090] acc: 0.7990291819852942
val--86/100 [690/1090] acc: 0.7991847826086956
val--86/100 [700/1090] acc: 0.7992075892857143
val--86/100 [710/1090] acc: 0.7991527288732394
val--86/100 [720/1090] acc: 0.7990288628472222
val--86/100 [730/1090] acc: 0.7990368150684931
val--86/100 [740/1090] acc: 0.7989653716216216
val--86/100 [750/1090] acc: 0.7989947916666666
val--86/100 [760/1090] acc: 0.799157072368421
val--86/100 [770/1090] acc: 0.7991274350649351
val--86/100 [780/1090] acc: 0.799033453525641
val--86/100 [790/1090] acc: 0.799011075949367
val--86/100 [800/1090] acc: 0.799248046875
val--86/100 [810/1090] acc: 0.7993055555555556
val--86/100 [820/1090] acc: 0.7993711890243902
val--86/100 [830/1090] acc: 0.7994493599397591
val--86/100 [840/1090] acc: 0.7994280133928572
val--86/100 [850/1090] acc: 0.7994577205882353
val--86/100 [860/1090] acc: 0.7997229287790698
val--86/100 [870/1090] acc: 0.7997171336206896
val--86/100 [880/1090] acc: 0.7997025923295454
val--86/100 [890/1090] acc: 0.7997761587078651
val--86/100 [900/1090] acc: 0.7997612847222222
val--86/100 [910/1090] acc: 0.7997682005494505
val--86/100 [920/1090] acc: 0.7997919497282608
val--86/100 [930/1090] acc: 0.7998865927419355
val--86/100 [940/1090] acc: 0.7999002659574468
val--86/100 [950/1090] acc: 0.7998601973684211
val--86/100 [960/1090] acc: 0.7997884114583333
val--86/100 [970/1090] acc: 0.799718105670103
val--86/100 [980/1090] acc: 0.799772799744898
val--86/100 [990/1090] acc: 0.7997080176767677
val--86/100 [1000/1090] acc: 0.79962890625
val--86/100 [1010/1090] acc: 0.7993927908415842
val--86/100 [1020/1090] acc: 0.7994255514705882
val--86/100 [1030/1090] acc: 0.7994652609223301
val--86/100 [1040/1090] acc: 0.7994516225961539
val--86/100 [1050/1090] acc: 0.7995089285714285
val--86/100 [1060/1090] acc: 0.799465654481132
val--86/100 [1070/1090] acc: 0.7994341413551402
val--86/100 [1080/1090] acc: 0.7993706597222222
val--86/100 [1090/1090] acc: 0.7992115825688073
epoch= 86, accuracy= 0.799212, rmse= 0.374787, auc= 0.859224
train--87/100 [9/1090] loss: 0.3978006154298782
train--87/100 [19/1090] loss: 0.4280410557985306
train--87/100 [29/1090] loss: 0.44444268345832827
train--87/100 [39/1090] loss: 0.4278227210044861
train--87/100 [49/1090] loss: 0.4492972820997238
train--87/100 [59/1090] loss: 0.42398618459701537
train--87/100 [69/1090] loss: 0.43137609362602236
train--87/100 [79/1090] loss: 0.45516480803489684
train--87/100 [89/1090] loss: 0.4273554295301437
train--87/100 [99/1090] loss: 0.44790718853473666
train--87/100 [109/1090] loss: 0.458262100815773
train--87/100 [119/1090] loss: 0.4473413586616516
train--87/100 [129/1090] loss: 0.424679771065712
train--87/100 [139/1090] loss: 0.4277447134256363
train--87/100 [149/1090] loss: 0.440643647313118
train--87/100 [159/1090] loss: 0.43628800213336943
train--87/100 [169/1090] loss: 0.4342717081308365
train--87/100 [179/1090] loss: 0.4285317599773407
train--87/100 [189/1090] loss: 0.43031753301620485
train--87/100 [199/1090] loss: 0.4487352788448334
train--87/100 [209/1090] loss: 0.42324868142604827
train--87/100 [219/1090] loss: 0.4354112148284912
train--87/100 [229/1090] loss: 0.44383669197559356
train--87/100 [239/1090] loss: 0.43488138616085054
train--87/100 [249/1090] loss: 0.4335623443126678
train--87/100 [259/1090] loss: 0.4305562525987625
train--87/100 [269/1090] loss: 0.4382746994495392
train--87/100 [279/1090] loss: 0.4322014689445496
train--87/100 [289/1090] loss: 0.4169776916503906
train--87/100 [299/1090] loss: 0.4533302903175354
train--87/100 [309/1090] loss: 0.44524383544921875
train--87/100 [319/1090] loss: 0.4388646811246872
train--87/100 [329/1090] loss: 0.44664903581142423
train--87/100 [339/1090] loss: 0.4445799946784973
train--87/100 [349/1090] loss: 0.42198454439640043
train--87/100 [359/1090] loss: 0.42907917499542236
train--87/100 [369/1090] loss: 0.4079335808753967
train--87/100 [379/1090] loss: 0.43914970457553865
train--87/100 [389/1090] loss: 0.41482843458652496
train--87/100 [399/1090] loss: 0.4367665946483612
train--87/100 [409/1090] loss: 0.44139291942119596
train--87/100 [419/1090] loss: 0.43640064597129824
train--87/100 [429/1090] loss: 0.4369698166847229
train--87/100 [439/1090] loss: 0.4391158252954483
train--87/100 [449/1090] loss: 0.4494513273239136
train--87/100 [459/1090] loss: 0.44181791245937346
train--87/100 [469/1090] loss: 0.4372766137123108
train--87/100 [479/1090] loss: 0.4471589386463165
train--87/100 [489/1090] loss: 0.4335449546575546
train--87/100 [499/1090] loss: 0.43793433010578153
train--87/100 [509/1090] loss: 0.4360599607229233
train--87/100 [519/1090] loss: 0.43505007326602935
train--87/100 [529/1090] loss: 0.4372142732143402
train--87/100 [539/1090] loss: 0.44620644450187685
train--87/100 [549/1090] loss: 0.44086706936359404
train--87/100 [559/1090] loss: 0.43048480451107024
train--87/100 [569/1090] loss: 0.4432416409254074
train--87/100 [579/1090] loss: 0.43297413885593417
train--87/100 [589/1090] loss: 0.44139064848423004
train--87/100 [599/1090] loss: 0.44419228136539457
train--87/100 [609/1090] loss: 0.4469116866588593
train--87/100 [619/1090] loss: 0.45054692029953003
train--87/100 [629/1090] loss: 0.43696905970573424
train--87/100 [639/1090] loss: 0.4536600410938263
train--87/100 [649/1090] loss: 0.42969071567058564
train--87/100 [659/1090] loss: 0.4301115572452545
train--87/100 [669/1090] loss: 0.4337793529033661
train--87/100 [679/1090] loss: 0.451120063662529
train--87/100 [689/1090] loss: 0.41409712433815005
train--87/100 [699/1090] loss: 0.4252725809812546
train--87/100 [709/1090] loss: 0.42972252368927
train--87/100 [719/1090] loss: 0.45378635823726654
train--87/100 [729/1090] loss: 0.45221012830734253
train--87/100 [739/1090] loss: 0.44112939536571505
train--87/100 [749/1090] loss: 0.43857710957527163
train--87/100 [759/1090] loss: 0.4288970440626144
train--87/100 [769/1090] loss: 0.44941559731960296
train--87/100 [779/1090] loss: 0.43568516671657564
train--87/100 [789/1090] loss: 0.43730882108211516
train--87/100 [799/1090] loss: 0.4440146505832672
train--87/100 [809/1090] loss: 0.43912512362003325
train--87/100 [819/1090] loss: 0.436700114607811
train--87/100 [829/1090] loss: 0.42229028344154357
train--87/100 [839/1090] loss: 0.42885782122612
train--87/100 [849/1090] loss: 0.4535841017961502
train--87/100 [859/1090] loss: 0.4427817970514297
train--87/100 [869/1090] loss: 0.4355217695236206
train--87/100 [879/1090] loss: 0.4418030232191086
train--87/100 [889/1090] loss: 0.4278563052415848
train--87/100 [899/1090] loss: 0.4369989186525345
train--87/100 [909/1090] loss: 0.4518535673618317
train--87/100 [919/1090] loss: 0.4464493066072464
train--87/100 [929/1090] loss: 0.43761609196662904
train--87/100 [939/1090] loss: 0.44425176084041595
train--87/100 [949/1090] loss: 0.44351144433021544
train--87/100 [959/1090] loss: 0.43008975088596346
train--87/100 [969/1090] loss: 0.44448875784873965
train--87/100 [979/1090] loss: 0.4358918875455856
train--87/100 [989/1090] loss: 0.44396704733371734
train--87/100 [999/1090] loss: 0.4401607304811478
train--87/100 [1009/1090] loss: 0.4475976526737213
train--87/100 [1019/1090] loss: 0.43385854959487913
train--87/100 [1029/1090] loss: 0.45894066989421844
train--87/100 [1039/1090] loss: 0.4412955641746521
train--87/100 [1049/1090] loss: 0.4312720000743866
train--87/100 [1059/1090] loss: 0.4312817484140396
train--87/100 [1069/1090] loss: 0.4557842880487442
train--87/100 [1079/1090] loss: 0.4541206926107407
train--87/100 [1089/1090] loss: 0.45850363969802854
predicting model...
val--87/100 [10/1090] acc: 0.799609375
val--87/100 [20/1090] acc: 0.8009765625
val--87/100 [30/1090] acc: 0.800390625
val--87/100 [40/1090] acc: 0.799609375
val--87/100 [50/1090] acc: 0.7984375
val--87/100 [60/1090] acc: 0.7977213541666667
val--87/100 [70/1090] acc: 0.7979910714285714
val--87/100 [80/1090] acc: 0.7970703125
val--87/100 [90/1090] acc: 0.7973524305555556
val--87/100 [100/1090] acc: 0.7984375
val--87/100 [110/1090] acc: 0.7988991477272728
val--87/100 [120/1090] acc: 0.7984700520833333
val--87/100 [130/1090] acc: 0.7992487980769231
val--87/100 [140/1090] acc: 0.7990513392857143
val--87/100 [150/1090] acc: 0.799140625
val--87/100 [160/1090] acc: 0.79921875
val--87/100 [170/1090] acc: 0.7993106617647059
val--87/100 [180/1090] acc: 0.7991970486111111
val--87/100 [190/1090] acc: 0.7997738486842105
val--87/100 [200/1090] acc: 0.80005859375
val--87/100 [210/1090] acc: 0.8005022321428571
val--87/100 [220/1090] acc: 0.7995561079545455
val--87/100 [230/1090] acc: 0.8002038043478261
val--87/100 [240/1090] acc: 0.8000813802083333
val--87/100 [250/1090] acc: 0.800359375
val--87/100 [260/1090] acc: 0.8003305288461539
val--87/100 [270/1090] acc: 0.8005642361111112
val--87/100 [280/1090] acc: 0.8004464285714286
val--87/100 [290/1090] acc: 0.8003098060344828
val--87/100 [300/1090] acc: 0.8005208333333333
val--87/100 [310/1090] acc: 0.8003402217741935
val--87/100 [320/1090] acc: 0.8004638671875
val--87/100 [330/1090] acc: 0.8006036931818182
val--87/100 [340/1090] acc: 0.8007123161764705
val--87/100 [350/1090] acc: 0.8009040178571428
val--87/100 [360/1090] acc: 0.8007161458333333
val--87/100 [370/1090] acc: 0.8008234797297298
val--87/100 [380/1090] acc: 0.8008532072368421
val--87/100 [390/1090] acc: 0.8007011217948717
val--87/100 [400/1090] acc: 0.80060546875
val--87/100 [410/1090] acc: 0.8007050304878048
val--87/100 [420/1090] acc: 0.8006138392857143
val--87/100 [430/1090] acc: 0.8003179505813953
val--87/100 [440/1090] acc: 0.8003728693181819
val--87/100 [450/1090] acc: 0.8001736111111111
val--87/100 [460/1090] acc: 0.8000254755434782
val--87/100 [470/1090] acc: 0.7999251994680852
val--87/100 [480/1090] acc: 0.7998779296875
val--87/100 [490/1090] acc: 0.7999282525510204
val--87/100 [500/1090] acc: 0.8000625
val--87/100 [510/1090] acc: 0.7999157475490196
val--87/100 [520/1090] acc: 0.8001802884615384
val--87/100 [530/1090] acc: 0.8000958136792453
val--87/100 [540/1090] acc: 0.8001880787037037
val--87/100 [550/1090] acc: 0.800078125
val--87/100 [560/1090] acc: 0.79990234375
val--87/100 [570/1090] acc: 0.7996573464912281
val--87/100 [580/1090] acc: 0.7996363146551724
val--87/100 [590/1090] acc: 0.7995828919491526
val--87/100 [600/1090] acc: 0.7995442708333333
val--87/100 [610/1090] acc: 0.799500512295082
val--87/100 [620/1090] acc: 0.7994707661290322
val--87/100 [630/1090] acc: 0.799702380952381
val--87/100 [640/1090] acc: 0.7999267578125
val--87/100 [650/1090] acc: 0.7999038461538461
val--87/100 [660/1090] acc: 0.7997869318181818
val--87/100 [670/1090] acc: 0.7995685634328358
val--87/100 [680/1090] acc: 0.7994600183823529
val--87/100 [690/1090] acc: 0.7995980525362318
val--87/100 [700/1090] acc: 0.7996428571428571
val--87/100 [710/1090] acc: 0.7995818661971831
val--87/100 [720/1090] acc: 0.7994520399305556
val--87/100 [730/1090] acc: 0.7993899828767124
val--87/100 [740/1090] acc: 0.7993454391891892
val--87/100 [750/1090] acc: 0.7993958333333333
val--87/100 [760/1090] acc: 0.799573396381579
val--87/100 [770/1090] acc: 0.7995637175324676
val--87/100 [780/1090] acc: 0.7994791666666666
val--87/100 [790/1090] acc: 0.7994808148734177
val--87/100 [800/1090] acc: 0.7997216796875
val--87/100 [810/1090] acc: 0.7997733410493827
val--87/100 [820/1090] acc: 0.7998809070121952
val--87/100 [830/1090] acc: 0.7999670557228916
val--87/100 [840/1090] acc: 0.7999209449404762
val--87/100 [850/1090] acc: 0.799921875
val--87/100 [860/1090] acc: 0.8002316497093023
val--87/100 [870/1090] acc: 0.8001885775862069
val--87/100 [880/1090] acc: 0.8001553622159091
val--87/100 [890/1090] acc: 0.8002370084269663
val--87/100 [900/1090] acc: 0.8002083333333333
val--87/100 [910/1090] acc: 0.8002103365384615
val--87/100 [920/1090] acc: 0.8002505095108695
val--87/100 [930/1090] acc: 0.8003402217741935
val--87/100 [940/1090] acc: 0.8003449135638298
val--87/100 [950/1090] acc: 0.8003001644736842
val--87/100 [960/1090] acc: 0.8002156575520833
val--87/100 [970/1090] acc: 0.8001328930412371
val--87/100 [980/1090] acc: 0.800163424744898
val--87/100 [990/1090] acc: 0.8000789141414142
val--87/100 [1000/1090] acc: 0.7999765625
val--87/100 [1010/1090] acc: 0.7997408725247525
val--87/100 [1020/1090] acc: 0.7997855392156863
val--87/100 [1030/1090] acc: 0.7998255461165048
val--87/100 [1040/1090] acc: 0.7998084435096153
val--87/100 [1050/1090] acc: 0.7998214285714286
val--87/100 [1060/1090] acc: 0.7997788915094339
val--87/100 [1070/1090] acc: 0.7997554030373831
val--87/100 [1080/1090] acc: 0.7996853298611111
val--87/100 [1090/1090] acc: 0.7994946961009174
epoch= 87, accuracy= 0.799495, rmse= 0.374616, auc= 0.859389
train--88/100 [9/1090] loss: 0.3934225678443909
train--88/100 [19/1090] loss: 0.43537864089012146
train--88/100 [29/1090] loss: 0.45241462588310244
train--88/100 [39/1090] loss: 0.4337352097034454
train--88/100 [49/1090] loss: 0.4350134789943695
train--88/100 [59/1090] loss: 0.43250171542167665
train--88/100 [69/1090] loss: 0.43540496230125425
train--88/100 [79/1090] loss: 0.43160698711872103
train--88/100 [89/1090] loss: 0.4250551134347916
train--88/100 [99/1090] loss: 0.46044908463954926
train--88/100 [109/1090] loss: 0.4382439196109772
train--88/100 [119/1090] loss: 0.43489137291908264
train--88/100 [129/1090] loss: 0.4303045004606247
train--88/100 [139/1090] loss: 0.4324006915092468
train--88/100 [149/1090] loss: 0.4387493968009949
train--88/100 [159/1090] loss: 0.4373764544725418
train--88/100 [169/1090] loss: 0.4362020164728165
train--88/100 [179/1090] loss: 0.45008247494697573
train--88/100 [189/1090] loss: 0.4265503227710724
train--88/100 [199/1090] loss: 0.4374863415956497
train--88/100 [209/1090] loss: 0.45096116364002226
train--88/100 [219/1090] loss: 0.42949322462081907
train--88/100 [229/1090] loss: 0.436690691113472
train--88/100 [239/1090] loss: 0.4370300233364105
train--88/100 [249/1090] loss: 0.46176148056983946
train--88/100 [259/1090] loss: 0.42943993806838987
train--88/100 [269/1090] loss: 0.4212868094444275
train--88/100 [279/1090] loss: 0.4244188219308853
train--88/100 [289/1090] loss: 0.447884202003479
train--88/100 [299/1090] loss: 0.4174778550863266
train--88/100 [309/1090] loss: 0.4479030340909958
train--88/100 [319/1090] loss: 0.4397381216287613
train--88/100 [329/1090] loss: 0.4474080353975296
train--88/100 [339/1090] loss: 0.42559134364128115
train--88/100 [349/1090] loss: 0.42810219526290894
train--88/100 [359/1090] loss: 0.45176976919174194
train--88/100 [369/1090] loss: 0.4411902904510498
train--88/100 [379/1090] loss: 0.44902223646640776
train--88/100 [389/1090] loss: 0.43476007878780365
train--88/100 [399/1090] loss: 0.4440578371286392
train--88/100 [409/1090] loss: 0.42884179651737214
train--88/100 [419/1090] loss: 0.4353898674249649
train--88/100 [429/1090] loss: 0.44564505517482755
train--88/100 [439/1090] loss: 0.4467455714941025
train--88/100 [449/1090] loss: 0.4275295287370682
train--88/100 [459/1090] loss: 0.42614731192588806
train--88/100 [469/1090] loss: 0.4304658591747284
train--88/100 [479/1090] loss: 0.4401681929826736
train--88/100 [489/1090] loss: 0.4283537954092026
train--88/100 [499/1090] loss: 0.43864153921604154
train--88/100 [509/1090] loss: 0.43744136989116666
train--88/100 [519/1090] loss: 0.4367797762155533
train--88/100 [529/1090] loss: 0.43272885084152224
train--88/100 [539/1090] loss: 0.44369701743125917
train--88/100 [549/1090] loss: 0.4389464735984802
train--88/100 [559/1090] loss: 0.4295721143484116
train--88/100 [569/1090] loss: 0.4251545757055283
train--88/100 [579/1090] loss: 0.4404201775789261
train--88/100 [589/1090] loss: 0.4372109234333038
train--88/100 [599/1090] loss: 0.4314300775527954
train--88/100 [609/1090] loss: 0.4347758889198303
train--88/100 [619/1090] loss: 0.4469226270914078
train--88/100 [629/1090] loss: 0.45554265677928923
train--88/100 [639/1090] loss: 0.43954929113388064
train--88/100 [649/1090] loss: 0.4258380889892578
train--88/100 [659/1090] loss: 0.4338493973016739
train--88/100 [669/1090] loss: 0.4234484493732452
train--88/100 [679/1090] loss: 0.44065654575824736
train--88/100 [689/1090] loss: 0.41735579669475553
train--88/100 [699/1090] loss: 0.45565235912799834
train--88/100 [709/1090] loss: 0.424589267373085
train--88/100 [719/1090] loss: 0.41934790909290315
train--88/100 [729/1090] loss: 0.43966635763645173
train--88/100 [739/1090] loss: 0.4570541024208069
train--88/100 [749/1090] loss: 0.4498714655637741
train--88/100 [759/1090] loss: 0.45176278352737426
train--88/100 [769/1090] loss: 0.4375096529722214
train--88/100 [779/1090] loss: 0.43232434093952177
train--88/100 [789/1090] loss: 0.4505652517080307
train--88/100 [799/1090] loss: 0.44128804504871366
train--88/100 [809/1090] loss: 0.43603067100048065
train--88/100 [819/1090] loss: 0.44878968596458435
train--88/100 [829/1090] loss: 0.4336735099554062
train--88/100 [839/1090] loss: 0.42450618743896484
train--88/100 [849/1090] loss: 0.43883966505527494
train--88/100 [859/1090] loss: 0.42960705757141116
train--88/100 [869/1090] loss: 0.43947621881961824
train--88/100 [879/1090] loss: 0.46109037697315214
train--88/100 [889/1090] loss: 0.4455114483833313
train--88/100 [899/1090] loss: 0.4358138293027878
train--88/100 [909/1090] loss: 0.42281474471092223
train--88/100 [919/1090] loss: 0.44342570304870604
train--88/100 [929/1090] loss: 0.43506333231925964
train--88/100 [939/1090] loss: 0.4358771026134491
train--88/100 [949/1090] loss: 0.44761071503162386
train--88/100 [959/1090] loss: 0.44621068239212036
train--88/100 [969/1090] loss: 0.439317986369133
train--88/100 [979/1090] loss: 0.43262134194374086
train--88/100 [989/1090] loss: 0.4572332799434662
train--88/100 [999/1090] loss: 0.4327729731798172
train--88/100 [1009/1090] loss: 0.4449837297201157
train--88/100 [1019/1090] loss: 0.44215455949306487
train--88/100 [1029/1090] loss: 0.45017741024494173
train--88/100 [1039/1090] loss: 0.45477382838726044
train--88/100 [1049/1090] loss: 0.43987844586372377
train--88/100 [1059/1090] loss: 0.43864530622959136
train--88/100 [1069/1090] loss: 0.4462297856807709
train--88/100 [1079/1090] loss: 0.447972247004509
train--88/100 [1089/1090] loss: 0.43115720748901365
predicting model...
val--88/100 [10/1090] acc: 0.798046875
val--88/100 [20/1090] acc: 0.8
val--88/100 [30/1090] acc: 0.800390625
val--88/100 [40/1090] acc: 0.80009765625
val--88/100 [50/1090] acc: 0.799453125
val--88/100 [60/1090] acc: 0.7985677083333333
val--88/100 [70/1090] acc: 0.7986049107142857
val--88/100 [80/1090] acc: 0.79775390625
val--88/100 [90/1090] acc: 0.7977864583333333
val--88/100 [100/1090] acc: 0.7988671875
val--88/100 [110/1090] acc: 0.7990056818181818
val--88/100 [120/1090] acc: 0.7986002604166667
val--88/100 [130/1090] acc: 0.7994891826923077
val--88/100 [140/1090] acc: 0.7993582589285714
val--88/100 [150/1090] acc: 0.799296875
val--88/100 [160/1090] acc: 0.79931640625
val--88/100 [170/1090] acc: 0.7991268382352941
val--88/100 [180/1090] acc: 0.7989583333333333
val--88/100 [190/1090] acc: 0.7995682565789474
val--88/100 [200/1090] acc: 0.79990234375
val--88/100 [210/1090] acc: 0.800483630952381
val--88/100 [220/1090] acc: 0.7995738636363636
val--88/100 [230/1090] acc: 0.8001188858695653
val--88/100 [240/1090] acc: 0.799951171875
val--88/100 [250/1090] acc: 0.8000625
val--88/100 [260/1090] acc: 0.8000901442307692
val--88/100 [270/1090] acc: 0.8003616898148148
val--88/100 [280/1090] acc: 0.8002790178571428
val--88/100 [290/1090] acc: 0.8002020474137931
val--88/100 [300/1090] acc: 0.8003645833333334
val--88/100 [310/1090] acc: 0.8001890120967742
val--88/100 [320/1090] acc: 0.800341796875
val--88/100 [330/1090] acc: 0.8004142992424242
val--88/100 [340/1090] acc: 0.8005399816176471
val--88/100 [350/1090] acc: 0.8006696428571428
val--88/100 [360/1090] acc: 0.8005750868055556
val--88/100 [370/1090] acc: 0.800633445945946
val--88/100 [380/1090] acc: 0.8006990131578947
val--88/100 [390/1090] acc: 0.8006209935897436
val--88/100 [400/1090] acc: 0.800595703125
val--88/100 [410/1090] acc: 0.8006764481707317
val--88/100 [420/1090] acc: 0.8005859375
val--88/100 [430/1090] acc: 0.800281613372093
val--88/100 [440/1090] acc: 0.8002840909090909
val--88/100 [450/1090] acc: 0.8001649305555556
val--88/100 [460/1090] acc: 0.7999745244565217
val--88/100 [470/1090] acc: 0.7998753324468085
val--88/100 [480/1090] acc: 0.7998453776041666
val--88/100 [490/1090] acc: 0.7998565051020409
val--88/100 [500/1090] acc: 0.7999453125
val--88/100 [510/1090] acc: 0.7998314950980392
val--88/100 [520/1090] acc: 0.8001652644230769
val--88/100 [530/1090] acc: 0.8000368514150943
val--88/100 [540/1090] acc: 0.8001012731481482
val--88/100 [550/1090] acc: 0.7999147727272727
val--88/100 [560/1090] acc: 0.7996930803571428
val--88/100 [570/1090] acc: 0.7994517543859649
val--88/100 [580/1090] acc: 0.7993938577586207
val--88/100 [590/1090] acc: 0.7993379237288135
val--88/100 [600/1090] acc: 0.7993033854166667
val--88/100 [610/1090] acc: 0.7992955942622951
val--88/100 [620/1090] acc: 0.7992565524193549
val--88/100 [630/1090] acc: 0.7994543650793651
val--88/100 [640/1090] acc: 0.799652099609375
val--88/100 [650/1090] acc: 0.799639423076923
val--88/100 [660/1090] acc: 0.7995738636363636
val--88/100 [670/1090] acc: 0.7994169776119403
val--88/100 [680/1090] acc: 0.7993336397058823
val--88/100 [690/1090] acc: 0.7994621829710145
val--88/100 [700/1090] acc: 0.7994866071428571
val--88/100 [710/1090] acc: 0.7993672975352113
val--88/100 [720/1090] acc: 0.7992567274305555
val--88/100 [730/1090] acc: 0.7992294520547946
val--88/100 [740/1090] acc: 0.799192356418919
val--88/100 [750/1090] acc: 0.7992395833333333
val--88/100 [760/1090] acc: 0.7993832236842106
val--88/100 [770/1090] acc: 0.7993810876623376
val--88/100 [780/1090] acc: 0.7993439503205129
val--88/100 [790/1090] acc: 0.7993275316455696
val--88/100 [800/1090] acc: 0.799560546875
val--88/100 [810/1090] acc: 0.7995949074074075
val--88/100 [820/1090] acc: 0.7997094131097561
val--88/100 [830/1090] acc: 0.7997646837349398
val--88/100 [840/1090] acc: 0.7997302827380952
val--88/100 [850/1090] acc: 0.7997472426470589
val--88/100 [860/1090] acc: 0.8000363372093023
val--88/100 [870/1090] acc: 0.7999955100574713
val--88/100 [880/1090] acc: 0.8000044389204546
val--88/100 [890/1090] acc: 0.8000833918539326
val--88/100 [900/1090] acc: 0.8000564236111111
val--88/100 [910/1090] acc: 0.8000643887362637
val--88/100 [920/1090] acc: 0.8000849184782609
val--88/100 [930/1090] acc: 0.8002100134408602
val--88/100 [940/1090] acc: 0.8001994680851063
val--88/100 [950/1090] acc: 0.8001685855263158
val--88/100 [960/1090] acc: 0.80009765625
val--88/100 [970/1090] acc: 0.8000281894329897
val--88/100 [980/1090] acc: 0.8000518176020408
val--88/100 [990/1090] acc: 0.7999644886363636
val--88/100 [1000/1090] acc: 0.79986328125
val--88/100 [1010/1090] acc: 0.7996364480198019
val--88/100 [1020/1090] acc: 0.7996859681372549
val--88/100 [1030/1090] acc: 0.7997117718446602
val--88/100 [1040/1090] acc: 0.7996882512019231
val--88/100 [1050/1090] acc: 0.7997247023809524
val--88/100 [1060/1090] acc: 0.7996830778301887
val--88/100 [1070/1090] acc: 0.7996641355140187
val--88/100 [1080/1090] acc: 0.799584056712963
val--88/100 [1090/1090] acc: 0.7994015194954128
epoch= 88, accuracy= 0.799402, rmse= 0.374548, auc= 0.859416
train--89/100 [9/1090] loss: 0.3935637354850769
train--89/100 [19/1090] loss: 0.43660407364368437
train--89/100 [29/1090] loss: 0.4606443166732788
train--89/100 [39/1090] loss: 0.42450242936611177
train--89/100 [49/1090] loss: 0.41453773975372316
train--89/100 [59/1090] loss: 0.43007151782512665
train--89/100 [69/1090] loss: 0.43450661897659304
train--89/100 [79/1090] loss: 0.4217330068349838
train--89/100 [89/1090] loss: 0.43852248787879944
train--89/100 [99/1090] loss: 0.44746666848659516
train--89/100 [109/1090] loss: 0.44184272587299345
train--89/100 [119/1090] loss: 0.4478386610746384
train--89/100 [129/1090] loss: 0.4384892761707306
train--89/100 [139/1090] loss: 0.42356071472167967
train--89/100 [149/1090] loss: 0.42092426419258117
train--89/100 [159/1090] loss: 0.44361607134342196
train--89/100 [169/1090] loss: 0.43773127496242525
train--89/100 [179/1090] loss: 0.4381181001663208
train--89/100 [189/1090] loss: 0.44416376352310183
train--89/100 [199/1090] loss: 0.43610078692436216
train--89/100 [209/1090] loss: 0.42764090597629545
train--89/100 [219/1090] loss: 0.4357146829366684
train--89/100 [229/1090] loss: 0.45401853024959565
train--89/100 [239/1090] loss: 0.42606736421585084
train--89/100 [249/1090] loss: 0.4504644423723221
train--89/100 [259/1090] loss: 0.43869582414627073
train--89/100 [269/1090] loss: 0.4422724902629852
train--89/100 [279/1090] loss: 0.4359306037425995
train--89/100 [289/1090] loss: 0.4377827137708664
train--89/100 [299/1090] loss: 0.43822277784347535
train--89/100 [309/1090] loss: 0.44661255478858947
train--89/100 [319/1090] loss: 0.43120203614234925
train--89/100 [329/1090] loss: 0.4268131673336029
train--89/100 [339/1090] loss: 0.4258184194564819
train--89/100 [349/1090] loss: 0.4585218995809555
train--89/100 [359/1090] loss: 0.42431898415088654
train--89/100 [369/1090] loss: 0.4470146417617798
train--89/100 [379/1090] loss: 0.42449983954429626
train--89/100 [389/1090] loss: 0.4346037954092026
train--89/100 [399/1090] loss: 0.43445430397987367
train--89/100 [409/1090] loss: 0.44341063797473906
train--89/100 [419/1090] loss: 0.42971904277801515
train--89/100 [429/1090] loss: 0.4349872797727585
train--89/100 [439/1090] loss: 0.42208858728408816
train--89/100 [449/1090] loss: 0.4374311059713364
train--89/100 [459/1090] loss: 0.4270771235227585
train--89/100 [469/1090] loss: 0.4438300132751465
train--89/100 [479/1090] loss: 0.45039530992507937
train--89/100 [489/1090] loss: 0.42173153162002563
train--89/100 [499/1090] loss: 0.4473101645708084
train--89/100 [509/1090] loss: 0.44039509296417234
train--89/100 [519/1090] loss: 0.42406870126724244
train--89/100 [529/1090] loss: 0.43605886697769164
train--89/100 [539/1090] loss: 0.44111827909946444
train--89/100 [549/1090] loss: 0.4437248706817627
train--89/100 [559/1090] loss: 0.43861656785011294
train--89/100 [569/1090] loss: 0.4407284766435623
train--89/100 [579/1090] loss: 0.4484607070684433
train--89/100 [589/1090] loss: 0.44134011268615725
train--89/100 [599/1090] loss: 0.44128663241863253
train--89/100 [609/1090] loss: 0.4217938810586929
train--89/100 [619/1090] loss: 0.4505449771881104
train--89/100 [629/1090] loss: 0.4458555459976196
train--89/100 [639/1090] loss: 0.43156959414482116
train--89/100 [649/1090] loss: 0.4447163850069046
train--89/100 [659/1090] loss: 0.44906427562236784
train--89/100 [669/1090] loss: 0.4410053461790085
train--89/100 [679/1090] loss: 0.42715595960617064
train--89/100 [689/1090] loss: 0.42435766756534576
train--89/100 [699/1090] loss: 0.4603643298149109
train--89/100 [709/1090] loss: 0.43445369601249695
train--89/100 [719/1090] loss: 0.4296024918556213
train--89/100 [729/1090] loss: 0.4347846955060959
train--89/100 [739/1090] loss: 0.43326772153377535
train--89/100 [749/1090] loss: 0.45537852942943574
train--89/100 [759/1090] loss: 0.45991232693195344
train--89/100 [769/1090] loss: 0.4506180614233017
train--89/100 [779/1090] loss: 0.4305300861597061
train--89/100 [789/1090] loss: 0.45245716273784636
train--89/100 [799/1090] loss: 0.4423384010791779
train--89/100 [809/1090] loss: 0.43506890833377837
train--89/100 [819/1090] loss: 0.45513122975826265
train--89/100 [829/1090] loss: 0.4487539529800415
train--89/100 [839/1090] loss: 0.4742844730615616
train--89/100 [849/1090] loss: 0.4356591820716858
train--89/100 [859/1090] loss: 0.43635689914226533
train--89/100 [869/1090] loss: 0.4365164369344711
train--89/100 [879/1090] loss: 0.444579604268074
train--89/100 [889/1090] loss: 0.4381420284509659
train--89/100 [899/1090] loss: 0.44287045001983644
train--89/100 [909/1090] loss: 0.4311062455177307
train--89/100 [919/1090] loss: 0.4356944590806961
train--89/100 [929/1090] loss: 0.4381136536598206
train--89/100 [939/1090] loss: 0.4434665411710739
train--89/100 [949/1090] loss: 0.44162785410881045
train--89/100 [959/1090] loss: 0.42875499427318575
train--89/100 [969/1090] loss: 0.4354397088289261
train--89/100 [979/1090] loss: 0.4447847634553909
train--89/100 [989/1090] loss: 0.4397017329931259
train--89/100 [999/1090] loss: 0.4431242734193802
train--89/100 [1009/1090] loss: 0.4463971585035324
train--89/100 [1019/1090] loss: 0.4214063107967377
train--89/100 [1029/1090] loss: 0.43480012714862826
train--89/100 [1039/1090] loss: 0.4222497493028641
train--89/100 [1049/1090] loss: 0.43414419889450073
train--89/100 [1059/1090] loss: 0.43019738495349885
train--89/100 [1069/1090] loss: 0.4206455945968628
train--89/100 [1079/1090] loss: 0.43590845763683317
train--89/100 [1089/1090] loss: 0.437298646569252
predicting model...
val--89/100 [10/1090] acc: 0.801171875
val--89/100 [20/1090] acc: 0.8017578125
val--89/100 [30/1090] acc: 0.800390625
val--89/100 [40/1090] acc: 0.79990234375
val--89/100 [50/1090] acc: 0.7990625
val--89/100 [60/1090] acc: 0.7982421875
val--89/100 [70/1090] acc: 0.7983816964285714
val--89/100 [80/1090] acc: 0.797802734375
val--89/100 [90/1090] acc: 0.798046875
val--89/100 [100/1090] acc: 0.7990625
val--89/100 [110/1090] acc: 0.7992897727272728
val--89/100 [120/1090] acc: 0.7988932291666667
val--89/100 [130/1090] acc: 0.799639423076923
val--89/100 [140/1090] acc: 0.7995535714285714
val--89/100 [150/1090] acc: 0.7994270833333333
val--89/100 [160/1090] acc: 0.7994873046875
val--89/100 [170/1090] acc: 0.7993106617647059
val--89/100 [180/1090] acc: 0.7990885416666667
val--89/100 [190/1090] acc: 0.7995682565789474
val--89/100 [200/1090] acc: 0.79974609375
val--89/100 [210/1090] acc: 0.8002232142857143
val--89/100 [220/1090] acc: 0.7994318181818182
val--89/100 [230/1090] acc: 0.7999830163043479
val--89/100 [240/1090] acc: 0.7997395833333333
val--89/100 [250/1090] acc: 0.7998125
val--89/100 [260/1090] acc: 0.7997596153846154
val--89/100 [270/1090] acc: 0.800144675925926
val--89/100 [280/1090] acc: 0.8001255580357143
val--89/100 [290/1090] acc: 0.8000942887931034
val--89/100 [300/1090] acc: 0.8001953125
val--89/100 [310/1090] acc: 0.8000126008064516
val--89/100 [320/1090] acc: 0.80018310546875
val--89/100 [330/1090] acc: 0.8002840909090909
val--89/100 [340/1090] acc: 0.8003216911764706
val--89/100 [350/1090] acc: 0.8005580357142857
val--89/100 [360/1090] acc: 0.8005099826388888
val--89/100 [370/1090] acc: 0.8006862331081082
val--89/100 [380/1090] acc: 0.8006887335526316
val--89/100 [390/1090] acc: 0.8006009615384615
val--89/100 [400/1090] acc: 0.800546875
val--89/100 [410/1090] acc: 0.8006288109756098
val--89/100 [420/1090] acc: 0.8005208333333333
val--89/100 [430/1090] acc: 0.8002271075581395
val--89/100 [440/1090] acc: 0.8003284801136363
val--89/100 [450/1090] acc: 0.8001736111111111
val--89/100 [460/1090] acc: 0.8000424592391304
val--89/100 [470/1090] acc: 0.7999418218085106
val--89/100 [480/1090] acc: 0.7999267578125
val--89/100 [490/1090] acc: 0.7999282525510204
val--89/100 [500/1090] acc: 0.800140625
val--89/100 [510/1090] acc: 0.800030637254902
val--89/100 [520/1090] acc: 0.8003155048076923
val--89/100 [530/1090] acc: 0.8001842570754717
val--89/100 [540/1090] acc: 0.8002242476851852
val--89/100 [550/1090] acc: 0.8000355113636364
val--89/100 [560/1090] acc: 0.7998744419642857
val--89/100 [570/1090] acc: 0.7996436403508772
val--89/100 [580/1090] acc: 0.7996430495689655
val--89/100 [590/1090] acc: 0.799556408898305
val--89/100 [600/1090] acc: 0.79951171875
val--89/100 [610/1090] acc: 0.7994941086065573
val--89/100 [620/1090] acc: 0.7994266633064516
val--89/100 [630/1090] acc: 0.7996837797619047
val--89/100 [640/1090] acc: 0.799871826171875
val--89/100 [650/1090] acc: 0.7998858173076923
val--89/100 [660/1090] acc: 0.7998224431818182
val--89/100 [670/1090] acc: 0.7996501865671641
val--89/100 [680/1090] acc: 0.7995634191176471
val--89/100 [690/1090] acc: 0.7996886322463768
val--89/100 [700/1090] acc: 0.7997544642857143
val--89/100 [710/1090] acc: 0.799636883802817
val--89/100 [720/1090] acc: 0.7995171440972222
val--89/100 [730/1090] acc: 0.7994970034246576
val--89/100 [740/1090] acc: 0.7994510135135136
val--89/100 [750/1090] acc: 0.7994947916666667
val--89/100 [760/1090] acc: 0.7996710526315789
val--89/100 [770/1090] acc: 0.7996601055194805
val--89/100 [780/1090] acc: 0.7995592948717949
val--89/100 [790/1090] acc: 0.799550039556962
val--89/100 [800/1090] acc: 0.79978515625
val--89/100 [810/1090] acc: 0.7998263888888889
val--89/100 [820/1090] acc: 0.7999047256097561
val--89/100 [830/1090] acc: 0.7999905873493975
val--89/100 [840/1090] acc: 0.7999627976190476
val--89/100 [850/1090] acc: 0.7999632352941176
val--89/100 [860/1090] acc: 0.8002589026162791
val--89/100 [870/1090] acc: 0.8002469468390805
val--89/100 [880/1090] acc: 0.800235262784091
val--89/100 [890/1090] acc: 0.8003028441011236
val--89/100 [900/1090] acc: 0.8002690972222222
val--89/100 [910/1090] acc: 0.8002918956043956
val--89/100 [920/1090] acc: 0.8003439198369565
val--89/100 [930/1090] acc: 0.8004242271505376
val--89/100 [940/1090] acc: 0.8004072473404256
val--89/100 [950/1090] acc: 0.8003741776315789
val--89/100 [960/1090] acc: 0.8003092447916667
val--89/100 [970/1090] acc: 0.8002214884020619
val--89/100 [980/1090] acc: 0.8002670599489796
val--89/100 [990/1090] acc: 0.8001815025252526
val--89/100 [1000/1090] acc: 0.8000703125
val--89/100 [1010/1090] acc: 0.7998530321782178
val--89/100 [1020/1090] acc: 0.7999080882352941
val--89/100 [1030/1090] acc: 0.7999355279126213
val--89/100 [1040/1090] acc: 0.7999136117788461
val--89/100 [1050/1090] acc: 0.7999479166666666
val--89/100 [1060/1090] acc: 0.7998931308962264
val--89/100 [1070/1090] acc: 0.799861273364486
val--89/100 [1080/1090] acc: 0.7998010706018519
val--89/100 [1090/1090] acc: 0.7996380447247706
epoch= 89, accuracy= 0.799638, rmse= 0.374517, auc= 0.859468
train--90/100 [9/1090] loss: 0.37629732191562654
train--90/100 [19/1090] loss: 0.4267821341753006
train--90/100 [29/1090] loss: 0.434872105717659
train--90/100 [39/1090] loss: 0.4409323275089264
train--90/100 [49/1090] loss: 0.43770650327205657
train--90/100 [59/1090] loss: 0.41931118071079254
train--90/100 [69/1090] loss: 0.4390069842338562
train--90/100 [79/1090] loss: 0.43576317727565766
train--90/100 [89/1090] loss: 0.4404709845781326
train--90/100 [99/1090] loss: 0.4398983299732208
train--90/100 [109/1090] loss: 0.4288633197546005
train--90/100 [119/1090] loss: 0.4520707666873932
train--90/100 [129/1090] loss: 0.4327754706144333
train--90/100 [139/1090] loss: 0.42323835790157316
train--90/100 [149/1090] loss: 0.4253349781036377
train--90/100 [159/1090] loss: 0.4470847576856613
train--90/100 [169/1090] loss: 0.4460929840803146
train--90/100 [179/1090] loss: 0.4292014122009277
train--90/100 [189/1090] loss: 0.42682943046092986
train--90/100 [199/1090] loss: 0.4504911094903946
train--90/100 [209/1090] loss: 0.4399024248123169
train--90/100 [219/1090] loss: 0.44447074830532074
train--90/100 [229/1090] loss: 0.4635737508535385
train--90/100 [239/1090] loss: 0.42928509414196014
train--90/100 [249/1090] loss: 0.449885767698288
train--90/100 [259/1090] loss: 0.4245400369167328
train--90/100 [269/1090] loss: 0.425292843580246
train--90/100 [279/1090] loss: 0.42568109929561615
train--90/100 [289/1090] loss: 0.4385424017906189
train--90/100 [299/1090] loss: 0.42727226912975313
train--90/100 [309/1090] loss: 0.44393743872642516
train--90/100 [319/1090] loss: 0.4414107143878937
train--90/100 [329/1090] loss: 0.44118653535842894
train--90/100 [339/1090] loss: 0.4426541537046432
train--90/100 [349/1090] loss: 0.4356812298297882
train--90/100 [359/1090] loss: 0.4355123698711395
train--90/100 [369/1090] loss: 0.4221638858318329
train--90/100 [379/1090] loss: 0.44930910766124726
train--90/100 [389/1090] loss: 0.41473830938339235
train--90/100 [399/1090] loss: 0.4420257031917572
train--90/100 [409/1090] loss: 0.4308099687099457
train--90/100 [419/1090] loss: 0.4378264218568802
train--90/100 [429/1090] loss: 0.436835503578186
train--90/100 [439/1090] loss: 0.4219520926475525
train--90/100 [449/1090] loss: 0.4327994793653488
train--90/100 [459/1090] loss: 0.4297104924917221
train--90/100 [469/1090] loss: 0.43264923691749574
train--90/100 [479/1090] loss: 0.43789839148521426
train--90/100 [489/1090] loss: 0.4442636877298355
train--90/100 [499/1090] loss: 0.4406170338392258
train--90/100 [509/1090] loss: 0.4414779722690582
train--90/100 [519/1090] loss: 0.4370079398155212
train--90/100 [529/1090] loss: 0.4272890478372574
train--90/100 [539/1090] loss: 0.4354412168264389
train--90/100 [549/1090] loss: 0.42772662043571474
train--90/100 [559/1090] loss: 0.44465858340263364
train--90/100 [569/1090] loss: 0.4380024492740631
train--90/100 [579/1090] loss: 0.43703250885009765
train--90/100 [589/1090] loss: 0.43218457996845244
train--90/100 [599/1090] loss: 0.4247723311185837
train--90/100 [609/1090] loss: 0.4283000558614731
train--90/100 [619/1090] loss: 0.44144744873046876
train--90/100 [629/1090] loss: 0.42873288989067077
train--90/100 [639/1090] loss: 0.4536911159753799
train--90/100 [649/1090] loss: 0.41931675672531127
train--90/100 [659/1090] loss: 0.43152052760124204
train--90/100 [669/1090] loss: 0.4455099284648895
train--90/100 [679/1090] loss: 0.43221468329429624
train--90/100 [689/1090] loss: 0.4453959494829178
train--90/100 [699/1090] loss: 0.44562975466251376
train--90/100 [709/1090] loss: 0.44229147732257845
train--90/100 [719/1090] loss: 0.4480948507785797
train--90/100 [729/1090] loss: 0.4532642275094986
train--90/100 [739/1090] loss: 0.4407464563846588
train--90/100 [749/1090] loss: 0.44290333390235903
train--90/100 [759/1090] loss: 0.4474238157272339
train--90/100 [769/1090] loss: 0.45117529630661013
train--90/100 [779/1090] loss: 0.453961706161499
train--90/100 [789/1090] loss: 0.42078658044338224
train--90/100 [799/1090] loss: 0.41845848858356477
train--90/100 [809/1090] loss: 0.4434508502483368
train--90/100 [819/1090] loss: 0.4465614020824432
train--90/100 [829/1090] loss: 0.4336388260126114
train--90/100 [839/1090] loss: 0.44421468377113343
train--90/100 [849/1090] loss: 0.4527934342622757
train--90/100 [859/1090] loss: 0.43515745997428895
train--90/100 [869/1090] loss: 0.4329137414693832
train--90/100 [879/1090] loss: 0.45053001642227175
train--90/100 [889/1090] loss: 0.43572593331336973
train--90/100 [899/1090] loss: 0.4536207735538483
train--90/100 [909/1090] loss: 0.4556485563516617
train--90/100 [919/1090] loss: 0.43937618732452394
train--90/100 [929/1090] loss: 0.43868394792079923
train--90/100 [939/1090] loss: 0.43428214490413664
train--90/100 [949/1090] loss: 0.4312897980213165
train--90/100 [959/1090] loss: 0.4364491641521454
train--90/100 [969/1090] loss: 0.44054543375968935
train--90/100 [979/1090] loss: 0.4322565883398056
train--90/100 [989/1090] loss: 0.43156600594520567
train--90/100 [999/1090] loss: 0.46321713626384736
train--90/100 [1009/1090] loss: 0.4396026372909546
train--90/100 [1019/1090] loss: 0.4539241135120392
train--90/100 [1029/1090] loss: 0.43768064975738524
train--90/100 [1039/1090] loss: 0.45092535614967344
train--90/100 [1049/1090] loss: 0.4428229182958603
train--90/100 [1059/1090] loss: 0.43897767961025236
train--90/100 [1069/1090] loss: 0.4390605419874191
train--90/100 [1079/1090] loss: 0.43527487814426424
train--90/100 [1089/1090] loss: 0.4429206222295761
predicting model...
val--90/100 [10/1090] acc: 0.801171875
val--90/100 [20/1090] acc: 0.801171875
val--90/100 [30/1090] acc: 0.8010416666666667
val--90/100 [40/1090] acc: 0.80048828125
val--90/100 [50/1090] acc: 0.79984375
val--90/100 [60/1090] acc: 0.7990234375
val--90/100 [70/1090] acc: 0.7989397321428572
val--90/100 [80/1090] acc: 0.7986328125
val--90/100 [90/1090] acc: 0.7989149305555555
val--90/100 [100/1090] acc: 0.79984375
val--90/100 [110/1090] acc: 0.7998579545454545
val--90/100 [120/1090] acc: 0.7993815104166667
val--90/100 [130/1090] acc: 0.8000901442307692
val--90/100 [140/1090] acc: 0.7999720982142857
val--90/100 [150/1090] acc: 0.7998697916666667
val--90/100 [160/1090] acc: 0.7999267578125
val--90/100 [170/1090] acc: 0.7999310661764706
val--90/100 [180/1090] acc: 0.7995659722222223
val--90/100 [190/1090] acc: 0.8001233552631579
val--90/100 [200/1090] acc: 0.80029296875
val--90/100 [210/1090] acc: 0.8007068452380952
val--90/100 [220/1090] acc: 0.7998757102272728
val--90/100 [230/1090] acc: 0.8004755434782609
val--90/100 [240/1090] acc: 0.8002278645833333
val--90/100 [250/1090] acc: 0.800390625
val--90/100 [260/1090] acc: 0.8003155048076923
val--90/100 [270/1090] acc: 0.8006944444444445
val--90/100 [280/1090] acc: 0.8006277901785714
val--90/100 [290/1090] acc: 0.8005118534482759
val--90/100 [300/1090] acc: 0.8006119791666667
val--90/100 [310/1090] acc: 0.8004284274193548
val--90/100 [320/1090] acc: 0.800537109375
val--90/100 [330/1090] acc: 0.8006628787878788
val--90/100 [340/1090] acc: 0.8006548713235294
val--90/100 [350/1090] acc: 0.8008816964285714
val--90/100 [360/1090] acc: 0.8008029513888889
val--90/100 [370/1090] acc: 0.8008868243243243
val--90/100 [380/1090] acc: 0.8008840460526315
val--90/100 [390/1090] acc: 0.800771233974359
val--90/100 [400/1090] acc: 0.80068359375
val--90/100 [410/1090] acc: 0.8007240853658537
val--90/100 [420/1090] acc: 0.8005673363095238
val--90/100 [430/1090] acc: 0.8003270348837209
val--90/100 [440/1090] acc: 0.8003639914772728
val--90/100 [450/1090] acc: 0.800234375
val--90/100 [460/1090] acc: 0.8000849184782609
val--90/100 [470/1090] acc: 0.7999584441489361
val--90/100 [480/1090] acc: 0.7999593098958333
val--90/100 [490/1090] acc: 0.8000079719387755
val--90/100 [500/1090] acc: 0.8001796875
val--90/100 [510/1090] acc: 0.8000459558823529
val--90/100 [520/1090] acc: 0.80029296875
val--90/100 [530/1090] acc: 0.8001547759433962
val--90/100 [540/1090] acc: 0.8002314814814815
val--90/100 [550/1090] acc: 0.8000142045454546
val--90/100 [560/1090] acc: 0.7998256138392857
val--90/100 [570/1090] acc: 0.7995751096491228
val--90/100 [580/1090] acc: 0.7995689655172413
val--90/100 [590/1090] acc: 0.7994902012711864
val--90/100 [600/1090] acc: 0.7994596354166666
val--90/100 [610/1090] acc: 0.7994236680327869
val--90/100 [620/1090] acc: 0.7993447580645161
val--90/100 [630/1090] acc: 0.7995907738095238
val--90/100 [640/1090] acc: 0.799786376953125
val--90/100 [650/1090] acc: 0.7997776442307692
val--90/100 [660/1090] acc: 0.7996744791666667
val--90/100 [670/1090] acc: 0.7994577891791045
val--90/100 [680/1090] acc: 0.7994025735294118
val--90/100 [690/1090] acc: 0.7995357789855072
val--90/100 [700/1090] acc: 0.7995591517857142
val--90/100 [710/1090] acc: 0.7994663292253521
val--90/100 [720/1090] acc: 0.7993381076388889
val--90/100 [730/1090] acc: 0.7993097174657534
val--90/100 [740/1090] acc: 0.7992662584459459
val--90/100 [750/1090] acc: 0.7992864583333333
val--90/100 [760/1090] acc: 0.7994449013157895
val--90/100 [770/1090] acc: 0.7994165990259741
val--90/100 [780/1090] acc: 0.7993339342948718
val--90/100 [790/1090] acc: 0.7993176424050633
val--90/100 [800/1090] acc: 0.7995263671875
val--90/100 [810/1090] acc: 0.7995804398148149
val--90/100 [820/1090] acc: 0.7996665396341464
val--90/100 [830/1090] acc: 0.7997317394578313
val--90/100 [840/1090] acc: 0.7996744791666667
val--90/100 [850/1090] acc: 0.7996966911764706
val--90/100 [860/1090] acc: 0.7999818313953488
val--90/100 [870/1090] acc: 0.7999551005747126
val--90/100 [880/1090] acc: 0.7999644886363636
val--90/100 [890/1090] acc: 0.8000307233146068
val--90/100 [900/1090] acc: 0.7999869791666666
val--90/100 [910/1090] acc: 0.7999828296703296
val--90/100 [920/1090] acc: 0.8000169836956522
val--90/100 [930/1090] acc: 0.8001092069892473
val--90/100 [940/1090] acc: 0.8000914228723405
val--90/100 [950/1090] acc: 0.8000493421052631
val--90/100 [960/1090] acc: 0.7999755859375
val--90/100 [970/1090] acc: 0.7999033505154639
val--90/100 [980/1090] acc: 0.7999561543367347
val--90/100 [990/1090] acc: 0.7998816287878788
val--90/100 [1000/1090] acc: 0.7997734375
val--90/100 [1010/1090] acc: 0.7995629641089109
val--90/100 [1020/1090] acc: 0.7996017156862745
val--90/100 [1030/1090] acc: 0.7996359223300971
val--90/100 [1040/1090] acc: 0.799639423076923
val--90/100 [1050/1090] acc: 0.7996912202380952
val--90/100 [1060/1090] acc: 0.7996425412735849
val--90/100 [1070/1090] acc: 0.7996203271028037
val--90/100 [1080/1090] acc: 0.799537037037037
val--90/100 [1090/1090] acc: 0.7993836009174312
epoch= 90, accuracy= 0.799384, rmse= 0.374454, auc= 0.859559
train--91/100 [9/1090] loss: 0.40667381286621096
train--91/100 [19/1090] loss: 0.435514235496521
train--91/100 [29/1090] loss: 0.43671694993972776
train--91/100 [39/1090] loss: 0.45192683637142184
train--91/100 [49/1090] loss: 0.44573771953582764
train--91/100 [59/1090] loss: 0.4321190595626831
train--91/100 [69/1090] loss: 0.4187595784664154
train--91/100 [79/1090] loss: 0.44005605280399324
train--91/100 [89/1090] loss: 0.41730589866638185
train--91/100 [99/1090] loss: 0.42496986985206603
train--91/100 [109/1090] loss: 0.4501267492771149
train--91/100 [119/1090] loss: 0.4244892060756683
train--91/100 [129/1090] loss: 0.43480401039123534
train--91/100 [139/1090] loss: 0.44032774269580843
train--91/100 [149/1090] loss: 0.4525092959403992
train--91/100 [159/1090] loss: 0.4054096430540085
train--91/100 [169/1090] loss: 0.4270958036184311
train--91/100 [179/1090] loss: 0.4458968788385391
train--91/100 [189/1090] loss: 0.4240114361047745
train--91/100 [199/1090] loss: 0.4351487159729004
train--91/100 [209/1090] loss: 0.4342097878456116
train--91/100 [219/1090] loss: 0.43800189793109895
train--91/100 [229/1090] loss: 0.43267695009708407
train--91/100 [239/1090] loss: 0.43791861534118653
train--91/100 [249/1090] loss: 0.42959781289100646
train--91/100 [259/1090] loss: 0.42230958938598634
train--91/100 [269/1090] loss: 0.43136697113513944
train--91/100 [279/1090] loss: 0.44684029519557955
train--91/100 [289/1090] loss: 0.43019834756851194
train--91/100 [299/1090] loss: 0.42777052223682405
train--91/100 [309/1090] loss: 0.4499618113040924
train--91/100 [319/1090] loss: 0.44524653255939484
train--91/100 [329/1090] loss: 0.4444436877965927
train--91/100 [339/1090] loss: 0.42641532719135283
train--91/100 [349/1090] loss: 0.4304277926683426
train--91/100 [359/1090] loss: 0.43503878712654115
train--91/100 [369/1090] loss: 0.4384637624025345
train--91/100 [379/1090] loss: 0.4300813615322113
train--91/100 [389/1090] loss: 0.443662616610527
train--91/100 [399/1090] loss: 0.44416342973709105
train--91/100 [409/1090] loss: 0.43507909774780273
train--91/100 [419/1090] loss: 0.45836077332496644
train--91/100 [429/1090] loss: 0.42009626924991605
train--91/100 [439/1090] loss: 0.4379393458366394
train--91/100 [449/1090] loss: 0.43824797570705415
train--91/100 [459/1090] loss: 0.44650947451591494
train--91/100 [469/1090] loss: 0.4363516837358475
train--91/100 [479/1090] loss: 0.4252966731786728
train--91/100 [489/1090] loss: 0.43923073410987856
train--91/100 [499/1090] loss: 0.4233492106199265
train--91/100 [509/1090] loss: 0.4476083964109421
train--91/100 [519/1090] loss: 0.4493849515914917
train--91/100 [529/1090] loss: 0.42633027732372286
train--91/100 [539/1090] loss: 0.43220010697841643
train--91/100 [549/1090] loss: 0.43043599724769593
train--91/100 [559/1090] loss: 0.44881592988967894
train--91/100 [569/1090] loss: 0.43697736263275144
train--91/100 [579/1090] loss: 0.4357862055301666
train--91/100 [589/1090] loss: 0.4322890967130661
train--91/100 [599/1090] loss: 0.4470191955566406
train--91/100 [609/1090] loss: 0.4315316706895828
train--91/100 [619/1090] loss: 0.4534679114818573
train--91/100 [629/1090] loss: 0.42769426107406616
train--91/100 [639/1090] loss: 0.42570641338825227
train--91/100 [649/1090] loss: 0.44749308526515963
train--91/100 [659/1090] loss: 0.4324705958366394
train--91/100 [669/1090] loss: 0.43796862065792086
train--91/100 [679/1090] loss: 0.43690431118011475
train--91/100 [689/1090] loss: 0.45428902506828306
train--91/100 [699/1090] loss: 0.44362870454788206
train--91/100 [709/1090] loss: 0.4461972177028656
train--91/100 [719/1090] loss: 0.44168294966220856
train--91/100 [729/1090] loss: 0.4478295385837555
train--91/100 [739/1090] loss: 0.4518110007047653
train--91/100 [749/1090] loss: 0.4305010259151459
train--91/100 [759/1090] loss: 0.4100528955459595
train--91/100 [769/1090] loss: 0.42477349638938905
train--91/100 [779/1090] loss: 0.4358307719230652
train--91/100 [789/1090] loss: 0.4436184763908386
train--91/100 [799/1090] loss: 0.4409076690673828
train--91/100 [809/1090] loss: 0.429808235168457
train--91/100 [819/1090] loss: 0.44052141308784487
train--91/100 [829/1090] loss: 0.4235150009393692
train--91/100 [839/1090] loss: 0.434126952290535
train--91/100 [849/1090] loss: 0.42335516810417173
train--91/100 [859/1090] loss: 0.4534639179706573
train--91/100 [869/1090] loss: 0.44493597745895386
train--91/100 [879/1090] loss: 0.4460082739591599
train--91/100 [889/1090] loss: 0.4359560012817383
train--91/100 [899/1090] loss: 0.4285999685525894
train--91/100 [909/1090] loss: 0.43711088597774506
train--91/100 [919/1090] loss: 0.43069634437561033
train--91/100 [929/1090] loss: 0.4646764427423477
train--91/100 [939/1090] loss: 0.45228876173496246
train--91/100 [949/1090] loss: 0.44098593592643737
train--91/100 [959/1090] loss: 0.4594521254301071
train--91/100 [969/1090] loss: 0.43339725732803347
train--91/100 [979/1090] loss: 0.4620931565761566
train--91/100 [989/1090] loss: 0.4515213966369629
train--91/100 [999/1090] loss: 0.44794010519981386
train--91/100 [1009/1090] loss: 0.43558065593242645
train--91/100 [1019/1090] loss: 0.4419703662395477
train--91/100 [1029/1090] loss: 0.4372728854417801
train--91/100 [1039/1090] loss: 0.41873163878917696
train--91/100 [1049/1090] loss: 0.43385704755783083
train--91/100 [1059/1090] loss: 0.4483685255050659
train--91/100 [1069/1090] loss: 0.4449827790260315
train--91/100 [1079/1090] loss: 0.4445593923330307
train--91/100 [1089/1090] loss: 0.43313062489032744
predicting model...
val--91/100 [10/1090] acc: 0.8
val--91/100 [20/1090] acc: 0.800390625
val--91/100 [30/1090] acc: 0.7993489583333333
val--91/100 [40/1090] acc: 0.7994140625
val--91/100 [50/1090] acc: 0.798828125
val--91/100 [60/1090] acc: 0.7977213541666667
val--91/100 [70/1090] acc: 0.79765625
val--91/100 [80/1090] acc: 0.797021484375
val--91/100 [90/1090] acc: 0.7975260416666666
val--91/100 [100/1090] acc: 0.79875
val--91/100 [110/1090] acc: 0.7990411931818182
val--91/100 [120/1090] acc: 0.7987955729166667
val--91/100 [130/1090] acc: 0.7993689903846154
val--91/100 [140/1090] acc: 0.7992466517857143
val--91/100 [150/1090] acc: 0.7994270833333333
val--91/100 [160/1090] acc: 0.7995361328125
val--91/100 [170/1090] acc: 0.7994025735294118
val--91/100 [180/1090] acc: 0.7991536458333334
val--91/100 [190/1090] acc: 0.7998355263157895
val--91/100 [200/1090] acc: 0.800078125
val--91/100 [210/1090] acc: 0.8005766369047619
val--91/100 [220/1090] acc: 0.799502840909091
val--91/100 [230/1090] acc: 0.8001188858695653
val--91/100 [240/1090] acc: 0.7999348958333333
val--91/100 [250/1090] acc: 0.8000625
val--91/100 [260/1090] acc: 0.8000600961538461
val--91/100 [270/1090] acc: 0.8004340277777777
val--91/100 [280/1090] acc: 0.8003069196428572
val--91/100 [290/1090] acc: 0.8002155172413793
val--91/100 [300/1090] acc: 0.8003385416666666
val--91/100 [310/1090] acc: 0.8001512096774194
val--91/100 [320/1090] acc: 0.8003662109375
val--91/100 [330/1090] acc: 0.8005445075757576
val--91/100 [340/1090] acc: 0.800631893382353
val--91/100 [350/1090] acc: 0.8009263392857143
val--91/100 [360/1090] acc: 0.8008029513888889
val--91/100 [370/1090] acc: 0.8009079391891892
val--91/100 [380/1090] acc: 0.8009560032894737
val--91/100 [390/1090] acc: 0.8008914262820512
val--91/100 [400/1090] acc: 0.80080078125
val--91/100 [410/1090] acc: 0.8008669969512195
val--91/100 [420/1090] acc: 0.8007347470238095
val--91/100 [430/1090] acc: 0.8004905523255814
val--91/100 [440/1090] acc: 0.8005326704545455
val--91/100 [450/1090] acc: 0.8003732638888889
val--91/100 [460/1090] acc: 0.800186820652174
val--91/100 [470/1090] acc: 0.8000914228723405
val--91/100 [480/1090] acc: 0.8000325520833333
val--91/100 [490/1090] acc: 0.8001036352040817
val--91/100 [500/1090] acc: 0.8001875
val--91/100 [510/1090] acc: 0.8000076593137255
val--91/100 [520/1090] acc: 0.8003230168269231
val--91/100 [530/1090] acc: 0.8002137382075472
val--91/100 [540/1090] acc: 0.8002604166666667
val--91/100 [550/1090] acc: 0.8000994318181818
val--91/100 [560/1090] acc: 0.79990234375
val--91/100 [570/1090] acc: 0.7996230811403509
val--91/100 [580/1090] acc: 0.7995959051724137
val--91/100 [590/1090] acc: 0.7995365466101695
val--91/100 [600/1090] acc: 0.7995442708333333
val--91/100 [610/1090] acc: 0.7995261270491804
val--91/100 [620/1090] acc: 0.799445564516129
val--91/100 [630/1090] acc: 0.7996961805555556
val--91/100 [640/1090] acc: 0.7998779296875
val--91/100 [650/1090] acc: 0.7999098557692308
val--91/100 [660/1090] acc: 0.7998224431818182
val--91/100 [670/1090] acc: 0.7996676772388059
val--91/100 [680/1090] acc: 0.7996036305147058
val--91/100 [690/1090] acc: 0.7997282608695652
val--91/100 [700/1090] acc: 0.799765625
val--91/100 [710/1090] acc: 0.7996698943661972
val--91/100 [720/1090] acc: 0.799560546875
val--91/100 [730/1090] acc: 0.7995130565068493
val--91/100 [740/1090] acc: 0.7994721283783783
val--91/100 [750/1090] acc: 0.7995052083333334
val--91/100 [760/1090] acc: 0.7996916118421052
val--91/100 [770/1090] acc: 0.7996854707792208
val--91/100 [780/1090] acc: 0.799609375
val--91/100 [790/1090] acc: 0.7995895965189873
val--91/100 [800/1090] acc: 0.79982421875
val--91/100 [810/1090] acc: 0.799879436728395
val--91/100 [820/1090] acc: 0.7999809451219512
val--91/100 [830/1090] acc: 0.800047063253012
val--91/100 [840/1090] acc: 0.8000279017857143
val--91/100 [850/1090] acc: 0.8000229779411765
val--91/100 [860/1090] acc: 0.8003406613372093
val--91/100 [870/1090] acc: 0.8002873563218391
val--91/100 [880/1090] acc: 0.8003196022727272
val--91/100 [890/1090] acc: 0.8003862359550562
val--91/100 [900/1090] acc: 0.8003342013888889
val--91/100 [910/1090] acc: 0.8003219436813187
val--91/100 [920/1090] acc: 0.8003311820652174
val--91/100 [930/1090] acc: 0.800390625
val--91/100 [940/1090] acc: 0.8003864694148937
val--91/100 [950/1090] acc: 0.8003412828947368
val--91/100 [960/1090] acc: 0.80028076171875
val--91/100 [970/1090] acc: 0.8002134342783506
val--91/100 [980/1090] acc: 0.8002590880102041
val--91/100 [990/1090] acc: 0.8001538825757576
val--91/100 [1000/1090] acc: 0.8000546875
val--91/100 [1010/1090] acc: 0.7998143564356436
val--91/100 [1020/1090] acc: 0.7998621323529411
val--91/100 [1030/1090] acc: 0.7998938106796116
val--91/100 [1040/1090] acc: 0.7998873197115385
val--91/100 [1050/1090] acc: 0.7999144345238095
val--91/100 [1060/1090] acc: 0.7998415389150944
val--91/100 [1070/1090] acc: 0.7998393691588785
val--91/100 [1080/1090] acc: 0.7997504340277778
val--91/100 [1090/1090] acc: 0.7995341169724771
epoch= 91, accuracy= 0.799534, rmse= 0.374305, auc= 0.859881
train--92/100 [9/1090] loss: 0.38930279910564425
train--92/100 [19/1090] loss: 0.4170460969209671
train--92/100 [29/1090] loss: 0.4403431206941605
train--92/100 [39/1090] loss: 0.4339140057563782
train--92/100 [49/1090] loss: 0.44944964051246644
train--92/100 [59/1090] loss: 0.42606947422027586
train--92/100 [69/1090] loss: 0.4420425623655319
train--92/100 [79/1090] loss: 0.4318904012441635
train--92/100 [89/1090] loss: 0.4139715313911438
train--92/100 [99/1090] loss: 0.4300185739994049
train--92/100 [109/1090] loss: 0.43611817359924315
train--92/100 [119/1090] loss: 0.4306384682655334
train--92/100 [129/1090] loss: 0.4394274979829788
train--92/100 [139/1090] loss: 0.4571326792240143
train--92/100 [149/1090] loss: 0.42016456723213197
train--92/100 [159/1090] loss: 0.4435275882482529
train--92/100 [169/1090] loss: 0.4205447226762772
train--92/100 [179/1090] loss: 0.4470202594995499
train--92/100 [189/1090] loss: 0.4242668181657791
train--92/100 [199/1090] loss: 0.4387888967990875
train--92/100 [209/1090] loss: 0.43921172320842744
train--92/100 [219/1090] loss: 0.4170834571123123
train--92/100 [229/1090] loss: 0.4426721304655075
train--92/100 [239/1090] loss: 0.4408237874507904
train--92/100 [249/1090] loss: 0.4301911771297455
train--92/100 [259/1090] loss: 0.4506569683551788
train--92/100 [269/1090] loss: 0.4469021201133728
train--92/100 [279/1090] loss: 0.4332230716943741
train--92/100 [289/1090] loss: 0.443423455953598
train--92/100 [299/1090] loss: 0.4346386671066284
train--92/100 [309/1090] loss: 0.4456625938415527
train--92/100 [319/1090] loss: 0.4392396450042725
train--92/100 [329/1090] loss: 0.44497263729572295
train--92/100 [339/1090] loss: 0.4241238206624985
train--92/100 [349/1090] loss: 0.42435496747493745
train--92/100 [359/1090] loss: 0.44812099635601044
train--92/100 [369/1090] loss: 0.4291109383106232
train--92/100 [379/1090] loss: 0.4505187451839447
train--92/100 [389/1090] loss: 0.4419449597597122
train--92/100 [399/1090] loss: 0.43552625477313994
train--92/100 [409/1090] loss: 0.44021540582180024
train--92/100 [419/1090] loss: 0.4526395440101624
train--92/100 [429/1090] loss: 0.4267443656921387
train--92/100 [439/1090] loss: 0.4407759815454483
train--92/100 [449/1090] loss: 0.42175074219703673
train--92/100 [459/1090] loss: 0.43431863486766814
train--92/100 [469/1090] loss: 0.4361762791872025
train--92/100 [479/1090] loss: 0.4477163851261139
train--92/100 [489/1090] loss: 0.4288295179605484
train--92/100 [499/1090] loss: 0.4248509407043457
train--92/100 [509/1090] loss: 0.43796929717063904
train--92/100 [519/1090] loss: 0.4314845234155655
train--92/100 [529/1090] loss: 0.4475269436836243
train--92/100 [539/1090] loss: 0.4358028769493103
train--92/100 [549/1090] loss: 0.4228083252906799
train--92/100 [559/1090] loss: 0.4387688547372818
train--92/100 [569/1090] loss: 0.4478117823600769
train--92/100 [579/1090] loss: 0.41940546631813047
train--92/100 [589/1090] loss: 0.42865523099899294
train--92/100 [599/1090] loss: 0.44364105463027953
train--92/100 [609/1090] loss: 0.4573203593492508
train--92/100 [619/1090] loss: 0.42440093755722047
train--92/100 [629/1090] loss: 0.44071345031261444
train--92/100 [639/1090] loss: 0.43766216933727264
train--92/100 [649/1090] loss: 0.43485731780529024
train--92/100 [659/1090] loss: 0.43635239005088805
train--92/100 [669/1090] loss: 0.4268764525651932
train--92/100 [679/1090] loss: 0.4248682349920273
train--92/100 [689/1090] loss: 0.4295939326286316
train--92/100 [699/1090] loss: 0.4531834989786148
train--92/100 [709/1090] loss: 0.45548832416534424
train--92/100 [719/1090] loss: 0.4317134618759155
train--92/100 [729/1090] loss: 0.44353594183921813
train--92/100 [739/1090] loss: 0.440750715136528
train--92/100 [749/1090] loss: 0.43996487855911254
train--92/100 [759/1090] loss: 0.43925916254520414
train--92/100 [769/1090] loss: 0.4456086665391922
train--92/100 [779/1090] loss: 0.4283077508211136
train--92/100 [789/1090] loss: 0.44619462490081785
train--92/100 [799/1090] loss: 0.4312148720026016
train--92/100 [809/1090] loss: 0.44939929246902466
train--92/100 [819/1090] loss: 0.4175766885280609
train--92/100 [829/1090] loss: 0.42646060287952425
train--92/100 [839/1090] loss: 0.4376227080821991
train--92/100 [849/1090] loss: 0.43468900918960574
train--92/100 [859/1090] loss: 0.44554904103279114
train--92/100 [869/1090] loss: 0.45623086392879486
train--92/100 [879/1090] loss: 0.4344862014055252
train--92/100 [889/1090] loss: 0.42861447036266326
train--92/100 [899/1090] loss: 0.44339091777801515
train--92/100 [909/1090] loss: 0.44411667585372927
train--92/100 [919/1090] loss: 0.43431028723716736
train--92/100 [929/1090] loss: 0.4604534447193146
train--92/100 [939/1090] loss: 0.4629614293575287
train--92/100 [949/1090] loss: 0.4516922175884247
train--92/100 [959/1090] loss: 0.42912248969078065
train--92/100 [969/1090] loss: 0.43348395824432373
train--92/100 [979/1090] loss: 0.4424446702003479
train--92/100 [989/1090] loss: 0.4370617181062698
train--92/100 [999/1090] loss: 0.43607173264026644
train--92/100 [1009/1090] loss: 0.4289586186408997
train--92/100 [1019/1090] loss: 0.45147235691547394
train--92/100 [1029/1090] loss: 0.4325339287519455
train--92/100 [1039/1090] loss: 0.45352294147014616
train--92/100 [1049/1090] loss: 0.42940551340579985
train--92/100 [1059/1090] loss: 0.46196897625923156
train--92/100 [1069/1090] loss: 0.4362467646598816
train--92/100 [1079/1090] loss: 0.44035516381263734
train--92/100 [1089/1090] loss: 0.4356068193912506
predicting model...
val--92/100 [10/1090] acc: 0.8
val--92/100 [20/1090] acc: 0.8001953125
val--92/100 [30/1090] acc: 0.7994791666666666
val--92/100 [40/1090] acc: 0.79921875
val--92/100 [50/1090] acc: 0.798671875
val--92/100 [60/1090] acc: 0.7977213541666667
val--92/100 [70/1090] acc: 0.7981026785714286
val--92/100 [80/1090] acc: 0.79765625
val--92/100 [90/1090] acc: 0.7979600694444444
val--92/100 [100/1090] acc: 0.7991796875
val--92/100 [110/1090] acc: 0.7992542613636363
val--92/100 [120/1090] acc: 0.7987630208333333
val--92/100 [130/1090] acc: 0.7994591346153846
val--92/100 [140/1090] acc: 0.7994140625
val--92/100 [150/1090] acc: 0.7993489583333333
val--92/100 [160/1090] acc: 0.7994384765625
val--92/100 [170/1090] acc: 0.7993795955882353
val--92/100 [180/1090] acc: 0.7992621527777778
val--92/100 [190/1090] acc: 0.7999383223684211
val--92/100 [200/1090] acc: 0.800234375
val--92/100 [210/1090] acc: 0.8004650297619048
val--92/100 [220/1090] acc: 0.7997159090909091
val--92/100 [230/1090] acc: 0.8003226902173913
val--92/100 [240/1090] acc: 0.7999674479166666
val--92/100 [250/1090] acc: 0.800171875
val--92/100 [260/1090] acc: 0.8001652644230769
val--92/100 [270/1090] acc: 0.8004629629629629
val--92/100 [280/1090] acc: 0.800390625
val--92/100 [290/1090] acc: 0.8003636853448276
val--92/100 [300/1090] acc: 0.8005598958333333
val--92/100 [310/1090] acc: 0.8003528225806451
val--92/100 [320/1090] acc: 0.8005615234375
val--92/100 [330/1090] acc: 0.8007694128787879
val--92/100 [340/1090] acc: 0.80078125
val--92/100 [350/1090] acc: 0.8010267857142858
val--92/100 [360/1090] acc: 0.8009765625
val--92/100 [370/1090] acc: 0.8010663006756756
val--92/100 [380/1090] acc: 0.8010690789473685
val--92/100 [390/1090] acc: 0.8009214743589743
val--92/100 [400/1090] acc: 0.8008984375
val--92/100 [410/1090] acc: 0.800952743902439
val--92/100 [420/1090] acc: 0.8008742559523809
val--92/100 [430/1090] acc: 0.8005995639534884
val--92/100 [440/1090] acc: 0.80068359375
val--92/100 [450/1090] acc: 0.800546875
val--92/100 [460/1090] acc: 0.8003821331521739
val--92/100 [470/1090] acc: 0.8002908909574468
val--92/100 [480/1090] acc: 0.8003011067708333
val--92/100 [490/1090] acc: 0.8002949617346938
val--92/100 [500/1090] acc: 0.8004765625
val--92/100 [510/1090] acc: 0.800329350490196
val--92/100 [520/1090] acc: 0.8005784254807692
val--92/100 [530/1090] acc: 0.8004938089622642
val--92/100 [540/1090] acc: 0.800535300925926
val--92/100 [550/1090] acc: 0.800340909090909
val--92/100 [560/1090] acc: 0.8001883370535714
val--92/100 [570/1090] acc: 0.7999177631578948
val--92/100 [580/1090] acc: 0.7998989762931035
val--92/100 [590/1090] acc: 0.7998808262711864
val--92/100 [600/1090] acc: 0.79982421875
val--92/100 [610/1090] acc: 0.7998142930327868
val--92/100 [620/1090] acc: 0.7997416834677419
val--92/100 [630/1090] acc: 0.7999751984126984
val--92/100 [640/1090] acc: 0.800177001953125
val--92/100 [650/1090] acc: 0.8001682692307692
val--92/100 [660/1090] acc: 0.8000473484848485
val--92/100 [670/1090] acc: 0.7998425839552239
val--92/100 [680/1090] acc: 0.7997414981617647
val--92/100 [690/1090] acc: 0.7998754528985508
val--92/100 [700/1090] acc: 0.7999274553571428
val--92/100 [710/1090] acc: 0.7998294454225352
val--92/100 [720/1090] acc: 0.7997178819444445
val--92/100 [730/1090] acc: 0.7996682363013699
val--92/100 [740/1090] acc: 0.7996040962837838
val--92/100 [750/1090] acc: 0.7996458333333333
val--92/100 [760/1090] acc: 0.7998098273026316
val--92/100 [770/1090] acc: 0.7997970779220779
val--92/100 [780/1090] acc: 0.7996594551282051
val--92/100 [790/1090] acc: 0.799668710443038
val--92/100 [800/1090] acc: 0.7998876953125
val--92/100 [810/1090] acc: 0.7999228395061728
val--92/100 [820/1090] acc: 0.7999904725609757
val--92/100 [830/1090] acc: 0.8000564759036145
val--92/100 [840/1090] acc: 0.8000232514880953
val--92/100 [850/1090] acc: 0.8000459558823529
val--92/100 [860/1090] acc: 0.8003088662790697
val--92/100 [870/1090] acc: 0.800305316091954
val--92/100 [880/1090] acc: 0.8003284801136363
val--92/100 [890/1090] acc: 0.8003730688202247
val--92/100 [900/1090] acc: 0.8003168402777778
val--92/100 [910/1090] acc: 0.8003476991758242
val--92/100 [920/1090] acc: 0.8003821331521739
val--92/100 [930/1090] acc: 0.8004872311827957
val--92/100 [940/1090] acc: 0.8004778922872341
val--92/100 [950/1090] acc: 0.8004481907894737
val--92/100 [960/1090] acc: 0.8003946940104166
val--92/100 [970/1090] acc: 0.8003060567010309
val--92/100 [980/1090] acc: 0.8003667091836735
val--92/100 [990/1090] acc: 0.8002643623737373
val--92/100 [1000/1090] acc: 0.8001796875
val--92/100 [1010/1090] acc: 0.7999767945544555
val--92/100 [1020/1090] acc: 0.8000114889705883
val--92/100 [1030/1090] acc: 0.8000530946601941
val--92/100 [1040/1090] acc: 0.8000375600961539
val--92/100 [1050/1090] acc: 0.8000892857142857
val--92/100 [1060/1090] acc: 0.8000552771226415
val--92/100 [1070/1090] acc: 0.8000109521028037
val--92/100 [1080/1090] acc: 0.7999457465277777
val--92/100 [1090/1090] acc: 0.7997921444954128
epoch= 92, accuracy= 0.799792, rmse= 0.374239, auc= 0.859912
train--93/100 [9/1090] loss: 0.3783484220504761
train--93/100 [19/1090] loss: 0.43593759536743165
train--93/100 [29/1090] loss: 0.42835632860660555
train--93/100 [39/1090] loss: 0.4303069621324539
train--93/100 [49/1090] loss: 0.43121638596057893
train--93/100 [59/1090] loss: 0.43136061131954195
train--93/100 [69/1090] loss: 0.43171961307525636
train--93/100 [79/1090] loss: 0.45004274845123293
train--93/100 [89/1090] loss: 0.4318070948123932
train--93/100 [99/1090] loss: 0.4476634293794632
train--93/100 [109/1090] loss: 0.4207776576280594
train--93/100 [119/1090] loss: 0.4311030685901642
train--93/100 [129/1090] loss: 0.447063347697258
train--93/100 [139/1090] loss: 0.44672712683677673
train--93/100 [149/1090] loss: 0.439192533493042
train--93/100 [159/1090] loss: 0.42429176568984983
train--93/100 [169/1090] loss: 0.4406558036804199
train--93/100 [179/1090] loss: 0.44076012074947357
train--93/100 [189/1090] loss: 0.4239284127950668
train--93/100 [199/1090] loss: 0.4420358449220657
train--93/100 [209/1090] loss: 0.442160439491272
train--93/100 [219/1090] loss: 0.42786434292793274
train--93/100 [229/1090] loss: 0.4323593467473984
train--93/100 [239/1090] loss: 0.41997015178203584
train--93/100 [249/1090] loss: 0.4468887895345688
train--93/100 [259/1090] loss: 0.4274598956108093
train--93/100 [269/1090] loss: 0.4399372637271881
train--93/100 [279/1090] loss: 0.4471613526344299
train--93/100 [289/1090] loss: 0.42453160881996155
train--93/100 [299/1090] loss: 0.4156074732542038
train--93/100 [309/1090] loss: 0.4314385265111923
train--93/100 [319/1090] loss: 0.44627341330051423
train--93/100 [329/1090] loss: 0.4439221233129501
train--93/100 [339/1090] loss: 0.4427565008401871
train--93/100 [349/1090] loss: 0.4351244330406189
train--93/100 [359/1090] loss: 0.4339138090610504
train--93/100 [369/1090] loss: 0.4256309539079666
train--93/100 [379/1090] loss: 0.44745653569698335
train--93/100 [389/1090] loss: 0.4443759024143219
train--93/100 [399/1090] loss: 0.4409696817398071
train--93/100 [409/1090] loss: 0.4569518446922302
train--93/100 [419/1090] loss: 0.4249342858791351
train--93/100 [429/1090] loss: 0.4466574162244797
train--93/100 [439/1090] loss: 0.4471648931503296
train--93/100 [449/1090] loss: 0.43858487606048585
train--93/100 [459/1090] loss: 0.4424942433834076
train--93/100 [469/1090] loss: 0.43277435600757597
train--93/100 [479/1090] loss: 0.4204777330160141
train--93/100 [489/1090] loss: 0.4410599708557129
train--93/100 [499/1090] loss: 0.435945001244545
train--93/100 [509/1090] loss: 0.43299196362495423
train--93/100 [519/1090] loss: 0.4420549005270004
train--93/100 [529/1090] loss: 0.4282649427652359
train--93/100 [539/1090] loss: 0.42649114429950713
train--93/100 [549/1090] loss: 0.4334872990846634
train--93/100 [559/1090] loss: 0.4168954610824585
train--93/100 [569/1090] loss: 0.4177322745323181
train--93/100 [579/1090] loss: 0.46448435485363004
train--93/100 [589/1090] loss: 0.44106360375881193
train--93/100 [599/1090] loss: 0.4448836505413055
train--93/100 [609/1090] loss: 0.42107981741428374
train--93/100 [619/1090] loss: 0.4546851873397827
train--93/100 [629/1090] loss: 0.45574104487895967
train--93/100 [639/1090] loss: 0.4232997387647629
train--93/100 [649/1090] loss: 0.4306395471096039
train--93/100 [659/1090] loss: 0.437432861328125
train--93/100 [669/1090] loss: 0.4405742257833481
train--93/100 [679/1090] loss: 0.418808376789093
train--93/100 [689/1090] loss: 0.43702338337898256
train--93/100 [699/1090] loss: 0.42502757012844083
train--93/100 [709/1090] loss: 0.4359938472509384
train--93/100 [719/1090] loss: 0.44683343470096587
train--93/100 [729/1090] loss: 0.4470706969499588
train--93/100 [739/1090] loss: 0.45581544041633604
train--93/100 [749/1090] loss: 0.42990520894527434
train--93/100 [759/1090] loss: 0.44333224594593046
train--93/100 [769/1090] loss: 0.42813022136688234
train--93/100 [779/1090] loss: 0.4317561209201813
train--93/100 [789/1090] loss: 0.45937575995922086
train--93/100 [799/1090] loss: 0.4264323264360428
train--93/100 [809/1090] loss: 0.45931788086891173
train--93/100 [819/1090] loss: 0.43462174832820893
train--93/100 [829/1090] loss: 0.4710680156946182
train--93/100 [839/1090] loss: 0.45195320844650266
train--93/100 [849/1090] loss: 0.4296898186206818
train--93/100 [859/1090] loss: 0.4438632637262344
train--93/100 [869/1090] loss: 0.45088464915752413
train--93/100 [879/1090] loss: 0.435693821310997
train--93/100 [889/1090] loss: 0.436950808763504
train--93/100 [899/1090] loss: 0.4316299229860306
train--93/100 [909/1090] loss: 0.4291724503040314
train--93/100 [919/1090] loss: 0.44428770542144774
train--93/100 [929/1090] loss: 0.43643165230751035
train--93/100 [939/1090] loss: 0.43555839359760284
train--93/100 [949/1090] loss: 0.43545181453228
train--93/100 [959/1090] loss: 0.4431187570095062
train--93/100 [969/1090] loss: 0.4338500082492828
train--93/100 [979/1090] loss: 0.4411453455686569
train--93/100 [989/1090] loss: 0.45061700642108915
train--93/100 [999/1090] loss: 0.4305149167776108
train--93/100 [1009/1090] loss: 0.4422190487384796
train--93/100 [1019/1090] loss: 0.4301493614912033
train--93/100 [1029/1090] loss: 0.4322705835103989
train--93/100 [1039/1090] loss: 0.43671264946460725
train--93/100 [1049/1090] loss: 0.4408883273601532
train--93/100 [1059/1090] loss: 0.42544789910316466
train--93/100 [1069/1090] loss: 0.45042848587036133
train--93/100 [1079/1090] loss: 0.44108458459377287
train--93/100 [1089/1090] loss: 0.4402616411447525
predicting model...
val--93/100 [10/1090] acc: 0.80078125
val--93/100 [20/1090] acc: 0.8005859375
val--93/100 [30/1090] acc: 0.80078125
val--93/100 [40/1090] acc: 0.80048828125
val--93/100 [50/1090] acc: 0.79953125
val--93/100 [60/1090] acc: 0.7985026041666666
val--93/100 [70/1090] acc: 0.7983258928571428
val--93/100 [80/1090] acc: 0.79755859375
val--93/100 [90/1090] acc: 0.7980034722222222
val--93/100 [100/1090] acc: 0.7990625
val--93/100 [110/1090] acc: 0.7993607954545454
val--93/100 [120/1090] acc: 0.79892578125
val--93/100 [130/1090] acc: 0.7998798076923077
val--93/100 [140/1090] acc: 0.7997209821428571
val--93/100 [150/1090] acc: 0.79984375
val--93/100 [160/1090] acc: 0.8000244140625
val--93/100 [170/1090] acc: 0.7999080882352941
val--93/100 [180/1090] acc: 0.7996527777777778
val--93/100 [190/1090] acc: 0.8003083881578947
val--93/100 [200/1090] acc: 0.800625
val--93/100 [210/1090] acc: 0.8010602678571429
val--93/100 [220/1090] acc: 0.8002308238636363
val--93/100 [230/1090] acc: 0.8008152173913043
val--93/100 [240/1090] acc: 0.800537109375
val--93/100 [250/1090] acc: 0.8006875
val--93/100 [260/1090] acc: 0.8006911057692307
val--93/100 [270/1090] acc: 0.8010416666666667
val--93/100 [280/1090] acc: 0.80087890625
val--93/100 [290/1090] acc: 0.8007408405172414
val--93/100 [300/1090] acc: 0.8008072916666666
val--93/100 [310/1090] acc: 0.8005922379032258
val--93/100 [320/1090] acc: 0.80072021484375
val--93/100 [330/1090] acc: 0.8008167613636363
val--93/100 [340/1090] acc: 0.8008501838235295
val--93/100 [350/1090] acc: 0.8011049107142857
val--93/100 [360/1090] acc: 0.8010199652777777
val--93/100 [370/1090] acc: 0.8011613175675676
val--93/100 [380/1090] acc: 0.8012335526315789
val--93/100 [390/1090] acc: 0.8011017628205128
val--93/100 [400/1090] acc: 0.801044921875
val--93/100 [410/1090] acc: 0.8011147103658537
val--93/100 [420/1090] acc: 0.801078869047619
val--93/100 [430/1090] acc: 0.8007539970930233
val--93/100 [440/1090] acc: 0.8008078835227272
val--93/100 [450/1090] acc: 0.8006597222222223
val--93/100 [460/1090] acc: 0.8004500679347826
val--93/100 [470/1090] acc: 0.8004072473404256
val--93/100 [480/1090] acc: 0.8003336588541666
val--93/100 [490/1090] acc: 0.8003507653061225
val--93/100 [500/1090] acc: 0.80040625
val--93/100 [510/1090] acc: 0.8002604166666667
val--93/100 [520/1090] acc: 0.8005634014423076
val--93/100 [530/1090] acc: 0.8004716981132075
val--93/100 [540/1090] acc: 0.8005208333333333
val--93/100 [550/1090] acc: 0.8003551136363637
val--93/100 [560/1090] acc: 0.8001534598214286
val--93/100 [570/1090] acc: 0.7998972039473684
val--93/100 [580/1090] acc: 0.7998787715517242
val--93/100 [590/1090] acc: 0.7998344809322034
val--93/100 [600/1090] acc: 0.7997981770833333
val--93/100 [610/1090] acc: 0.7997374487704918
val--93/100 [620/1090] acc: 0.7996723790322581
val--93/100 [630/1090] acc: 0.799906994047619
val--93/100 [640/1090] acc: 0.80010986328125
val--93/100 [650/1090] acc: 0.8001081730769231
val--93/100 [660/1090] acc: 0.8000236742424243
val--93/100 [670/1090] acc: 0.7998309235074627
val--93/100 [680/1090] acc: 0.7997587316176471
val--93/100 [690/1090] acc: 0.7998697916666667
val--93/100 [700/1090] acc: 0.7998828125
val--93/100 [710/1090] acc: 0.7997634242957746
val--93/100 [720/1090] acc: 0.7996907552083333
val--93/100 [730/1090] acc: 0.7996735873287671
val--93/100 [740/1090] acc: 0.7996199324324325
val--93/100 [750/1090] acc: 0.799609375
val--93/100 [760/1090] acc: 0.7997687088815789
val--93/100 [770/1090] acc: 0.799705762987013
val--93/100 [780/1090] acc: 0.7996644631410257
val--93/100 [790/1090] acc: 0.7996538765822785
val--93/100 [800/1090] acc: 0.799873046875
val--93/100 [810/1090] acc: 0.799927662037037
val--93/100 [820/1090] acc: 0.800023818597561
val--93/100 [830/1090] acc: 0.8000847138554217
val--93/100 [840/1090] acc: 0.8000651041666667
val--93/100 [850/1090] acc: 0.8000827205882353
val--93/100 [860/1090] acc: 0.8003724563953488
val--93/100 [870/1090] acc: 0.8003502155172414
val--93/100 [880/1090] acc: 0.800350674715909
val--93/100 [890/1090] acc: 0.8004301264044944
val--93/100 [900/1090] acc: 0.8003949652777778
val--93/100 [910/1090] acc: 0.800412087912088
val--93/100 [920/1090] acc: 0.8004288383152174
val--93/100 [930/1090] acc: 0.8005082325268817
val--93/100 [940/1090] acc: 0.8005277593085106
val--93/100 [950/1090] acc: 0.8004646381578947
val--93/100 [960/1090] acc: 0.8003865559895833
val--93/100 [970/1090] acc: 0.8003261920103093
val--93/100 [980/1090] acc: 0.8003587372448979
val--93/100 [990/1090] acc: 0.8002367424242425
val--93/100 [1000/1090] acc: 0.80012890625
val--93/100 [1010/1090] acc: 0.7999187809405941
val--93/100 [1020/1090] acc: 0.7999348958333333
val--93/100 [1030/1090] acc: 0.7999582827669903
val--93/100 [1040/1090] acc: 0.7999399038461539
val--93/100 [1050/1090] acc: 0.7999590773809524
val--93/100 [1060/1090] acc: 0.7999115566037736
val--93/100 [1070/1090] acc: 0.7998904789719626
val--93/100 [1080/1090] acc: 0.7998263888888889
val--93/100 [1090/1090] acc: 0.7996452121559633
epoch= 93, accuracy= 0.799645, rmse= 0.374167, auc= 0.860047
train--94/100 [9/1090] loss: 0.39155380725860595
train--94/100 [19/1090] loss: 0.4509005665779114
train--94/100 [29/1090] loss: 0.4219857454299927
train--94/100 [39/1090] loss: 0.4455475777387619
train--94/100 [49/1090] loss: 0.43165493607521055
train--94/100 [59/1090] loss: 0.42191818356513977
train--94/100 [69/1090] loss: 0.44238088428974154
train--94/100 [79/1090] loss: 0.43902621865272523
train--94/100 [89/1090] loss: 0.4315172404050827
train--94/100 [99/1090] loss: 0.42015173137187956
train--94/100 [109/1090] loss: 0.43351619243621825
train--94/100 [119/1090] loss: 0.4454023718833923
train--94/100 [129/1090] loss: 0.42479260861873624
train--94/100 [139/1090] loss: 0.4285065233707428
train--94/100 [149/1090] loss: 0.4229623287916183
train--94/100 [159/1090] loss: 0.4422649145126343
train--94/100 [169/1090] loss: 0.4350446105003357
train--94/100 [179/1090] loss: 0.43477158844470976
train--94/100 [189/1090] loss: 0.44742874801158905
train--94/100 [199/1090] loss: 0.44323804080486295
train--94/100 [209/1090] loss: 0.4357555240392685
train--94/100 [219/1090] loss: 0.4409761518239975
train--94/100 [229/1090] loss: 0.4430972695350647
train--94/100 [239/1090] loss: 0.4325748562812805
train--94/100 [249/1090] loss: 0.40661404430866244
train--94/100 [259/1090] loss: 0.43664673566818235
train--94/100 [269/1090] loss: 0.43073606491088867
train--94/100 [279/1090] loss: 0.42424900233745577
train--94/100 [289/1090] loss: 0.4424085706472397
train--94/100 [299/1090] loss: 0.4272647529840469
train--94/100 [309/1090] loss: 0.43565091788768767
train--94/100 [319/1090] loss: 0.4519199311733246
train--94/100 [329/1090] loss: 0.4315746247768402
train--94/100 [339/1090] loss: 0.43801717460155487
train--94/100 [349/1090] loss: 0.4532638967037201
train--94/100 [359/1090] loss: 0.43169060349464417
train--94/100 [369/1090] loss: 0.45080493986606596
train--94/100 [379/1090] loss: 0.42024011015892027
train--94/100 [389/1090] loss: 0.425059512257576
train--94/100 [399/1090] loss: 0.4382754236459732
train--94/100 [409/1090] loss: 0.42662830650806427
train--94/100 [419/1090] loss: 0.423540985584259
train--94/100 [429/1090] loss: 0.45651566088199613
train--94/100 [439/1090] loss: 0.4326948344707489
train--94/100 [449/1090] loss: 0.42803901731967925
train--94/100 [459/1090] loss: 0.43028082847595217
train--94/100 [469/1090] loss: 0.43005599081516266
train--94/100 [479/1090] loss: 0.4332402676343918
train--94/100 [489/1090] loss: 0.4500743091106415
train--94/100 [499/1090] loss: 0.4183970332145691
train--94/100 [509/1090] loss: 0.45058860182762145
train--94/100 [519/1090] loss: 0.4257207751274109
train--94/100 [529/1090] loss: 0.44409737884998324
train--94/100 [539/1090] loss: 0.4238949120044708
train--94/100 [549/1090] loss: 0.44361218214035036
train--94/100 [559/1090] loss: 0.42849952578544614
train--94/100 [569/1090] loss: 0.4170410543680191
train--94/100 [579/1090] loss: 0.4242774248123169
train--94/100 [589/1090] loss: 0.43723114430904386
train--94/100 [599/1090] loss: 0.4456660062074661
train--94/100 [609/1090] loss: 0.455180236697197
train--94/100 [619/1090] loss: 0.44764209985733033
train--94/100 [629/1090] loss: 0.44829905927181246
train--94/100 [639/1090] loss: 0.44170127213001253
train--94/100 [649/1090] loss: 0.4362635761499405
train--94/100 [659/1090] loss: 0.4466113358736038
train--94/100 [669/1090] loss: 0.4581836462020874
train--94/100 [679/1090] loss: 0.44703662395477295
train--94/100 [689/1090] loss: 0.428077757358551
train--94/100 [699/1090] loss: 0.4285936146974564
train--94/100 [709/1090] loss: 0.4661475867033005
train--94/100 [719/1090] loss: 0.4309255540370941
train--94/100 [729/1090] loss: 0.4397554486989975
train--94/100 [739/1090] loss: 0.4297321617603302
train--94/100 [749/1090] loss: 0.4278118371963501
train--94/100 [759/1090] loss: 0.4293365955352783
train--94/100 [769/1090] loss: 0.46474118530750275
train--94/100 [779/1090] loss: 0.4624524712562561
train--94/100 [789/1090] loss: 0.4266152173280716
train--94/100 [799/1090] loss: 0.4279993176460266
train--94/100 [809/1090] loss: 0.42302030324935913
train--94/100 [819/1090] loss: 0.4404605746269226
train--94/100 [829/1090] loss: 0.43677972853183744
train--94/100 [839/1090] loss: 0.435381743311882
train--94/100 [849/1090] loss: 0.43298227787017823
train--94/100 [859/1090] loss: 0.42732425034046173
train--94/100 [869/1090] loss: 0.4271432012319565
train--94/100 [879/1090] loss: 0.4456122875213623
train--94/100 [889/1090] loss: 0.4455172002315521
train--94/100 [899/1090] loss: 0.4276438981294632
train--94/100 [909/1090] loss: 0.4338759571313858
train--94/100 [919/1090] loss: 0.4556955277919769
train--94/100 [929/1090] loss: 0.42832415997982026
train--94/100 [939/1090] loss: 0.43058216869831084
train--94/100 [949/1090] loss: 0.45025759041309354
train--94/100 [959/1090] loss: 0.45838603079319
train--94/100 [969/1090] loss: 0.4448795229196548
train--94/100 [979/1090] loss: 0.4524572521448135
train--94/100 [989/1090] loss: 0.43072130382061
train--94/100 [999/1090] loss: 0.45221844911575315
train--94/100 [1009/1090] loss: 0.4316567987203598
train--94/100 [1019/1090] loss: 0.4364788830280304
train--94/100 [1029/1090] loss: 0.43479483127593993
train--94/100 [1039/1090] loss: 0.4281190186738968
train--94/100 [1049/1090] loss: 0.44109855890274047
train--94/100 [1059/1090] loss: 0.45111546814441683
train--94/100 [1069/1090] loss: 0.44387194216251374
train--94/100 [1079/1090] loss: 0.43370680809020995
train--94/100 [1089/1090] loss: 0.4483355849981308
predicting model...
val--94/100 [10/1090] acc: 0.80234375
val--94/100 [20/1090] acc: 0.801953125
val--94/100 [30/1090] acc: 0.801171875
val--94/100 [40/1090] acc: 0.80078125
val--94/100 [50/1090] acc: 0.80015625
val--94/100 [60/1090] acc: 0.7990885416666667
val--94/100 [70/1090] acc: 0.7991629464285714
val--94/100 [80/1090] acc: 0.79833984375
val--94/100 [90/1090] acc: 0.7986545138888889
val--94/100 [100/1090] acc: 0.7997265625
val--94/100 [110/1090] acc: 0.7995383522727273
val--94/100 [120/1090] acc: 0.79912109375
val--94/100 [130/1090] acc: 0.799969951923077
val--94/100 [140/1090] acc: 0.7998883928571429
val--94/100 [150/1090] acc: 0.79984375
val--94/100 [160/1090] acc: 0.7999755859375
val--94/100 [170/1090] acc: 0.799954044117647
val--94/100 [180/1090] acc: 0.7996744791666667
val--94/100 [190/1090] acc: 0.8003289473684211
val--94/100 [200/1090] acc: 0.8005859375
val--94/100 [210/1090] acc: 0.8010044642857143
val--94/100 [220/1090] acc: 0.8001598011363636
val--94/100 [230/1090] acc: 0.8007302989130435
val--94/100 [240/1090] acc: 0.8004720052083333
val--94/100 [250/1090] acc: 0.800671875
val--94/100 [260/1090] acc: 0.8006009615384615
val--94/100 [270/1090] acc: 0.801027199074074
val--94/100 [280/1090] acc: 0.8009347098214286
val--94/100 [290/1090] acc: 0.8008890086206897
val--94/100 [300/1090] acc: 0.8011588541666667
val--94/100 [310/1090] acc: 0.8009954637096774
val--94/100 [320/1090] acc: 0.80115966796875
val--94/100 [330/1090] acc: 0.801266571969697
val--94/100 [340/1090] acc: 0.801321231617647
val--94/100 [350/1090] acc: 0.8015178571428572
val--94/100 [360/1090] acc: 0.8013997395833333
val--94/100 [370/1090] acc: 0.8015308277027027
val--94/100 [380/1090] acc: 0.8015419407894737
val--94/100 [390/1090] acc: 0.8014122596153846
val--94/100 [400/1090] acc: 0.801357421875
val--94/100 [410/1090] acc: 0.801391006097561
val--94/100 [420/1090] acc: 0.8012648809523809
val--94/100 [430/1090] acc: 0.8010356104651163
val--94/100 [440/1090] acc: 0.8010475852272727
val--94/100 [450/1090] acc: 0.8009027777777777
val--94/100 [460/1090] acc: 0.8007133152173913
val--94/100 [470/1090] acc: 0.8005984042553191
val--94/100 [480/1090] acc: 0.8006429036458333
val--94/100 [490/1090] acc: 0.8006776147959184
val--94/100 [500/1090] acc: 0.80084375
val--94/100 [510/1090] acc: 0.800719975490196
val--94/100 [520/1090] acc: 0.8009390024038462
val--94/100 [530/1090] acc: 0.8008181014150944
val--94/100 [540/1090] acc: 0.8008752893518518
val--94/100 [550/1090] acc: 0.800703125
val--94/100 [560/1090] acc: 0.8005022321428571
val--94/100 [570/1090] acc: 0.800219298245614
val--94/100 [580/1090] acc: 0.8001616379310345
val--94/100 [590/1090] acc: 0.8000794491525424
val--94/100 [600/1090] acc: 0.8000455729166667
val--94/100 [610/1090] acc: 0.7999935963114754
val--94/100 [620/1090] acc: 0.7999054939516129
val--94/100 [630/1090] acc: 0.800124007936508
val--94/100 [640/1090] acc: 0.8003173828125
val--94/100 [650/1090] acc: 0.8003365384615385
val--94/100 [660/1090] acc: 0.8002130681818181
val--94/100 [670/1090] acc: 0.7999883395522388
val--94/100 [680/1090] acc: 0.7998965992647059
val--94/100 [690/1090] acc: 0.8000339673913044
val--94/100 [700/1090] acc: 0.8001116071428571
val--94/100 [710/1090] acc: 0.8000440140845071
val--94/100 [720/1090] acc: 0.7999348958333333
val--94/100 [730/1090] acc: 0.799898330479452
val--94/100 [740/1090] acc: 0.7998627533783784
val--94/100 [750/1090] acc: 0.79990625
val--94/100 [760/1090] acc: 0.8000925164473685
val--94/100 [770/1090] acc: 0.8000862418831168
val--94/100 [780/1090] acc: 0.799979967948718
val--94/100 [790/1090] acc: 0.7999802215189873
val--94/100 [800/1090] acc: 0.800205078125
val--94/100 [810/1090] acc: 0.8002363040123457
val--94/100 [820/1090] acc: 0.8002905868902439
val--94/100 [830/1090] acc: 0.8003388554216867
val--94/100 [840/1090] acc: 0.8002883184523809
val--94/100 [850/1090] acc: 0.8002757352941177
val--94/100 [860/1090] acc: 0.8005450581395349
val--94/100 [870/1090] acc: 0.8004804238505747
val--94/100 [880/1090] acc: 0.8004616477272727
val--94/100 [890/1090] acc: 0.8005310744382023
val--94/100 [900/1090] acc: 0.80046875
val--94/100 [910/1090] acc: 0.8004979395604396
val--94/100 [920/1090] acc: 0.8005180027173913
val--94/100 [930/1090] acc: 0.8006258400537635
val--94/100 [940/1090] acc: 0.8006233377659574
val--94/100 [950/1090] acc: 0.8005797697368421
val--94/100 [960/1090] acc: 0.8005167643229166
val--94/100 [970/1090] acc: 0.8004349226804124
val--94/100 [980/1090] acc: 0.8004902742346939
val--94/100 [990/1090] acc: 0.8004142992424242
val--94/100 [1000/1090] acc: 0.8003203125
val--94/100 [1010/1090] acc: 0.8001160272277228
val--94/100 [1020/1090] acc: 0.8001455269607843
val--94/100 [1030/1090] acc: 0.8001820388349514
val--94/100 [1040/1090] acc: 0.8001615084134616
val--94/100 [1050/1090] acc: 0.8001934523809524
val--94/100 [1060/1090] acc: 0.8001510908018868
val--94/100 [1070/1090] acc: 0.800113171728972
val--94/100 [1080/1090] acc: 0.8000651041666667
val--94/100 [1090/1090] acc: 0.7998960722477064
epoch= 94, accuracy= 0.799896, rmse= 0.374041, auc= 0.860270
train--95/100 [9/1090] loss: 0.3781326740980148
train--95/100 [19/1090] loss: 0.45299077332019805
train--95/100 [29/1090] loss: 0.4329671889543533
train--95/100 [39/1090] loss: 0.43838011026382445
train--95/100 [49/1090] loss: 0.4301791936159134
train--95/100 [59/1090] loss: 0.41595942378044126
train--95/100 [69/1090] loss: 0.42556279301643374
train--95/100 [79/1090] loss: 0.42940222918987275
train--95/100 [89/1090] loss: 0.4403801798820496
train--95/100 [99/1090] loss: 0.44277580082416534
train--95/100 [109/1090] loss: 0.43776304125785825
train--95/100 [119/1090] loss: 0.43671672642230985
train--95/100 [129/1090] loss: 0.4502662539482117
train--95/100 [139/1090] loss: 0.4312243491411209
train--95/100 [149/1090] loss: 0.4372103810310364
train--95/100 [159/1090] loss: 0.45059648156166077
train--95/100 [169/1090] loss: 0.4316623419523239
train--95/100 [179/1090] loss: 0.4444559097290039
train--95/100 [189/1090] loss: 0.41724825501441953
train--95/100 [199/1090] loss: 0.4308625519275665
train--95/100 [209/1090] loss: 0.4260498255491257
train--95/100 [219/1090] loss: 0.45175197124481203
train--95/100 [229/1090] loss: 0.4310420900583267
train--95/100 [239/1090] loss: 0.4378268331289291
train--95/100 [249/1090] loss: 0.4195121079683304
train--95/100 [259/1090] loss: 0.4321888774633408
train--95/100 [269/1090] loss: 0.43290733397006986
train--95/100 [279/1090] loss: 0.4234861433506012
train--95/100 [289/1090] loss: 0.4305883288383484
train--95/100 [299/1090] loss: 0.44341305196285247
train--95/100 [309/1090] loss: 0.43323572874069216
train--95/100 [319/1090] loss: 0.4191878378391266
train--95/100 [329/1090] loss: 0.4310187757015228
train--95/100 [339/1090] loss: 0.4426006019115448
train--95/100 [349/1090] loss: 0.45648378431797026
train--95/100 [359/1090] loss: 0.4359110057353973
train--95/100 [369/1090] loss: 0.4318028151988983
train--95/100 [379/1090] loss: 0.4255255997180939
train--95/100 [389/1090] loss: 0.43771916031837466
train--95/100 [399/1090] loss: 0.43386333286762235
train--95/100 [409/1090] loss: 0.4226356655359268
train--95/100 [419/1090] loss: 0.43914814591407775
train--95/100 [429/1090] loss: 0.43583081364631654
train--95/100 [439/1090] loss: 0.43557179272174834
train--95/100 [449/1090] loss: 0.4426142662763596
train--95/100 [459/1090] loss: 0.44492717981338503
train--95/100 [469/1090] loss: 0.44950738847255706
train--95/100 [479/1090] loss: 0.43317435681819916
train--95/100 [489/1090] loss: 0.42789655923843384
train--95/100 [499/1090] loss: 0.4249007642269135
train--95/100 [509/1090] loss: 0.430915766954422
train--95/100 [519/1090] loss: 0.451081195473671
train--95/100 [529/1090] loss: 0.42267559468746185
train--95/100 [539/1090] loss: 0.44690521359443663
train--95/100 [549/1090] loss: 0.44764589667320254
train--95/100 [559/1090] loss: 0.4394561469554901
train--95/100 [569/1090] loss: 0.42439259588718414
train--95/100 [579/1090] loss: 0.4460457772016525
train--95/100 [589/1090] loss: 0.4473465085029602
train--95/100 [599/1090] loss: 0.42341033816337587
train--95/100 [609/1090] loss: 0.44219534397125243
train--95/100 [619/1090] loss: 0.44627336859703065
train--95/100 [629/1090] loss: 0.45921547412872316
train--95/100 [639/1090] loss: 0.4366642266511917
train--95/100 [649/1090] loss: 0.42932325303554536
train--95/100 [659/1090] loss: 0.43064168393611907
train--95/100 [669/1090] loss: 0.43847007155418394
train--95/100 [679/1090] loss: 0.4392168462276459
train--95/100 [689/1090] loss: 0.4508392333984375
train--95/100 [699/1090] loss: 0.4328677415847778
train--95/100 [709/1090] loss: 0.4278328001499176
train--95/100 [719/1090] loss: 0.446231946349144
train--95/100 [729/1090] loss: 0.4334280014038086
train--95/100 [739/1090] loss: 0.43512138426303865
train--95/100 [749/1090] loss: 0.4430425375699997
train--95/100 [759/1090] loss: 0.4128142952919006
train--95/100 [769/1090] loss: 0.4293154180049896
train--95/100 [779/1090] loss: 0.42441305220127107
train--95/100 [789/1090] loss: 0.44384962022304536
train--95/100 [799/1090] loss: 0.4510105699300766
train--95/100 [809/1090] loss: 0.4536128371953964
train--95/100 [819/1090] loss: 0.44508984684944153
train--95/100 [829/1090] loss: 0.4562336802482605
train--95/100 [839/1090] loss: 0.433216792345047
train--95/100 [849/1090] loss: 0.43016892969608306
train--95/100 [859/1090] loss: 0.45644738972187043
train--95/100 [869/1090] loss: 0.4093095391988754
train--95/100 [879/1090] loss: 0.4556803673505783
train--95/100 [889/1090] loss: 0.43139317333698274
train--95/100 [899/1090] loss: 0.4358193963766098
train--95/100 [909/1090] loss: 0.458897802233696
train--95/100 [919/1090] loss: 0.4414032310247421
train--95/100 [929/1090] loss: 0.4349211364984512
train--95/100 [939/1090] loss: 0.4446079581975937
train--95/100 [949/1090] loss: 0.4441714286804199
train--95/100 [959/1090] loss: 0.4299878805875778
train--95/100 [969/1090] loss: 0.4335998594760895
train--95/100 [979/1090] loss: 0.44113282561302186
train--95/100 [989/1090] loss: 0.4408992141485214
train--95/100 [999/1090] loss: 0.43586719036102295
train--95/100 [1009/1090] loss: 0.45695228278636935
train--95/100 [1019/1090] loss: 0.4360479325056076
train--95/100 [1029/1090] loss: 0.4265723466873169
train--95/100 [1039/1090] loss: 0.43928821086883546
train--95/100 [1049/1090] loss: 0.4495105415582657
train--95/100 [1059/1090] loss: 0.4413702964782715
train--95/100 [1069/1090] loss: 0.43654459416866304
train--95/100 [1079/1090] loss: 0.42265855669975283
train--95/100 [1089/1090] loss: 0.422913259267807
predicting model...
val--95/100 [10/1090] acc: 0.8015625
val--95/100 [20/1090] acc: 0.8009765625
val--95/100 [30/1090] acc: 0.80078125
val--95/100 [40/1090] acc: 0.800390625
val--95/100 [50/1090] acc: 0.80015625
val--95/100 [60/1090] acc: 0.7991536458333334
val--95/100 [70/1090] acc: 0.7990513392857143
val--95/100 [80/1090] acc: 0.798193359375
val--95/100 [90/1090] acc: 0.7983940972222222
val--95/100 [100/1090] acc: 0.799375
val--95/100 [110/1090] acc: 0.7997159090909091
val--95/100 [120/1090] acc: 0.79912109375
val--95/100 [130/1090] acc: 0.8
val--95/100 [140/1090] acc: 0.8
val--95/100 [150/1090] acc: 0.8
val--95/100 [160/1090] acc: 0.799951171875
val--95/100 [170/1090] acc: 0.7998391544117647
val--95/100 [180/1090] acc: 0.7996310763888889
val--95/100 [190/1090] acc: 0.8003083881578947
val--95/100 [200/1090] acc: 0.800625
val--95/100 [210/1090] acc: 0.8009114583333333
val--95/100 [220/1090] acc: 0.8000710227272727
val--95/100 [230/1090] acc: 0.8007133152173913
val--95/100 [240/1090] acc: 0.8003580729166667
val--95/100 [250/1090] acc: 0.800484375
val--95/100 [260/1090] acc: 0.8004356971153846
val--95/100 [270/1090] acc: 0.8007378472222222
val--95/100 [280/1090] acc: 0.8006556919642858
val--95/100 [290/1090] acc: 0.8005253232758621
val--95/100 [300/1090] acc: 0.8007161458333333
val--95/100 [310/1090] acc: 0.8005040322580645
val--95/100 [320/1090] acc: 0.8006591796875
val--95/100 [330/1090] acc: 0.8008285984848484
val--95/100 [340/1090] acc: 0.8008731617647059
val--95/100 [350/1090] acc: 0.8011495535714286
val--95/100 [360/1090] acc: 0.8010416666666667
val--95/100 [370/1090] acc: 0.8011929898648649
val--95/100 [380/1090] acc: 0.8011821546052632
val--95/100 [390/1090] acc: 0.8010717147435897
val--95/100 [400/1090] acc: 0.80099609375
val--95/100 [410/1090] acc: 0.801000381097561
val--95/100 [420/1090] acc: 0.8009207589285714
val--95/100 [430/1090] acc: 0.8006904069767442
val--95/100 [440/1090] acc: 0.8008078835227272
val--95/100 [450/1090] acc: 0.8007118055555555
val--95/100 [460/1090] acc: 0.8004925271739131
val--95/100 [470/1090] acc: 0.8003989361702127
val--95/100 [480/1090] acc: 0.8003662109375
val--95/100 [490/1090] acc: 0.800374681122449
val--95/100 [500/1090] acc: 0.800578125
val--95/100 [510/1090] acc: 0.8004518995098039
val--95/100 [520/1090] acc: 0.8006911057692307
val--95/100 [530/1090] acc: 0.8005969929245284
val--95/100 [540/1090] acc: 0.8006510416666667
val--95/100 [550/1090] acc: 0.8004616477272727
val--95/100 [560/1090] acc: 0.800244140625
val--95/100 [570/1090] acc: 0.7999451754385964
val--95/100 [580/1090] acc: 0.7998585668103448
val--95/100 [590/1090] acc: 0.7998278601694915
val--95/100 [600/1090] acc: 0.7997981770833333
val--95/100 [610/1090] acc: 0.7997566598360656
val--95/100 [620/1090] acc: 0.7996597782258065
val--95/100 [630/1090] acc: 0.7999255952380953
val--95/100 [640/1090] acc: 0.800140380859375
val--95/100 [650/1090] acc: 0.80015625
val--95/100 [660/1090] acc: 0.8000828598484848
val--95/100 [670/1090] acc: 0.7998775652985075
val--95/100 [680/1090] acc: 0.7997931985294118
val--95/100 [690/1090] acc: 0.7999433876811595
val--95/100 [700/1090] acc: 0.8000223214285714
val--95/100 [710/1090] acc: 0.7999504841549295
val--95/100 [720/1090] acc: 0.7998480902777778
val--95/100 [730/1090] acc: 0.7998234160958904
val--95/100 [740/1090] acc: 0.799778293918919
val--95/100 [750/1090] acc: 0.7997864583333333
val--95/100 [760/1090] acc: 0.7999588815789473
val--95/100 [770/1090] acc: 0.7999441964285714
val--95/100 [780/1090] acc: 0.7998497596153846
val--95/100 [790/1090] acc: 0.7998417721518988
val--95/100 [800/1090] acc: 0.8000634765625
val--95/100 [810/1090] acc: 0.8001157407407408
val--95/100 [820/1090] acc: 0.8002096036585366
val--95/100 [830/1090] acc: 0.8002635542168675
val--95/100 [840/1090] acc: 0.8002325148809524
val--95/100 [850/1090] acc: 0.8002527573529412
val--95/100 [860/1090] acc: 0.8005450581395349
val--95/100 [870/1090] acc: 0.8005298132183908
val--95/100 [880/1090] acc: 0.8004927201704546
val--95/100 [890/1090] acc: 0.8005398525280899
val--95/100 [900/1090] acc: 0.8005164930555555
val--95/100 [910/1090] acc: 0.800523695054945
val--95/100 [920/1090] acc: 0.8005604619565218
val--95/100 [930/1090] acc: 0.8006720430107527
val--95/100 [940/1090] acc: 0.8006690492021277
val--95/100 [950/1090] acc: 0.8006085526315789
val--95/100 [960/1090] acc: 0.8005655924479167
val--95/100 [970/1090] acc: 0.8004832474226804
val--95/100 [980/1090] acc: 0.800538105867347
val--95/100 [990/1090] acc: 0.8004616477272727
val--95/100 [1000/1090] acc: 0.80036328125
val--95/100 [1010/1090] acc: 0.8001392326732674
val--95/100 [1020/1090] acc: 0.800164675245098
val--95/100 [1030/1090] acc: 0.800197208737864
val--95/100 [1040/1090] acc: 0.8001990685096154
val--95/100 [1050/1090] acc: 0.8002306547619048
val--95/100 [1060/1090] acc: 0.8001879422169811
val--95/100 [1070/1090] acc: 0.8001679322429907
val--95/100 [1080/1090] acc: 0.8001229745370371
val--95/100 [1090/1090] acc: 0.799956995412844
epoch= 95, accuracy= 0.799957, rmse= 0.373908, auc= 0.860401
train--96/100 [9/1090] loss: 0.39361223578453064
train--96/100 [19/1090] loss: 0.4406110316514969
train--96/100 [29/1090] loss: 0.41844363808631896
train--96/100 [39/1090] loss: 0.4433500975370407
train--96/100 [49/1090] loss: 0.41642324030399325
train--96/100 [59/1090] loss: 0.43949280083179476
train--96/100 [69/1090] loss: 0.41345633566379547
train--96/100 [79/1090] loss: 0.45302817821502683
train--96/100 [89/1090] loss: 0.43399943709373473
train--96/100 [99/1090] loss: 0.4180727034807205
train--96/100 [109/1090] loss: 0.4434037357568741
train--96/100 [119/1090] loss: 0.42840155959129333
train--96/100 [129/1090] loss: 0.4387859791517258
train--96/100 [139/1090] loss: 0.4340877443552017
train--96/100 [149/1090] loss: 0.45744247138500216
train--96/100 [159/1090] loss: 0.4370896279811859
train--96/100 [169/1090] loss: 0.4160895079374313
train--96/100 [179/1090] loss: 0.4304907202720642
train--96/100 [189/1090] loss: 0.44358005225658415
train--96/100 [199/1090] loss: 0.4382185608148575
train--96/100 [209/1090] loss: 0.44967968463897706
train--96/100 [219/1090] loss: 0.4207671195268631
train--96/100 [229/1090] loss: 0.4281879633665085
train--96/100 [239/1090] loss: 0.4171869844198227
train--96/100 [249/1090] loss: 0.4347943037748337
train--96/100 [259/1090] loss: 0.45159918665885923
train--96/100 [269/1090] loss: 0.41716634929180146
train--96/100 [279/1090] loss: 0.432813361287117
train--96/100 [289/1090] loss: 0.422969263792038
train--96/100 [299/1090] loss: 0.41288778781890867
train--96/100 [309/1090] loss: 0.4329254776239395
train--96/100 [319/1090] loss: 0.42702731788158416
train--96/100 [329/1090] loss: 0.41999935507774355
train--96/100 [339/1090] loss: 0.4494221478700638
train--96/100 [349/1090] loss: 0.4330132186412811
train--96/100 [359/1090] loss: 0.4443804115056992
train--96/100 [369/1090] loss: 0.43381164968013763
train--96/100 [379/1090] loss: 0.43667649030685424
train--96/100 [389/1090] loss: 0.43496514558792115
train--96/100 [399/1090] loss: 0.4346596121788025
train--96/100 [409/1090] loss: 0.439135929942131
train--96/100 [419/1090] loss: 0.41623315811157224
train--96/100 [429/1090] loss: 0.45646937787532804
train--96/100 [439/1090] loss: 0.44122260212898257
train--96/100 [449/1090] loss: 0.43118288815021516
train--96/100 [459/1090] loss: 0.4408043444156647
train--96/100 [469/1090] loss: 0.44390854239463806
train--96/100 [479/1090] loss: 0.4219625651836395
train--96/100 [489/1090] loss: 0.43350965678691866
train--96/100 [499/1090] loss: 0.4374823123216629
train--96/100 [509/1090] loss: 0.44361182749271394
train--96/100 [519/1090] loss: 0.42911598086357117
train--96/100 [529/1090] loss: 0.4321379154920578
train--96/100 [539/1090] loss: 0.43411579430103303
train--96/100 [549/1090] loss: 0.4194037139415741
train--96/100 [559/1090] loss: 0.4431208848953247
train--96/100 [569/1090] loss: 0.4437310338020325
train--96/100 [579/1090] loss: 0.4120597928762436
train--96/100 [589/1090] loss: 0.45384475588798523
train--96/100 [599/1090] loss: 0.44997806549072267
train--96/100 [609/1090] loss: 0.4395188897848129
train--96/100 [619/1090] loss: 0.4455702185630798
train--96/100 [629/1090] loss: 0.43989403247833253
train--96/100 [639/1090] loss: 0.44360590577125547
train--96/100 [649/1090] loss: 0.4473048210144043
train--96/100 [659/1090] loss: 0.4458754390478134
train--96/100 [669/1090] loss: 0.43159308433532717
train--96/100 [679/1090] loss: 0.4313911646604538
train--96/100 [689/1090] loss: 0.44361464977264403
train--96/100 [699/1090] loss: 0.4480906009674072
train--96/100 [709/1090] loss: 0.4175597012042999
train--96/100 [719/1090] loss: 0.43993430137634276
train--96/100 [729/1090] loss: 0.43014619052410125
train--96/100 [739/1090] loss: 0.4364346981048584
train--96/100 [749/1090] loss: 0.43407873511314393
train--96/100 [759/1090] loss: 0.4308374285697937
train--96/100 [769/1090] loss: 0.4375337094068527
train--96/100 [779/1090] loss: 0.4398631274700165
train--96/100 [789/1090] loss: 0.4277529239654541
train--96/100 [799/1090] loss: 0.446188160777092
train--96/100 [809/1090] loss: 0.44344583749771116
train--96/100 [819/1090] loss: 0.4251883298158646
train--96/100 [829/1090] loss: 0.4496162384748459
train--96/100 [839/1090] loss: 0.4362922668457031
train--96/100 [849/1090] loss: 0.4370137095451355
train--96/100 [859/1090] loss: 0.45355803668498995
train--96/100 [869/1090] loss: 0.4368770956993103
train--96/100 [879/1090] loss: 0.44412609934806824
train--96/100 [889/1090] loss: 0.4390260398387909
train--96/100 [899/1090] loss: 0.4440704107284546
train--96/100 [909/1090] loss: 0.4290083825588226
train--96/100 [919/1090] loss: 0.4431739240884781
train--96/100 [929/1090] loss: 0.47236580550670626
train--96/100 [939/1090] loss: 0.46153285503387453
train--96/100 [949/1090] loss: 0.43992692828178404
train--96/100 [959/1090] loss: 0.4239416241645813
train--96/100 [969/1090] loss: 0.4439481198787689
train--96/100 [979/1090] loss: 0.456372532248497
train--96/100 [989/1090] loss: 0.42667911350727084
train--96/100 [999/1090] loss: 0.4413281261920929
train--96/100 [1009/1090] loss: 0.44792515933513644
train--96/100 [1019/1090] loss: 0.42576695084571836
train--96/100 [1029/1090] loss: 0.4343596577644348
train--96/100 [1039/1090] loss: 0.44341746270656585
train--96/100 [1049/1090] loss: 0.43461376428604126
train--96/100 [1059/1090] loss: 0.4252360016107559
train--96/100 [1069/1090] loss: 0.4341635167598724
train--96/100 [1079/1090] loss: 0.4396106034517288
train--96/100 [1089/1090] loss: 0.45064486265182496
predicting model...
val--96/100 [10/1090] acc: 0.80234375
val--96/100 [20/1090] acc: 0.801953125
val--96/100 [30/1090] acc: 0.801171875
val--96/100 [40/1090] acc: 0.80107421875
val--96/100 [50/1090] acc: 0.800546875
val--96/100 [60/1090] acc: 0.799609375
val--96/100 [70/1090] acc: 0.7997767857142857
val--96/100 [80/1090] acc: 0.798779296875
val--96/100 [90/1090] acc: 0.7986111111111112
val--96/100 [100/1090] acc: 0.79984375
val--96/100 [110/1090] acc: 0.7998224431818182
val--96/100 [120/1090] acc: 0.7993815104166667
val--96/100 [130/1090] acc: 0.8001201923076923
val--96/100 [140/1090] acc: 0.7999441964285714
val--96/100 [150/1090] acc: 0.79984375
val--96/100 [160/1090] acc: 0.8000244140625
val--96/100 [170/1090] acc: 0.7997931985294118
val--96/100 [180/1090] acc: 0.7995659722222223
val--96/100 [190/1090] acc: 0.8002467105263158
val--96/100 [200/1090] acc: 0.800546875
val--96/100 [210/1090] acc: 0.8008928571428572
val--96/100 [220/1090] acc: 0.8000355113636364
val--96/100 [230/1090] acc: 0.8006283967391304
val--96/100 [240/1090] acc: 0.8003092447916667
val--96/100 [250/1090] acc: 0.800578125
val--96/100 [260/1090] acc: 0.8005258413461539
val--96/100 [270/1090] acc: 0.8008535879629629
val--96/100 [280/1090] acc: 0.8007952008928572
val--96/100 [290/1090] acc: 0.8006734913793103
val--96/100 [300/1090] acc: 0.8008203125
val--96/100 [310/1090] acc: 0.800554435483871
val--96/100 [320/1090] acc: 0.8007080078125
val--96/100 [330/1090] acc: 0.8008167613636363
val--96/100 [340/1090] acc: 0.8009880514705883
val--96/100 [350/1090] acc: 0.8012276785714286
val--96/100 [360/1090] acc: 0.801171875
val--96/100 [370/1090] acc: 0.801245777027027
val--96/100 [380/1090] acc: 0.8012643914473684
val--96/100 [390/1090] acc: 0.8011217948717949
val--96/100 [400/1090] acc: 0.801083984375
val--96/100 [410/1090] acc: 0.8011147103658537
val--96/100 [420/1090] acc: 0.8010230654761905
val--96/100 [430/1090] acc: 0.80078125
val--96/100 [440/1090] acc: 0.8008256392045454
val--96/100 [450/1090] acc: 0.8007291666666667
val--96/100 [460/1090] acc: 0.8005434782608696
val--96/100 [470/1090] acc: 0.8004238696808511
val--96/100 [480/1090] acc: 0.8004150390625
val--96/100 [490/1090] acc: 0.8004145408163266
val--96/100 [500/1090] acc: 0.8005703125
val--96/100 [510/1090] acc: 0.8004748774509803
val--96/100 [520/1090] acc: 0.8008037860576923
val--96/100 [530/1090] acc: 0.800729658018868
val--96/100 [540/1090] acc: 0.80078125
val--96/100 [550/1090] acc: 0.800625
val--96/100 [560/1090] acc: 0.8004255022321428
val--96/100 [570/1090] acc: 0.8001576206140351
val--96/100 [580/1090] acc: 0.8001481681034482
val--96/100 [590/1090] acc: 0.8001324152542373
val--96/100 [600/1090] acc: 0.8000846354166666
val--96/100 [610/1090] acc: 0.8000448258196722
val--96/100 [620/1090] acc: 0.7999936995967742
val--96/100 [630/1090] acc: 0.800235615079365
val--96/100 [640/1090] acc: 0.80042724609375
val--96/100 [650/1090] acc: 0.8004206730769231
val--96/100 [660/1090] acc: 0.8003610321969697
val--96/100 [670/1090] acc: 0.8001807369402985
val--96/100 [680/1090] acc: 0.8000689338235294
val--96/100 [690/1090] acc: 0.800192481884058
val--96/100 [700/1090] acc: 0.8002455357142857
val--96/100 [710/1090] acc: 0.8002200704225352
val--96/100 [720/1090] acc: 0.8001519097222223
val--96/100 [730/1090] acc: 0.8001123715753424
val--96/100 [740/1090] acc: 0.800073902027027
val--96/100 [750/1090] acc: 0.8001041666666666
val--96/100 [760/1090] acc: 0.8002775493421053
val--96/100 [770/1090] acc: 0.8002637987012987
val--96/100 [780/1090] acc: 0.800175280448718
val--96/100 [790/1090] acc: 0.8001483386075949
val--96/100 [800/1090] acc: 0.800361328125
val--96/100 [810/1090] acc: 0.8003858024691358
val--96/100 [820/1090] acc: 0.8004763719512196
val--96/100 [830/1090] acc: 0.800527108433735
val--96/100 [840/1090] acc: 0.8004975818452381
val--96/100 [850/1090] acc: 0.8004963235294118
val--96/100 [860/1090] acc: 0.8007857921511627
val--96/100 [870/1090] acc: 0.8007543103448276
val--96/100 [880/1090] acc: 0.8007457386363637
val--96/100 [890/1090] acc: 0.8008163623595506
val--96/100 [900/1090] acc: 0.8007942708333333
val--96/100 [910/1090] acc: 0.8008198832417582
val--96/100 [920/1090] acc: 0.8008661684782609
val--96/100 [930/1090] acc: 0.8009702620967742
val--96/100 [940/1090] acc: 0.8009640957446809
val--96/100 [950/1090] acc: 0.8009333881578947
val--96/100 [960/1090] acc: 0.8008707682291667
val--96/100 [970/1090] acc: 0.8007731958762887
val--96/100 [980/1090] acc: 0.8008211096938775
val--96/100 [990/1090] acc: 0.8007417929292929
val--96/100 [1000/1090] acc: 0.80064453125
val--96/100 [1010/1090] acc: 0.8004138304455446
val--96/100 [1020/1090] acc: 0.800421262254902
val--96/100 [1030/1090] acc: 0.8004323422330097
val--96/100 [1040/1090] acc: 0.8003868689903846
val--96/100 [1050/1090] acc: 0.8004278273809524
val--96/100 [1060/1090] acc: 0.8003795695754717
val--96/100 [1070/1090] acc: 0.8003650700934579
val--96/100 [1080/1090] acc: 0.8003146701388889
val--96/100 [1090/1090] acc: 0.8001361811926605
epoch= 96, accuracy= 0.800136, rmse= 0.373728, auc= 0.860769
train--97/100 [9/1090] loss: 0.38925490379333494
train--97/100 [19/1090] loss: 0.44045411944389345
train--97/100 [29/1090] loss: 0.42823716402053835
train--97/100 [39/1090] loss: 0.4350022852420807
train--97/100 [49/1090] loss: 0.42446250915527345
train--97/100 [59/1090] loss: 0.4509796380996704
train--97/100 [69/1090] loss: 0.43241477608680723
train--97/100 [79/1090] loss: 0.42816971242427826
train--97/100 [89/1090] loss: 0.43118037581443786
train--97/100 [99/1090] loss: 0.4433948755264282
train--97/100 [109/1090] loss: 0.42827174067497253
train--97/100 [119/1090] loss: 0.44401457607746125
train--97/100 [129/1090] loss: 0.42732451260089876
train--97/100 [139/1090] loss: 0.4436934977769852
train--97/100 [149/1090] loss: 0.42947329580783844
train--97/100 [159/1090] loss: 0.4296285420656204
train--97/100 [169/1090] loss: 0.4335032969713211
train--97/100 [179/1090] loss: 0.4316898167133331
train--97/100 [189/1090] loss: 0.4308603465557098
train--97/100 [199/1090] loss: 0.4196208298206329
train--97/100 [209/1090] loss: 0.4381657183170319
train--97/100 [219/1090] loss: 0.4266103535890579
train--97/100 [229/1090] loss: 0.4309007257223129
train--97/100 [239/1090] loss: 0.4511184096336365
train--97/100 [249/1090] loss: 0.44110341370105743
train--97/100 [259/1090] loss: 0.450026798248291
train--97/100 [269/1090] loss: 0.4363071769475937
train--97/100 [279/1090] loss: 0.43618619740009307
train--97/100 [289/1090] loss: 0.4334608882665634
train--97/100 [299/1090] loss: 0.42647341191768645
train--97/100 [309/1090] loss: 0.42321752309799193
train--97/100 [319/1090] loss: 0.44427920281887057
train--97/100 [329/1090] loss: 0.43102075457572936
train--97/100 [339/1090] loss: 0.4424771130084991
train--97/100 [349/1090] loss: 0.4520696043968201
train--97/100 [359/1090] loss: 0.43267094194889066
train--97/100 [369/1090] loss: 0.4329271376132965
train--97/100 [379/1090] loss: 0.4536902755498886
train--97/100 [389/1090] loss: 0.45380361676216124
train--97/100 [399/1090] loss: 0.43557813167572024
train--97/100 [409/1090] loss: 0.4435821086168289
train--97/100 [419/1090] loss: 0.4405793011188507
train--97/100 [429/1090] loss: 0.42166549563407896
train--97/100 [439/1090] loss: 0.4425817370414734
train--97/100 [449/1090] loss: 0.4461899161338806
train--97/100 [459/1090] loss: 0.4503623992204666
train--97/100 [469/1090] loss: 0.43433633744716643
train--97/100 [479/1090] loss: 0.4317166209220886
train--97/100 [489/1090] loss: 0.4234986066818237
train--97/100 [499/1090] loss: 0.45514521300792693
train--97/100 [509/1090] loss: 0.4431228131055832
train--97/100 [519/1090] loss: 0.4182906150817871
train--97/100 [529/1090] loss: 0.44605364203453063
train--97/100 [539/1090] loss: 0.4359315425157547
train--97/100 [549/1090] loss: 0.42285936176776884
train--97/100 [559/1090] loss: 0.4328751802444458
train--97/100 [569/1090] loss: 0.436211484670639
train--97/100 [579/1090] loss: 0.4394881695508957
train--97/100 [589/1090] loss: 0.42638708353042604
train--97/100 [599/1090] loss: 0.41588002145290376
train--97/100 [609/1090] loss: 0.42790418565273286
train--97/100 [619/1090] loss: 0.43901766538619996
train--97/100 [629/1090] loss: 0.43620515763759615
train--97/100 [639/1090] loss: 0.4404138386249542
train--97/100 [649/1090] loss: 0.4317466914653778
train--97/100 [659/1090] loss: 0.4331687390804291
train--97/100 [669/1090] loss: 0.4315874546766281
train--97/100 [679/1090] loss: 0.439612939953804
train--97/100 [689/1090] loss: 0.42841485142707825
train--97/100 [699/1090] loss: 0.4254649102687836
train--97/100 [709/1090] loss: 0.41266240179538727
train--97/100 [719/1090] loss: 0.4459024786949158
train--97/100 [729/1090] loss: 0.4499572694301605
train--97/100 [739/1090] loss: 0.43927018344402313
train--97/100 [749/1090] loss: 0.4358478754758835
train--97/100 [759/1090] loss: 0.4327543616294861
train--97/100 [769/1090] loss: 0.4363405078649521
train--97/100 [779/1090] loss: 0.4458669602870941
train--97/100 [789/1090] loss: 0.44012671411037446
train--97/100 [799/1090] loss: 0.4348806321620941
train--97/100 [809/1090] loss: 0.4273237019777298
train--97/100 [819/1090] loss: 0.4224107712507248
train--97/100 [829/1090] loss: 0.4260626286268234
train--97/100 [839/1090] loss: 0.43214561939239504
train--97/100 [849/1090] loss: 0.44632086157798767
train--97/100 [859/1090] loss: 0.41665735840797424
train--97/100 [869/1090] loss: 0.43498789370059965
train--97/100 [879/1090] loss: 0.4329964190721512
train--97/100 [889/1090] loss: 0.4478715091943741
train--97/100 [899/1090] loss: 0.4446796864271164
train--97/100 [909/1090] loss: 0.4509322166442871
train--97/100 [919/1090] loss: 0.43564597368240354
train--97/100 [929/1090] loss: 0.42554305493831635
train--97/100 [939/1090] loss: 0.43933106362819674
train--97/100 [949/1090] loss: 0.44312593936920164
train--97/100 [959/1090] loss: 0.4634485900402069
train--97/100 [969/1090] loss: 0.43957392275333407
train--97/100 [979/1090] loss: 0.4342580705881119
train--97/100 [989/1090] loss: 0.4424590140581131
train--97/100 [999/1090] loss: 0.4458699584007263
train--97/100 [1009/1090] loss: 0.4645577043294907
train--97/100 [1019/1090] loss: 0.4461203426122665
train--97/100 [1029/1090] loss: 0.43839815855026243
train--97/100 [1039/1090] loss: 0.42348607182502745
train--97/100 [1049/1090] loss: 0.43654657900333405
train--97/100 [1059/1090] loss: 0.4481630682945251
train--97/100 [1069/1090] loss: 0.420809343457222
train--97/100 [1079/1090] loss: 0.4245298892259598
train--97/100 [1089/1090] loss: 0.4352013498544693
predicting model...
val--97/100 [10/1090] acc: 0.80234375
val--97/100 [20/1090] acc: 0.8015625
val--97/100 [30/1090] acc: 0.800390625
val--97/100 [40/1090] acc: 0.80048828125
val--97/100 [50/1090] acc: 0.800078125
val--97/100 [60/1090] acc: 0.79921875
val--97/100 [70/1090] acc: 0.7993861607142857
val--97/100 [80/1090] acc: 0.79853515625
val--97/100 [90/1090] acc: 0.7987413194444445
val--97/100 [100/1090] acc: 0.8000390625
val--97/100 [110/1090] acc: 0.8000710227272727
val--97/100 [120/1090] acc: 0.7997721354166667
val--97/100 [130/1090] acc: 0.8005108173076924
val--97/100 [140/1090] acc: 0.8002232142857143
val--97/100 [150/1090] acc: 0.8001822916666667
val--97/100 [160/1090] acc: 0.80029296875
val--97/100 [170/1090] acc: 0.8000689338235294
val--97/100 [180/1090] acc: 0.7997829861111111
val--97/100 [190/1090] acc: 0.8003289473684211
val--97/100 [200/1090] acc: 0.8006640625
val--97/100 [210/1090] acc: 0.8010416666666667
val--97/100 [220/1090] acc: 0.8001775568181818
val--97/100 [230/1090] acc: 0.8007642663043478
val--97/100 [240/1090] acc: 0.8004069010416667
val--97/100 [250/1090] acc: 0.800578125
val--97/100 [260/1090] acc: 0.8006310096153846
val--97/100 [270/1090] acc: 0.8010127314814814
val--97/100 [280/1090] acc: 0.8009207589285714
val--97/100 [290/1090] acc: 0.8007273706896552
val--97/100 [300/1090] acc: 0.800859375
val--97/100 [310/1090] acc: 0.8006678427419355
val--97/100 [320/1090] acc: 0.800830078125
val--97/100 [330/1090] acc: 0.8009943181818182
val--97/100 [340/1090] acc: 0.8010569852941176
val--97/100 [350/1090] acc: 0.8013616071428571
val--97/100 [360/1090] acc: 0.8012586805555556
val--97/100 [370/1090] acc: 0.8013407939189189
val--97/100 [380/1090] acc: 0.8013363486842106
val--97/100 [390/1090] acc: 0.8012219551282052
val--97/100 [400/1090] acc: 0.801181640625
val--97/100 [410/1090] acc: 0.8011909298780487
val--97/100 [420/1090] acc: 0.8010974702380952
val--97/100 [430/1090] acc: 0.8009084302325581
val--97/100 [440/1090] acc: 0.8009943181818182
val--97/100 [450/1090] acc: 0.8008940972222223
val--97/100 [460/1090] acc: 0.8007302989130435
val--97/100 [470/1090] acc: 0.8006316489361702
val--97/100 [480/1090] acc: 0.8006754557291667
val--97/100 [490/1090] acc: 0.8006696428571428
val--97/100 [500/1090] acc: 0.8008359375
val--97/100 [510/1090] acc: 0.8007046568627451
val--97/100 [520/1090] acc: 0.8009840745192308
val--97/100 [530/1090] acc: 0.8008918042452831
val--97/100 [540/1090] acc: 0.8009331597222222
val--97/100 [550/1090] acc: 0.8007457386363637
val--97/100 [560/1090] acc: 0.8005580357142857
val--97/100 [570/1090] acc: 0.8002946820175438
val--97/100 [580/1090] acc: 0.8002222521551724
val--97/100 [590/1090] acc: 0.8001655190677966
val--97/100 [600/1090] acc: 0.8001171875
val--97/100 [610/1090] acc: 0.8000832479508196
val--97/100 [620/1090] acc: 0.8000378024193548
val--97/100 [630/1090] acc: 0.8003100198412698
val--97/100 [640/1090] acc: 0.800494384765625
val--97/100 [650/1090] acc: 0.8004747596153846
val--97/100 [660/1090] acc: 0.8003432765151515
val--97/100 [670/1090] acc: 0.800145755597015
val--97/100 [680/1090] acc: 0.8000287224264706
val--97/100 [690/1090] acc: 0.8001754981884058
val--97/100 [700/1090] acc: 0.800234375
val--97/100 [710/1090] acc: 0.8001705545774648
val--97/100 [720/1090] acc: 0.8000868055555556
val--97/100 [730/1090] acc: 0.8000642123287671
val--97/100 [740/1090] acc: 0.8000052787162162
val--97/100 [750/1090] acc: 0.8000364583333334
val--97/100 [760/1090] acc: 0.8002210115131579
val--97/100 [770/1090] acc: 0.8001775568181818
val--97/100 [780/1090] acc: 0.8000951522435897
val--97/100 [790/1090] acc: 0.800089003164557
val--97/100 [800/1090] acc: 0.800283203125
val--97/100 [810/1090] acc: 0.8003038194444444
val--97/100 [820/1090] acc: 0.8003668064024391
val--97/100 [830/1090] acc: 0.8004376882530121
val--97/100 [840/1090] acc: 0.8004045758928572
val--97/100 [850/1090] acc: 0.8004090073529412
val--97/100 [860/1090] acc: 0.800694949127907
val--97/100 [870/1090] acc: 0.8006824712643679
val--97/100 [880/1090] acc: 0.8006569602272727
val--97/100 [890/1090] acc: 0.8007285814606742
val--97/100 [900/1090] acc: 0.8006684027777777
val--97/100 [910/1090] acc: 0.8006996909340659
val--97/100 [920/1090] acc: 0.8007430366847826
val--97/100 [930/1090] acc: 0.8008526545698925
val--97/100 [940/1090] acc: 0.8008726728723404
val--97/100 [950/1090] acc: 0.800826480263158
val--97/100 [960/1090] acc: 0.8007405598958334
val--97/100 [970/1090] acc: 0.8006725193298969
val--97/100 [980/1090] acc: 0.8007095025510204
val--97/100 [990/1090] acc: 0.8006549873737374
val--97/100 [1000/1090] acc: 0.8005703125
val--97/100 [1010/1090] acc: 0.8003480816831683
val--97/100 [1020/1090] acc: 0.8003753063725491
val--97/100 [1030/1090] acc: 0.8004020024271845
val--97/100 [1040/1090] acc: 0.8003943810096154
val--97/100 [1050/1090] acc: 0.8004278273809524
val--97/100 [1060/1090] acc: 0.8003979952830189
val--97/100 [1070/1090] acc: 0.8003687207943925
val--97/100 [1080/1090] acc: 0.8003110532407407
val--97/100 [1090/1090] acc: 0.8001325974770642
epoch= 97, accuracy= 0.800133, rmse= 0.373573, auc= 0.860954
train--98/100 [9/1090] loss: 0.3816051334142685
train--98/100 [19/1090] loss: 0.43401212692260743
train--98/100 [29/1090] loss: 0.4357146769762039
train--98/100 [39/1090] loss: 0.42322017550468444
train--98/100 [49/1090] loss: 0.4245990961790085
train--98/100 [59/1090] loss: 0.42448078095912933
train--98/100 [69/1090] loss: 0.43945108354091644
train--98/100 [79/1090] loss: 0.42736767530441283
train--98/100 [89/1090] loss: 0.4338929742574692
train--98/100 [99/1090] loss: 0.4327968150377274
train--98/100 [109/1090] loss: 0.4357383459806442
train--98/100 [119/1090] loss: 0.4460233300924301
train--98/100 [129/1090] loss: 0.4409321635961533
train--98/100 [139/1090] loss: 0.4368882656097412
train--98/100 [149/1090] loss: 0.4370047032833099
train--98/100 [159/1090] loss: 0.43342921137809753
train--98/100 [169/1090] loss: 0.4414068400859833
train--98/100 [179/1090] loss: 0.4238410085439682
train--98/100 [189/1090] loss: 0.4266036421060562
train--98/100 [199/1090] loss: 0.4327757805585861
train--98/100 [209/1090] loss: 0.4385630816221237
train--98/100 [219/1090] loss: 0.43532625734806063
train--98/100 [229/1090] loss: 0.45443579852581023
train--98/100 [239/1090] loss: 0.4263334572315216
train--98/100 [249/1090] loss: 0.43904212713241575
train--98/100 [259/1090] loss: 0.4554800271987915
train--98/100 [269/1090] loss: 0.4341260612010956
train--98/100 [279/1090] loss: 0.43765170574188234
train--98/100 [289/1090] loss: 0.4113802134990692
train--98/100 [299/1090] loss: 0.43225752711296084
train--98/100 [309/1090] loss: 0.4259137213230133
train--98/100 [319/1090] loss: 0.42136824131011963
train--98/100 [329/1090] loss: 0.44621517062187194
train--98/100 [339/1090] loss: 0.4356906771659851
train--98/100 [349/1090] loss: 0.4404174566268921
train--98/100 [359/1090] loss: 0.42301427721977236
train--98/100 [369/1090] loss: 0.43260326981544495
train--98/100 [379/1090] loss: 0.4301183342933655
train--98/100 [389/1090] loss: 0.4232660382986069
train--98/100 [399/1090] loss: 0.4227871745824814
train--98/100 [409/1090] loss: 0.4412522703409195
train--98/100 [419/1090] loss: 0.4302956581115723
train--98/100 [429/1090] loss: 0.4569841086864471
train--98/100 [439/1090] loss: 0.44829405546188356
train--98/100 [449/1090] loss: 0.4546969264745712
train--98/100 [459/1090] loss: 0.4315295904874802
train--98/100 [469/1090] loss: 0.4448108285665512
train--98/100 [479/1090] loss: 0.4403071075677872
train--98/100 [489/1090] loss: 0.45272640585899354
train--98/100 [499/1090] loss: 0.41334343552589414
train--98/100 [509/1090] loss: 0.45175993740558623
train--98/100 [519/1090] loss: 0.420367494225502
train--98/100 [529/1090] loss: 0.43215163350105285
train--98/100 [539/1090] loss: 0.43995031118392947
train--98/100 [549/1090] loss: 0.42709938883781434
train--98/100 [559/1090] loss: 0.44327023029327395
train--98/100 [569/1090] loss: 0.4340116918087006
train--98/100 [579/1090] loss: 0.45444554686546323
train--98/100 [589/1090] loss: 0.43157579600811
train--98/100 [599/1090] loss: 0.4509206563234329
train--98/100 [609/1090] loss: 0.4397917568683624
train--98/100 [619/1090] loss: 0.41669732630252837
train--98/100 [629/1090] loss: 0.46377903819084165
train--98/100 [639/1090] loss: 0.431979763507843
train--98/100 [649/1090] loss: 0.42762912809848785
train--98/100 [659/1090] loss: 0.4399340122938156
train--98/100 [669/1090] loss: 0.4458085745573044
train--98/100 [679/1090] loss: 0.4294291138648987
train--98/100 [689/1090] loss: 0.43766696751117706
train--98/100 [699/1090] loss: 0.4441876530647278
train--98/100 [709/1090] loss: 0.429690083861351
train--98/100 [719/1090] loss: 0.4282377928495407
train--98/100 [729/1090] loss: 0.45042367875576017
train--98/100 [739/1090] loss: 0.4183967411518097
train--98/100 [749/1090] loss: 0.4207220286130905
train--98/100 [759/1090] loss: 0.44115298986434937
train--98/100 [769/1090] loss: 0.4312891036272049
train--98/100 [779/1090] loss: 0.4488974928855896
train--98/100 [789/1090] loss: 0.4484774857759476
train--98/100 [799/1090] loss: 0.43646429777145385
train--98/100 [809/1090] loss: 0.42270957827568056
train--98/100 [819/1090] loss: 0.4308903932571411
train--98/100 [829/1090] loss: 0.43394832611083983
train--98/100 [839/1090] loss: 0.4399862974882126
train--98/100 [849/1090] loss: 0.4277923256158829
train--98/100 [859/1090] loss: 0.44579764306545255
train--98/100 [869/1090] loss: 0.4388334631919861
train--98/100 [879/1090] loss: 0.4481017589569092
train--98/100 [889/1090] loss: 0.43905270397663115
train--98/100 [899/1090] loss: 0.4344023674726486
train--98/100 [909/1090] loss: 0.4372407257556915
train--98/100 [919/1090] loss: 0.414200684428215
train--98/100 [929/1090] loss: 0.4278288811445236
train--98/100 [939/1090] loss: 0.4380861222743988
train--98/100 [949/1090] loss: 0.43523050248622897
train--98/100 [959/1090] loss: 0.4219208151102066
train--98/100 [969/1090] loss: 0.45060094594955447
train--98/100 [979/1090] loss: 0.43280073404312136
train--98/100 [989/1090] loss: 0.4398880273103714
train--98/100 [999/1090] loss: 0.4324363648891449
train--98/100 [1009/1090] loss: 0.45173211991786955
train--98/100 [1019/1090] loss: 0.43321687281131743
train--98/100 [1029/1090] loss: 0.46348837614059446
train--98/100 [1039/1090] loss: 0.440550884604454
train--98/100 [1049/1090] loss: 0.42983444929122927
train--98/100 [1059/1090] loss: 0.431492754817009
train--98/100 [1069/1090] loss: 0.4348297655582428
train--98/100 [1079/1090] loss: 0.4405213475227356
train--98/100 [1089/1090] loss: 0.4326722502708435
predicting model...
val--98/100 [10/1090] acc: 0.801953125
val--98/100 [20/1090] acc: 0.8013671875
val--98/100 [30/1090] acc: 0.8001302083333334
val--98/100 [40/1090] acc: 0.80029296875
val--98/100 [50/1090] acc: 0.800078125
val--98/100 [60/1090] acc: 0.7988932291666667
val--98/100 [70/1090] acc: 0.7989397321428572
val--98/100 [80/1090] acc: 0.798046875
val--98/100 [90/1090] acc: 0.7984809027777777
val--98/100 [100/1090] acc: 0.799453125
val--98/100 [110/1090] acc: 0.7994673295454545
val--98/100 [120/1090] acc: 0.7990885416666667
val--98/100 [130/1090] acc: 0.7997295673076923
val--98/100 [140/1090] acc: 0.7996651785714286
val--98/100 [150/1090] acc: 0.7996875
val--98/100 [160/1090] acc: 0.79990234375
val--98/100 [170/1090] acc: 0.8000229779411765
val--98/100 [180/1090] acc: 0.7997178819444445
val--98/100 [190/1090] acc: 0.8002261513157894
val--98/100 [200/1090] acc: 0.8003515625
val--98/100 [210/1090] acc: 0.80078125
val--98/100 [220/1090] acc: 0.8000355113636364
val--98/100 [230/1090] acc: 0.8007302989130435
val--98/100 [240/1090] acc: 0.8004069010416667
val--98/100 [250/1090] acc: 0.80059375
val--98/100 [260/1090] acc: 0.8006610576923077
val--98/100 [270/1090] acc: 0.8009982638888888
val--98/100 [280/1090] acc: 0.8009068080357142
val--98/100 [290/1090] acc: 0.80078125
val--98/100 [300/1090] acc: 0.8009895833333334
val--98/100 [310/1090] acc: 0.8007434475806452
val--98/100 [320/1090] acc: 0.800927734375
val--98/100 [330/1090] acc: 0.8009943181818182
val--98/100 [340/1090] acc: 0.8010914522058824
val--98/100 [350/1090] acc: 0.8013392857142857
val--98/100 [360/1090] acc: 0.80126953125
val--98/100 [370/1090] acc: 0.8013619087837838
val--98/100 [380/1090] acc: 0.8014083059210526
val--98/100 [390/1090] acc: 0.8013221153846154
val--98/100 [400/1090] acc: 0.801318359375
val--98/100 [410/1090] acc: 0.8013814786585366
val--98/100 [420/1090] acc: 0.8012927827380952
val--98/100 [430/1090] acc: 0.801062863372093
val--98/100 [440/1090] acc: 0.801171875
val--98/100 [450/1090] acc: 0.8011805555555556
val--98/100 [460/1090] acc: 0.8009850543478261
val--98/100 [470/1090] acc: 0.8008228058510638
val--98/100 [480/1090] acc: 0.8007975260416667
val--98/100 [490/1090] acc: 0.8008689413265306
val--98/100 [500/1090] acc: 0.801
val--98/100 [510/1090] acc: 0.8008348651960784
val--98/100 [520/1090] acc: 0.8010516826923076
val--98/100 [530/1090] acc: 0.8009360259433962
val--98/100 [540/1090] acc: 0.8009837962962963
val--98/100 [550/1090] acc: 0.8008735795454546
val--98/100 [560/1090] acc: 0.8007045200892857
val--98/100 [570/1090] acc: 0.800452302631579
val--98/100 [580/1090] acc: 0.8004445043103449
val--98/100 [590/1090] acc: 0.800390625
val--98/100 [600/1090] acc: 0.8004166666666667
val--98/100 [610/1090] acc: 0.8003778176229508
val--98/100 [620/1090] acc: 0.8003150201612903
val--98/100 [630/1090] acc: 0.8005208333333333
val--98/100 [640/1090] acc: 0.80068359375
val--98/100 [650/1090] acc: 0.800733173076923
val--98/100 [660/1090] acc: 0.8006569602272727
val--98/100 [670/1090] acc: 0.800448927238806
val--98/100 [680/1090] acc: 0.8003389246323529
val--98/100 [690/1090] acc: 0.8004528985507247
val--98/100 [700/1090] acc: 0.8004631696428571
val--98/100 [710/1090] acc: 0.8003851232394367
val--98/100 [720/1090] acc: 0.8003526475694445
val--98/100 [730/1090] acc: 0.800288955479452
val--98/100 [740/1090] acc: 0.8002428209459459
val--98/100 [750/1090] acc: 0.8002604166666667
val--98/100 [760/1090] acc: 0.8004317434210526
val--98/100 [770/1090] acc: 0.8004312094155844
val--98/100 [780/1090] acc: 0.800350560897436
val--98/100 [790/1090] acc: 0.8003016218354431
val--98/100 [800/1090] acc: 0.8005224609375
val--98/100 [810/1090] acc: 0.8005401234567902
val--98/100 [820/1090] acc: 0.800633574695122
val--98/100 [830/1090] acc: 0.8006965361445784
val--98/100 [840/1090] acc: 0.8006696428571428
val--98/100 [850/1090] acc: 0.8006387867647059
val--98/100 [860/1090] acc: 0.8009084302325581
val--98/100 [870/1090] acc: 0.8008755387931035
val--98/100 [880/1090] acc: 0.8008922230113636
val--98/100 [890/1090] acc: 0.8009480337078652
val--98/100 [900/1090] acc: 0.8009288194444445
val--98/100 [910/1090] acc: 0.8009014423076923
val--98/100 [920/1090] acc: 0.8009256114130435
val--98/100 [930/1090] acc: 0.801029065860215
val--98/100 [940/1090] acc: 0.801030585106383
val--98/100 [950/1090] acc: 0.8009909539473684
val--98/100 [960/1090] acc: 0.8009358723958333
val--98/100 [970/1090] acc: 0.8008738724226804
val--98/100 [980/1090] acc: 0.800928730867347
val--98/100 [990/1090] acc: 0.8008641098484849
val--98/100 [1000/1090] acc: 0.80078515625
val--98/100 [1010/1090] acc: 0.8005917388613861
val--98/100 [1020/1090] acc: 0.8006089154411765
val--98/100 [1030/1090] acc: 0.8006409283980582
val--98/100 [1040/1090] acc: 0.8006234975961538
val--98/100 [1050/1090] acc: 0.8006287202380953
val--98/100 [1060/1090] acc: 0.8005822523584906
val--98/100 [1070/1090] acc: 0.8005585572429906
val--98/100 [1080/1090] acc: 0.8004991319444444
val--98/100 [1090/1090] acc: 0.800347620412844
epoch= 98, accuracy= 0.800348, rmse= 0.373427, auc= 0.861278
train--99/100 [9/1090] loss: 0.3916758030653
train--99/100 [19/1090] loss: 0.4282861351966858
train--99/100 [29/1090] loss: 0.4459674388170242
train--99/100 [39/1090] loss: 0.44204235076904297
train--99/100 [49/1090] loss: 0.4468177407979965
train--99/100 [59/1090] loss: 0.4301032364368439
train--99/100 [69/1090] loss: 0.45042760074138644
train--99/100 [79/1090] loss: 0.4403992146253586
train--99/100 [89/1090] loss: 0.42275649309158325
train--99/100 [99/1090] loss: 0.4318296700716019
train--99/100 [109/1090] loss: 0.4294492036104202
train--99/100 [119/1090] loss: 0.4193829745054245
train--99/100 [129/1090] loss: 0.4411525070667267
train--99/100 [139/1090] loss: 0.4254309594631195
train--99/100 [149/1090] loss: 0.44031272232532503
train--99/100 [159/1090] loss: 0.4352700591087341
train--99/100 [169/1090] loss: 0.4381398320198059
train--99/100 [179/1090] loss: 0.43337623178958895
train--99/100 [189/1090] loss: 0.4197568506002426
train--99/100 [199/1090] loss: 0.44675387144088746
train--99/100 [209/1090] loss: 0.4309834480285645
train--99/100 [219/1090] loss: 0.4137424498796463
train--99/100 [229/1090] loss: 0.4511629641056061
train--99/100 [239/1090] loss: 0.43560324907302855
train--99/100 [249/1090] loss: 0.447834312915802
train--99/100 [259/1090] loss: 0.4510106146335602
train--99/100 [269/1090] loss: 0.4530194282531738
train--99/100 [279/1090] loss: 0.4182777047157288
train--99/100 [289/1090] loss: 0.43480028212070465
train--99/100 [299/1090] loss: 0.42199460566043856
train--99/100 [309/1090] loss: 0.4282329916954041
train--99/100 [319/1090] loss: 0.43820021152496336
train--99/100 [329/1090] loss: 0.43160630762577057
train--99/100 [339/1090] loss: 0.4291890263557434
train--99/100 [349/1090] loss: 0.42507695555686953
train--99/100 [359/1090] loss: 0.43349628150463104
train--99/100 [369/1090] loss: 0.4202424347400665
train--99/100 [379/1090] loss: 0.4327566921710968
train--99/100 [389/1090] loss: 0.44739590883255004
train--99/100 [399/1090] loss: 0.4339689493179321
train--99/100 [409/1090] loss: 0.4348285228013992
train--99/100 [419/1090] loss: 0.4181641459465027
train--99/100 [429/1090] loss: 0.4388256728649139
train--99/100 [439/1090] loss: 0.42240418791770934
train--99/100 [449/1090] loss: 0.42618207931518554
train--99/100 [459/1090] loss: 0.44429445564746856
train--99/100 [469/1090] loss: 0.41855819821357726
train--99/100 [479/1090] loss: 0.44697011113166807
train--99/100 [489/1090] loss: 0.41866861283779144
train--99/100 [499/1090] loss: 0.43462634086608887
train--99/100 [509/1090] loss: 0.4389188468456268
train--99/100 [519/1090] loss: 0.43227867782115936
train--99/100 [529/1090] loss: 0.4358425736427307
train--99/100 [539/1090] loss: 0.4324590444564819
train--99/100 [549/1090] loss: 0.4302410423755646
train--99/100 [559/1090] loss: 0.4342477828264236
train--99/100 [569/1090] loss: 0.45259431600570676
train--99/100 [579/1090] loss: 0.44216553270816805
train--99/100 [589/1090] loss: 0.43084217607975006
train--99/100 [599/1090] loss: 0.4262374460697174
train--99/100 [609/1090] loss: 0.43001016080379484
train--99/100 [619/1090] loss: 0.4468200296163559
train--99/100 [629/1090] loss: 0.4377338618040085
train--99/100 [639/1090] loss: 0.4256576061248779
train--99/100 [649/1090] loss: 0.4341008275747299
train--99/100 [659/1090] loss: 0.44002614319324496
train--99/100 [669/1090] loss: 0.4307229071855545
train--99/100 [679/1090] loss: 0.43631504476070404
train--99/100 [689/1090] loss: 0.4357175588607788
train--99/100 [699/1090] loss: 0.45129273533821107
train--99/100 [709/1090] loss: 0.45136569142341615
train--99/100 [719/1090] loss: 0.4187269926071167
train--99/100 [729/1090] loss: 0.4347150087356567
train--99/100 [739/1090] loss: 0.42786059677600863
train--99/100 [749/1090] loss: 0.4335241585969925
train--99/100 [759/1090] loss: 0.4313421010971069
train--99/100 [769/1090] loss: 0.4283378630876541
train--99/100 [779/1090] loss: 0.4538180291652679
train--99/100 [789/1090] loss: 0.41601098477840426
train--99/100 [799/1090] loss: 0.4530415743589401
train--99/100 [809/1090] loss: 0.44538167119026184
train--99/100 [819/1090] loss: 0.43148067593574524
train--99/100 [829/1090] loss: 0.4373511284589767
train--99/100 [839/1090] loss: 0.4437894433736801
train--99/100 [849/1090] loss: 0.43502468764781954
train--99/100 [859/1090] loss: 0.42894133031368253
train--99/100 [869/1090] loss: 0.42235595285892485
train--99/100 [879/1090] loss: 0.4371023029088974
train--99/100 [889/1090] loss: 0.44198311269283297
train--99/100 [899/1090] loss: 0.43718981444835664
train--99/100 [909/1090] loss: 0.44040921330451965
train--99/100 [919/1090] loss: 0.43288500905036925
train--99/100 [929/1090] loss: 0.4625586211681366
train--99/100 [939/1090] loss: 0.44414235055446627
train--99/100 [949/1090] loss: 0.4395717352628708
train--99/100 [959/1090] loss: 0.4461661517620087
train--99/100 [969/1090] loss: 0.4331523537635803
train--99/100 [979/1090] loss: 0.43808271884918215
train--99/100 [989/1090] loss: 0.41734379529953003
train--99/100 [999/1090] loss: 0.46293939352035524
train--99/100 [1009/1090] loss: 0.41560454964637755
train--99/100 [1019/1090] loss: 0.43697973191738126
train--99/100 [1029/1090] loss: 0.4323157101869583
train--99/100 [1039/1090] loss: 0.43698122203350065
train--99/100 [1049/1090] loss: 0.4329560250043869
train--99/100 [1059/1090] loss: 0.439370858669281
train--99/100 [1069/1090] loss: 0.4354503810405731
train--99/100 [1079/1090] loss: 0.45661952197551725
train--99/100 [1089/1090] loss: 0.44022943675518034
predicting model...
val--99/100 [10/1090] acc: 0.801171875
val--99/100 [20/1090] acc: 0.8005859375
val--99/100 [30/1090] acc: 0.8009114583333333
val--99/100 [40/1090] acc: 0.8015625
val--99/100 [50/1090] acc: 0.800546875
val--99/100 [60/1090] acc: 0.7993489583333333
val--99/100 [70/1090] acc: 0.7991629464285714
val--99/100 [80/1090] acc: 0.7984375
val--99/100 [90/1090] acc: 0.7985243055555555
val--99/100 [100/1090] acc: 0.7996875
val--99/100 [110/1090] acc: 0.7999644886363636
val--99/100 [120/1090] acc: 0.7995768229166667
val--99/100 [130/1090] acc: 0.800390625
val--99/100 [140/1090] acc: 0.7999441964285714
val--99/100 [150/1090] acc: 0.799921875
val--99/100 [160/1090] acc: 0.8001708984375
val--99/100 [170/1090] acc: 0.8002297794117647
val--99/100 [180/1090] acc: 0.7999782986111111
val--99/100 [190/1090] acc: 0.8005345394736842
val--99/100 [200/1090] acc: 0.800703125
val--99/100 [210/1090] acc: 0.8011346726190476
val--99/100 [220/1090] acc: 0.8002840909090909
val--99/100 [230/1090] acc: 0.8010869565217391
val--99/100 [240/1090] acc: 0.8008626302083334
val--99/100 [250/1090] acc: 0.8009375
val--99/100 [260/1090] acc: 0.8008713942307693
val--99/100 [270/1090] acc: 0.8011574074074074
val--99/100 [280/1090] acc: 0.8010463169642857
val--99/100 [290/1090] acc: 0.8010102370689656
val--99/100 [300/1090] acc: 0.801171875
val--99/100 [310/1090] acc: 0.8009450604838709
val--99/100 [320/1090] acc: 0.80113525390625
val--99/100 [330/1090] acc: 0.8013139204545454
val--99/100 [340/1090] acc: 0.8013556985294118
val--99/100 [350/1090] acc: 0.8016183035714286
val--99/100 [360/1090] acc: 0.80146484375
val--99/100 [370/1090] acc: 0.8016258445945946
val--99/100 [380/1090] acc: 0.8016550164473685
val--99/100 [390/1090] acc: 0.801592548076923
val--99/100 [400/1090] acc: 0.801416015625
val--99/100 [410/1090] acc: 0.8015053353658537
val--99/100 [420/1090] acc: 0.801469494047619
val--99/100 [430/1090] acc: 0.8011537063953489
val--99/100 [440/1090] acc: 0.8012517755681818
val--99/100 [450/1090] acc: 0.8011545138888889
val--99/100 [460/1090] acc: 0.8010444972826087
val--99/100 [470/1090] acc: 0.8009225398936171
val--99/100 [480/1090] acc: 0.8009684244791667
val--99/100 [490/1090] acc: 0.8011160714285714
val--99/100 [500/1090] acc: 0.801265625
val--99/100 [510/1090] acc: 0.8010876225490197
val--99/100 [520/1090] acc: 0.8013070913461539
val--99/100 [530/1090] acc: 0.8011939858490567
val--99/100 [540/1090] acc: 0.8012659143518519
val--99/100 [550/1090] acc: 0.8010866477272728
val--99/100 [560/1090] acc: 0.8008649553571429
val--99/100 [570/1090] acc: 0.8005756578947368
val--99/100 [580/1090] acc: 0.8005051185344828
val--99/100 [590/1090] acc: 0.8004700741525423
val--99/100 [600/1090] acc: 0.8004361979166666
val--99/100 [610/1090] acc: 0.8004738729508196
val--99/100 [620/1090] acc: 0.8004032258064516
val--99/100 [630/1090] acc: 0.8006572420634921
val--99/100 [640/1090] acc: 0.800830078125
val--99/100 [650/1090] acc: 0.8008052884615384
val--99/100 [660/1090] acc: 0.8007339015151516
val--99/100 [670/1090] acc: 0.8005538712686567
val--99/100 [680/1090] acc: 0.8004653033088235
val--99/100 [690/1090] acc: 0.8006000905797102
val--99/100 [700/1090] acc: 0.8005524553571428
val--99/100 [710/1090] acc: 0.8004676496478873
val--99/100 [720/1090] acc: 0.8003634982638889
val--99/100 [730/1090] acc: 0.8003210616438357
val--99/100 [740/1090] acc: 0.8002744932432433
val--99/100 [750/1090] acc: 0.8003072916666667
val--99/100 [760/1090] acc: 0.8004420230263158
val--99/100 [770/1090] acc: 0.8004109172077922
val--99/100 [780/1090] acc: 0.8003305288461539
val--99/100 [790/1090] acc: 0.8003362341772152
val--99/100 [800/1090] acc: 0.8005517578125
val--99/100 [810/1090] acc: 0.8006124614197531
val--99/100 [820/1090] acc: 0.8006764481707317
val--99/100 [830/1090] acc: 0.8007200677710843
val--99/100 [840/1090] acc: 0.8006882440476191
val--99/100 [850/1090] acc: 0.8006893382352941
val--99/100 [860/1090] acc: 0.8010128997093023
val--99/100 [870/1090] acc: 0.8009294181034483
val--99/100 [880/1090] acc: 0.8009454900568181
val--99/100 [890/1090] acc: 0.801048981741573
val--99/100 [900/1090] acc: 0.8009982638888888
val--99/100 [910/1090] acc: 0.8009830013736263
val--99/100 [920/1090] acc: 0.8009977921195652
val--99/100 [930/1090] acc: 0.801071068548387
val--99/100 [940/1090] acc: 0.8010887632978724
val--99/100 [950/1090] acc: 0.8010361842105264
val--99/100 [960/1090] acc: 0.80098876953125
val--99/100 [970/1090] acc: 0.8009262242268042
val--99/100 [980/1090] acc: 0.8009566326530613
val--99/100 [990/1090] acc: 0.800848327020202
val--99/100 [1000/1090] acc: 0.80077734375
val--99/100 [1010/1090] acc: 0.8005646658415841
val--99/100 [1020/1090] acc: 0.8006280637254902
val--99/100 [1030/1090] acc: 0.8006560983009708
val--99/100 [1040/1090] acc: 0.8006873497596154
val--99/100 [1050/1090] acc: 0.8007217261904762
val--99/100 [1060/1090] acc: 0.8006227889150943
val--99/100 [1070/1090] acc: 0.8006096670560747
val--99/100 [1080/1090] acc: 0.8005570023148149
val--99/100 [1090/1090] acc: 0.8004049598623854
epoch= 99, accuracy= 0.800405, rmse= 0.373402, auc= 0.861639
train--100/100 [9/1090] loss: 0.37425602078437803
train--100/100 [19/1090] loss: 0.449879652261734
train--100/100 [29/1090] loss: 0.43418094217777253
train--100/100 [39/1090] loss: 0.42709062099456785
train--100/100 [49/1090] loss: 0.4314291000366211
train--100/100 [59/1090] loss: 0.4663142114877701
train--100/100 [69/1090] loss: 0.42316230237483976
train--100/100 [79/1090] loss: 0.4337619811296463
train--100/100 [89/1090] loss: 0.42040441036224363
train--100/100 [99/1090] loss: 0.42902547121047974
train--100/100 [109/1090] loss: 0.44157862961292266
train--100/100 [119/1090] loss: 0.42929708063602445
train--100/100 [129/1090] loss: 0.43163302838802337
train--100/100 [139/1090] loss: 0.4161570847034454
train--100/100 [149/1090] loss: 0.4206237614154816
train--100/100 [159/1090] loss: 0.429001647233963
train--100/100 [169/1090] loss: 0.4475665032863617
train--100/100 [179/1090] loss: 0.41502438485622406
train--100/100 [189/1090] loss: 0.42398159503936766
train--100/100 [199/1090] loss: 0.4331762492656708
train--100/100 [209/1090] loss: 0.447772878408432
train--100/100 [219/1090] loss: 0.41580151319503783
train--100/100 [229/1090] loss: 0.42605273723602294
train--100/100 [239/1090] loss: 0.43471059799194334
train--100/100 [249/1090] loss: 0.4405532330274582
train--100/100 [259/1090] loss: 0.4343500226736069
train--100/100 [269/1090] loss: 0.4550987720489502
train--100/100 [279/1090] loss: 0.41186357140541074
train--100/100 [289/1090] loss: 0.4227711260318756
train--100/100 [299/1090] loss: 0.4572094947099686
train--100/100 [309/1090] loss: 0.43854103088378904
train--100/100 [319/1090] loss: 0.4475388079881668
train--100/100 [329/1090] loss: 0.43252645134925843
train--100/100 [339/1090] loss: 0.43661339282989503
train--100/100 [349/1090] loss: 0.4417498707771301
train--100/100 [359/1090] loss: 0.42877903282642366
train--100/100 [369/1090] loss: 0.4455700844526291
train--100/100 [379/1090] loss: 0.4315564215183258
train--100/100 [389/1090] loss: 0.4433332771062851
train--100/100 [399/1090] loss: 0.4190422832965851
train--100/100 [409/1090] loss: 0.423287832736969
train--100/100 [419/1090] loss: 0.42758760750293734
train--100/100 [429/1090] loss: 0.4210968315601349
train--100/100 [439/1090] loss: 0.4185202568769455
train--100/100 [449/1090] loss: 0.4332433879375458
train--100/100 [459/1090] loss: 0.43409075140953063
train--100/100 [469/1090] loss: 0.4210832715034485
train--100/100 [479/1090] loss: 0.4318647474050522
train--100/100 [489/1090] loss: 0.41108174324035646
train--100/100 [499/1090] loss: 0.44245185852050783
train--100/100 [509/1090] loss: 0.4417837649583817
train--100/100 [519/1090] loss: 0.44479170739650725
train--100/100 [529/1090] loss: 0.43771162033081057
train--100/100 [539/1090] loss: 0.42948669493198394
train--100/100 [549/1090] loss: 0.4293054074048996
train--100/100 [559/1090] loss: 0.44288029968738557
train--100/100 [569/1090] loss: 0.44285888671875
train--100/100 [579/1090] loss: 0.44221894145011903
train--100/100 [589/1090] loss: 0.44887649416923525
train--100/100 [599/1090] loss: 0.45647297203540804
train--100/100 [609/1090] loss: 0.44159395694732667
train--100/100 [619/1090] loss: 0.4462949275970459
train--100/100 [629/1090] loss: 0.43902270793914794
train--100/100 [639/1090] loss: 0.4315038561820984
train--100/100 [649/1090] loss: 0.44234020411968233
train--100/100 [659/1090] loss: 0.4361529409885406
train--100/100 [669/1090] loss: 0.4303785115480423
train--100/100 [679/1090] loss: 0.4328914999961853
train--100/100 [689/1090] loss: 0.4391932874917984
train--100/100 [699/1090] loss: 0.4385208964347839
train--100/100 [709/1090] loss: 0.4440651834011078
train--100/100 [719/1090] loss: 0.422219118475914
train--100/100 [729/1090] loss: 0.42972663342952727
train--100/100 [739/1090] loss: 0.4393362462520599
train--100/100 [749/1090] loss: 0.43521375954151154
train--100/100 [759/1090] loss: 0.41494460105895997
train--100/100 [769/1090] loss: 0.445202162861824
train--100/100 [779/1090] loss: 0.4146087408065796
train--100/100 [789/1090] loss: 0.44021942317485807
train--100/100 [799/1090] loss: 0.41928568482398987
train--100/100 [809/1090] loss: 0.44021510481834414
train--100/100 [819/1090] loss: 0.4358215630054474
train--100/100 [829/1090] loss: 0.42412195801734925
train--100/100 [839/1090] loss: 0.4370009571313858
train--100/100 [849/1090] loss: 0.43037948906421664
train--100/100 [859/1090] loss: 0.4464520841836929
train--100/100 [869/1090] loss: 0.44669395983219146
train--100/100 [879/1090] loss: 0.446200293302536
train--100/100 [889/1090] loss: 0.43598116636276246
train--100/100 [899/1090] loss: 0.4374745339155197
train--100/100 [909/1090] loss: 0.444364994764328
train--100/100 [919/1090] loss: 0.45338712334632875
train--100/100 [929/1090] loss: 0.4175151824951172
train--100/100 [939/1090] loss: 0.4340591013431549
train--100/100 [949/1090] loss: 0.42793205976486204
train--100/100 [959/1090] loss: 0.4422593355178833
train--100/100 [969/1090] loss: 0.43094344437122345
train--100/100 [979/1090] loss: 0.4500211000442505
train--100/100 [989/1090] loss: 0.44112018346786497
train--100/100 [999/1090] loss: 0.44519713819026946
train--100/100 [1009/1090] loss: 0.4459137976169586
train--100/100 [1019/1090] loss: 0.43961024284362793
train--100/100 [1029/1090] loss: 0.4519010692834854
train--100/100 [1039/1090] loss: 0.4233339011669159
train--100/100 [1049/1090] loss: 0.4345704108476639
train--100/100 [1059/1090] loss: 0.4272328406572342
train--100/100 [1069/1090] loss: 0.45236635208129883
train--100/100 [1079/1090] loss: 0.4408881187438965
train--100/100 [1089/1090] loss: 0.4332109272480011
predicting model...
val--100/100 [10/1090] acc: 0.801171875
val--100/100 [20/1090] acc: 0.799609375
val--100/100 [30/1090] acc: 0.799609375
val--100/100 [40/1090] acc: 0.80029296875
val--100/100 [50/1090] acc: 0.799921875
val--100/100 [60/1090] acc: 0.79921875
val--100/100 [70/1090] acc: 0.7990513392857143
val--100/100 [80/1090] acc: 0.798583984375
val--100/100 [90/1090] acc: 0.7990017361111111
val--100/100 [100/1090] acc: 0.8001171875
val--100/100 [110/1090] acc: 0.8001775568181818
val--100/100 [120/1090] acc: 0.7997721354166667
val--100/100 [130/1090] acc: 0.800390625
val--100/100 [140/1090] acc: 0.8001395089285714
val--100/100 [150/1090] acc: 0.8002083333333333
val--100/100 [160/1090] acc: 0.800390625
val--100/100 [170/1090] acc: 0.8003216911764706
val--100/100 [180/1090] acc: 0.8000217013888888
val--100/100 [190/1090] acc: 0.8005962171052632
val--100/100 [200/1090] acc: 0.80076171875
val--100/100 [210/1090] acc: 0.8012648809523809
val--100/100 [220/1090] acc: 0.8004616477272727
val--100/100 [230/1090] acc: 0.8010869565217391
val--100/100 [240/1090] acc: 0.8008626302083334
val--100/100 [250/1090] acc: 0.8009375
val--100/100 [260/1090] acc: 0.8008563701923077
val--100/100 [270/1090] acc: 0.8011863425925926
val--100/100 [280/1090] acc: 0.80107421875
val--100/100 [290/1090] acc: 0.8009967672413794
val--100/100 [300/1090] acc: 0.8011588541666667
val--100/100 [310/1090] acc: 0.8009576612903225
val--100/100 [320/1090] acc: 0.8010986328125
val--100/100 [330/1090] acc: 0.8012310606060606
val--100/100 [340/1090] acc: 0.8012867647058823
val--100/100 [350/1090] acc: 0.8015513392857143
val--100/100 [360/1090] acc: 0.8015190972222223
val--100/100 [370/1090] acc: 0.8016575168918919
val--100/100 [380/1090] acc: 0.8016755756578947
val--100/100 [390/1090] acc: 0.8016626602564103
val--100/100 [400/1090] acc: 0.80162109375
val--100/100 [410/1090] acc: 0.801686356707317
val--100/100 [420/1090] acc: 0.8016462053571428
val--100/100 [430/1090] acc: 0.8014171511627907
val--100/100 [440/1090] acc: 0.8015447443181818
val--100/100 [450/1090] acc: 0.8014670138888889
val--100/100 [460/1090] acc: 0.8013162364130435
val--100/100 [470/1090] acc: 0.8012217420212766
val--100/100 [480/1090] acc: 0.8012369791666667
val--100/100 [490/1090] acc: 0.8013552295918367
val--100/100 [500/1090] acc: 0.801515625
val--100/100 [510/1090] acc: 0.8013403799019608
val--100/100 [520/1090] acc: 0.801592548076923
val--100/100 [530/1090] acc: 0.8014814268867925
val--100/100 [540/1090] acc: 0.8015552662037037
val--100/100 [550/1090] acc: 0.8013849431818182
val--100/100 [560/1090] acc: 0.8011928013392857
val--100/100 [570/1090] acc: 0.800890899122807
val--100/100 [580/1090] acc: 0.800848599137931
val--100/100 [590/1090] acc: 0.8008077330508474
val--100/100 [600/1090] acc: 0.8007942708333333
val--100/100 [610/1090] acc: 0.80078125
val--100/100 [620/1090] acc: 0.8006867439516129
val--100/100 [630/1090] acc: 0.8009424603174603
val--100/100 [640/1090] acc: 0.801080322265625
val--100/100 [650/1090] acc: 0.8010276442307692
val--100/100 [660/1090] acc: 0.8009647253787879
val--100/100 [670/1090] acc: 0.8007637593283582
val--100/100 [680/1090] acc: 0.800631893382353
val--100/100 [690/1090] acc: 0.8007586050724638
val--100/100 [700/1090] acc: 0.8007533482142857
val--100/100 [710/1090] acc: 0.8006877200704225
val--100/100 [720/1090] acc: 0.8005967881944445
val--100/100 [730/1090] acc: 0.8005297517123288
val--100/100 [740/1090] acc: 0.8005014780405405
val--100/100 [750/1090] acc: 0.800546875
val--100/100 [760/1090] acc: 0.8006990131578947
val--100/100 [770/1090] acc: 0.8007000811688312
val--100/100 [780/1090] acc: 0.8006560496794872
val--100/100 [790/1090] acc: 0.8006675237341773
val--100/100 [800/1090] acc: 0.8008984375
val--100/100 [810/1090] acc: 0.8009452160493827
val--100/100 [820/1090] acc: 0.801000381097561
val--100/100 [830/1090] acc: 0.8010448042168675
val--100/100 [840/1090] acc: 0.8009951636904762
val--100/100 [850/1090] acc: 0.8010064338235294
val--100/100 [860/1090] acc: 0.8012990552325582
val--100/100 [870/1090] acc: 0.8012167744252874
val--100/100 [880/1090] acc: 0.801220703125
val--100/100 [890/1090] acc: 0.8013211025280899
val--100/100 [900/1090] acc: 0.8012717013888889
val--100/100 [910/1090] acc: 0.8012534340659341
val--100/100 [920/1090] acc: 0.8012907608695652
val--100/100 [930/1090] acc: 0.8013692876344086
val--100/100 [940/1090] acc: 0.8013588763297872
val--100/100 [950/1090] acc: 0.8013034539473685
val--100/100 [960/1090] acc: 0.80120849609375
val--100/100 [970/1090] acc: 0.8011678479381443
val--100/100 [980/1090] acc: 0.8012037627551021
val--100/100 [990/1090] acc: 0.80111663510101
val--100/100 [1000/1090] acc: 0.80105078125
val--100/100 [1010/1090] acc: 0.8008547339108911
val--100/100 [1020/1090] acc: 0.8009152879901961
val--100/100 [1030/1090] acc: 0.8009481189320389
val--100/100 [1040/1090] acc: 0.8009803185096154
val--100/100 [1050/1090] acc: 0.8010230654761905
val--100/100 [1060/1090] acc: 0.8009397110849057
val--100/100 [1070/1090] acc: 0.800894421728972
val--100/100 [1080/1090] acc: 0.8008282696759259
val--100/100 [1090/1090] acc: 0.8006880733944954
epoch= 100, accuracy= 0.800688, rmse= 0.373072, auc= 0.861899
